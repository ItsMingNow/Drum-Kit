/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@babel/runtime/helpers/arrayLikeToArray.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/arrayLikeToArray.js ***!
  \*****************************************************************/
/***/ ((module) => {

eval("function _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nmodule.exports = _arrayLikeToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/arrayLikeToArray.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/arrayWithHoles.js":
/*!***************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/arrayWithHoles.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("function _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\n\nmodule.exports = _arrayWithHoles, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/arrayWithHoles.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/classCallCheck.js":
/*!***************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/classCallCheck.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("function _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nmodule.exports = _classCallCheck, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/classCallCheck.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/createClass.js":
/*!************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/createClass.js ***!
  \************************************************************/
/***/ ((module) => {

eval("function _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  Object.defineProperty(Constructor, \"prototype\", {\n    writable: false\n  });\n  return Constructor;\n}\n\nmodule.exports = _createClass, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/createClass.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js ***!
  \*********************************************************************/
/***/ ((module) => {

eval("function _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n\n  var _s, _e;\n\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}\n\nmodule.exports = _iterableToArrayLimit, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/nonIterableRest.js":
/*!****************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/nonIterableRest.js ***!
  \****************************************************************/
/***/ ((module) => {

eval("function _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nmodule.exports = _nonIterableRest, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/nonIterableRest.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/slicedToArray.js":
/*!**************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/slicedToArray.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var arrayWithHoles = __webpack_require__(/*! ./arrayWithHoles.js */ \"./node_modules/@babel/runtime/helpers/arrayWithHoles.js\");\n\nvar iterableToArrayLimit = __webpack_require__(/*! ./iterableToArrayLimit.js */ \"./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js\");\n\nvar unsupportedIterableToArray = __webpack_require__(/*! ./unsupportedIterableToArray.js */ \"./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js\");\n\nvar nonIterableRest = __webpack_require__(/*! ./nonIterableRest.js */ \"./node_modules/@babel/runtime/helpers/nonIterableRest.js\");\n\nfunction _slicedToArray(arr, i) {\n  return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();\n}\n\nmodule.exports = _slicedToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/slicedToArray.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var arrayLikeToArray = __webpack_require__(/*! ./arrayLikeToArray.js */ \"./node_modules/@babel/runtime/helpers/arrayLikeToArray.js\");\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);\n}\n\nmodule.exports = _unsupportedIterableToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://react-demo/./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js?");

/***/ }),

/***/ "./node_modules/automation-events/build/es5/bundle.js":
/*!************************************************************!*\
  !*** ./node_modules/automation-events/build/es5/bundle.js ***!
  \************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

eval("(function (global, factory) {\n     true ? factory(exports, __webpack_require__(/*! @babel/runtime/helpers/slicedToArray */ \"./node_modules/@babel/runtime/helpers/slicedToArray.js\"), __webpack_require__(/*! @babel/runtime/helpers/classCallCheck */ \"./node_modules/@babel/runtime/helpers/classCallCheck.js\"), __webpack_require__(/*! @babel/runtime/helpers/createClass */ \"./node_modules/@babel/runtime/helpers/createClass.js\")) :\n    0;\n})(this, (function (exports, _slicedToArray, _classCallCheck, _createClass) { 'use strict';\n\n    function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\n    var _slicedToArray__default = /*#__PURE__*/_interopDefaultLegacy(_slicedToArray);\n    var _classCallCheck__default = /*#__PURE__*/_interopDefaultLegacy(_classCallCheck);\n    var _createClass__default = /*#__PURE__*/_interopDefaultLegacy(_createClass);\n\n    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {\n      return {\n        startTime: startTime,\n        type: 'setValue',\n        value: value\n      };\n    };\n\n    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {\n      return {\n        duration: duration,\n        startTime: startTime,\n        type: 'setValueCurve',\n        values: values\n      };\n    };\n\n    var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {\n      var startTime = _ref.startTime,\n          target = _ref.target,\n          timeConstant = _ref.timeConstant;\n      return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);\n    };\n\n    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'exponentialRampToValue';\n    };\n\n    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'linearRampToValue';\n    };\n\n    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {\n      return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);\n    };\n\n    var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValue';\n    };\n\n    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValueCurve';\n    };\n\n    var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {\n      var automationEvent = automationEvents[index];\n      return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);\n    };\n\n    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {\n      return currentAutomationEvent === undefined ? [nextAutomationEvent.insertTime, defaultValue] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.endTime, currentAutomationEvent.value] : isSetValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime, currentAutomationEvent.value] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime + currentAutomationEvent.duration, currentAutomationEvent.values[currentAutomationEvent.values.length - 1]] : [currentAutomationEvent.startTime, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)];\n    };\n\n    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelAndHold';\n    };\n\n    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelScheduledValues';\n    };\n\n    var getEventTime = function getEventTime(automationEvent) {\n      if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n        return automationEvent.cancelTime;\n      }\n\n      if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) {\n        return automationEvent.endTime;\n      }\n\n      return automationEvent.startTime;\n    };\n\n    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n\n      if (valueAtStartTime === value) {\n        return value;\n      }\n\n      if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) {\n        return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));\n      }\n\n      return 0;\n    };\n\n    var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n      return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);\n    };\n\n    var interpolateValue = function interpolateValue(values, theoreticIndex) {\n      var lowerIndex = Math.floor(theoreticIndex);\n      var upperIndex = Math.ceil(theoreticIndex);\n\n      if (lowerIndex === upperIndex) {\n        return values[lowerIndex];\n      }\n\n      return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];\n    };\n\n    var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {\n      var duration = _ref.duration,\n          startTime = _ref.startTime,\n          values = _ref.values;\n      var theoreticIndex = (time - startTime) / duration * (values.length - 1);\n      return interpolateValue(values, theoreticIndex);\n    };\n\n    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setTarget';\n    };\n\n    var AutomationEventList = /*#__PURE__*/function (_Symbol$iterator) {\n      function AutomationEventList(defaultValue) {\n        _classCallCheck__default[\"default\"](this, AutomationEventList);\n\n        this._automationEvents = [];\n        this._currenTime = 0;\n        this._defaultValue = defaultValue;\n      }\n\n      _createClass__default[\"default\"](AutomationEventList, [{\n        key: _Symbol$iterator,\n        value: function value() {\n          return this._automationEvents[Symbol.iterator]();\n        }\n      }, {\n        key: \"add\",\n        value: function add(automationEvent) {\n          var eventTime = getEventTime(automationEvent);\n\n          if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n            var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) {\n                return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;\n              }\n\n              return getEventTime(currentAutomationEvent) >= eventTime;\n            });\n\n            var removedAutomationEvent = this._automationEvents[index];\n\n            if (index !== -1) {\n              this._automationEvents = this._automationEvents.slice(0, index);\n            }\n\n            if (isCancelAndHoldAutomationEvent(automationEvent)) {\n              var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];\n\n              if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {\n                if (isSetTargetAutomationEvent(lastAutomationEvent)) {\n                  throw new Error('The internal list is malformed.');\n                }\n\n                var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);\n                var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;\n                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);\n                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);\n\n                this._automationEvents.push(truncatedAutomationEvent);\n              }\n\n              if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) {\n                this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));\n              }\n\n              if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) {\n                this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([6, 7]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);\n              }\n            }\n          } else {\n            var _index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              return getEventTime(currentAutomationEvent) > eventTime;\n            });\n\n            var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];\n\n            if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) {\n              return false;\n            }\n\n            var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;\n\n            if (_index === -1) {\n              this._automationEvents.push(persistentAutomationEvent);\n            } else {\n              if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) {\n                return false;\n              }\n\n              this._automationEvents.splice(_index, 0, persistentAutomationEvent);\n            }\n          }\n\n          return true;\n        }\n      }, {\n        key: \"flush\",\n        value: function flush(time) {\n          var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n            return getEventTime(currentAutomationEvent) > time;\n          });\n\n          if (index > 1) {\n            var remainingAutomationEvents = this._automationEvents.slice(index - 1);\n\n            var firstRemainingAutomationEvent = remainingAutomationEvents[0];\n\n            if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) {\n              remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));\n            }\n\n            this._automationEvents = remainingAutomationEvents;\n          }\n        }\n      }, {\n        key: \"getValue\",\n        value: function getValue(time) {\n          if (this._automationEvents.length === 0) {\n            return this._defaultValue;\n          }\n\n          var indexOfNextEvent = this._automationEvents.findIndex(function (automationEvent) {\n            return getEventTime(automationEvent) > time;\n          });\n\n          var nextAutomationEvent = this._automationEvents[indexOfNextEvent];\n          var indexOfCurrentEvent = (indexOfNextEvent === -1 ? this._automationEvents.length : indexOfNextEvent) - 1;\n          var currentAutomationEvent = this._automationEvents[indexOfCurrentEvent];\n\n          if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) {\n            return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, indexOfCurrentEvent - 1, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {\n            if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) {\n              return getValueCurveValueAtTime(time, currentAutomationEvent);\n            }\n\n            return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];\n          }\n\n          if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf2 = _slicedToArray__default[\"default\"](_getEndTimeAndValueOf, 2),\n                startTime = _getEndTimeAndValueOf2[0],\n                value = _getEndTimeAndValueOf2[1];\n\n            return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);\n          }\n\n          if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf4 = _slicedToArray__default[\"default\"](_getEndTimeAndValueOf3, 2),\n                _startTime = _getEndTimeAndValueOf4[0],\n                _value = _getEndTimeAndValueOf4[1];\n\n            return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);\n          }\n\n          return this._defaultValue;\n        }\n      }]);\n\n      return AutomationEventList;\n    }(Symbol.iterator);\n\n    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelAndHold'\n      };\n    };\n\n    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelScheduledValues'\n      };\n    };\n\n    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {\n      return {\n        startTime: startTime,\n        target: target,\n        timeConstant: timeConstant,\n        type: 'setTarget'\n      };\n    };\n\n    exports.AutomationEventList = AutomationEventList;\n    exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;\n    exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;\n    exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;\n    exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;\n    exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;\n    exports.createSetValueAutomationEvent = createSetValueAutomationEvent;\n    exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n}));\n\n\n//# sourceURL=webpack://react-demo/./node_modules/automation-events/build/es5/bundle.js?");

/***/ }),

/***/ "./src/App.js":
/*!********************!*\
  !*** ./src/App.js ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var App_css__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! App.css */ \"./src/App.css\");\n/* harmony import */ var _container_DrumMachine__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./container/DrumMachine */ \"./src/container/DrumMachine.jsx\");\n // Import CSS\n\n // Import Components\n\n\n\nvar App = function App() {\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    className: \"HolderOfAll\"\n  }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_container_DrumMachine__WEBPACK_IMPORTED_MODULE_2__[\"default\"], null));\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (App);\n\n//# sourceURL=webpack://react-demo/./src/App.js?");

/***/ }),

/***/ "./src/assets/DrumSamples.js":
/*!***********************************!*\
  !*** ./src/assets/DrumSamples.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"samples\": () => (/* binding */ samples)\n/* harmony export */ });\n/* harmony import */ var _drums_testKick_mp3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./drums/testKick.mp3 */ \"./src/assets/drums/testKick.mp3\");\n/* harmony import */ var _drums_snare_mp3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./drums/snare.mp3 */ \"./src/assets/drums/snare.mp3\");\n/* harmony import */ var _drums_clap_mp3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./drums/clap.mp3 */ \"./src/assets/drums/clap.mp3\");\n/* harmony import */ var _drums_hatopen_mp3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./drums/hatopen.mp3 */ \"./src/assets/drums/hatopen.mp3\");\n/* harmony import */ var _drums_hatclose_mp3__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./drums/hatclose.mp3 */ \"./src/assets/drums/hatclose.mp3\");\n/* harmony import */ var _drums_block_mp3__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./drums/block.mp3 */ \"./src/assets/drums/block.mp3\");\n/* harmony import */ var _drums_wood_mp3__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./drums/wood.mp3 */ \"./src/assets/drums/wood.mp3\");\n\n\n\n\n\n\n\nvar samples = {\n  kick: _drums_testKick_mp3__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n  snare: _drums_snare_mp3__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  clap: _drums_clap_mp3__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n  hatOpen: _drums_hatopen_mp3__WEBPACK_IMPORTED_MODULE_3__[\"default\"],\n  hatClose: _drums_hatclose_mp3__WEBPACK_IMPORTED_MODULE_4__[\"default\"],\n  block: _drums_block_mp3__WEBPACK_IMPORTED_MODULE_5__[\"default\"],\n  wood: _drums_wood_mp3__WEBPACK_IMPORTED_MODULE_6__[\"default\"]\n};\n\n//# sourceURL=webpack://react-demo/./src/assets/DrumSamples.js?");

/***/ }),

/***/ "./src/componets/CheckBox.jsx":
/*!************************************!*\
  !*** ./src/componets/CheckBox.jsx ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\nfunction _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }\n\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"] != null) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; }\n\nfunction _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }\n\n\n\nvar CheckBox = function CheckBox(props) {\n  var _useState = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)(false),\n      _useState2 = _slicedToArray(_useState, 2),\n      isChecked = _useState2[0],\n      setCheck = _useState2[1];\n\n  var toggleCheck = function toggleCheck(event) {\n    // if (event)\n    setCheck(!isChecked);\n  };\n\n  var mouseDownAndHover = function mouseDownAndHover(event) {\n    if (event.altKey === true || event.ctrlKey === true) {\n      props.updateGrid(props.id);\n      toggleCheck();\n    }\n  };\n\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"input\", {\n    type: 'checkbox',\n    onMouseEnter: mouseDownAndHover,\n    checked: isChecked,\n    onChange: function onChange() {\n      return props.updateGrid(props.id), toggleCheck();\n    },\n    className: 'box'\n  });\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CheckBox);\n\n//# sourceURL=webpack://react-demo/./src/componets/CheckBox.jsx?");

/***/ }),

/***/ "./src/componets/Drum-Instrument.jsx":
/*!*******************************************!*\
  !*** ./src/componets/Drum-Instrument.jsx ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../assets/DrumSamples */ \"./src/assets/DrumSamples.js\");\n/* harmony import */ var _CheckBox__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./CheckBox */ \"./src/componets/CheckBox.jsx\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n\n // import\n\n\n\nvar DrumInstrument = /*#__PURE__*/function (_React$Component) {\n  _inherits(DrumInstrument, _React$Component);\n\n  var _super = _createSuper(DrumInstrument);\n\n  function DrumInstrument(props) {\n    var _this;\n\n    _classCallCheck(this, DrumInstrument);\n\n    _this = _super.call(this, props);\n\n    _defineProperty(_assertThisInitialized(_this), \"updateGridState\", function (checkBoxIndex) {\n      console.log('DrumInstrument - update');\n      console.log('Drum Instrument passed in: ', checkBoxIndex);\n      _this.state.gridRep[checkBoxIndex] = !_this.state.gridRep[checkBoxIndex];\n\n      _this.setState({\n        gridRep: _this.state.gridRep\n      });\n\n      var passedUp = {};\n      passedUp[_this.state.value] = _this.state.gridRep;\n\n      _this.props.updateTheMainGrid(passedUp);\n    });\n\n    _defineProperty(_assertThisInitialized(_this), \"updateGridName\", function (newID) {\n      var passedUp = {};\n      passedUp[newID] = _this.state.gridRep;\n\n      _this.props.updateTheMainGrid(passedUp);\n    });\n\n    _defineProperty(_assertThisInitialized(_this), \"handleSampleChange\", function (event) {\n      // console.log({value: event.target.value});\n      _this.setState({\n        value: event.target.value\n      });\n\n      _this.updateGridName(event.target.value);\n    });\n\n    _this.state = {\n      checkBoxes: [],\n      gridRep: [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false],\n      value: 'none'\n    };\n    _this.updateGridState = _this.updateGridState.bind(); // console.log('DrumInstrument - props: ', this.props);\n    // MAKES THE CHECKBOXES\n\n    for (var i = 0; i < 16; i++) {\n      _this.state.checkBoxes.push( /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_CheckBox__WEBPACK_IMPORTED_MODULE_2__[\"default\"], {\n        key: i,\n        id: i,\n        updateGrid: _this.updateGridState\n      }));\n    } // init state for Grid\n\n\n    var initState = {};\n    initState[_this.props.id] = _this.state.gridRep;\n\n    _this.props.updateTheMainGrid(initState); //!!! TESTING AREA!!!\n    // console.log('TESTING SAMPLES', props.samples);\n    // console.log('TESTING OBJ KEY SAMPLES: ', Object.keys(samples));\n\n\n    return _this;\n  } // CHECKS IF DRUM INSTRUMENT UPDATED\n\n\n  _createClass(DrumInstrument, [{\n    key: \"componentDidUpdate\",\n    value: function componentDidUpdate() {\n      console.log('DRUM INSTR ID', this.props.id);\n      console.log('NEW DRUMOPTION STATE', this.state.value);\n    }\n  }, {\n    key: \"render\",\n    value: function render() {\n      var options = [];\n      var sampleNames = Object.keys(_assets_DrumSamples__WEBPACK_IMPORTED_MODULE_1__.samples);\n      var key = 0;\n      options.push({\n        label: 'none',\n        value: 'none',\n        key: key++\n      });\n      sampleNames.forEach(function (ele) {\n        var newObj = {\n          label: \"\".concat(ele),\n          value: \"\".concat(ele),\n          key: key++\n        };\n        options.push(newObj);\n      });\n      return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n        className: \"DrumInstrument\"\n      }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n        id: \"select\"\n      }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"select\", {\n        className: \"selectBox\",\n        onChange: this.handleSampleChange\n      }, options.map(function (option) {\n        return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"option\", {\n          value: option.value,\n          key: option.key\n        }, option.label);\n      }))), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n        className: \"allCheckBoxes\"\n      }, this.state.checkBoxes));\n    }\n  }]);\n\n  return DrumInstrument;\n}(react__WEBPACK_IMPORTED_MODULE_0__.Component);\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DrumInstrument);\n\n//# sourceURL=webpack://react-demo/./src/componets/Drum-Instrument.jsx?");

/***/ }),

/***/ "./src/componets/Transport.jsx":
/*!*************************************!*\
  !*** ./src/componets/Transport.jsx ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\nfunction _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }\n\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"] != null) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; }\n\nfunction _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }\n\n\n\nvar Transport = function Transport(props) {\n  var _useState = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)(100),\n      _useState2 = _slicedToArray(_useState, 2),\n      bpmRange = _useState2[0],\n      SetBpmRange = _useState2[1];\n\n  var _useState3 = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)(0),\n      _useState4 = _slicedToArray(_useState3, 2),\n      volumeRange = _useState4[0],\n      SetVolumeRange = _useState4[1];\n\n  (0,react__WEBPACK_IMPORTED_MODULE_0__.useEffect)(function () {\n    console.log('!!!!Transport use effect!');\n    updateThatBPM();\n  }, [bpmRange]);\n  (0,react__WEBPACK_IMPORTED_MODULE_0__.useEffect)(function () {\n    updateThatVolume();\n  }, [volumeRange]);\n\n  var updateThatBPM = function updateThatBPM() {\n    props.setBPM(returnBPM()); // console.log(props.setBPM());\n  };\n\n  var changeBpm = function changeBpm(e) {\n    // console.log(e.target.value);\n    SetBpmRange(e.target.value);\n  };\n\n  var returnBPM = function returnBPM() {\n    return bpmRange;\n  };\n\n  var changeVolume = function changeVolume(e) {\n    // console.log(e.target.value);\n    SetVolumeRange(e.target.value); // props.updateVolume(e.target.value);\n  };\n\n  var updateThatVolume = function updateThatVolume() {\n    props.updateVolume(returnVolume());\n  };\n\n  var returnVolume = function returnVolume() {\n    return volumeRange;\n  };\n\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    className: \"Transport\"\n  }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"label\", null, \"BPM\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"input\", {\n    type: \"range\",\n    min: 0,\n    max: 200,\n    value: bpmRange,\n    onChange: changeBpm,\n    className: \"slider\",\n    id: \"BPM\"\n  }), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"button\", {\n    onClick: props.play\n  }, \"Play/Pause\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"button\", {\n    onClick: props.stop\n  }, \"Stop\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"label\", null, \"Volume\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"input\", {\n    id: \"volumeInput\",\n    type: \"range\",\n    min: -50,\n    max: 0,\n    value: volumeRange,\n    onChange: changeVolume,\n    className: \"slider\"\n  }));\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Transport);\n\n//# sourceURL=webpack://react-demo/./src/componets/Transport.jsx?");

/***/ }),

/***/ "./src/container/DrumMachine.jsx":
/*!***************************************!*\
  !*** ./src/container/DrumMachine.jsx ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tone */ \"./node_modules/tone/build/esm/index.js\");\n/* harmony import */ var _display_Grid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../display/Grid */ \"./src/display/Grid.jsx\");\n/* harmony import */ var _display_Transport__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../display/Transport */ \"./src/display/Transport.jsx\");\n/* harmony import */ var _display_Info__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../display/Info */ \"./src/display/Info.jsx\");\n/* harmony import */ var _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../assets/DrumSamples */ \"./src/assets/DrumSamples.js\");\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n // Tone JS\n\n\n // Import Display Components\n\n\n\n // import drum samples\n\n\n\nvar DrumMachineContainer = /*#__PURE__*/function (_React$Component) {\n  _inherits(DrumMachineContainer, _React$Component);\n\n  var _super = _createSuper(DrumMachineContainer);\n\n  function DrumMachineContainer(props) {\n    var _this;\n\n    _classCallCheck(this, DrumMachineContainer);\n\n    _this = _super.call(this, props);\n    _this.state = {\n      isLoaded: false,\n      gridState: {},\n      bpm: 100,\n      beat: 0,\n      volume: 0\n    }; // BIND CONTEXT\n\n    _this.clickPlay = _this.clickPlay.bind(_assertThisInitialized(_this));\n    _this.clickStop = _this.clickStop.bind(_assertThisInitialized(_this));\n    _this.updategridView = _this.updategridView.bind(_assertThisInitialized(_this));\n    _this.updateBPM = _this.updateBPM.bind(_assertThisInitialized(_this));\n    _this.updateVolume = _this.updateVolume.bind(_assertThisInitialized(_this)); // Creates Sampler to  \n\n    _this.sampler = new tone__WEBPACK_IMPORTED_MODULE_1__.Sampler({\n      urls: {\n        C1: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.kick,\n        D1: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.snare,\n        E1: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.clap,\n        F1: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.hatOpen,\n        G1: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.hatClose,\n        A2: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.block,\n        B2: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples.wood\n      },\n      onload: function onload() {\n        _this.setState({\n          isLoaded: true\n        });\n      }\n    }).toDestination(); // Initialize Volume\n\n    _this.sampler.volume.value = _this.state.volume; // Start Tonejs Engine\n\n    tone__WEBPACK_IMPORTED_MODULE_1__.start(); // Initialize BPM\n\n    tone__WEBPACK_IMPORTED_MODULE_1__.Transport.bpm.value = _this.state.bpm; // OLD\n\n    var beat = _this.state.beat; // LOOPING MECHANICS\n\n    var loop = new tone__WEBPACK_IMPORTED_MODULE_1__.Loop(function (time) {\n      // Volume MECHANIC\n      _this.sampler.volume.value = _this.state.volume; // Beat MECHANIC\n\n      var beat = _this.state.beat; // IF GRID HAS STUFF\n\n      if (_this.state.gridState) {\n        // IF GRID HAS A KICK ON THIS BEAT\n        if (_this.state.gridState.kick) {\n          if (_this.state.gridState.kick[beat] === true) {\n            _this.sampler.triggerAttack(\"C1\");\n          }\n        } // IF GRID HAS A SNARE ON THIS BEAT\n\n\n        if (_this.state.gridState.snare) {\n          if (_this.state.gridState.snare[beat] === true) {\n            _this.sampler.triggerAttack(\"D1\");\n          }\n        } // IF GRID HAS A CLAP ON THIS BEAT\n\n\n        if (_this.state.gridState.clap) {\n          if (_this.state.gridState.clap[beat] === true) {\n            _this.sampler.triggerAttack(\"E1\");\n          }\n        } // IF GRID HAS A hatOpen ON THIS BEAT\n\n\n        if (_this.state.gridState.hatOpen) {\n          if (_this.state.gridState.hatOpen[beat] === true) {\n            _this.sampler.triggerAttack(\"F1\");\n          }\n        } // IF GRID HAS A hatClose ON THIS BEAT\n\n\n        if (_this.state.gridState.hatClose) {\n          if (_this.state.gridState.hatClose[beat] === true) {\n            _this.sampler.triggerAttack(\"G1\");\n          }\n        } // IF GRID HAS A block ON THIS BEAT\n\n\n        if (_this.state.gridState.block) {\n          if (_this.state.gridState.block[beat] === true) {\n            _this.sampler.triggerAttack(\"A2\");\n          }\n        } // IF GRID HAS A wood ON THIS BEAT\n\n\n        if (_this.state.gridState.wood) {\n          if (_this.state.gridState.wood[beat] === true) {\n            _this.sampler.triggerAttack(\"B2\");\n          }\n        }\n      } // Checking BEATS\n      // console.log('current beat: ',(beat + 1));\n\n\n      _this.setState({\n        beat: (beat + 1) % 16\n      }); // beat = (beat + 1) % 16;\n\n    }, \"8n\").start(0);\n    return _this;\n  }\n\n  _createClass(DrumMachineContainer, [{\n    key: \"componentDidUpdate\",\n    value: function componentDidUpdate() {\n      // console.log('DRUMMACHINE - GRID UPDATED ', this.state.gridState);\n      tone__WEBPACK_IMPORTED_MODULE_1__.Transport.bpm.value = this.state.bpm;\n    }\n  }, {\n    key: \"updategridView\",\n    value: function updategridView(gridObj) {\n      console.log('DRUMMACHINE - UPDATEGRIDVIEW line 100 - GRID UPDATED AT DRUMACHINE');\n      this.setState({\n        gridState: gridObj\n      });\n    }\n  }, {\n    key: \"clickPlay\",\n    value: function clickPlay() {\n      if (Object.keys(this.state.gridState).length === 0) {\n        return;\n      }\n\n      if (tone__WEBPACK_IMPORTED_MODULE_1__.Transport.state !== 'started') {\n        tone__WEBPACK_IMPORTED_MODULE_1__.start();\n        tone__WEBPACK_IMPORTED_MODULE_1__.Transport.start();\n        console.log('play clicked');\n      } else {\n        tone__WEBPACK_IMPORTED_MODULE_1__.Transport.stop();\n        console.log('pause clicked');\n      }\n    }\n  }, {\n    key: \"clickStop\",\n    value: function clickStop() {\n      if (tone__WEBPACK_IMPORTED_MODULE_1__.Transport.state === 'started') {\n        tone__WEBPACK_IMPORTED_MODULE_1__.Transport.stop();\n      }\n\n      this.setState({\n        beat: 0\n      }); // this.state.bpm = 0;\n    } // Tranport Update BPM\n\n  }, {\n    key: \"updateBPM\",\n    value: function updateBPM(newBpm) {\n      this.setState({\n        bpm: newBpm\n      });\n    }\n  }, {\n    key: \"updateVolume\",\n    value: function updateVolume(newVolume) {\n      this.setState({\n        volume: newVolume\n      });\n    }\n  }, {\n    key: \"render\",\n    value: function render() {\n      return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n        className: \"Drum-Machine-Container\"\n      }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"h2\", null, \"Drum Machine Container\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_display_Transport__WEBPACK_IMPORTED_MODULE_3__[\"default\"], {\n        updateVolume: this.updateVolume,\n        volume: this.volume,\n        setBPM: this.updateBPM,\n        bpm: this.state.bpm,\n        play: this.clickPlay,\n        stop: this.clickStop\n      }), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_display_Info__WEBPACK_IMPORTED_MODULE_4__[\"default\"], {\n        theBPM: this.state.bpm,\n        theVolume: this.state.volume\n      }), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_display_Grid__WEBPACK_IMPORTED_MODULE_2__[\"default\"], {\n        samples: _assets_DrumSamples__WEBPACK_IMPORTED_MODULE_5__.samples,\n        updategridView: this.updategridView\n      }));\n    }\n  }]);\n\n  return DrumMachineContainer;\n}(react__WEBPACK_IMPORTED_MODULE_0__.Component);\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DrumMachineContainer);\n\n//# sourceURL=webpack://react-demo/./src/container/DrumMachine.jsx?");

/***/ }),

/***/ "./src/display/Grid.jsx":
/*!******************************!*\
  !*** ./src/display/Grid.jsx ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var _componets_Drum_Instrument__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../componets/Drum-Instrument */ \"./src/componets/Drum-Instrument.jsx\");\nfunction _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }\n\nfunction _nonIterableSpread() { throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _iterableToArray(iter) { if (typeof Symbol !== \"undefined\" && iter[Symbol.iterator] != null || iter[\"@@iterator\"] != null) return Array.from(iter); }\n\nfunction _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }\n\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"] != null) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; }\n\nfunction _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }\n\n // Import Instrument Components\n\n\n\nvar GridDisplay = function GridDisplay(props) {\n  var _useState = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)([]),\n      _useState2 = _slicedToArray(_useState, 2),\n      drums = _useState2[0],\n      addDrums = _useState2[1];\n\n  var _useState3 = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)(0),\n      _useState4 = _slicedToArray(_useState3, 2),\n      keys = _useState4[0],\n      keyIncre = _useState4[1];\n\n  var _useState5 = (0,react__WEBPACK_IMPORTED_MODULE_0__.useState)({}),\n      _useState6 = _slicedToArray(_useState5, 2),\n      mainGrid = _useState6[0],\n      updateMainGrid = _useState6[1]; // USE THIS TO DRILL UP TO DRUM MACHINE, PUT DRUMMACHINE FUNCTION HERE\n\n\n  (0,react__WEBPACK_IMPORTED_MODULE_0__.useEffect)(function () {\n    // console.log('!!!!DrumInstrument use effect!');\n    // console.log('CHECKING PASSED UP GRID FROM GRID TO DM: ', totalGrid());\n    updateGridView();\n  }, [mainGrid]);\n\n  var totalGrid = function totalGrid() {\n    return mainGrid;\n  };\n\n  var updateGridView = function updateGridView() {\n    props.updategridView(checkReturnState());\n  };\n\n  var updateTheMainGrid = function updateTheMainGrid(drumInstrumentGridArryState) {\n    var newState = _objectSpread(_objectSpread({}, mainGrid), drumInstrumentGridArryState);\n\n    console.log('1 --- CHECKING MAINGRID AND PASSED IN', mainGrid, drumInstrumentGridArryState);\n    updateMainGrid(function (prevStat) {\n      return _objectSpread(_objectSpread({}, prevStat), drumInstrumentGridArryState);\n    });\n    console.log('2 --- AFTER CHECKING MAINGRID AND PASSED IN', mainGrid, drumInstrumentGridArryState);\n  };\n\n  var addDrumsClicked = function addDrumsClicked() {\n    drums.push( /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_componets_Drum_Instrument__WEBPACK_IMPORTED_MODULE_1__[\"default\"], {\n      samples: props.samples,\n      updateTheMainGrid: updateTheMainGrid,\n      key: keys,\n      id: 'inst' + keys\n    }));\n    addDrums(_toConsumableArray(drums));\n    keyIncre(keys + 1);\n  };\n\n  var checkReturnState = function checkReturnState() {\n    return mainGrid;\n  };\n\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    className: \"Grid-Display\"\n  }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"button\", {\n    id: \"add-button\",\n    onClick: function onClick() {\n      return addDrumsClicked();\n    }\n  }, \"Add Drum\"), drums);\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (GridDisplay);\n\n//# sourceURL=webpack://react-demo/./src/display/Grid.jsx?");

/***/ }),

/***/ "./src/display/Info.jsx":
/*!******************************!*\
  !*** ./src/display/Info.jsx ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n\n\nvar InfoDisplay = function InfoDisplay(props) {\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    className: \"Info-Display\"\n  }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    id: \"bpmMeter\"\n  }, \"BPM : \", props.theBPM, \" Volume : \", props.theVolume, \"dB\"));\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (InfoDisplay);\n\n//# sourceURL=webpack://react-demo/./src/display/Info.jsx?");

/***/ }),

/***/ "./src/display/Transport.jsx":
/*!***********************************!*\
  !*** ./src/display/Transport.jsx ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var _componets_Transport__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../componets/Transport */ \"./src/componets/Transport.jsx\");\n // Import Transport Components\n\n\n\nvar TransportDisplay = function TransportDisplay(props) {\n  return /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"div\", {\n    className: \"Transport-Display\"\n  }, /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(\"h2\", null, \"TransportDisplay\"), /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_componets_Transport__WEBPACK_IMPORTED_MODULE_1__[\"default\"], {\n    updateVolume: props.updateVolume,\n    setBPM: props.setBPM,\n    bpm: props.bpm,\n    volume: props.volume,\n    play: props.play,\n    stop: props.stop\n  }));\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TransportDisplay);\n\n//# sourceURL=webpack://react-demo/./src/display/Transport.jsx?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var react_dom__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! react-dom */ \"./node_modules/react-dom/index.js\");\n/* harmony import */ var _App__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./App */ \"./src/App.js\");\n\n // import app\n\n\nreact_dom__WEBPACK_IMPORTED_MODULE_1__.render( /*#__PURE__*/react__WEBPACK_IMPORTED_MODULE_0__.createElement(_App__WEBPACK_IMPORTED_MODULE_2__[\"default\"], null), document.querySelector(\"#root\"));\n\n//# sourceURL=webpack://react-demo/./src/index.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/cjs.js!./src/App.css":
/*!***********************************************************!*\
  !*** ./node_modules/css-loader/dist/cjs.js!./src/App.css ***!
  \***********************************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../node_modules/css-loader/dist/runtime/noSourceMaps.js */ \"./node_modules/css-loader/dist/runtime/noSourceMaps.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__);\n// Imports\n\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default()((_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default()));\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \"* {\\n  margin: 5px;\\n}\\nbody {\\n  background-color: #34495e20;\\n  \\n  /* DISPLAY */\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n}\\n\\n.Drum-Machine-Container {\\n\\n  max-width: 700px;\\n\\n  background-color: rgb(169, 143, 143);\\n  \\n  /* DISPLAY */\\n  display: flexbox;\\n  justify-content: center;\\n  align-items: center;\\n\\n  /* BOX MODEL */\\n  padding: 10px;\\n\\n  /* Round Border */\\n  border-radius: 10px;\\n\\n  /* Font Text Color */\\n  /* text-shadow: -.25px 0 black, 0 .25px black, .25px 0 black, 0 -.25px black; */\\n  color: rgb(237, 235, 235);\\n  font-family: 'Franklin Gothic Medium', 'Arial Narrow', Arial, sans-serif;\\n  font-weight: 1000;\\n}\\n\\n.Transport-Display{\\n\\n  /* Border */\\n  border-radius: 5px;\\n  \\n  background-color: rgb(193, 172, 172);\\n  \\n}\\n\\n.Info-Display {\\n  /* Border */\\n  border-radius: 5px;\\n\\n  background-color: rgb(145, 124, 124);\\n\\n  display: flex;\\n  align-items: center;\\n\\n  height: 50px;\\n}\\n\\n/* GRID */\\n\\n.Grid-Display {\\n  /* TEST VISIBILITY */\\n  background-color: rgb(87, 73, 73);\\n\\n  /* Border */\\n  border-radius: 5px;\\n  \\n  /* DISPLAY */\\n  display: flex;\\n  flex-direction: column;\\n  align-items: center;\\n\\n  min-height: 75px;\\n  /* Transform */\\n  /* max-height: auto;\\n  transition: max-height 0.5s ease-out; */\\n\\n}\\n\\n#add-button{\\n\\n  background-color: #34495e82;\\n  color: #e9b5b5;\\n  border-radius: 5px;\\n  font-family: 'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif;\\n  font-size: large;\\n  font-weight: 700;\\n  width: 570px;\\n\\n}\\n\\n\\n/* INSTRUMENT */\\n\\n.DrumInstrument {\\n  /* DISPLAY */\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n\\n\\n\\n  /* BOX MODEL */\\n  margin: 0;\\n  padding: 0;\\n}\\n\\n.DrumInstrument div {\\n  margin: 0;\\n  padding: 0;\\n}\\n\\n/* .DrumInstrument > input {\\n  font-family: 'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif;\\n} */\\n\\n.selectBox {\\n  /* FONT */\\n  font-family: 'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif;\\n  font-size: large;\\n\\n  border-radius: 3px;\\n\\n  border: 0px;\\n  margin: 0;\\n  margin-bottom: 3px;\\n  margin-right: 5px;\\n  height: 25px;\\n  width: 100px;\\n  background-color: #eee;\\n}\\n\\n\\n.allCheckBoxes > input {\\n  margin: 2px;\\n  height: 25px;\\n  width: 25px;\\n  -webkit-appearance: none;\\n  -moz-appearance: none;\\n  -o-appearance: none;\\n  appearance: none;\\n  border: 1px solid #34495E;\\n  border-radius: 4px;\\n  outline: none;\\n  transition-duration: 0.3s;\\n  background-color: #c2c2c2;\\n  cursor: pointer;\\n}\\n\\n.allCheckBoxes > input:checked {\\n  border: 1px solid #bf821a;\\n  background-color: #e45151;\\n}\\n\\n\", \"\"]);\n// Exports\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://react-demo/./src/App.css?./node_modules/css-loader/dist/cjs.js");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/api.js":
/*!*****************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/api.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n  MIT License http://www.opensource.org/licenses/mit-license.php\n  Author Tobias Koppers @sokra\n*/\nmodule.exports = function (cssWithMappingToString) {\n  var list = []; // return the list of modules as css string\n\n  list.toString = function toString() {\n    return this.map(function (item) {\n      var content = \"\";\n      var needLayer = typeof item[5] !== \"undefined\";\n\n      if (item[4]) {\n        content += \"@supports (\".concat(item[4], \") {\");\n      }\n\n      if (item[2]) {\n        content += \"@media \".concat(item[2], \" {\");\n      }\n\n      if (needLayer) {\n        content += \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\");\n      }\n\n      content += cssWithMappingToString(item);\n\n      if (needLayer) {\n        content += \"}\";\n      }\n\n      if (item[2]) {\n        content += \"}\";\n      }\n\n      if (item[4]) {\n        content += \"}\";\n      }\n\n      return content;\n    }).join(\"\");\n  }; // import a list of modules into the list\n\n\n  list.i = function i(modules, media, dedupe, supports, layer) {\n    if (typeof modules === \"string\") {\n      modules = [[null, modules, undefined]];\n    }\n\n    var alreadyImportedModules = {};\n\n    if (dedupe) {\n      for (var k = 0; k < this.length; k++) {\n        var id = this[k][0];\n\n        if (id != null) {\n          alreadyImportedModules[id] = true;\n        }\n      }\n    }\n\n    for (var _k = 0; _k < modules.length; _k++) {\n      var item = [].concat(modules[_k]);\n\n      if (dedupe && alreadyImportedModules[item[0]]) {\n        continue;\n      }\n\n      if (typeof layer !== \"undefined\") {\n        if (typeof item[5] === \"undefined\") {\n          item[5] = layer;\n        } else {\n          item[1] = \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\").concat(item[1], \"}\");\n          item[5] = layer;\n        }\n      }\n\n      if (media) {\n        if (!item[2]) {\n          item[2] = media;\n        } else {\n          item[1] = \"@media \".concat(item[2], \" {\").concat(item[1], \"}\");\n          item[2] = media;\n        }\n      }\n\n      if (supports) {\n        if (!item[4]) {\n          item[4] = \"\".concat(supports);\n        } else {\n          item[1] = \"@supports (\".concat(item[4], \") {\").concat(item[1], \"}\");\n          item[4] = supports;\n        }\n      }\n\n      list.push(item);\n    }\n  };\n\n  return list;\n};\n\n//# sourceURL=webpack://react-demo/./node_modules/css-loader/dist/runtime/api.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/noSourceMaps.js":
/*!**************************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/noSourceMaps.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function (i) {\n  return i[1];\n};\n\n//# sourceURL=webpack://react-demo/./node_modules/css-loader/dist/runtime/noSourceMaps.js?");

/***/ }),

/***/ "./src/assets/drums/block.mp3":
/*!************************************!*\
  !*** ./src/assets/drums/block.mp3 ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"81d2fb47df19191ecaa364af7c28606b.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/block.mp3?");

/***/ }),

/***/ "./src/assets/drums/clap.mp3":
/*!***********************************!*\
  !*** ./src/assets/drums/clap.mp3 ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"2374f78099ebd52fe9d6a14bc2e33c84.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/clap.mp3?");

/***/ }),

/***/ "./src/assets/drums/hatclose.mp3":
/*!***************************************!*\
  !*** ./src/assets/drums/hatclose.mp3 ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"cba0026247573b33f4d6707219483ae9.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/hatclose.mp3?");

/***/ }),

/***/ "./src/assets/drums/hatopen.mp3":
/*!**************************************!*\
  !*** ./src/assets/drums/hatopen.mp3 ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"435a3392e9602e783ff9643ff54e8af5.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/hatopen.mp3?");

/***/ }),

/***/ "./src/assets/drums/snare.mp3":
/*!************************************!*\
  !*** ./src/assets/drums/snare.mp3 ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"7eca40436d9af95775f752724ef18857.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/snare.mp3?");

/***/ }),

/***/ "./src/assets/drums/testKick.mp3":
/*!***************************************!*\
  !*** ./src/assets/drums/testKick.mp3 ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"911713214343e7208b4c65092d34b6f4.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/testKick.mp3?");

/***/ }),

/***/ "./src/assets/drums/wood.mp3":
/*!***********************************!*\
  !*** ./src/assets/drums/wood.mp3 ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"814aff2d0182bbf4710c57c82cd2a74e.mp3\");\n\n//# sourceURL=webpack://react-demo/./src/assets/drums/wood.mp3?");

/***/ }),

/***/ "./node_modules/object-assign/index.js":
/*!*********************************************!*\
  !*** ./node_modules/object-assign/index.js ***!
  \*********************************************/
/***/ ((module) => {

"use strict";
eval("/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n\n\n//# sourceURL=webpack://react-demo/./node_modules/object-assign/index.js?");

/***/ }),

/***/ "./node_modules/react-dom/cjs/react-dom.development.js":
/*!*************************************************************!*\
  !*** ./node_modules/react-dom/cjs/react-dom.development.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/** @license React v17.0.2\n * react-dom.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nvar React = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\nvar _assign = __webpack_require__(/*! object-assign */ \"./node_modules/object-assign/index.js\");\nvar Scheduler = __webpack_require__(/*! scheduler */ \"./node_modules/scheduler/index.js\");\nvar tracing = __webpack_require__(/*! scheduler/tracing */ \"./node_modules/scheduler/tracing.js\");\n\nvar ReactSharedInternals = React.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;\n\n// by calls to these methods by a Babel plugin.\n//\n// In PROD (or in packages without access to React internals),\n// they are left as they are instead.\n\nfunction warn(format) {\n  {\n    for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      args[_key - 1] = arguments[_key];\n    }\n\n    printWarning('warn', format, args);\n  }\n}\nfunction error(format) {\n  {\n    for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n      args[_key2 - 1] = arguments[_key2];\n    }\n\n    printWarning('error', format, args);\n  }\n}\n\nfunction printWarning(level, format, args) {\n  // When changing this logic, you might want to also\n  // update consoleWithStackDev.www.js as well.\n  {\n    var ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\n    var stack = ReactDebugCurrentFrame.getStackAddendum();\n\n    if (stack !== '') {\n      format += '%s';\n      args = args.concat([stack]);\n    }\n\n    var argsWithFormat = args.map(function (item) {\n      return '' + item;\n    }); // Careful: RN currently depends on this prefix\n\n    argsWithFormat.unshift('Warning: ' + format); // We intentionally don't use spread (or .apply) directly because it\n    // breaks IE9: https://github.com/facebook/react/issues/13610\n    // eslint-disable-next-line react-internal/no-production-logging\n\n    Function.prototype.apply.call(console[level], console, argsWithFormat);\n  }\n}\n\nif (!React) {\n  {\n    throw Error( \"ReactDOM was loaded before React. Make sure you load the React package before loading ReactDOM.\" );\n  }\n}\n\nvar FunctionComponent = 0;\nvar ClassComponent = 1;\nvar IndeterminateComponent = 2; // Before we know whether it is function or class\n\nvar HostRoot = 3; // Root of a host tree. Could be nested inside another node.\n\nvar HostPortal = 4; // A subtree. Could be an entry point to a different renderer.\n\nvar HostComponent = 5;\nvar HostText = 6;\nvar Fragment = 7;\nvar Mode = 8;\nvar ContextConsumer = 9;\nvar ContextProvider = 10;\nvar ForwardRef = 11;\nvar Profiler = 12;\nvar SuspenseComponent = 13;\nvar MemoComponent = 14;\nvar SimpleMemoComponent = 15;\nvar LazyComponent = 16;\nvar IncompleteClassComponent = 17;\nvar DehydratedFragment = 18;\nvar SuspenseListComponent = 19;\nvar FundamentalComponent = 20;\nvar ScopeComponent = 21;\nvar Block = 22;\nvar OffscreenComponent = 23;\nvar LegacyHiddenComponent = 24;\n\n// Filter certain DOM attributes (e.g. src, href) if their values are empty strings.\n\nvar enableProfilerTimer = true; // Record durations for commit and passive effects phases.\n\nvar enableFundamentalAPI = false; // Experimental Scope support.\nvar enableNewReconciler = false; // Errors that are thrown while unmounting (or after in the case of passive effects)\nvar warnAboutStringRefs = false;\n\nvar allNativeEvents = new Set();\n/**\n * Mapping from registration name to event name\n */\n\n\nvar registrationNameDependencies = {};\n/**\n * Mapping from lowercase registration names to the properly cased version,\n * used to warn in the case of missing event handlers. Available\n * only in true.\n * @type {Object}\n */\n\nvar possibleRegistrationNames =  {} ; // Trust the developer to only use possibleRegistrationNames in true\n\nfunction registerTwoPhaseEvent(registrationName, dependencies) {\n  registerDirectEvent(registrationName, dependencies);\n  registerDirectEvent(registrationName + 'Capture', dependencies);\n}\nfunction registerDirectEvent(registrationName, dependencies) {\n  {\n    if (registrationNameDependencies[registrationName]) {\n      error('EventRegistry: More than one plugin attempted to publish the same ' + 'registration name, `%s`.', registrationName);\n    }\n  }\n\n  registrationNameDependencies[registrationName] = dependencies;\n\n  {\n    var lowerCasedName = registrationName.toLowerCase();\n    possibleRegistrationNames[lowerCasedName] = registrationName;\n\n    if (registrationName === 'onDoubleClick') {\n      possibleRegistrationNames.ondblclick = registrationName;\n    }\n  }\n\n  for (var i = 0; i < dependencies.length; i++) {\n    allNativeEvents.add(dependencies[i]);\n  }\n}\n\nvar canUseDOM = !!(typeof window !== 'undefined' && typeof window.document !== 'undefined' && typeof window.document.createElement !== 'undefined');\n\n// A reserved attribute.\n// It is handled by React separately and shouldn't be written to the DOM.\nvar RESERVED = 0; // A simple string attribute.\n// Attributes that aren't in the filter are presumed to have this type.\n\nvar STRING = 1; // A string attribute that accepts booleans in React. In HTML, these are called\n// \"enumerated\" attributes with \"true\" and \"false\" as possible values.\n// When true, it should be set to a \"true\" string.\n// When false, it should be set to a \"false\" string.\n\nvar BOOLEANISH_STRING = 2; // A real boolean attribute.\n// When true, it should be present (set either to an empty string or its name).\n// When false, it should be omitted.\n\nvar BOOLEAN = 3; // An attribute that can be used as a flag as well as with a value.\n// When true, it should be present (set either to an empty string or its name).\n// When false, it should be omitted.\n// For any other value, should be present with that value.\n\nvar OVERLOADED_BOOLEAN = 4; // An attribute that must be numeric or parse as a numeric.\n// When falsy, it should be removed.\n\nvar NUMERIC = 5; // An attribute that must be positive numeric or parse as a positive numeric.\n// When falsy, it should be removed.\n\nvar POSITIVE_NUMERIC = 6;\n\n/* eslint-disable max-len */\nvar ATTRIBUTE_NAME_START_CHAR = \":A-Z_a-z\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\";\n/* eslint-enable max-len */\n\nvar ATTRIBUTE_NAME_CHAR = ATTRIBUTE_NAME_START_CHAR + \"\\\\-.0-9\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040\";\nvar ROOT_ATTRIBUTE_NAME = 'data-reactroot';\nvar VALID_ATTRIBUTE_NAME_REGEX = new RegExp('^[' + ATTRIBUTE_NAME_START_CHAR + '][' + ATTRIBUTE_NAME_CHAR + ']*$');\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar illegalAttributeNameCache = {};\nvar validatedAttributeNameCache = {};\nfunction isAttributeNameSafe(attributeName) {\n  if (hasOwnProperty.call(validatedAttributeNameCache, attributeName)) {\n    return true;\n  }\n\n  if (hasOwnProperty.call(illegalAttributeNameCache, attributeName)) {\n    return false;\n  }\n\n  if (VALID_ATTRIBUTE_NAME_REGEX.test(attributeName)) {\n    validatedAttributeNameCache[attributeName] = true;\n    return true;\n  }\n\n  illegalAttributeNameCache[attributeName] = true;\n\n  {\n    error('Invalid attribute name: `%s`', attributeName);\n  }\n\n  return false;\n}\nfunction shouldIgnoreAttribute(name, propertyInfo, isCustomComponentTag) {\n  if (propertyInfo !== null) {\n    return propertyInfo.type === RESERVED;\n  }\n\n  if (isCustomComponentTag) {\n    return false;\n  }\n\n  if (name.length > 2 && (name[0] === 'o' || name[0] === 'O') && (name[1] === 'n' || name[1] === 'N')) {\n    return true;\n  }\n\n  return false;\n}\nfunction shouldRemoveAttributeWithWarning(name, value, propertyInfo, isCustomComponentTag) {\n  if (propertyInfo !== null && propertyInfo.type === RESERVED) {\n    return false;\n  }\n\n  switch (typeof value) {\n    case 'function': // $FlowIssue symbol is perfectly valid here\n\n    case 'symbol':\n      // eslint-disable-line\n      return true;\n\n    case 'boolean':\n      {\n        if (isCustomComponentTag) {\n          return false;\n        }\n\n        if (propertyInfo !== null) {\n          return !propertyInfo.acceptsBooleans;\n        } else {\n          var prefix = name.toLowerCase().slice(0, 5);\n          return prefix !== 'data-' && prefix !== 'aria-';\n        }\n      }\n\n    default:\n      return false;\n  }\n}\nfunction shouldRemoveAttribute(name, value, propertyInfo, isCustomComponentTag) {\n  if (value === null || typeof value === 'undefined') {\n    return true;\n  }\n\n  if (shouldRemoveAttributeWithWarning(name, value, propertyInfo, isCustomComponentTag)) {\n    return true;\n  }\n\n  if (isCustomComponentTag) {\n    return false;\n  }\n\n  if (propertyInfo !== null) {\n\n    switch (propertyInfo.type) {\n      case BOOLEAN:\n        return !value;\n\n      case OVERLOADED_BOOLEAN:\n        return value === false;\n\n      case NUMERIC:\n        return isNaN(value);\n\n      case POSITIVE_NUMERIC:\n        return isNaN(value) || value < 1;\n    }\n  }\n\n  return false;\n}\nfunction getPropertyInfo(name) {\n  return properties.hasOwnProperty(name) ? properties[name] : null;\n}\n\nfunction PropertyInfoRecord(name, type, mustUseProperty, attributeName, attributeNamespace, sanitizeURL, removeEmptyString) {\n  this.acceptsBooleans = type === BOOLEANISH_STRING || type === BOOLEAN || type === OVERLOADED_BOOLEAN;\n  this.attributeName = attributeName;\n  this.attributeNamespace = attributeNamespace;\n  this.mustUseProperty = mustUseProperty;\n  this.propertyName = name;\n  this.type = type;\n  this.sanitizeURL = sanitizeURL;\n  this.removeEmptyString = removeEmptyString;\n} // When adding attributes to this list, be sure to also add them to\n// the `possibleStandardNames` module to ensure casing and incorrect\n// name warnings.\n\n\nvar properties = {}; // These props are reserved by React. They shouldn't be written to the DOM.\n\nvar reservedProps = ['children', 'dangerouslySetInnerHTML', // TODO: This prevents the assignment of defaultValue to regular\n// elements (not just inputs). Now that ReactDOMInput assigns to the\n// defaultValue property -- do we need this?\n'defaultValue', 'defaultChecked', 'innerHTML', 'suppressContentEditableWarning', 'suppressHydrationWarning', 'style'];\nreservedProps.forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, RESERVED, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // A few React string attributes have a different name.\n// This is a mapping from React prop names to the attribute names.\n\n[['acceptCharset', 'accept-charset'], ['className', 'class'], ['htmlFor', 'for'], ['httpEquiv', 'http-equiv']].forEach(function (_ref) {\n  var name = _ref[0],\n      attributeName = _ref[1];\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are \"enumerated\" HTML attributes that accept \"true\" and \"false\".\n// In React, we let users pass `true` and `false` even though technically\n// these aren't boolean attributes (they are coerced to strings).\n\n['contentEditable', 'draggable', 'spellCheck', 'value'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEANISH_STRING, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are \"enumerated\" SVG attributes that accept \"true\" and \"false\".\n// In React, we let users pass `true` and `false` even though technically\n// these aren't boolean attributes (they are coerced to strings).\n// Since these are SVG attributes, their attribute names are case-sensitive.\n\n['autoReverse', 'externalResourcesRequired', 'focusable', 'preserveAlpha'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEANISH_STRING, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML boolean attributes.\n\n['allowFullScreen', 'async', // Note: there is a special case that prevents it from being written to the DOM\n// on the client side because the browsers are inconsistent. Instead we call focus().\n'autoFocus', 'autoPlay', 'controls', 'default', 'defer', 'disabled', 'disablePictureInPicture', 'disableRemotePlayback', 'formNoValidate', 'hidden', 'loop', 'noModule', 'noValidate', 'open', 'playsInline', 'readOnly', 'required', 'reversed', 'scoped', 'seamless', // Microdata\n'itemScope'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEAN, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are the few React props that we set as DOM properties\n// rather than attributes. These are all booleans.\n\n['checked', // Note: `option.selected` is not updated if `select.multiple` is\n// disabled with `removeAttribute`. We have special logic for handling this.\n'multiple', 'muted', 'selected' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEAN, true, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that are \"overloaded booleans\": they behave like\n// booleans, but can also accept a string value.\n\n['capture', 'download' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, OVERLOADED_BOOLEAN, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that must be positive numbers.\n\n['cols', 'rows', 'size', 'span' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, POSITIVE_NUMERIC, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that must be numbers.\n\n['rowSpan', 'start'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, NUMERIC, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n});\nvar CAMELIZE = /[\\-\\:]([a-z])/g;\n\nvar capitalize = function (token) {\n  return token[1].toUpperCase();\n}; // This is a list of all SVG attributes that need special casing, namespacing,\n// or boolean value assignment. Regular attributes that just accept strings\n// and have the same names are omitted, just like in the HTML attribute filter.\n// Some of these attributes can be hard to find. This list was created by\n// scraping the MDN documentation.\n\n\n['accent-height', 'alignment-baseline', 'arabic-form', 'baseline-shift', 'cap-height', 'clip-path', 'clip-rule', 'color-interpolation', 'color-interpolation-filters', 'color-profile', 'color-rendering', 'dominant-baseline', 'enable-background', 'fill-opacity', 'fill-rule', 'flood-color', 'flood-opacity', 'font-family', 'font-size', 'font-size-adjust', 'font-stretch', 'font-style', 'font-variant', 'font-weight', 'glyph-name', 'glyph-orientation-horizontal', 'glyph-orientation-vertical', 'horiz-adv-x', 'horiz-origin-x', 'image-rendering', 'letter-spacing', 'lighting-color', 'marker-end', 'marker-mid', 'marker-start', 'overline-position', 'overline-thickness', 'paint-order', 'panose-1', 'pointer-events', 'rendering-intent', 'shape-rendering', 'stop-color', 'stop-opacity', 'strikethrough-position', 'strikethrough-thickness', 'stroke-dasharray', 'stroke-dashoffset', 'stroke-linecap', 'stroke-linejoin', 'stroke-miterlimit', 'stroke-opacity', 'stroke-width', 'text-anchor', 'text-decoration', 'text-rendering', 'underline-position', 'underline-thickness', 'unicode-bidi', 'unicode-range', 'units-per-em', 'v-alphabetic', 'v-hanging', 'v-ideographic', 'v-mathematical', 'vector-effect', 'vert-adv-y', 'vert-origin-x', 'vert-origin-y', 'word-spacing', 'writing-mode', 'xmlns:xlink', 'x-height' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // String SVG attributes with the xlink namespace.\n\n['xlink:actuate', 'xlink:arcrole', 'xlink:role', 'xlink:show', 'xlink:title', 'xlink:type' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, 'http://www.w3.org/1999/xlink', false, // sanitizeURL\n  false);\n}); // String SVG attributes with the xml namespace.\n\n['xml:base', 'xml:lang', 'xml:space' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, 'http://www.w3.org/XML/1998/namespace', false, // sanitizeURL\n  false);\n}); // These attribute exists both in HTML and SVG.\n// The attribute name is case-sensitive in SVG so we can't just use\n// the React name like we do for attributes that exist only in HTML.\n\n['tabIndex', 'crossOrigin'].forEach(function (attributeName) {\n  properties[attributeName] = new PropertyInfoRecord(attributeName, STRING, false, // mustUseProperty\n  attributeName.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These attributes accept URLs. These must not allow javascript: URLS.\n// These will also need to accept Trusted Types object in the future.\n\nvar xlinkHref = 'xlinkHref';\nproperties[xlinkHref] = new PropertyInfoRecord('xlinkHref', STRING, false, // mustUseProperty\n'xlink:href', 'http://www.w3.org/1999/xlink', true, // sanitizeURL\nfalse);\n['src', 'href', 'action', 'formAction'].forEach(function (attributeName) {\n  properties[attributeName] = new PropertyInfoRecord(attributeName, STRING, false, // mustUseProperty\n  attributeName.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  true, // sanitizeURL\n  true);\n});\n\n// and any newline or tab are filtered out as if they're not part of the URL.\n// https://url.spec.whatwg.org/#url-parsing\n// Tab or newline are defined as \\r\\n\\t:\n// https://infra.spec.whatwg.org/#ascii-tab-or-newline\n// A C0 control is a code point in the range \\u0000 NULL to \\u001F\n// INFORMATION SEPARATOR ONE, inclusive:\n// https://infra.spec.whatwg.org/#c0-control-or-space\n\n/* eslint-disable max-len */\n\nvar isJavaScriptProtocol = /^[\\u0000-\\u001F ]*j[\\r\\n\\t]*a[\\r\\n\\t]*v[\\r\\n\\t]*a[\\r\\n\\t]*s[\\r\\n\\t]*c[\\r\\n\\t]*r[\\r\\n\\t]*i[\\r\\n\\t]*p[\\r\\n\\t]*t[\\r\\n\\t]*\\:/i;\nvar didWarn = false;\n\nfunction sanitizeURL(url) {\n  {\n    if (!didWarn && isJavaScriptProtocol.test(url)) {\n      didWarn = true;\n\n      error('A future version of React will block javascript: URLs as a security precaution. ' + 'Use event handlers instead if you can. If you need to generate unsafe HTML try ' + 'using dangerouslySetInnerHTML instead. React was passed %s.', JSON.stringify(url));\n    }\n  }\n}\n\n/**\n * Get the value for a property on a node. Only used in DEV for SSR validation.\n * The \"expected\" argument is used as a hint of what the expected value is.\n * Some properties have multiple equivalent values.\n */\nfunction getValueForProperty(node, name, expected, propertyInfo) {\n  {\n    if (propertyInfo.mustUseProperty) {\n      var propertyName = propertyInfo.propertyName;\n      return node[propertyName];\n    } else {\n      if ( propertyInfo.sanitizeURL) {\n        // If we haven't fully disabled javascript: URLs, and if\n        // the hydration is successful of a javascript: URL, we\n        // still want to warn on the client.\n        sanitizeURL('' + expected);\n      }\n\n      var attributeName = propertyInfo.attributeName;\n      var stringValue = null;\n\n      if (propertyInfo.type === OVERLOADED_BOOLEAN) {\n        if (node.hasAttribute(attributeName)) {\n          var value = node.getAttribute(attributeName);\n\n          if (value === '') {\n            return true;\n          }\n\n          if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n            return value;\n          }\n\n          if (value === '' + expected) {\n            return expected;\n          }\n\n          return value;\n        }\n      } else if (node.hasAttribute(attributeName)) {\n        if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n          // We had an attribute but shouldn't have had one, so read it\n          // for the error message.\n          return node.getAttribute(attributeName);\n        }\n\n        if (propertyInfo.type === BOOLEAN) {\n          // If this was a boolean, it doesn't matter what the value is\n          // the fact that we have it is the same as the expected.\n          return expected;\n        } // Even if this property uses a namespace we use getAttribute\n        // because we assume its namespaced name is the same as our config.\n        // To use getAttributeNS we need the local name which we don't have\n        // in our config atm.\n\n\n        stringValue = node.getAttribute(attributeName);\n      }\n\n      if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n        return stringValue === null ? expected : stringValue;\n      } else if (stringValue === '' + expected) {\n        return expected;\n      } else {\n        return stringValue;\n      }\n    }\n  }\n}\n/**\n * Get the value for a attribute on a node. Only used in DEV for SSR validation.\n * The third argument is used as a hint of what the expected value is. Some\n * attributes have multiple equivalent values.\n */\n\nfunction getValueForAttribute(node, name, expected) {\n  {\n    if (!isAttributeNameSafe(name)) {\n      return;\n    } // If the object is an opaque reference ID, it's expected that\n    // the next prop is different than the server value, so just return\n    // expected\n\n\n    if (isOpaqueHydratingObject(expected)) {\n      return expected;\n    }\n\n    if (!node.hasAttribute(name)) {\n      return expected === undefined ? undefined : null;\n    }\n\n    var value = node.getAttribute(name);\n\n    if (value === '' + expected) {\n      return expected;\n    }\n\n    return value;\n  }\n}\n/**\n * Sets the value for a property on a node.\n *\n * @param {DOMElement} node\n * @param {string} name\n * @param {*} value\n */\n\nfunction setValueForProperty(node, name, value, isCustomComponentTag) {\n  var propertyInfo = getPropertyInfo(name);\n\n  if (shouldIgnoreAttribute(name, propertyInfo, isCustomComponentTag)) {\n    return;\n  }\n\n  if (shouldRemoveAttribute(name, value, propertyInfo, isCustomComponentTag)) {\n    value = null;\n  } // If the prop isn't in the special list, treat it as a simple attribute.\n\n\n  if (isCustomComponentTag || propertyInfo === null) {\n    if (isAttributeNameSafe(name)) {\n      var _attributeName = name;\n\n      if (value === null) {\n        node.removeAttribute(_attributeName);\n      } else {\n        node.setAttribute(_attributeName,  '' + value);\n      }\n    }\n\n    return;\n  }\n\n  var mustUseProperty = propertyInfo.mustUseProperty;\n\n  if (mustUseProperty) {\n    var propertyName = propertyInfo.propertyName;\n\n    if (value === null) {\n      var type = propertyInfo.type;\n      node[propertyName] = type === BOOLEAN ? false : '';\n    } else {\n      // Contrary to `setAttribute`, object properties are properly\n      // `toString`ed by IE8/9.\n      node[propertyName] = value;\n    }\n\n    return;\n  } // The rest are treated as attributes with special cases.\n\n\n  var attributeName = propertyInfo.attributeName,\n      attributeNamespace = propertyInfo.attributeNamespace;\n\n  if (value === null) {\n    node.removeAttribute(attributeName);\n  } else {\n    var _type = propertyInfo.type;\n    var attributeValue;\n\n    if (_type === BOOLEAN || _type === OVERLOADED_BOOLEAN && value === true) {\n      // If attribute type is boolean, we know for sure it won't be an execution sink\n      // and we won't require Trusted Type here.\n      attributeValue = '';\n    } else {\n      // `setAttribute` with objects becomes only `[object]` in IE8/9,\n      // ('' + value) makes it output the correct toString()-value.\n      {\n        attributeValue = '' + value;\n      }\n\n      if (propertyInfo.sanitizeURL) {\n        sanitizeURL(attributeValue.toString());\n      }\n    }\n\n    if (attributeNamespace) {\n      node.setAttributeNS(attributeNamespace, attributeName, attributeValue);\n    } else {\n      node.setAttribute(attributeName, attributeValue);\n    }\n  }\n}\n\n// ATTENTION\n// When adding new symbols to this file,\n// Please consider also adding to 'react-devtools-shared/src/backend/ReactSymbols'\n// The Symbol used to tag the ReactElement-like types. If there is no native Symbol\n// nor polyfill, then a plain number is used for performance.\nvar REACT_ELEMENT_TYPE = 0xeac7;\nvar REACT_PORTAL_TYPE = 0xeaca;\nvar REACT_FRAGMENT_TYPE = 0xeacb;\nvar REACT_STRICT_MODE_TYPE = 0xeacc;\nvar REACT_PROFILER_TYPE = 0xead2;\nvar REACT_PROVIDER_TYPE = 0xeacd;\nvar REACT_CONTEXT_TYPE = 0xeace;\nvar REACT_FORWARD_REF_TYPE = 0xead0;\nvar REACT_SUSPENSE_TYPE = 0xead1;\nvar REACT_SUSPENSE_LIST_TYPE = 0xead8;\nvar REACT_MEMO_TYPE = 0xead3;\nvar REACT_LAZY_TYPE = 0xead4;\nvar REACT_BLOCK_TYPE = 0xead9;\nvar REACT_SERVER_BLOCK_TYPE = 0xeada;\nvar REACT_FUNDAMENTAL_TYPE = 0xead5;\nvar REACT_SCOPE_TYPE = 0xead7;\nvar REACT_OPAQUE_ID_TYPE = 0xeae0;\nvar REACT_DEBUG_TRACING_MODE_TYPE = 0xeae1;\nvar REACT_OFFSCREEN_TYPE = 0xeae2;\nvar REACT_LEGACY_HIDDEN_TYPE = 0xeae3;\n\nif (typeof Symbol === 'function' && Symbol.for) {\n  var symbolFor = Symbol.for;\n  REACT_ELEMENT_TYPE = symbolFor('react.element');\n  REACT_PORTAL_TYPE = symbolFor('react.portal');\n  REACT_FRAGMENT_TYPE = symbolFor('react.fragment');\n  REACT_STRICT_MODE_TYPE = symbolFor('react.strict_mode');\n  REACT_PROFILER_TYPE = symbolFor('react.profiler');\n  REACT_PROVIDER_TYPE = symbolFor('react.provider');\n  REACT_CONTEXT_TYPE = symbolFor('react.context');\n  REACT_FORWARD_REF_TYPE = symbolFor('react.forward_ref');\n  REACT_SUSPENSE_TYPE = symbolFor('react.suspense');\n  REACT_SUSPENSE_LIST_TYPE = symbolFor('react.suspense_list');\n  REACT_MEMO_TYPE = symbolFor('react.memo');\n  REACT_LAZY_TYPE = symbolFor('react.lazy');\n  REACT_BLOCK_TYPE = symbolFor('react.block');\n  REACT_SERVER_BLOCK_TYPE = symbolFor('react.server.block');\n  REACT_FUNDAMENTAL_TYPE = symbolFor('react.fundamental');\n  REACT_SCOPE_TYPE = symbolFor('react.scope');\n  REACT_OPAQUE_ID_TYPE = symbolFor('react.opaque.id');\n  REACT_DEBUG_TRACING_MODE_TYPE = symbolFor('react.debug_trace_mode');\n  REACT_OFFSCREEN_TYPE = symbolFor('react.offscreen');\n  REACT_LEGACY_HIDDEN_TYPE = symbolFor('react.legacy_hidden');\n}\n\nvar MAYBE_ITERATOR_SYMBOL = typeof Symbol === 'function' && Symbol.iterator;\nvar FAUX_ITERATOR_SYMBOL = '@@iterator';\nfunction getIteratorFn(maybeIterable) {\n  if (maybeIterable === null || typeof maybeIterable !== 'object') {\n    return null;\n  }\n\n  var maybeIterator = MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL] || maybeIterable[FAUX_ITERATOR_SYMBOL];\n\n  if (typeof maybeIterator === 'function') {\n    return maybeIterator;\n  }\n\n  return null;\n}\n\n// Helpers to patch console.logs to avoid logging during side-effect free\n// replaying on render function. This currently only patches the object\n// lazily which won't cover if the log function was extracted eagerly.\n// We could also eagerly patch the method.\nvar disabledDepth = 0;\nvar prevLog;\nvar prevInfo;\nvar prevWarn;\nvar prevError;\nvar prevGroup;\nvar prevGroupCollapsed;\nvar prevGroupEnd;\n\nfunction disabledLog() {}\n\ndisabledLog.__reactDisabledLog = true;\nfunction disableLogs() {\n  {\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      prevLog = console.log;\n      prevInfo = console.info;\n      prevWarn = console.warn;\n      prevError = console.error;\n      prevGroup = console.group;\n      prevGroupCollapsed = console.groupCollapsed;\n      prevGroupEnd = console.groupEnd; // https://github.com/facebook/react/issues/19099\n\n      var props = {\n        configurable: true,\n        enumerable: true,\n        value: disabledLog,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        info: props,\n        log: props,\n        warn: props,\n        error: props,\n        group: props,\n        groupCollapsed: props,\n        groupEnd: props\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    disabledDepth++;\n  }\n}\nfunction reenableLogs() {\n  {\n    disabledDepth--;\n\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      var props = {\n        configurable: true,\n        enumerable: true,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        log: _assign({}, props, {\n          value: prevLog\n        }),\n        info: _assign({}, props, {\n          value: prevInfo\n        }),\n        warn: _assign({}, props, {\n          value: prevWarn\n        }),\n        error: _assign({}, props, {\n          value: prevError\n        }),\n        group: _assign({}, props, {\n          value: prevGroup\n        }),\n        groupCollapsed: _assign({}, props, {\n          value: prevGroupCollapsed\n        }),\n        groupEnd: _assign({}, props, {\n          value: prevGroupEnd\n        })\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    if (disabledDepth < 0) {\n      error('disabledDepth fell below zero. ' + 'This is a bug in React. Please file an issue.');\n    }\n  }\n}\n\nvar ReactCurrentDispatcher = ReactSharedInternals.ReactCurrentDispatcher;\nvar prefix;\nfunction describeBuiltInComponentFrame(name, source, ownerFn) {\n  {\n    if (prefix === undefined) {\n      // Extract the VM specific prefix used by each line.\n      try {\n        throw Error();\n      } catch (x) {\n        var match = x.stack.trim().match(/\\n( *(at )?)/);\n        prefix = match && match[1] || '';\n      }\n    } // We use the prefix to ensure our stacks line up with native stack frames.\n\n\n    return '\\n' + prefix + name;\n  }\n}\nvar reentry = false;\nvar componentFrameCache;\n\n{\n  var PossiblyWeakMap = typeof WeakMap === 'function' ? WeakMap : Map;\n  componentFrameCache = new PossiblyWeakMap();\n}\n\nfunction describeNativeComponentFrame(fn, construct) {\n  // If something asked for a stack inside a fake render, it should get ignored.\n  if (!fn || reentry) {\n    return '';\n  }\n\n  {\n    var frame = componentFrameCache.get(fn);\n\n    if (frame !== undefined) {\n      return frame;\n    }\n  }\n\n  var control;\n  reentry = true;\n  var previousPrepareStackTrace = Error.prepareStackTrace; // $FlowFixMe It does accept undefined.\n\n  Error.prepareStackTrace = undefined;\n  var previousDispatcher;\n\n  {\n    previousDispatcher = ReactCurrentDispatcher.current; // Set the dispatcher in DEV because this might be call in the render function\n    // for warnings.\n\n    ReactCurrentDispatcher.current = null;\n    disableLogs();\n  }\n\n  try {\n    // This should throw.\n    if (construct) {\n      // Something should be setting the props in the constructor.\n      var Fake = function () {\n        throw Error();\n      }; // $FlowFixMe\n\n\n      Object.defineProperty(Fake.prototype, 'props', {\n        set: function () {\n          // We use a throwing setter instead of frozen or non-writable props\n          // because that won't throw in a non-strict mode function.\n          throw Error();\n        }\n      });\n\n      if (typeof Reflect === 'object' && Reflect.construct) {\n        // We construct a different control for this case to include any extra\n        // frames added by the construct call.\n        try {\n          Reflect.construct(Fake, []);\n        } catch (x) {\n          control = x;\n        }\n\n        Reflect.construct(fn, [], Fake);\n      } else {\n        try {\n          Fake.call();\n        } catch (x) {\n          control = x;\n        }\n\n        fn.call(Fake.prototype);\n      }\n    } else {\n      try {\n        throw Error();\n      } catch (x) {\n        control = x;\n      }\n\n      fn();\n    }\n  } catch (sample) {\n    // This is inlined manually because closure doesn't do it for us.\n    if (sample && control && typeof sample.stack === 'string') {\n      // This extracts the first frame from the sample that isn't also in the control.\n      // Skipping one frame that we assume is the frame that calls the two.\n      var sampleLines = sample.stack.split('\\n');\n      var controlLines = control.stack.split('\\n');\n      var s = sampleLines.length - 1;\n      var c = controlLines.length - 1;\n\n      while (s >= 1 && c >= 0 && sampleLines[s] !== controlLines[c]) {\n        // We expect at least one stack frame to be shared.\n        // Typically this will be the root most one. However, stack frames may be\n        // cut off due to maximum stack limits. In this case, one maybe cut off\n        // earlier than the other. We assume that the sample is longer or the same\n        // and there for cut off earlier. So we should find the root most frame in\n        // the sample somewhere in the control.\n        c--;\n      }\n\n      for (; s >= 1 && c >= 0; s--, c--) {\n        // Next we find the first one that isn't the same which should be the\n        // frame that called our sample function and the control.\n        if (sampleLines[s] !== controlLines[c]) {\n          // In V8, the first line is describing the message but other VMs don't.\n          // If we're about to return the first line, and the control is also on the same\n          // line, that's a pretty good indicator that our sample threw at same line as\n          // the control. I.e. before we entered the sample frame. So we ignore this result.\n          // This can happen if you passed a class to function component, or non-function.\n          if (s !== 1 || c !== 1) {\n            do {\n              s--;\n              c--; // We may still have similar intermediate frames from the construct call.\n              // The next one that isn't the same should be our match though.\n\n              if (c < 0 || sampleLines[s] !== controlLines[c]) {\n                // V8 adds a \"new\" prefix for native classes. Let's remove it to make it prettier.\n                var _frame = '\\n' + sampleLines[s].replace(' at new ', ' at ');\n\n                {\n                  if (typeof fn === 'function') {\n                    componentFrameCache.set(fn, _frame);\n                  }\n                } // Return the line we found.\n\n\n                return _frame;\n              }\n            } while (s >= 1 && c >= 0);\n          }\n\n          break;\n        }\n      }\n    }\n  } finally {\n    reentry = false;\n\n    {\n      ReactCurrentDispatcher.current = previousDispatcher;\n      reenableLogs();\n    }\n\n    Error.prepareStackTrace = previousPrepareStackTrace;\n  } // Fallback to just using the name if we couldn't make it throw.\n\n\n  var name = fn ? fn.displayName || fn.name : '';\n  var syntheticFrame = name ? describeBuiltInComponentFrame(name) : '';\n\n  {\n    if (typeof fn === 'function') {\n      componentFrameCache.set(fn, syntheticFrame);\n    }\n  }\n\n  return syntheticFrame;\n}\n\nfunction describeClassComponentFrame(ctor, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(ctor, true);\n  }\n}\nfunction describeFunctionComponentFrame(fn, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(fn, false);\n  }\n}\n\nfunction shouldConstruct(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction describeUnknownElementTypeFrameInDEV(type, source, ownerFn) {\n\n  if (type == null) {\n    return '';\n  }\n\n  if (typeof type === 'function') {\n    {\n      return describeNativeComponentFrame(type, shouldConstruct(type));\n    }\n  }\n\n  if (typeof type === 'string') {\n    return describeBuiltInComponentFrame(type);\n  }\n\n  switch (type) {\n    case REACT_SUSPENSE_TYPE:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return describeBuiltInComponentFrame('SuspenseList');\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_FORWARD_REF_TYPE:\n        return describeFunctionComponentFrame(type.render);\n\n      case REACT_MEMO_TYPE:\n        // Memo may contain any component type so we recursively resolve it.\n        return describeUnknownElementTypeFrameInDEV(type.type, source, ownerFn);\n\n      case REACT_BLOCK_TYPE:\n        return describeFunctionComponentFrame(type._render);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            // Lazy may contain any component type so we recursively resolve it.\n            return describeUnknownElementTypeFrameInDEV(init(payload), source, ownerFn);\n          } catch (x) {}\n        }\n    }\n  }\n\n  return '';\n}\n\nfunction describeFiber(fiber) {\n  var owner =  fiber._debugOwner ? fiber._debugOwner.type : null ;\n  var source =  fiber._debugSource ;\n\n  switch (fiber.tag) {\n    case HostComponent:\n      return describeBuiltInComponentFrame(fiber.type);\n\n    case LazyComponent:\n      return describeBuiltInComponentFrame('Lazy');\n\n    case SuspenseComponent:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case SuspenseListComponent:\n      return describeBuiltInComponentFrame('SuspenseList');\n\n    case FunctionComponent:\n    case IndeterminateComponent:\n    case SimpleMemoComponent:\n      return describeFunctionComponentFrame(fiber.type);\n\n    case ForwardRef:\n      return describeFunctionComponentFrame(fiber.type.render);\n\n    case Block:\n      return describeFunctionComponentFrame(fiber.type._render);\n\n    case ClassComponent:\n      return describeClassComponentFrame(fiber.type);\n\n    default:\n      return '';\n  }\n}\n\nfunction getStackByFiberInDevAndProd(workInProgress) {\n  try {\n    var info = '';\n    var node = workInProgress;\n\n    do {\n      info += describeFiber(node);\n      node = node.return;\n    } while (node);\n\n    return info;\n  } catch (x) {\n    return '\\nError generating stack: ' + x.message + '\\n' + x.stack;\n  }\n}\n\nfunction getWrappedName(outerType, innerType, wrapperName) {\n  var functionName = innerType.displayName || innerType.name || '';\n  return outerType.displayName || (functionName !== '' ? wrapperName + \"(\" + functionName + \")\" : wrapperName);\n}\n\nfunction getContextName(type) {\n  return type.displayName || 'Context';\n}\n\nfunction getComponentName(type) {\n  if (type == null) {\n    // Host root, text node or just invalid type.\n    return null;\n  }\n\n  {\n    if (typeof type.tag === 'number') {\n      error('Received an unexpected object in getComponentName(). ' + 'This is likely a bug in React. Please file an issue.');\n    }\n  }\n\n  if (typeof type === 'function') {\n    return type.displayName || type.name || null;\n  }\n\n  if (typeof type === 'string') {\n    return type;\n  }\n\n  switch (type) {\n    case REACT_FRAGMENT_TYPE:\n      return 'Fragment';\n\n    case REACT_PORTAL_TYPE:\n      return 'Portal';\n\n    case REACT_PROFILER_TYPE:\n      return 'Profiler';\n\n    case REACT_STRICT_MODE_TYPE:\n      return 'StrictMode';\n\n    case REACT_SUSPENSE_TYPE:\n      return 'Suspense';\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return 'SuspenseList';\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_CONTEXT_TYPE:\n        var context = type;\n        return getContextName(context) + '.Consumer';\n\n      case REACT_PROVIDER_TYPE:\n        var provider = type;\n        return getContextName(provider._context) + '.Provider';\n\n      case REACT_FORWARD_REF_TYPE:\n        return getWrappedName(type, type.render, 'ForwardRef');\n\n      case REACT_MEMO_TYPE:\n        return getComponentName(type.type);\n\n      case REACT_BLOCK_TYPE:\n        return getComponentName(type._render);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            return getComponentName(init(payload));\n          } catch (x) {\n            return null;\n          }\n        }\n    }\n  }\n\n  return null;\n}\n\nvar ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\nvar current = null;\nvar isRendering = false;\nfunction getCurrentFiberOwnerNameInDevOrNull() {\n  {\n    if (current === null) {\n      return null;\n    }\n\n    var owner = current._debugOwner;\n\n    if (owner !== null && typeof owner !== 'undefined') {\n      return getComponentName(owner.type);\n    }\n  }\n\n  return null;\n}\n\nfunction getCurrentFiberStackInDev() {\n  {\n    if (current === null) {\n      return '';\n    } // Safe because if current fiber exists, we are reconciling,\n    // and it is guaranteed to be the work-in-progress version.\n\n\n    return getStackByFiberInDevAndProd(current);\n  }\n}\n\nfunction resetCurrentFiber() {\n  {\n    ReactDebugCurrentFrame.getCurrentStack = null;\n    current = null;\n    isRendering = false;\n  }\n}\nfunction setCurrentFiber(fiber) {\n  {\n    ReactDebugCurrentFrame.getCurrentStack = getCurrentFiberStackInDev;\n    current = fiber;\n    isRendering = false;\n  }\n}\nfunction setIsRendering(rendering) {\n  {\n    isRendering = rendering;\n  }\n}\nfunction getIsRendering() {\n  {\n    return isRendering;\n  }\n}\n\n// Flow does not allow string concatenation of most non-string types. To work\n// around this limitation, we use an opaque type that can only be obtained by\n// passing the value through getToStringValue first.\nfunction toString(value) {\n  return '' + value;\n}\nfunction getToStringValue(value) {\n  switch (typeof value) {\n    case 'boolean':\n    case 'number':\n    case 'object':\n    case 'string':\n    case 'undefined':\n      return value;\n\n    default:\n      // function, symbol are assigned as empty strings\n      return '';\n  }\n}\n\nvar hasReadOnlyValue = {\n  button: true,\n  checkbox: true,\n  image: true,\n  hidden: true,\n  radio: true,\n  reset: true,\n  submit: true\n};\nfunction checkControlledValueProps(tagName, props) {\n  {\n    if (!(hasReadOnlyValue[props.type] || props.onChange || props.onInput || props.readOnly || props.disabled || props.value == null)) {\n      error('You provided a `value` prop to a form field without an ' + '`onChange` handler. This will render a read-only field. If ' + 'the field should be mutable use `defaultValue`. Otherwise, ' + 'set either `onChange` or `readOnly`.');\n    }\n\n    if (!(props.onChange || props.readOnly || props.disabled || props.checked == null)) {\n      error('You provided a `checked` prop to a form field without an ' + '`onChange` handler. This will render a read-only field. If ' + 'the field should be mutable use `defaultChecked`. Otherwise, ' + 'set either `onChange` or `readOnly`.');\n    }\n  }\n}\n\nfunction isCheckable(elem) {\n  var type = elem.type;\n  var nodeName = elem.nodeName;\n  return nodeName && nodeName.toLowerCase() === 'input' && (type === 'checkbox' || type === 'radio');\n}\n\nfunction getTracker(node) {\n  return node._valueTracker;\n}\n\nfunction detachTracker(node) {\n  node._valueTracker = null;\n}\n\nfunction getValueFromNode(node) {\n  var value = '';\n\n  if (!node) {\n    return value;\n  }\n\n  if (isCheckable(node)) {\n    value = node.checked ? 'true' : 'false';\n  } else {\n    value = node.value;\n  }\n\n  return value;\n}\n\nfunction trackValueOnNode(node) {\n  var valueField = isCheckable(node) ? 'checked' : 'value';\n  var descriptor = Object.getOwnPropertyDescriptor(node.constructor.prototype, valueField);\n  var currentValue = '' + node[valueField]; // if someone has already defined a value or Safari, then bail\n  // and don't track value will cause over reporting of changes,\n  // but it's better then a hard failure\n  // (needed for certain tests that spyOn input values and Safari)\n\n  if (node.hasOwnProperty(valueField) || typeof descriptor === 'undefined' || typeof descriptor.get !== 'function' || typeof descriptor.set !== 'function') {\n    return;\n  }\n\n  var get = descriptor.get,\n      set = descriptor.set;\n  Object.defineProperty(node, valueField, {\n    configurable: true,\n    get: function () {\n      return get.call(this);\n    },\n    set: function (value) {\n      currentValue = '' + value;\n      set.call(this, value);\n    }\n  }); // We could've passed this the first time\n  // but it triggers a bug in IE11 and Edge 14/15.\n  // Calling defineProperty() again should be equivalent.\n  // https://github.com/facebook/react/issues/11768\n\n  Object.defineProperty(node, valueField, {\n    enumerable: descriptor.enumerable\n  });\n  var tracker = {\n    getValue: function () {\n      return currentValue;\n    },\n    setValue: function (value) {\n      currentValue = '' + value;\n    },\n    stopTracking: function () {\n      detachTracker(node);\n      delete node[valueField];\n    }\n  };\n  return tracker;\n}\n\nfunction track(node) {\n  if (getTracker(node)) {\n    return;\n  } // TODO: Once it's just Fiber we can move this to node._wrapperState\n\n\n  node._valueTracker = trackValueOnNode(node);\n}\nfunction updateValueIfChanged(node) {\n  if (!node) {\n    return false;\n  }\n\n  var tracker = getTracker(node); // if there is no tracker at this point it's unlikely\n  // that trying again will succeed\n\n  if (!tracker) {\n    return true;\n  }\n\n  var lastValue = tracker.getValue();\n  var nextValue = getValueFromNode(node);\n\n  if (nextValue !== lastValue) {\n    tracker.setValue(nextValue);\n    return true;\n  }\n\n  return false;\n}\n\nfunction getActiveElement(doc) {\n  doc = doc || (typeof document !== 'undefined' ? document : undefined);\n\n  if (typeof doc === 'undefined') {\n    return null;\n  }\n\n  try {\n    return doc.activeElement || doc.body;\n  } catch (e) {\n    return doc.body;\n  }\n}\n\nvar didWarnValueDefaultValue = false;\nvar didWarnCheckedDefaultChecked = false;\nvar didWarnControlledToUncontrolled = false;\nvar didWarnUncontrolledToControlled = false;\n\nfunction isControlled(props) {\n  var usesChecked = props.type === 'checkbox' || props.type === 'radio';\n  return usesChecked ? props.checked != null : props.value != null;\n}\n/**\n * Implements an <input> host component that allows setting these optional\n * props: `checked`, `value`, `defaultChecked`, and `defaultValue`.\n *\n * If `checked` or `value` are not supplied (or null/undefined), user actions\n * that affect the checked state or value will trigger updates to the element.\n *\n * If they are supplied (and not null/undefined), the rendered element will not\n * trigger updates to the element. Instead, the props must change in order for\n * the rendered element to be updated.\n *\n * The rendered element will be initialized as unchecked (or `defaultChecked`)\n * with an empty value (or `defaultValue`).\n *\n * See http://www.w3.org/TR/2012/WD-html5-20121025/the-input-element.html\n */\n\n\nfunction getHostProps(element, props) {\n  var node = element;\n  var checked = props.checked;\n\n  var hostProps = _assign({}, props, {\n    defaultChecked: undefined,\n    defaultValue: undefined,\n    value: undefined,\n    checked: checked != null ? checked : node._wrapperState.initialChecked\n  });\n\n  return hostProps;\n}\nfunction initWrapperState(element, props) {\n  {\n    checkControlledValueProps('input', props);\n\n    if (props.checked !== undefined && props.defaultChecked !== undefined && !didWarnCheckedDefaultChecked) {\n      error('%s contains an input of type %s with both checked and defaultChecked props. ' + 'Input elements must be either controlled or uncontrolled ' + '(specify either the checked prop, or the defaultChecked prop, but not ' + 'both). Decide between using a controlled or uncontrolled input ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component', props.type);\n\n      didWarnCheckedDefaultChecked = true;\n    }\n\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValueDefaultValue) {\n      error('%s contains an input of type %s with both value and defaultValue props. ' + 'Input elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled input ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component', props.type);\n\n      didWarnValueDefaultValue = true;\n    }\n  }\n\n  var node = element;\n  var defaultValue = props.defaultValue == null ? '' : props.defaultValue;\n  node._wrapperState = {\n    initialChecked: props.checked != null ? props.checked : props.defaultChecked,\n    initialValue: getToStringValue(props.value != null ? props.value : defaultValue),\n    controlled: isControlled(props)\n  };\n}\nfunction updateChecked(element, props) {\n  var node = element;\n  var checked = props.checked;\n\n  if (checked != null) {\n    setValueForProperty(node, 'checked', checked, false);\n  }\n}\nfunction updateWrapper(element, props) {\n  var node = element;\n\n  {\n    var controlled = isControlled(props);\n\n    if (!node._wrapperState.controlled && controlled && !didWarnUncontrolledToControlled) {\n      error('A component is changing an uncontrolled input to be controlled. ' + 'This is likely caused by the value changing from undefined to ' + 'a defined value, which should not happen. ' + 'Decide between using a controlled or uncontrolled input ' + 'element for the lifetime of the component. More info: https://reactjs.org/link/controlled-components');\n\n      didWarnUncontrolledToControlled = true;\n    }\n\n    if (node._wrapperState.controlled && !controlled && !didWarnControlledToUncontrolled) {\n      error('A component is changing a controlled input to be uncontrolled. ' + 'This is likely caused by the value changing from a defined to ' + 'undefined, which should not happen. ' + 'Decide between using a controlled or uncontrolled input ' + 'element for the lifetime of the component. More info: https://reactjs.org/link/controlled-components');\n\n      didWarnControlledToUncontrolled = true;\n    }\n  }\n\n  updateChecked(element, props);\n  var value = getToStringValue(props.value);\n  var type = props.type;\n\n  if (value != null) {\n    if (type === 'number') {\n      if (value === 0 && node.value === '' || // We explicitly want to coerce to number here if possible.\n      // eslint-disable-next-line\n      node.value != value) {\n        node.value = toString(value);\n      }\n    } else if (node.value !== toString(value)) {\n      node.value = toString(value);\n    }\n  } else if (type === 'submit' || type === 'reset') {\n    // Submit/reset inputs need the attribute removed completely to avoid\n    // blank-text buttons.\n    node.removeAttribute('value');\n    return;\n  }\n\n  {\n    // When syncing the value attribute, the value comes from a cascade of\n    // properties:\n    //  1. The value React property\n    //  2. The defaultValue React property\n    //  3. Otherwise there should be no change\n    if (props.hasOwnProperty('value')) {\n      setDefaultValue(node, props.type, value);\n    } else if (props.hasOwnProperty('defaultValue')) {\n      setDefaultValue(node, props.type, getToStringValue(props.defaultValue));\n    }\n  }\n\n  {\n    // When syncing the checked attribute, it only changes when it needs\n    // to be removed, such as transitioning from a checkbox into a text input\n    if (props.checked == null && props.defaultChecked != null) {\n      node.defaultChecked = !!props.defaultChecked;\n    }\n  }\n}\nfunction postMountWrapper(element, props, isHydrating) {\n  var node = element; // Do not assign value if it is already set. This prevents user text input\n  // from being lost during SSR hydration.\n\n  if (props.hasOwnProperty('value') || props.hasOwnProperty('defaultValue')) {\n    var type = props.type;\n    var isButton = type === 'submit' || type === 'reset'; // Avoid setting value attribute on submit/reset inputs as it overrides the\n    // default value provided by the browser. See: #12872\n\n    if (isButton && (props.value === undefined || props.value === null)) {\n      return;\n    }\n\n    var initialValue = toString(node._wrapperState.initialValue); // Do not assign value if it is already set. This prevents user text input\n    // from being lost during SSR hydration.\n\n    if (!isHydrating) {\n      {\n        // When syncing the value attribute, the value property should use\n        // the wrapperState._initialValue property. This uses:\n        //\n        //   1. The value React property when present\n        //   2. The defaultValue React property when present\n        //   3. An empty string\n        if (initialValue !== node.value) {\n          node.value = initialValue;\n        }\n      }\n    }\n\n    {\n      // Otherwise, the value attribute is synchronized to the property,\n      // so we assign defaultValue to the same thing as the value property\n      // assignment step above.\n      node.defaultValue = initialValue;\n    }\n  } // Normally, we'd just do `node.checked = node.checked` upon initial mount, less this bug\n  // this is needed to work around a chrome bug where setting defaultChecked\n  // will sometimes influence the value of checked (even after detachment).\n  // Reference: https://bugs.chromium.org/p/chromium/issues/detail?id=608416\n  // We need to temporarily unset name to avoid disrupting radio button groups.\n\n\n  var name = node.name;\n\n  if (name !== '') {\n    node.name = '';\n  }\n\n  {\n    // When syncing the checked attribute, both the checked property and\n    // attribute are assigned at the same time using defaultChecked. This uses:\n    //\n    //   1. The checked React property when present\n    //   2. The defaultChecked React property when present\n    //   3. Otherwise, false\n    node.defaultChecked = !node.defaultChecked;\n    node.defaultChecked = !!node._wrapperState.initialChecked;\n  }\n\n  if (name !== '') {\n    node.name = name;\n  }\n}\nfunction restoreControlledState(element, props) {\n  var node = element;\n  updateWrapper(node, props);\n  updateNamedCousins(node, props);\n}\n\nfunction updateNamedCousins(rootNode, props) {\n  var name = props.name;\n\n  if (props.type === 'radio' && name != null) {\n    var queryRoot = rootNode;\n\n    while (queryRoot.parentNode) {\n      queryRoot = queryRoot.parentNode;\n    } // If `rootNode.form` was non-null, then we could try `form.elements`,\n    // but that sometimes behaves strangely in IE8. We could also try using\n    // `form.getElementsByName`, but that will only return direct children\n    // and won't include inputs that use the HTML5 `form=` attribute. Since\n    // the input might not even be in a form. It might not even be in the\n    // document. Let's just use the local `querySelectorAll` to ensure we don't\n    // miss anything.\n\n\n    var group = queryRoot.querySelectorAll('input[name=' + JSON.stringify('' + name) + '][type=\"radio\"]');\n\n    for (var i = 0; i < group.length; i++) {\n      var otherNode = group[i];\n\n      if (otherNode === rootNode || otherNode.form !== rootNode.form) {\n        continue;\n      } // This will throw if radio buttons rendered by different copies of React\n      // and the same name are rendered into the same form (same as #1939).\n      // That's probably okay; we don't support it just as we don't support\n      // mixing React radio buttons with non-React ones.\n\n\n      var otherProps = getFiberCurrentPropsFromNode(otherNode);\n\n      if (!otherProps) {\n        {\n          throw Error( \"ReactDOMInput: Mixing React and non-React radio inputs with the same `name` is not supported.\" );\n        }\n      } // We need update the tracked value on the named cousin since the value\n      // was changed but the input saw no event or value set\n\n\n      updateValueIfChanged(otherNode); // If this is a controlled radio button group, forcing the input that\n      // was previously checked to update will cause it to be come re-checked\n      // as appropriate.\n\n      updateWrapper(otherNode, otherProps);\n    }\n  }\n} // In Chrome, assigning defaultValue to certain input types triggers input validation.\n// For number inputs, the display value loses trailing decimal points. For email inputs,\n// Chrome raises \"The specified value <x> is not a valid email address\".\n//\n// Here we check to see if the defaultValue has actually changed, avoiding these problems\n// when the user is inputting text\n//\n// https://github.com/facebook/react/issues/7253\n\n\nfunction setDefaultValue(node, type, value) {\n  if ( // Focused number inputs synchronize on blur. See ChangeEventPlugin.js\n  type !== 'number' || getActiveElement(node.ownerDocument) !== node) {\n    if (value == null) {\n      node.defaultValue = toString(node._wrapperState.initialValue);\n    } else if (node.defaultValue !== toString(value)) {\n      node.defaultValue = toString(value);\n    }\n  }\n}\n\nvar didWarnSelectedSetOnOption = false;\nvar didWarnInvalidChild = false;\n\nfunction flattenChildren(children) {\n  var content = ''; // Flatten children. We'll warn if they are invalid\n  // during validateProps() which runs for hydration too.\n  // Note that this would throw on non-element objects.\n  // Elements are stringified (which is normally irrelevant\n  // but matters for <fbt>).\n\n  React.Children.forEach(children, function (child) {\n    if (child == null) {\n      return;\n    }\n\n    content += child; // Note: we don't warn about invalid children here.\n    // Instead, this is done separately below so that\n    // it happens during the hydration code path too.\n  });\n  return content;\n}\n/**\n * Implements an <option> host component that warns when `selected` is set.\n */\n\n\nfunction validateProps(element, props) {\n  {\n    // This mirrors the code path above, but runs for hydration too.\n    // Warn about invalid children here so that client and hydration are consistent.\n    // TODO: this seems like it could cause a DEV-only throw for hydration\n    // if children contains a non-element object. We should try to avoid that.\n    if (typeof props.children === 'object' && props.children !== null) {\n      React.Children.forEach(props.children, function (child) {\n        if (child == null) {\n          return;\n        }\n\n        if (typeof child === 'string' || typeof child === 'number') {\n          return;\n        }\n\n        if (typeof child.type !== 'string') {\n          return;\n        }\n\n        if (!didWarnInvalidChild) {\n          didWarnInvalidChild = true;\n\n          error('Only strings and numbers are supported as <option> children.');\n        }\n      });\n    } // TODO: Remove support for `selected` in <option>.\n\n\n    if (props.selected != null && !didWarnSelectedSetOnOption) {\n      error('Use the `defaultValue` or `value` props on <select> instead of ' + 'setting `selected` on <option>.');\n\n      didWarnSelectedSetOnOption = true;\n    }\n  }\n}\nfunction postMountWrapper$1(element, props) {\n  // value=\"\" should make a value attribute (#6219)\n  if (props.value != null) {\n    element.setAttribute('value', toString(getToStringValue(props.value)));\n  }\n}\nfunction getHostProps$1(element, props) {\n  var hostProps = _assign({\n    children: undefined\n  }, props);\n\n  var content = flattenChildren(props.children);\n\n  if (content) {\n    hostProps.children = content;\n  }\n\n  return hostProps;\n}\n\nvar didWarnValueDefaultValue$1;\n\n{\n  didWarnValueDefaultValue$1 = false;\n}\n\nfunction getDeclarationErrorAddendum() {\n  var ownerName = getCurrentFiberOwnerNameInDevOrNull();\n\n  if (ownerName) {\n    return '\\n\\nCheck the render method of `' + ownerName + '`.';\n  }\n\n  return '';\n}\n\nvar valuePropNames = ['value', 'defaultValue'];\n/**\n * Validation function for `value` and `defaultValue`.\n */\n\nfunction checkSelectPropTypes(props) {\n  {\n    checkControlledValueProps('select', props);\n\n    for (var i = 0; i < valuePropNames.length; i++) {\n      var propName = valuePropNames[i];\n\n      if (props[propName] == null) {\n        continue;\n      }\n\n      var isArray = Array.isArray(props[propName]);\n\n      if (props.multiple && !isArray) {\n        error('The `%s` prop supplied to <select> must be an array if ' + '`multiple` is true.%s', propName, getDeclarationErrorAddendum());\n      } else if (!props.multiple && isArray) {\n        error('The `%s` prop supplied to <select> must be a scalar ' + 'value if `multiple` is false.%s', propName, getDeclarationErrorAddendum());\n      }\n    }\n  }\n}\n\nfunction updateOptions(node, multiple, propValue, setDefaultSelected) {\n  var options = node.options;\n\n  if (multiple) {\n    var selectedValues = propValue;\n    var selectedValue = {};\n\n    for (var i = 0; i < selectedValues.length; i++) {\n      // Prefix to avoid chaos with special keys.\n      selectedValue['$' + selectedValues[i]] = true;\n    }\n\n    for (var _i = 0; _i < options.length; _i++) {\n      var selected = selectedValue.hasOwnProperty('$' + options[_i].value);\n\n      if (options[_i].selected !== selected) {\n        options[_i].selected = selected;\n      }\n\n      if (selected && setDefaultSelected) {\n        options[_i].defaultSelected = true;\n      }\n    }\n  } else {\n    // Do not set `select.value` as exact behavior isn't consistent across all\n    // browsers for all cases.\n    var _selectedValue = toString(getToStringValue(propValue));\n\n    var defaultSelected = null;\n\n    for (var _i2 = 0; _i2 < options.length; _i2++) {\n      if (options[_i2].value === _selectedValue) {\n        options[_i2].selected = true;\n\n        if (setDefaultSelected) {\n          options[_i2].defaultSelected = true;\n        }\n\n        return;\n      }\n\n      if (defaultSelected === null && !options[_i2].disabled) {\n        defaultSelected = options[_i2];\n      }\n    }\n\n    if (defaultSelected !== null) {\n      defaultSelected.selected = true;\n    }\n  }\n}\n/**\n * Implements a <select> host component that allows optionally setting the\n * props `value` and `defaultValue`. If `multiple` is false, the prop must be a\n * stringable. If `multiple` is true, the prop must be an array of stringables.\n *\n * If `value` is not supplied (or null/undefined), user actions that change the\n * selected option will trigger updates to the rendered options.\n *\n * If it is supplied (and not null/undefined), the rendered options will not\n * update in response to user actions. Instead, the `value` prop must change in\n * order for the rendered options to update.\n *\n * If `defaultValue` is provided, any options with the supplied values will be\n * selected.\n */\n\n\nfunction getHostProps$2(element, props) {\n  return _assign({}, props, {\n    value: undefined\n  });\n}\nfunction initWrapperState$1(element, props) {\n  var node = element;\n\n  {\n    checkSelectPropTypes(props);\n  }\n\n  node._wrapperState = {\n    wasMultiple: !!props.multiple\n  };\n\n  {\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValueDefaultValue$1) {\n      error('Select elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled select ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components');\n\n      didWarnValueDefaultValue$1 = true;\n    }\n  }\n}\nfunction postMountWrapper$2(element, props) {\n  var node = element;\n  node.multiple = !!props.multiple;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  } else if (props.defaultValue != null) {\n    updateOptions(node, !!props.multiple, props.defaultValue, true);\n  }\n}\nfunction postUpdateWrapper(element, props) {\n  var node = element;\n  var wasMultiple = node._wrapperState.wasMultiple;\n  node._wrapperState.wasMultiple = !!props.multiple;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  } else if (wasMultiple !== !!props.multiple) {\n    // For simplicity, reapply `defaultValue` if `multiple` is toggled.\n    if (props.defaultValue != null) {\n      updateOptions(node, !!props.multiple, props.defaultValue, true);\n    } else {\n      // Revert the select back to its default unselected state.\n      updateOptions(node, !!props.multiple, props.multiple ? [] : '', false);\n    }\n  }\n}\nfunction restoreControlledState$1(element, props) {\n  var node = element;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  }\n}\n\nvar didWarnValDefaultVal = false;\n\n/**\n * Implements a <textarea> host component that allows setting `value`, and\n * `defaultValue`. This differs from the traditional DOM API because value is\n * usually set as PCDATA children.\n *\n * If `value` is not supplied (or null/undefined), user actions that affect the\n * value will trigger updates to the element.\n *\n * If `value` is supplied (and not null/undefined), the rendered element will\n * not trigger updates to the element. Instead, the `value` prop must change in\n * order for the rendered element to be updated.\n *\n * The rendered element will be initialized with an empty value, the prop\n * `defaultValue` if specified, or the children content (deprecated).\n */\nfunction getHostProps$3(element, props) {\n  var node = element;\n\n  if (!(props.dangerouslySetInnerHTML == null)) {\n    {\n      throw Error( \"`dangerouslySetInnerHTML` does not make sense on <textarea>.\" );\n    }\n  } // Always set children to the same thing. In IE9, the selection range will\n  // get reset if `textContent` is mutated.  We could add a check in setTextContent\n  // to only set the value if/when the value differs from the node value (which would\n  // completely solve this IE9 bug), but Sebastian+Sophie seemed to like this\n  // solution. The value can be a boolean or object so that's why it's forced\n  // to be a string.\n\n\n  var hostProps = _assign({}, props, {\n    value: undefined,\n    defaultValue: undefined,\n    children: toString(node._wrapperState.initialValue)\n  });\n\n  return hostProps;\n}\nfunction initWrapperState$2(element, props) {\n  var node = element;\n\n  {\n    checkControlledValueProps('textarea', props);\n\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValDefaultVal) {\n      error('%s contains a textarea with both value and defaultValue props. ' + 'Textarea elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled textarea ' + 'and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component');\n\n      didWarnValDefaultVal = true;\n    }\n  }\n\n  var initialValue = props.value; // Only bother fetching default value if we're going to use it\n\n  if (initialValue == null) {\n    var children = props.children,\n        defaultValue = props.defaultValue;\n\n    if (children != null) {\n      {\n        error('Use the `defaultValue` or `value` props instead of setting ' + 'children on <textarea>.');\n      }\n\n      {\n        if (!(defaultValue == null)) {\n          {\n            throw Error( \"If you supply `defaultValue` on a <textarea>, do not pass children.\" );\n          }\n        }\n\n        if (Array.isArray(children)) {\n          if (!(children.length <= 1)) {\n            {\n              throw Error( \"<textarea> can only have at most one child.\" );\n            }\n          }\n\n          children = children[0];\n        }\n\n        defaultValue = children;\n      }\n    }\n\n    if (defaultValue == null) {\n      defaultValue = '';\n    }\n\n    initialValue = defaultValue;\n  }\n\n  node._wrapperState = {\n    initialValue: getToStringValue(initialValue)\n  };\n}\nfunction updateWrapper$1(element, props) {\n  var node = element;\n  var value = getToStringValue(props.value);\n  var defaultValue = getToStringValue(props.defaultValue);\n\n  if (value != null) {\n    // Cast `value` to a string to ensure the value is set correctly. While\n    // browsers typically do this as necessary, jsdom doesn't.\n    var newValue = toString(value); // To avoid side effects (such as losing text selection), only set value if changed\n\n    if (newValue !== node.value) {\n      node.value = newValue;\n    }\n\n    if (props.defaultValue == null && node.defaultValue !== newValue) {\n      node.defaultValue = newValue;\n    }\n  }\n\n  if (defaultValue != null) {\n    node.defaultValue = toString(defaultValue);\n  }\n}\nfunction postMountWrapper$3(element, props) {\n  var node = element; // This is in postMount because we need access to the DOM node, which is not\n  // available until after the component has mounted.\n\n  var textContent = node.textContent; // Only set node.value if textContent is equal to the expected\n  // initial value. In IE10/IE11 there is a bug where the placeholder attribute\n  // will populate textContent as well.\n  // https://developer.microsoft.com/microsoft-edge/platform/issues/101525/\n\n  if (textContent === node._wrapperState.initialValue) {\n    if (textContent !== '' && textContent !== null) {\n      node.value = textContent;\n    }\n  }\n}\nfunction restoreControlledState$2(element, props) {\n  // DOM component is still mounted; update\n  updateWrapper$1(element, props);\n}\n\nvar HTML_NAMESPACE = 'http://www.w3.org/1999/xhtml';\nvar MATH_NAMESPACE = 'http://www.w3.org/1998/Math/MathML';\nvar SVG_NAMESPACE = 'http://www.w3.org/2000/svg';\nvar Namespaces = {\n  html: HTML_NAMESPACE,\n  mathml: MATH_NAMESPACE,\n  svg: SVG_NAMESPACE\n}; // Assumes there is no parent namespace.\n\nfunction getIntrinsicNamespace(type) {\n  switch (type) {\n    case 'svg':\n      return SVG_NAMESPACE;\n\n    case 'math':\n      return MATH_NAMESPACE;\n\n    default:\n      return HTML_NAMESPACE;\n  }\n}\nfunction getChildNamespace(parentNamespace, type) {\n  if (parentNamespace == null || parentNamespace === HTML_NAMESPACE) {\n    // No (or default) parent namespace: potential entry point.\n    return getIntrinsicNamespace(type);\n  }\n\n  if (parentNamespace === SVG_NAMESPACE && type === 'foreignObject') {\n    // We're leaving SVG.\n    return HTML_NAMESPACE;\n  } // By default, pass namespace below.\n\n\n  return parentNamespace;\n}\n\n/* globals MSApp */\n\n/**\n * Create a function which has 'unsafe' privileges (required by windows8 apps)\n */\nvar createMicrosoftUnsafeLocalFunction = function (func) {\n  if (typeof MSApp !== 'undefined' && MSApp.execUnsafeLocalFunction) {\n    return function (arg0, arg1, arg2, arg3) {\n      MSApp.execUnsafeLocalFunction(function () {\n        return func(arg0, arg1, arg2, arg3);\n      });\n    };\n  } else {\n    return func;\n  }\n};\n\nvar reusableSVGContainer;\n/**\n * Set the innerHTML property of a node\n *\n * @param {DOMElement} node\n * @param {string} html\n * @internal\n */\n\nvar setInnerHTML = createMicrosoftUnsafeLocalFunction(function (node, html) {\n  if (node.namespaceURI === Namespaces.svg) {\n\n    if (!('innerHTML' in node)) {\n      // IE does not have innerHTML for SVG nodes, so instead we inject the\n      // new markup in a temp node and then move the child nodes across into\n      // the target node\n      reusableSVGContainer = reusableSVGContainer || document.createElement('div');\n      reusableSVGContainer.innerHTML = '<svg>' + html.valueOf().toString() + '</svg>';\n      var svgNode = reusableSVGContainer.firstChild;\n\n      while (node.firstChild) {\n        node.removeChild(node.firstChild);\n      }\n\n      while (svgNode.firstChild) {\n        node.appendChild(svgNode.firstChild);\n      }\n\n      return;\n    }\n  }\n\n  node.innerHTML = html;\n});\n\n/**\n * HTML nodeType values that represent the type of the node\n */\nvar ELEMENT_NODE = 1;\nvar TEXT_NODE = 3;\nvar COMMENT_NODE = 8;\nvar DOCUMENT_NODE = 9;\nvar DOCUMENT_FRAGMENT_NODE = 11;\n\n/**\n * Set the textContent property of a node. For text updates, it's faster\n * to set the `nodeValue` of the Text node directly instead of using\n * `.textContent` which will remove the existing node and create a new one.\n *\n * @param {DOMElement} node\n * @param {string} text\n * @internal\n */\n\nvar setTextContent = function (node, text) {\n  if (text) {\n    var firstChild = node.firstChild;\n\n    if (firstChild && firstChild === node.lastChild && firstChild.nodeType === TEXT_NODE) {\n      firstChild.nodeValue = text;\n      return;\n    }\n  }\n\n  node.textContent = text;\n};\n\n// List derived from Gecko source code:\n// https://github.com/mozilla/gecko-dev/blob/4e638efc71/layout/style/test/property_database.js\nvar shorthandToLonghand = {\n  animation: ['animationDelay', 'animationDirection', 'animationDuration', 'animationFillMode', 'animationIterationCount', 'animationName', 'animationPlayState', 'animationTimingFunction'],\n  background: ['backgroundAttachment', 'backgroundClip', 'backgroundColor', 'backgroundImage', 'backgroundOrigin', 'backgroundPositionX', 'backgroundPositionY', 'backgroundRepeat', 'backgroundSize'],\n  backgroundPosition: ['backgroundPositionX', 'backgroundPositionY'],\n  border: ['borderBottomColor', 'borderBottomStyle', 'borderBottomWidth', 'borderImageOutset', 'borderImageRepeat', 'borderImageSlice', 'borderImageSource', 'borderImageWidth', 'borderLeftColor', 'borderLeftStyle', 'borderLeftWidth', 'borderRightColor', 'borderRightStyle', 'borderRightWidth', 'borderTopColor', 'borderTopStyle', 'borderTopWidth'],\n  borderBlockEnd: ['borderBlockEndColor', 'borderBlockEndStyle', 'borderBlockEndWidth'],\n  borderBlockStart: ['borderBlockStartColor', 'borderBlockStartStyle', 'borderBlockStartWidth'],\n  borderBottom: ['borderBottomColor', 'borderBottomStyle', 'borderBottomWidth'],\n  borderColor: ['borderBottomColor', 'borderLeftColor', 'borderRightColor', 'borderTopColor'],\n  borderImage: ['borderImageOutset', 'borderImageRepeat', 'borderImageSlice', 'borderImageSource', 'borderImageWidth'],\n  borderInlineEnd: ['borderInlineEndColor', 'borderInlineEndStyle', 'borderInlineEndWidth'],\n  borderInlineStart: ['borderInlineStartColor', 'borderInlineStartStyle', 'borderInlineStartWidth'],\n  borderLeft: ['borderLeftColor', 'borderLeftStyle', 'borderLeftWidth'],\n  borderRadius: ['borderBottomLeftRadius', 'borderBottomRightRadius', 'borderTopLeftRadius', 'borderTopRightRadius'],\n  borderRight: ['borderRightColor', 'borderRightStyle', 'borderRightWidth'],\n  borderStyle: ['borderBottomStyle', 'borderLeftStyle', 'borderRightStyle', 'borderTopStyle'],\n  borderTop: ['borderTopColor', 'borderTopStyle', 'borderTopWidth'],\n  borderWidth: ['borderBottomWidth', 'borderLeftWidth', 'borderRightWidth', 'borderTopWidth'],\n  columnRule: ['columnRuleColor', 'columnRuleStyle', 'columnRuleWidth'],\n  columns: ['columnCount', 'columnWidth'],\n  flex: ['flexBasis', 'flexGrow', 'flexShrink'],\n  flexFlow: ['flexDirection', 'flexWrap'],\n  font: ['fontFamily', 'fontFeatureSettings', 'fontKerning', 'fontLanguageOverride', 'fontSize', 'fontSizeAdjust', 'fontStretch', 'fontStyle', 'fontVariant', 'fontVariantAlternates', 'fontVariantCaps', 'fontVariantEastAsian', 'fontVariantLigatures', 'fontVariantNumeric', 'fontVariantPosition', 'fontWeight', 'lineHeight'],\n  fontVariant: ['fontVariantAlternates', 'fontVariantCaps', 'fontVariantEastAsian', 'fontVariantLigatures', 'fontVariantNumeric', 'fontVariantPosition'],\n  gap: ['columnGap', 'rowGap'],\n  grid: ['gridAutoColumns', 'gridAutoFlow', 'gridAutoRows', 'gridTemplateAreas', 'gridTemplateColumns', 'gridTemplateRows'],\n  gridArea: ['gridColumnEnd', 'gridColumnStart', 'gridRowEnd', 'gridRowStart'],\n  gridColumn: ['gridColumnEnd', 'gridColumnStart'],\n  gridColumnGap: ['columnGap'],\n  gridGap: ['columnGap', 'rowGap'],\n  gridRow: ['gridRowEnd', 'gridRowStart'],\n  gridRowGap: ['rowGap'],\n  gridTemplate: ['gridTemplateAreas', 'gridTemplateColumns', 'gridTemplateRows'],\n  listStyle: ['listStyleImage', 'listStylePosition', 'listStyleType'],\n  margin: ['marginBottom', 'marginLeft', 'marginRight', 'marginTop'],\n  marker: ['markerEnd', 'markerMid', 'markerStart'],\n  mask: ['maskClip', 'maskComposite', 'maskImage', 'maskMode', 'maskOrigin', 'maskPositionX', 'maskPositionY', 'maskRepeat', 'maskSize'],\n  maskPosition: ['maskPositionX', 'maskPositionY'],\n  outline: ['outlineColor', 'outlineStyle', 'outlineWidth'],\n  overflow: ['overflowX', 'overflowY'],\n  padding: ['paddingBottom', 'paddingLeft', 'paddingRight', 'paddingTop'],\n  placeContent: ['alignContent', 'justifyContent'],\n  placeItems: ['alignItems', 'justifyItems'],\n  placeSelf: ['alignSelf', 'justifySelf'],\n  textDecoration: ['textDecorationColor', 'textDecorationLine', 'textDecorationStyle'],\n  textEmphasis: ['textEmphasisColor', 'textEmphasisStyle'],\n  transition: ['transitionDelay', 'transitionDuration', 'transitionProperty', 'transitionTimingFunction'],\n  wordWrap: ['overflowWrap']\n};\n\n/**\n * CSS properties which accept numbers but are not in units of \"px\".\n */\nvar isUnitlessNumber = {\n  animationIterationCount: true,\n  borderImageOutset: true,\n  borderImageSlice: true,\n  borderImageWidth: true,\n  boxFlex: true,\n  boxFlexGroup: true,\n  boxOrdinalGroup: true,\n  columnCount: true,\n  columns: true,\n  flex: true,\n  flexGrow: true,\n  flexPositive: true,\n  flexShrink: true,\n  flexNegative: true,\n  flexOrder: true,\n  gridArea: true,\n  gridRow: true,\n  gridRowEnd: true,\n  gridRowSpan: true,\n  gridRowStart: true,\n  gridColumn: true,\n  gridColumnEnd: true,\n  gridColumnSpan: true,\n  gridColumnStart: true,\n  fontWeight: true,\n  lineClamp: true,\n  lineHeight: true,\n  opacity: true,\n  order: true,\n  orphans: true,\n  tabSize: true,\n  widows: true,\n  zIndex: true,\n  zoom: true,\n  // SVG-related properties\n  fillOpacity: true,\n  floodOpacity: true,\n  stopOpacity: true,\n  strokeDasharray: true,\n  strokeDashoffset: true,\n  strokeMiterlimit: true,\n  strokeOpacity: true,\n  strokeWidth: true\n};\n/**\n * @param {string} prefix vendor-specific prefix, eg: Webkit\n * @param {string} key style name, eg: transitionDuration\n * @return {string} style name prefixed with `prefix`, properly camelCased, eg:\n * WebkitTransitionDuration\n */\n\nfunction prefixKey(prefix, key) {\n  return prefix + key.charAt(0).toUpperCase() + key.substring(1);\n}\n/**\n * Support style names that may come passed in prefixed by adding permutations\n * of vendor prefixes.\n */\n\n\nvar prefixes = ['Webkit', 'ms', 'Moz', 'O']; // Using Object.keys here, or else the vanilla for-in loop makes IE8 go into an\n// infinite loop, because it iterates over the newly added props too.\n\nObject.keys(isUnitlessNumber).forEach(function (prop) {\n  prefixes.forEach(function (prefix) {\n    isUnitlessNumber[prefixKey(prefix, prop)] = isUnitlessNumber[prop];\n  });\n});\n\n/**\n * Convert a value into the proper css writable value. The style name `name`\n * should be logical (no hyphens), as specified\n * in `CSSProperty.isUnitlessNumber`.\n *\n * @param {string} name CSS property name such as `topMargin`.\n * @param {*} value CSS property value such as `10px`.\n * @return {string} Normalized style value with dimensions applied.\n */\n\nfunction dangerousStyleValue(name, value, isCustomProperty) {\n  // Note that we've removed escapeTextForBrowser() calls here since the\n  // whole string will be escaped when the attribute is injected into\n  // the markup. If you provide unsafe user data here they can inject\n  // arbitrary CSS which may be problematic (I couldn't repro this):\n  // https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet\n  // http://www.thespanner.co.uk/2007/11/26/ultimate-xss-css-injection/\n  // This is not an XSS hole but instead a potential CSS injection issue\n  // which has lead to a greater discussion about how we're going to\n  // trust URLs moving forward. See #2115901\n  var isEmpty = value == null || typeof value === 'boolean' || value === '';\n\n  if (isEmpty) {\n    return '';\n  }\n\n  if (!isCustomProperty && typeof value === 'number' && value !== 0 && !(isUnitlessNumber.hasOwnProperty(name) && isUnitlessNumber[name])) {\n    return value + 'px'; // Presumes implicit 'px' suffix for unitless numbers\n  }\n\n  return ('' + value).trim();\n}\n\nvar uppercasePattern = /([A-Z])/g;\nvar msPattern = /^ms-/;\n/**\n * Hyphenates a camelcased CSS property name, for example:\n *\n *   > hyphenateStyleName('backgroundColor')\n *   < \"background-color\"\n *   > hyphenateStyleName('MozTransition')\n *   < \"-moz-transition\"\n *   > hyphenateStyleName('msTransition')\n *   < \"-ms-transition\"\n *\n * As Modernizr suggests (http://modernizr.com/docs/#prefixed), an `ms` prefix\n * is converted to `-ms-`.\n */\n\nfunction hyphenateStyleName(name) {\n  return name.replace(uppercasePattern, '-$1').toLowerCase().replace(msPattern, '-ms-');\n}\n\nvar warnValidStyle = function () {};\n\n{\n  // 'msTransform' is correct, but the other prefixes should be capitalized\n  var badVendoredStyleNamePattern = /^(?:webkit|moz|o)[A-Z]/;\n  var msPattern$1 = /^-ms-/;\n  var hyphenPattern = /-(.)/g; // style values shouldn't contain a semicolon\n\n  var badStyleValueWithSemicolonPattern = /;\\s*$/;\n  var warnedStyleNames = {};\n  var warnedStyleValues = {};\n  var warnedForNaNValue = false;\n  var warnedForInfinityValue = false;\n\n  var camelize = function (string) {\n    return string.replace(hyphenPattern, function (_, character) {\n      return character.toUpperCase();\n    });\n  };\n\n  var warnHyphenatedStyleName = function (name) {\n    if (warnedStyleNames.hasOwnProperty(name) && warnedStyleNames[name]) {\n      return;\n    }\n\n    warnedStyleNames[name] = true;\n\n    error('Unsupported style property %s. Did you mean %s?', name, // As Andi Smith suggests\n    // (http://www.andismith.com/blog/2012/02/modernizr-prefixed/), an `-ms` prefix\n    // is converted to lowercase `ms`.\n    camelize(name.replace(msPattern$1, 'ms-')));\n  };\n\n  var warnBadVendoredStyleName = function (name) {\n    if (warnedStyleNames.hasOwnProperty(name) && warnedStyleNames[name]) {\n      return;\n    }\n\n    warnedStyleNames[name] = true;\n\n    error('Unsupported vendor-prefixed style property %s. Did you mean %s?', name, name.charAt(0).toUpperCase() + name.slice(1));\n  };\n\n  var warnStyleValueWithSemicolon = function (name, value) {\n    if (warnedStyleValues.hasOwnProperty(value) && warnedStyleValues[value]) {\n      return;\n    }\n\n    warnedStyleValues[value] = true;\n\n    error(\"Style property values shouldn't contain a semicolon. \" + 'Try \"%s: %s\" instead.', name, value.replace(badStyleValueWithSemicolonPattern, ''));\n  };\n\n  var warnStyleValueIsNaN = function (name, value) {\n    if (warnedForNaNValue) {\n      return;\n    }\n\n    warnedForNaNValue = true;\n\n    error('`NaN` is an invalid value for the `%s` css style property.', name);\n  };\n\n  var warnStyleValueIsInfinity = function (name, value) {\n    if (warnedForInfinityValue) {\n      return;\n    }\n\n    warnedForInfinityValue = true;\n\n    error('`Infinity` is an invalid value for the `%s` css style property.', name);\n  };\n\n  warnValidStyle = function (name, value) {\n    if (name.indexOf('-') > -1) {\n      warnHyphenatedStyleName(name);\n    } else if (badVendoredStyleNamePattern.test(name)) {\n      warnBadVendoredStyleName(name);\n    } else if (badStyleValueWithSemicolonPattern.test(value)) {\n      warnStyleValueWithSemicolon(name, value);\n    }\n\n    if (typeof value === 'number') {\n      if (isNaN(value)) {\n        warnStyleValueIsNaN(name, value);\n      } else if (!isFinite(value)) {\n        warnStyleValueIsInfinity(name, value);\n      }\n    }\n  };\n}\n\nvar warnValidStyle$1 = warnValidStyle;\n\n/**\n * Operations for dealing with CSS properties.\n */\n\n/**\n * This creates a string that is expected to be equivalent to the style\n * attribute generated by server-side rendering. It by-passes warnings and\n * security checks so it's not safe to use this value for anything other than\n * comparison. It is only used in DEV for SSR validation.\n */\n\nfunction createDangerousStringForStyles(styles) {\n  {\n    var serialized = '';\n    var delimiter = '';\n\n    for (var styleName in styles) {\n      if (!styles.hasOwnProperty(styleName)) {\n        continue;\n      }\n\n      var styleValue = styles[styleName];\n\n      if (styleValue != null) {\n        var isCustomProperty = styleName.indexOf('--') === 0;\n        serialized += delimiter + (isCustomProperty ? styleName : hyphenateStyleName(styleName)) + ':';\n        serialized += dangerousStyleValue(styleName, styleValue, isCustomProperty);\n        delimiter = ';';\n      }\n    }\n\n    return serialized || null;\n  }\n}\n/**\n * Sets the value for multiple styles on a node.  If a value is specified as\n * '' (empty string), the corresponding style property will be unset.\n *\n * @param {DOMElement} node\n * @param {object} styles\n */\n\nfunction setValueForStyles(node, styles) {\n  var style = node.style;\n\n  for (var styleName in styles) {\n    if (!styles.hasOwnProperty(styleName)) {\n      continue;\n    }\n\n    var isCustomProperty = styleName.indexOf('--') === 0;\n\n    {\n      if (!isCustomProperty) {\n        warnValidStyle$1(styleName, styles[styleName]);\n      }\n    }\n\n    var styleValue = dangerousStyleValue(styleName, styles[styleName], isCustomProperty);\n\n    if (styleName === 'float') {\n      styleName = 'cssFloat';\n    }\n\n    if (isCustomProperty) {\n      style.setProperty(styleName, styleValue);\n    } else {\n      style[styleName] = styleValue;\n    }\n  }\n}\n\nfunction isValueEmpty(value) {\n  return value == null || typeof value === 'boolean' || value === '';\n}\n/**\n * Given {color: 'red', overflow: 'hidden'} returns {\n *   color: 'color',\n *   overflowX: 'overflow',\n *   overflowY: 'overflow',\n * }. This can be read as \"the overflowY property was set by the overflow\n * shorthand\". That is, the values are the property that each was derived from.\n */\n\n\nfunction expandShorthandMap(styles) {\n  var expanded = {};\n\n  for (var key in styles) {\n    var longhands = shorthandToLonghand[key] || [key];\n\n    for (var i = 0; i < longhands.length; i++) {\n      expanded[longhands[i]] = key;\n    }\n  }\n\n  return expanded;\n}\n/**\n * When mixing shorthand and longhand property names, we warn during updates if\n * we expect an incorrect result to occur. In particular, we warn for:\n *\n * Updating a shorthand property (longhand gets overwritten):\n *   {font: 'foo', fontVariant: 'bar'} -> {font: 'baz', fontVariant: 'bar'}\n *   becomes .style.font = 'baz'\n * Removing a shorthand property (longhand gets lost too):\n *   {font: 'foo', fontVariant: 'bar'} -> {fontVariant: 'bar'}\n *   becomes .style.font = ''\n * Removing a longhand property (should revert to shorthand; doesn't):\n *   {font: 'foo', fontVariant: 'bar'} -> {font: 'foo'}\n *   becomes .style.fontVariant = ''\n */\n\n\nfunction validateShorthandPropertyCollisionInDev(styleUpdates, nextStyles) {\n  {\n    if (!nextStyles) {\n      return;\n    }\n\n    var expandedUpdates = expandShorthandMap(styleUpdates);\n    var expandedStyles = expandShorthandMap(nextStyles);\n    var warnedAbout = {};\n\n    for (var key in expandedUpdates) {\n      var originalKey = expandedUpdates[key];\n      var correctOriginalKey = expandedStyles[key];\n\n      if (correctOriginalKey && originalKey !== correctOriginalKey) {\n        var warningKey = originalKey + ',' + correctOriginalKey;\n\n        if (warnedAbout[warningKey]) {\n          continue;\n        }\n\n        warnedAbout[warningKey] = true;\n\n        error('%s a style property during rerender (%s) when a ' + 'conflicting property is set (%s) can lead to styling bugs. To ' + \"avoid this, don't mix shorthand and non-shorthand properties \" + 'for the same value; instead, replace the shorthand with ' + 'separate values.', isValueEmpty(styleUpdates[originalKey]) ? 'Removing' : 'Updating', originalKey, correctOriginalKey);\n      }\n    }\n  }\n}\n\n// For HTML, certain tags should omit their close tag. We keep a list for\n// those special-case tags.\nvar omittedCloseTags = {\n  area: true,\n  base: true,\n  br: true,\n  col: true,\n  embed: true,\n  hr: true,\n  img: true,\n  input: true,\n  keygen: true,\n  link: true,\n  meta: true,\n  param: true,\n  source: true,\n  track: true,\n  wbr: true // NOTE: menuitem's close tag should be omitted, but that causes problems.\n\n};\n\n// `omittedCloseTags` except that `menuitem` should still have its closing tag.\n\nvar voidElementTags = _assign({\n  menuitem: true\n}, omittedCloseTags);\n\nvar HTML = '__html';\n\nfunction assertValidProps(tag, props) {\n  if (!props) {\n    return;\n  } // Note the use of `==` which checks for null or undefined.\n\n\n  if (voidElementTags[tag]) {\n    if (!(props.children == null && props.dangerouslySetInnerHTML == null)) {\n      {\n        throw Error( tag + \" is a void element tag and must neither have `children` nor use `dangerouslySetInnerHTML`.\" );\n      }\n    }\n  }\n\n  if (props.dangerouslySetInnerHTML != null) {\n    if (!(props.children == null)) {\n      {\n        throw Error( \"Can only set one of `children` or `props.dangerouslySetInnerHTML`.\" );\n      }\n    }\n\n    if (!(typeof props.dangerouslySetInnerHTML === 'object' && HTML in props.dangerouslySetInnerHTML)) {\n      {\n        throw Error( \"`props.dangerouslySetInnerHTML` must be in the form `{__html: ...}`. Please visit https://reactjs.org/link/dangerously-set-inner-html for more information.\" );\n      }\n    }\n  }\n\n  {\n    if (!props.suppressContentEditableWarning && props.contentEditable && props.children != null) {\n      error('A component is `contentEditable` and contains `children` managed by ' + 'React. It is now your responsibility to guarantee that none of ' + 'those nodes are unexpectedly modified or duplicated. This is ' + 'probably not intentional.');\n    }\n  }\n\n  if (!(props.style == null || typeof props.style === 'object')) {\n    {\n      throw Error( \"The `style` prop expects a mapping from style properties to values, not a string. For example, style={{marginRight: spacing + 'em'}} when using JSX.\" );\n    }\n  }\n}\n\nfunction isCustomComponent(tagName, props) {\n  if (tagName.indexOf('-') === -1) {\n    return typeof props.is === 'string';\n  }\n\n  switch (tagName) {\n    // These are reserved SVG and MathML elements.\n    // We don't mind this list too much because we expect it to never grow.\n    // The alternative is to track the namespace in a few places which is convoluted.\n    // https://w3c.github.io/webcomponents/spec/custom/#custom-elements-core-concepts\n    case 'annotation-xml':\n    case 'color-profile':\n    case 'font-face':\n    case 'font-face-src':\n    case 'font-face-uri':\n    case 'font-face-format':\n    case 'font-face-name':\n    case 'missing-glyph':\n      return false;\n\n    default:\n      return true;\n  }\n}\n\n// When adding attributes to the HTML or SVG allowed attribute list, be sure to\n// also add them to this module to ensure casing and incorrect name\n// warnings.\nvar possibleStandardNames = {\n  // HTML\n  accept: 'accept',\n  acceptcharset: 'acceptCharset',\n  'accept-charset': 'acceptCharset',\n  accesskey: 'accessKey',\n  action: 'action',\n  allowfullscreen: 'allowFullScreen',\n  alt: 'alt',\n  as: 'as',\n  async: 'async',\n  autocapitalize: 'autoCapitalize',\n  autocomplete: 'autoComplete',\n  autocorrect: 'autoCorrect',\n  autofocus: 'autoFocus',\n  autoplay: 'autoPlay',\n  autosave: 'autoSave',\n  capture: 'capture',\n  cellpadding: 'cellPadding',\n  cellspacing: 'cellSpacing',\n  challenge: 'challenge',\n  charset: 'charSet',\n  checked: 'checked',\n  children: 'children',\n  cite: 'cite',\n  class: 'className',\n  classid: 'classID',\n  classname: 'className',\n  cols: 'cols',\n  colspan: 'colSpan',\n  content: 'content',\n  contenteditable: 'contentEditable',\n  contextmenu: 'contextMenu',\n  controls: 'controls',\n  controlslist: 'controlsList',\n  coords: 'coords',\n  crossorigin: 'crossOrigin',\n  dangerouslysetinnerhtml: 'dangerouslySetInnerHTML',\n  data: 'data',\n  datetime: 'dateTime',\n  default: 'default',\n  defaultchecked: 'defaultChecked',\n  defaultvalue: 'defaultValue',\n  defer: 'defer',\n  dir: 'dir',\n  disabled: 'disabled',\n  disablepictureinpicture: 'disablePictureInPicture',\n  disableremoteplayback: 'disableRemotePlayback',\n  download: 'download',\n  draggable: 'draggable',\n  enctype: 'encType',\n  enterkeyhint: 'enterKeyHint',\n  for: 'htmlFor',\n  form: 'form',\n  formmethod: 'formMethod',\n  formaction: 'formAction',\n  formenctype: 'formEncType',\n  formnovalidate: 'formNoValidate',\n  formtarget: 'formTarget',\n  frameborder: 'frameBorder',\n  headers: 'headers',\n  height: 'height',\n  hidden: 'hidden',\n  high: 'high',\n  href: 'href',\n  hreflang: 'hrefLang',\n  htmlfor: 'htmlFor',\n  httpequiv: 'httpEquiv',\n  'http-equiv': 'httpEquiv',\n  icon: 'icon',\n  id: 'id',\n  innerhtml: 'innerHTML',\n  inputmode: 'inputMode',\n  integrity: 'integrity',\n  is: 'is',\n  itemid: 'itemID',\n  itemprop: 'itemProp',\n  itemref: 'itemRef',\n  itemscope: 'itemScope',\n  itemtype: 'itemType',\n  keyparams: 'keyParams',\n  keytype: 'keyType',\n  kind: 'kind',\n  label: 'label',\n  lang: 'lang',\n  list: 'list',\n  loop: 'loop',\n  low: 'low',\n  manifest: 'manifest',\n  marginwidth: 'marginWidth',\n  marginheight: 'marginHeight',\n  max: 'max',\n  maxlength: 'maxLength',\n  media: 'media',\n  mediagroup: 'mediaGroup',\n  method: 'method',\n  min: 'min',\n  minlength: 'minLength',\n  multiple: 'multiple',\n  muted: 'muted',\n  name: 'name',\n  nomodule: 'noModule',\n  nonce: 'nonce',\n  novalidate: 'noValidate',\n  open: 'open',\n  optimum: 'optimum',\n  pattern: 'pattern',\n  placeholder: 'placeholder',\n  playsinline: 'playsInline',\n  poster: 'poster',\n  preload: 'preload',\n  profile: 'profile',\n  radiogroup: 'radioGroup',\n  readonly: 'readOnly',\n  referrerpolicy: 'referrerPolicy',\n  rel: 'rel',\n  required: 'required',\n  reversed: 'reversed',\n  role: 'role',\n  rows: 'rows',\n  rowspan: 'rowSpan',\n  sandbox: 'sandbox',\n  scope: 'scope',\n  scoped: 'scoped',\n  scrolling: 'scrolling',\n  seamless: 'seamless',\n  selected: 'selected',\n  shape: 'shape',\n  size: 'size',\n  sizes: 'sizes',\n  span: 'span',\n  spellcheck: 'spellCheck',\n  src: 'src',\n  srcdoc: 'srcDoc',\n  srclang: 'srcLang',\n  srcset: 'srcSet',\n  start: 'start',\n  step: 'step',\n  style: 'style',\n  summary: 'summary',\n  tabindex: 'tabIndex',\n  target: 'target',\n  title: 'title',\n  type: 'type',\n  usemap: 'useMap',\n  value: 'value',\n  width: 'width',\n  wmode: 'wmode',\n  wrap: 'wrap',\n  // SVG\n  about: 'about',\n  accentheight: 'accentHeight',\n  'accent-height': 'accentHeight',\n  accumulate: 'accumulate',\n  additive: 'additive',\n  alignmentbaseline: 'alignmentBaseline',\n  'alignment-baseline': 'alignmentBaseline',\n  allowreorder: 'allowReorder',\n  alphabetic: 'alphabetic',\n  amplitude: 'amplitude',\n  arabicform: 'arabicForm',\n  'arabic-form': 'arabicForm',\n  ascent: 'ascent',\n  attributename: 'attributeName',\n  attributetype: 'attributeType',\n  autoreverse: 'autoReverse',\n  azimuth: 'azimuth',\n  basefrequency: 'baseFrequency',\n  baselineshift: 'baselineShift',\n  'baseline-shift': 'baselineShift',\n  baseprofile: 'baseProfile',\n  bbox: 'bbox',\n  begin: 'begin',\n  bias: 'bias',\n  by: 'by',\n  calcmode: 'calcMode',\n  capheight: 'capHeight',\n  'cap-height': 'capHeight',\n  clip: 'clip',\n  clippath: 'clipPath',\n  'clip-path': 'clipPath',\n  clippathunits: 'clipPathUnits',\n  cliprule: 'clipRule',\n  'clip-rule': 'clipRule',\n  color: 'color',\n  colorinterpolation: 'colorInterpolation',\n  'color-interpolation': 'colorInterpolation',\n  colorinterpolationfilters: 'colorInterpolationFilters',\n  'color-interpolation-filters': 'colorInterpolationFilters',\n  colorprofile: 'colorProfile',\n  'color-profile': 'colorProfile',\n  colorrendering: 'colorRendering',\n  'color-rendering': 'colorRendering',\n  contentscripttype: 'contentScriptType',\n  contentstyletype: 'contentStyleType',\n  cursor: 'cursor',\n  cx: 'cx',\n  cy: 'cy',\n  d: 'd',\n  datatype: 'datatype',\n  decelerate: 'decelerate',\n  descent: 'descent',\n  diffuseconstant: 'diffuseConstant',\n  direction: 'direction',\n  display: 'display',\n  divisor: 'divisor',\n  dominantbaseline: 'dominantBaseline',\n  'dominant-baseline': 'dominantBaseline',\n  dur: 'dur',\n  dx: 'dx',\n  dy: 'dy',\n  edgemode: 'edgeMode',\n  elevation: 'elevation',\n  enablebackground: 'enableBackground',\n  'enable-background': 'enableBackground',\n  end: 'end',\n  exponent: 'exponent',\n  externalresourcesrequired: 'externalResourcesRequired',\n  fill: 'fill',\n  fillopacity: 'fillOpacity',\n  'fill-opacity': 'fillOpacity',\n  fillrule: 'fillRule',\n  'fill-rule': 'fillRule',\n  filter: 'filter',\n  filterres: 'filterRes',\n  filterunits: 'filterUnits',\n  floodopacity: 'floodOpacity',\n  'flood-opacity': 'floodOpacity',\n  floodcolor: 'floodColor',\n  'flood-color': 'floodColor',\n  focusable: 'focusable',\n  fontfamily: 'fontFamily',\n  'font-family': 'fontFamily',\n  fontsize: 'fontSize',\n  'font-size': 'fontSize',\n  fontsizeadjust: 'fontSizeAdjust',\n  'font-size-adjust': 'fontSizeAdjust',\n  fontstretch: 'fontStretch',\n  'font-stretch': 'fontStretch',\n  fontstyle: 'fontStyle',\n  'font-style': 'fontStyle',\n  fontvariant: 'fontVariant',\n  'font-variant': 'fontVariant',\n  fontweight: 'fontWeight',\n  'font-weight': 'fontWeight',\n  format: 'format',\n  from: 'from',\n  fx: 'fx',\n  fy: 'fy',\n  g1: 'g1',\n  g2: 'g2',\n  glyphname: 'glyphName',\n  'glyph-name': 'glyphName',\n  glyphorientationhorizontal: 'glyphOrientationHorizontal',\n  'glyph-orientation-horizontal': 'glyphOrientationHorizontal',\n  glyphorientationvertical: 'glyphOrientationVertical',\n  'glyph-orientation-vertical': 'glyphOrientationVertical',\n  glyphref: 'glyphRef',\n  gradienttransform: 'gradientTransform',\n  gradientunits: 'gradientUnits',\n  hanging: 'hanging',\n  horizadvx: 'horizAdvX',\n  'horiz-adv-x': 'horizAdvX',\n  horizoriginx: 'horizOriginX',\n  'horiz-origin-x': 'horizOriginX',\n  ideographic: 'ideographic',\n  imagerendering: 'imageRendering',\n  'image-rendering': 'imageRendering',\n  in2: 'in2',\n  in: 'in',\n  inlist: 'inlist',\n  intercept: 'intercept',\n  k1: 'k1',\n  k2: 'k2',\n  k3: 'k3',\n  k4: 'k4',\n  k: 'k',\n  kernelmatrix: 'kernelMatrix',\n  kernelunitlength: 'kernelUnitLength',\n  kerning: 'kerning',\n  keypoints: 'keyPoints',\n  keysplines: 'keySplines',\n  keytimes: 'keyTimes',\n  lengthadjust: 'lengthAdjust',\n  letterspacing: 'letterSpacing',\n  'letter-spacing': 'letterSpacing',\n  lightingcolor: 'lightingColor',\n  'lighting-color': 'lightingColor',\n  limitingconeangle: 'limitingConeAngle',\n  local: 'local',\n  markerend: 'markerEnd',\n  'marker-end': 'markerEnd',\n  markerheight: 'markerHeight',\n  markermid: 'markerMid',\n  'marker-mid': 'markerMid',\n  markerstart: 'markerStart',\n  'marker-start': 'markerStart',\n  markerunits: 'markerUnits',\n  markerwidth: 'markerWidth',\n  mask: 'mask',\n  maskcontentunits: 'maskContentUnits',\n  maskunits: 'maskUnits',\n  mathematical: 'mathematical',\n  mode: 'mode',\n  numoctaves: 'numOctaves',\n  offset: 'offset',\n  opacity: 'opacity',\n  operator: 'operator',\n  order: 'order',\n  orient: 'orient',\n  orientation: 'orientation',\n  origin: 'origin',\n  overflow: 'overflow',\n  overlineposition: 'overlinePosition',\n  'overline-position': 'overlinePosition',\n  overlinethickness: 'overlineThickness',\n  'overline-thickness': 'overlineThickness',\n  paintorder: 'paintOrder',\n  'paint-order': 'paintOrder',\n  panose1: 'panose1',\n  'panose-1': 'panose1',\n  pathlength: 'pathLength',\n  patterncontentunits: 'patternContentUnits',\n  patterntransform: 'patternTransform',\n  patternunits: 'patternUnits',\n  pointerevents: 'pointerEvents',\n  'pointer-events': 'pointerEvents',\n  points: 'points',\n  pointsatx: 'pointsAtX',\n  pointsaty: 'pointsAtY',\n  pointsatz: 'pointsAtZ',\n  prefix: 'prefix',\n  preservealpha: 'preserveAlpha',\n  preserveaspectratio: 'preserveAspectRatio',\n  primitiveunits: 'primitiveUnits',\n  property: 'property',\n  r: 'r',\n  radius: 'radius',\n  refx: 'refX',\n  refy: 'refY',\n  renderingintent: 'renderingIntent',\n  'rendering-intent': 'renderingIntent',\n  repeatcount: 'repeatCount',\n  repeatdur: 'repeatDur',\n  requiredextensions: 'requiredExtensions',\n  requiredfeatures: 'requiredFeatures',\n  resource: 'resource',\n  restart: 'restart',\n  result: 'result',\n  results: 'results',\n  rotate: 'rotate',\n  rx: 'rx',\n  ry: 'ry',\n  scale: 'scale',\n  security: 'security',\n  seed: 'seed',\n  shaperendering: 'shapeRendering',\n  'shape-rendering': 'shapeRendering',\n  slope: 'slope',\n  spacing: 'spacing',\n  specularconstant: 'specularConstant',\n  specularexponent: 'specularExponent',\n  speed: 'speed',\n  spreadmethod: 'spreadMethod',\n  startoffset: 'startOffset',\n  stddeviation: 'stdDeviation',\n  stemh: 'stemh',\n  stemv: 'stemv',\n  stitchtiles: 'stitchTiles',\n  stopcolor: 'stopColor',\n  'stop-color': 'stopColor',\n  stopopacity: 'stopOpacity',\n  'stop-opacity': 'stopOpacity',\n  strikethroughposition: 'strikethroughPosition',\n  'strikethrough-position': 'strikethroughPosition',\n  strikethroughthickness: 'strikethroughThickness',\n  'strikethrough-thickness': 'strikethroughThickness',\n  string: 'string',\n  stroke: 'stroke',\n  strokedasharray: 'strokeDasharray',\n  'stroke-dasharray': 'strokeDasharray',\n  strokedashoffset: 'strokeDashoffset',\n  'stroke-dashoffset': 'strokeDashoffset',\n  strokelinecap: 'strokeLinecap',\n  'stroke-linecap': 'strokeLinecap',\n  strokelinejoin: 'strokeLinejoin',\n  'stroke-linejoin': 'strokeLinejoin',\n  strokemiterlimit: 'strokeMiterlimit',\n  'stroke-miterlimit': 'strokeMiterlimit',\n  strokewidth: 'strokeWidth',\n  'stroke-width': 'strokeWidth',\n  strokeopacity: 'strokeOpacity',\n  'stroke-opacity': 'strokeOpacity',\n  suppresscontenteditablewarning: 'suppressContentEditableWarning',\n  suppresshydrationwarning: 'suppressHydrationWarning',\n  surfacescale: 'surfaceScale',\n  systemlanguage: 'systemLanguage',\n  tablevalues: 'tableValues',\n  targetx: 'targetX',\n  targety: 'targetY',\n  textanchor: 'textAnchor',\n  'text-anchor': 'textAnchor',\n  textdecoration: 'textDecoration',\n  'text-decoration': 'textDecoration',\n  textlength: 'textLength',\n  textrendering: 'textRendering',\n  'text-rendering': 'textRendering',\n  to: 'to',\n  transform: 'transform',\n  typeof: 'typeof',\n  u1: 'u1',\n  u2: 'u2',\n  underlineposition: 'underlinePosition',\n  'underline-position': 'underlinePosition',\n  underlinethickness: 'underlineThickness',\n  'underline-thickness': 'underlineThickness',\n  unicode: 'unicode',\n  unicodebidi: 'unicodeBidi',\n  'unicode-bidi': 'unicodeBidi',\n  unicoderange: 'unicodeRange',\n  'unicode-range': 'unicodeRange',\n  unitsperem: 'unitsPerEm',\n  'units-per-em': 'unitsPerEm',\n  unselectable: 'unselectable',\n  valphabetic: 'vAlphabetic',\n  'v-alphabetic': 'vAlphabetic',\n  values: 'values',\n  vectoreffect: 'vectorEffect',\n  'vector-effect': 'vectorEffect',\n  version: 'version',\n  vertadvy: 'vertAdvY',\n  'vert-adv-y': 'vertAdvY',\n  vertoriginx: 'vertOriginX',\n  'vert-origin-x': 'vertOriginX',\n  vertoriginy: 'vertOriginY',\n  'vert-origin-y': 'vertOriginY',\n  vhanging: 'vHanging',\n  'v-hanging': 'vHanging',\n  videographic: 'vIdeographic',\n  'v-ideographic': 'vIdeographic',\n  viewbox: 'viewBox',\n  viewtarget: 'viewTarget',\n  visibility: 'visibility',\n  vmathematical: 'vMathematical',\n  'v-mathematical': 'vMathematical',\n  vocab: 'vocab',\n  widths: 'widths',\n  wordspacing: 'wordSpacing',\n  'word-spacing': 'wordSpacing',\n  writingmode: 'writingMode',\n  'writing-mode': 'writingMode',\n  x1: 'x1',\n  x2: 'x2',\n  x: 'x',\n  xchannelselector: 'xChannelSelector',\n  xheight: 'xHeight',\n  'x-height': 'xHeight',\n  xlinkactuate: 'xlinkActuate',\n  'xlink:actuate': 'xlinkActuate',\n  xlinkarcrole: 'xlinkArcrole',\n  'xlink:arcrole': 'xlinkArcrole',\n  xlinkhref: 'xlinkHref',\n  'xlink:href': 'xlinkHref',\n  xlinkrole: 'xlinkRole',\n  'xlink:role': 'xlinkRole',\n  xlinkshow: 'xlinkShow',\n  'xlink:show': 'xlinkShow',\n  xlinktitle: 'xlinkTitle',\n  'xlink:title': 'xlinkTitle',\n  xlinktype: 'xlinkType',\n  'xlink:type': 'xlinkType',\n  xmlbase: 'xmlBase',\n  'xml:base': 'xmlBase',\n  xmllang: 'xmlLang',\n  'xml:lang': 'xmlLang',\n  xmlns: 'xmlns',\n  'xml:space': 'xmlSpace',\n  xmlnsxlink: 'xmlnsXlink',\n  'xmlns:xlink': 'xmlnsXlink',\n  xmlspace: 'xmlSpace',\n  y1: 'y1',\n  y2: 'y2',\n  y: 'y',\n  ychannelselector: 'yChannelSelector',\n  z: 'z',\n  zoomandpan: 'zoomAndPan'\n};\n\nvar ariaProperties = {\n  'aria-current': 0,\n  // state\n  'aria-details': 0,\n  'aria-disabled': 0,\n  // state\n  'aria-hidden': 0,\n  // state\n  'aria-invalid': 0,\n  // state\n  'aria-keyshortcuts': 0,\n  'aria-label': 0,\n  'aria-roledescription': 0,\n  // Widget Attributes\n  'aria-autocomplete': 0,\n  'aria-checked': 0,\n  'aria-expanded': 0,\n  'aria-haspopup': 0,\n  'aria-level': 0,\n  'aria-modal': 0,\n  'aria-multiline': 0,\n  'aria-multiselectable': 0,\n  'aria-orientation': 0,\n  'aria-placeholder': 0,\n  'aria-pressed': 0,\n  'aria-readonly': 0,\n  'aria-required': 0,\n  'aria-selected': 0,\n  'aria-sort': 0,\n  'aria-valuemax': 0,\n  'aria-valuemin': 0,\n  'aria-valuenow': 0,\n  'aria-valuetext': 0,\n  // Live Region Attributes\n  'aria-atomic': 0,\n  'aria-busy': 0,\n  'aria-live': 0,\n  'aria-relevant': 0,\n  // Drag-and-Drop Attributes\n  'aria-dropeffect': 0,\n  'aria-grabbed': 0,\n  // Relationship Attributes\n  'aria-activedescendant': 0,\n  'aria-colcount': 0,\n  'aria-colindex': 0,\n  'aria-colspan': 0,\n  'aria-controls': 0,\n  'aria-describedby': 0,\n  'aria-errormessage': 0,\n  'aria-flowto': 0,\n  'aria-labelledby': 0,\n  'aria-owns': 0,\n  'aria-posinset': 0,\n  'aria-rowcount': 0,\n  'aria-rowindex': 0,\n  'aria-rowspan': 0,\n  'aria-setsize': 0\n};\n\nvar warnedProperties = {};\nvar rARIA = new RegExp('^(aria)-[' + ATTRIBUTE_NAME_CHAR + ']*$');\nvar rARIACamel = new RegExp('^(aria)[A-Z][' + ATTRIBUTE_NAME_CHAR + ']*$');\nvar hasOwnProperty$1 = Object.prototype.hasOwnProperty;\n\nfunction validateProperty(tagName, name) {\n  {\n    if (hasOwnProperty$1.call(warnedProperties, name) && warnedProperties[name]) {\n      return true;\n    }\n\n    if (rARIACamel.test(name)) {\n      var ariaName = 'aria-' + name.slice(4).toLowerCase();\n      var correctName = ariaProperties.hasOwnProperty(ariaName) ? ariaName : null; // If this is an aria-* attribute, but is not listed in the known DOM\n      // DOM properties, then it is an invalid aria-* attribute.\n\n      if (correctName == null) {\n        error('Invalid ARIA attribute `%s`. ARIA attributes follow the pattern aria-* and must be lowercase.', name);\n\n        warnedProperties[name] = true;\n        return true;\n      } // aria-* attributes should be lowercase; suggest the lowercase version.\n\n\n      if (name !== correctName) {\n        error('Invalid ARIA attribute `%s`. Did you mean `%s`?', name, correctName);\n\n        warnedProperties[name] = true;\n        return true;\n      }\n    }\n\n    if (rARIA.test(name)) {\n      var lowerCasedName = name.toLowerCase();\n      var standardName = ariaProperties.hasOwnProperty(lowerCasedName) ? lowerCasedName : null; // If this is an aria-* attribute, but is not listed in the known DOM\n      // DOM properties, then it is an invalid aria-* attribute.\n\n      if (standardName == null) {\n        warnedProperties[name] = true;\n        return false;\n      } // aria-* attributes should be lowercase; suggest the lowercase version.\n\n\n      if (name !== standardName) {\n        error('Unknown ARIA attribute `%s`. Did you mean `%s`?', name, standardName);\n\n        warnedProperties[name] = true;\n        return true;\n      }\n    }\n  }\n\n  return true;\n}\n\nfunction warnInvalidARIAProps(type, props) {\n  {\n    var invalidProps = [];\n\n    for (var key in props) {\n      var isValid = validateProperty(type, key);\n\n      if (!isValid) {\n        invalidProps.push(key);\n      }\n    }\n\n    var unknownPropString = invalidProps.map(function (prop) {\n      return '`' + prop + '`';\n    }).join(', ');\n\n    if (invalidProps.length === 1) {\n      error('Invalid aria prop %s on <%s> tag. ' + 'For details, see https://reactjs.org/link/invalid-aria-props', unknownPropString, type);\n    } else if (invalidProps.length > 1) {\n      error('Invalid aria props %s on <%s> tag. ' + 'For details, see https://reactjs.org/link/invalid-aria-props', unknownPropString, type);\n    }\n  }\n}\n\nfunction validateProperties(type, props) {\n  if (isCustomComponent(type, props)) {\n    return;\n  }\n\n  warnInvalidARIAProps(type, props);\n}\n\nvar didWarnValueNull = false;\nfunction validateProperties$1(type, props) {\n  {\n    if (type !== 'input' && type !== 'textarea' && type !== 'select') {\n      return;\n    }\n\n    if (props != null && props.value === null && !didWarnValueNull) {\n      didWarnValueNull = true;\n\n      if (type === 'select' && props.multiple) {\n        error('`value` prop on `%s` should not be null. ' + 'Consider using an empty array when `multiple` is set to `true` ' + 'to clear the component or `undefined` for uncontrolled components.', type);\n      } else {\n        error('`value` prop on `%s` should not be null. ' + 'Consider using an empty string to clear the component or `undefined` ' + 'for uncontrolled components.', type);\n      }\n    }\n  }\n}\n\nvar validateProperty$1 = function () {};\n\n{\n  var warnedProperties$1 = {};\n  var _hasOwnProperty = Object.prototype.hasOwnProperty;\n  var EVENT_NAME_REGEX = /^on./;\n  var INVALID_EVENT_NAME_REGEX = /^on[^A-Z]/;\n  var rARIA$1 = new RegExp('^(aria)-[' + ATTRIBUTE_NAME_CHAR + ']*$');\n  var rARIACamel$1 = new RegExp('^(aria)[A-Z][' + ATTRIBUTE_NAME_CHAR + ']*$');\n\n  validateProperty$1 = function (tagName, name, value, eventRegistry) {\n    if (_hasOwnProperty.call(warnedProperties$1, name) && warnedProperties$1[name]) {\n      return true;\n    }\n\n    var lowerCasedName = name.toLowerCase();\n\n    if (lowerCasedName === 'onfocusin' || lowerCasedName === 'onfocusout') {\n      error('React uses onFocus and onBlur instead of onFocusIn and onFocusOut. ' + 'All React events are normalized to bubble, so onFocusIn and onFocusOut ' + 'are not needed/supported by React.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // We can't rely on the event system being injected on the server.\n\n\n    if (eventRegistry != null) {\n      var registrationNameDependencies = eventRegistry.registrationNameDependencies,\n          possibleRegistrationNames = eventRegistry.possibleRegistrationNames;\n\n      if (registrationNameDependencies.hasOwnProperty(name)) {\n        return true;\n      }\n\n      var registrationName = possibleRegistrationNames.hasOwnProperty(lowerCasedName) ? possibleRegistrationNames[lowerCasedName] : null;\n\n      if (registrationName != null) {\n        error('Invalid event handler property `%s`. Did you mean `%s`?', name, registrationName);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n\n      if (EVENT_NAME_REGEX.test(name)) {\n        error('Unknown event handler property `%s`. It will be ignored.', name);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n    } else if (EVENT_NAME_REGEX.test(name)) {\n      // If no event plugins have been injected, we are in a server environment.\n      // So we can't tell if the event name is correct for sure, but we can filter\n      // out known bad ones like `onclick`. We can't suggest a specific replacement though.\n      if (INVALID_EVENT_NAME_REGEX.test(name)) {\n        error('Invalid event handler property `%s`. ' + 'React events use the camelCase naming convention, for example `onClick`.', name);\n      }\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // Let the ARIA attribute hook validate ARIA attributes\n\n\n    if (rARIA$1.test(name) || rARIACamel$1.test(name)) {\n      return true;\n    }\n\n    if (lowerCasedName === 'innerhtml') {\n      error('Directly setting property `innerHTML` is not permitted. ' + 'For more information, lookup documentation on `dangerouslySetInnerHTML`.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (lowerCasedName === 'aria') {\n      error('The `aria` attribute is reserved for future use in React. ' + 'Pass individual `aria-` attributes instead.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (lowerCasedName === 'is' && value !== null && value !== undefined && typeof value !== 'string') {\n      error('Received a `%s` for a string attribute `is`. If this is expected, cast ' + 'the value to a string.', typeof value);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (typeof value === 'number' && isNaN(value)) {\n      error('Received NaN for the `%s` attribute. If this is expected, cast ' + 'the value to a string.', name);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    var propertyInfo = getPropertyInfo(name);\n    var isReserved = propertyInfo !== null && propertyInfo.type === RESERVED; // Known attributes should match the casing specified in the property config.\n\n    if (possibleStandardNames.hasOwnProperty(lowerCasedName)) {\n      var standardName = possibleStandardNames[lowerCasedName];\n\n      if (standardName !== name) {\n        error('Invalid DOM property `%s`. Did you mean `%s`?', name, standardName);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n    } else if (!isReserved && name !== lowerCasedName) {\n      // Unknown attributes should have lowercase casing since that's how they\n      // will be cased anyway with server rendering.\n      error('React does not recognize the `%s` prop on a DOM element. If you ' + 'intentionally want it to appear in the DOM as a custom ' + 'attribute, spell it as lowercase `%s` instead. ' + 'If you accidentally passed it from a parent component, remove ' + 'it from the DOM element.', name, lowerCasedName);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (typeof value === 'boolean' && shouldRemoveAttributeWithWarning(name, value, propertyInfo, false)) {\n      if (value) {\n        error('Received `%s` for a non-boolean attribute `%s`.\\n\\n' + 'If you want to write it to the DOM, pass a string instead: ' + '%s=\"%s\" or %s={value.toString()}.', value, name, name, value, name);\n      } else {\n        error('Received `%s` for a non-boolean attribute `%s`.\\n\\n' + 'If you want to write it to the DOM, pass a string instead: ' + '%s=\"%s\" or %s={value.toString()}.\\n\\n' + 'If you used to conditionally omit it with %s={condition && value}, ' + 'pass %s={condition ? value : undefined} instead.', value, name, name, value, name, name, name);\n      }\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // Now that we've validated casing, do not validate\n    // data types for reserved props\n\n\n    if (isReserved) {\n      return true;\n    } // Warn when a known attribute is a bad type\n\n\n    if (shouldRemoveAttributeWithWarning(name, value, propertyInfo, false)) {\n      warnedProperties$1[name] = true;\n      return false;\n    } // Warn when passing the strings 'false' or 'true' into a boolean prop\n\n\n    if ((value === 'false' || value === 'true') && propertyInfo !== null && propertyInfo.type === BOOLEAN) {\n      error('Received the string `%s` for the boolean attribute `%s`. ' + '%s ' + 'Did you mean %s={%s}?', value, name, value === 'false' ? 'The browser will interpret it as a truthy value.' : 'Although this works, it will not work as expected if you pass the string \"false\".', name, value);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    return true;\n  };\n}\n\nvar warnUnknownProperties = function (type, props, eventRegistry) {\n  {\n    var unknownProps = [];\n\n    for (var key in props) {\n      var isValid = validateProperty$1(type, key, props[key], eventRegistry);\n\n      if (!isValid) {\n        unknownProps.push(key);\n      }\n    }\n\n    var unknownPropString = unknownProps.map(function (prop) {\n      return '`' + prop + '`';\n    }).join(', ');\n\n    if (unknownProps.length === 1) {\n      error('Invalid value for prop %s on <%s> tag. Either remove it from the element, ' + 'or pass a string or number value to keep it in the DOM. ' + 'For details, see https://reactjs.org/link/attribute-behavior ', unknownPropString, type);\n    } else if (unknownProps.length > 1) {\n      error('Invalid values for props %s on <%s> tag. Either remove them from the element, ' + 'or pass a string or number value to keep them in the DOM. ' + 'For details, see https://reactjs.org/link/attribute-behavior ', unknownPropString, type);\n    }\n  }\n};\n\nfunction validateProperties$2(type, props, eventRegistry) {\n  if (isCustomComponent(type, props)) {\n    return;\n  }\n\n  warnUnknownProperties(type, props, eventRegistry);\n}\n\nvar IS_EVENT_HANDLE_NON_MANAGED_NODE = 1;\nvar IS_NON_DELEGATED = 1 << 1;\nvar IS_CAPTURE_PHASE = 1 << 2;\nvar IS_REPLAYED = 1 << 4;\n// set to LEGACY_FB_SUPPORT. LEGACY_FB_SUPPORT only gets set when\n// we call willDeferLaterForLegacyFBSupport, thus not bailing out\n// will result in endless cycles like an infinite loop.\n// We also don't want to defer during event replaying.\n\nvar SHOULD_NOT_PROCESS_POLYFILL_EVENT_PLUGINS = IS_EVENT_HANDLE_NON_MANAGED_NODE | IS_NON_DELEGATED | IS_CAPTURE_PHASE;\n\n/**\n * Gets the target node from a native browser event by accounting for\n * inconsistencies in browser DOM APIs.\n *\n * @param {object} nativeEvent Native browser event.\n * @return {DOMEventTarget} Target node.\n */\n\nfunction getEventTarget(nativeEvent) {\n  // Fallback to nativeEvent.srcElement for IE9\n  // https://github.com/facebook/react/issues/12506\n  var target = nativeEvent.target || nativeEvent.srcElement || window; // Normalize SVG <use> element events #4963\n\n  if (target.correspondingUseElement) {\n    target = target.correspondingUseElement;\n  } // Safari may fire events on text nodes (Node.TEXT_NODE is 3).\n  // @see http://www.quirksmode.org/js/events_properties.html\n\n\n  return target.nodeType === TEXT_NODE ? target.parentNode : target;\n}\n\nvar restoreImpl = null;\nvar restoreTarget = null;\nvar restoreQueue = null;\n\nfunction restoreStateOfTarget(target) {\n  // We perform this translation at the end of the event loop so that we\n  // always receive the correct fiber here\n  var internalInstance = getInstanceFromNode(target);\n\n  if (!internalInstance) {\n    // Unmounted\n    return;\n  }\n\n  if (!(typeof restoreImpl === 'function')) {\n    {\n      throw Error( \"setRestoreImplementation() needs to be called to handle a target for controlled events. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n\n  var stateNode = internalInstance.stateNode; // Guard against Fiber being unmounted.\n\n  if (stateNode) {\n    var _props = getFiberCurrentPropsFromNode(stateNode);\n\n    restoreImpl(internalInstance.stateNode, internalInstance.type, _props);\n  }\n}\n\nfunction setRestoreImplementation(impl) {\n  restoreImpl = impl;\n}\nfunction enqueueStateRestore(target) {\n  if (restoreTarget) {\n    if (restoreQueue) {\n      restoreQueue.push(target);\n    } else {\n      restoreQueue = [target];\n    }\n  } else {\n    restoreTarget = target;\n  }\n}\nfunction needsStateRestore() {\n  return restoreTarget !== null || restoreQueue !== null;\n}\nfunction restoreStateIfNeeded() {\n  if (!restoreTarget) {\n    return;\n  }\n\n  var target = restoreTarget;\n  var queuedTargets = restoreQueue;\n  restoreTarget = null;\n  restoreQueue = null;\n  restoreStateOfTarget(target);\n\n  if (queuedTargets) {\n    for (var i = 0; i < queuedTargets.length; i++) {\n      restoreStateOfTarget(queuedTargets[i]);\n    }\n  }\n}\n\n// the renderer. Such as when we're dispatching events or if third party\n// libraries need to call batchedUpdates. Eventually, this API will go away when\n// everything is batched by default. We'll then have a similar API to opt-out of\n// scheduled work and instead do synchronous work.\n// Defaults\n\nvar batchedUpdatesImpl = function (fn, bookkeeping) {\n  return fn(bookkeeping);\n};\n\nvar discreteUpdatesImpl = function (fn, a, b, c, d) {\n  return fn(a, b, c, d);\n};\n\nvar flushDiscreteUpdatesImpl = function () {};\n\nvar batchedEventUpdatesImpl = batchedUpdatesImpl;\nvar isInsideEventHandler = false;\nvar isBatchingEventUpdates = false;\n\nfunction finishEventHandler() {\n  // Here we wait until all updates have propagated, which is important\n  // when using controlled components within layers:\n  // https://github.com/facebook/react/issues/1698\n  // Then we restore state of any controlled component.\n  var controlledComponentsHavePendingUpdates = needsStateRestore();\n\n  if (controlledComponentsHavePendingUpdates) {\n    // If a controlled event was fired, we may need to restore the state of\n    // the DOM node back to the controlled value. This is necessary when React\n    // bails out of the update without touching the DOM.\n    flushDiscreteUpdatesImpl();\n    restoreStateIfNeeded();\n  }\n}\n\nfunction batchedUpdates(fn, bookkeeping) {\n  if (isInsideEventHandler) {\n    // If we are currently inside another batch, we need to wait until it\n    // fully completes before restoring state.\n    return fn(bookkeeping);\n  }\n\n  isInsideEventHandler = true;\n\n  try {\n    return batchedUpdatesImpl(fn, bookkeeping);\n  } finally {\n    isInsideEventHandler = false;\n    finishEventHandler();\n  }\n}\nfunction batchedEventUpdates(fn, a, b) {\n  if (isBatchingEventUpdates) {\n    // If we are currently inside another batch, we need to wait until it\n    // fully completes before restoring state.\n    return fn(a, b);\n  }\n\n  isBatchingEventUpdates = true;\n\n  try {\n    return batchedEventUpdatesImpl(fn, a, b);\n  } finally {\n    isBatchingEventUpdates = false;\n    finishEventHandler();\n  }\n}\nfunction discreteUpdates(fn, a, b, c, d) {\n  var prevIsInsideEventHandler = isInsideEventHandler;\n  isInsideEventHandler = true;\n\n  try {\n    return discreteUpdatesImpl(fn, a, b, c, d);\n  } finally {\n    isInsideEventHandler = prevIsInsideEventHandler;\n\n    if (!isInsideEventHandler) {\n      finishEventHandler();\n    }\n  }\n}\nfunction flushDiscreteUpdatesIfNeeded(timeStamp) {\n  {\n    if (!isInsideEventHandler) {\n      flushDiscreteUpdatesImpl();\n    }\n  }\n}\nfunction setBatchingImplementation(_batchedUpdatesImpl, _discreteUpdatesImpl, _flushDiscreteUpdatesImpl, _batchedEventUpdatesImpl) {\n  batchedUpdatesImpl = _batchedUpdatesImpl;\n  discreteUpdatesImpl = _discreteUpdatesImpl;\n  flushDiscreteUpdatesImpl = _flushDiscreteUpdatesImpl;\n  batchedEventUpdatesImpl = _batchedEventUpdatesImpl;\n}\n\nfunction isInteractive(tag) {\n  return tag === 'button' || tag === 'input' || tag === 'select' || tag === 'textarea';\n}\n\nfunction shouldPreventMouseEvent(name, type, props) {\n  switch (name) {\n    case 'onClick':\n    case 'onClickCapture':\n    case 'onDoubleClick':\n    case 'onDoubleClickCapture':\n    case 'onMouseDown':\n    case 'onMouseDownCapture':\n    case 'onMouseMove':\n    case 'onMouseMoveCapture':\n    case 'onMouseUp':\n    case 'onMouseUpCapture':\n    case 'onMouseEnter':\n      return !!(props.disabled && isInteractive(type));\n\n    default:\n      return false;\n  }\n}\n/**\n * @param {object} inst The instance, which is the source of events.\n * @param {string} registrationName Name of listener (e.g. `onClick`).\n * @return {?function} The stored callback.\n */\n\n\nfunction getListener(inst, registrationName) {\n  var stateNode = inst.stateNode;\n\n  if (stateNode === null) {\n    // Work in progress (ex: onload events in incremental mode).\n    return null;\n  }\n\n  var props = getFiberCurrentPropsFromNode(stateNode);\n\n  if (props === null) {\n    // Work in progress.\n    return null;\n  }\n\n  var listener = props[registrationName];\n\n  if (shouldPreventMouseEvent(registrationName, inst.type, props)) {\n    return null;\n  }\n\n  if (!(!listener || typeof listener === 'function')) {\n    {\n      throw Error( \"Expected `\" + registrationName + \"` listener to be a function, instead got a value of `\" + typeof listener + \"` type.\" );\n    }\n  }\n\n  return listener;\n}\n\nvar passiveBrowserEventsSupported = false; // Check if browser support events with passive listeners\n// https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener#Safely_detecting_option_support\n\nif (canUseDOM) {\n  try {\n    var options = {}; // $FlowFixMe: Ignore Flow complaining about needing a value\n\n    Object.defineProperty(options, 'passive', {\n      get: function () {\n        passiveBrowserEventsSupported = true;\n      }\n    });\n    window.addEventListener('test', options, options);\n    window.removeEventListener('test', options, options);\n  } catch (e) {\n    passiveBrowserEventsSupported = false;\n  }\n}\n\nfunction invokeGuardedCallbackProd(name, func, context, a, b, c, d, e, f) {\n  var funcArgs = Array.prototype.slice.call(arguments, 3);\n\n  try {\n    func.apply(context, funcArgs);\n  } catch (error) {\n    this.onError(error);\n  }\n}\n\nvar invokeGuardedCallbackImpl = invokeGuardedCallbackProd;\n\n{\n  // In DEV mode, we swap out invokeGuardedCallback for a special version\n  // that plays more nicely with the browser's DevTools. The idea is to preserve\n  // \"Pause on exceptions\" behavior. Because React wraps all user-provided\n  // functions in invokeGuardedCallback, and the production version of\n  // invokeGuardedCallback uses a try-catch, all user exceptions are treated\n  // like caught exceptions, and the DevTools won't pause unless the developer\n  // takes the extra step of enabling pause on caught exceptions. This is\n  // unintuitive, though, because even though React has caught the error, from\n  // the developer's perspective, the error is uncaught.\n  //\n  // To preserve the expected \"Pause on exceptions\" behavior, we don't use a\n  // try-catch in DEV. Instead, we synchronously dispatch a fake event to a fake\n  // DOM node, and call the user-provided callback from inside an event handler\n  // for that fake event. If the callback throws, the error is \"captured\" using\n  // a global event handler. But because the error happens in a different\n  // event loop context, it does not interrupt the normal program flow.\n  // Effectively, this gives us try-catch behavior without actually using\n  // try-catch. Neat!\n  // Check that the browser supports the APIs we need to implement our special\n  // DEV version of invokeGuardedCallback\n  if (typeof window !== 'undefined' && typeof window.dispatchEvent === 'function' && typeof document !== 'undefined' && typeof document.createEvent === 'function') {\n    var fakeNode = document.createElement('react');\n\n    invokeGuardedCallbackImpl = function invokeGuardedCallbackDev(name, func, context, a, b, c, d, e, f) {\n      // If document doesn't exist we know for sure we will crash in this method\n      // when we call document.createEvent(). However this can cause confusing\n      // errors: https://github.com/facebookincubator/create-react-app/issues/3482\n      // So we preemptively throw with a better message instead.\n      if (!(typeof document !== 'undefined')) {\n        {\n          throw Error( \"The `document` global was defined when React was initialized, but is not defined anymore. This can happen in a test environment if a component schedules an update from an asynchronous callback, but the test has already finished running. To solve this, you can either unmount the component at the end of your test (and ensure that any asynchronous operations get canceled in `componentWillUnmount`), or you can change the test itself to be asynchronous.\" );\n        }\n      }\n\n      var evt = document.createEvent('Event');\n      var didCall = false; // Keeps track of whether the user-provided callback threw an error. We\n      // set this to true at the beginning, then set it to false right after\n      // calling the function. If the function errors, `didError` will never be\n      // set to false. This strategy works even if the browser is flaky and\n      // fails to call our global error handler, because it doesn't rely on\n      // the error event at all.\n\n      var didError = true; // Keeps track of the value of window.event so that we can reset it\n      // during the callback to let user code access window.event in the\n      // browsers that support it.\n\n      var windowEvent = window.event; // Keeps track of the descriptor of window.event to restore it after event\n      // dispatching: https://github.com/facebook/react/issues/13688\n\n      var windowEventDescriptor = Object.getOwnPropertyDescriptor(window, 'event');\n\n      function restoreAfterDispatch() {\n        // We immediately remove the callback from event listeners so that\n        // nested `invokeGuardedCallback` calls do not clash. Otherwise, a\n        // nested call would trigger the fake event handlers of any call higher\n        // in the stack.\n        fakeNode.removeEventListener(evtType, callCallback, false); // We check for window.hasOwnProperty('event') to prevent the\n        // window.event assignment in both IE <= 10 as they throw an error\n        // \"Member not found\" in strict mode, and in Firefox which does not\n        // support window.event.\n\n        if (typeof window.event !== 'undefined' && window.hasOwnProperty('event')) {\n          window.event = windowEvent;\n        }\n      } // Create an event handler for our fake event. We will synchronously\n      // dispatch our fake event using `dispatchEvent`. Inside the handler, we\n      // call the user-provided callback.\n\n\n      var funcArgs = Array.prototype.slice.call(arguments, 3);\n\n      function callCallback() {\n        didCall = true;\n        restoreAfterDispatch();\n        func.apply(context, funcArgs);\n        didError = false;\n      } // Create a global error event handler. We use this to capture the value\n      // that was thrown. It's possible that this error handler will fire more\n      // than once; for example, if non-React code also calls `dispatchEvent`\n      // and a handler for that event throws. We should be resilient to most of\n      // those cases. Even if our error event handler fires more than once, the\n      // last error event is always used. If the callback actually does error,\n      // we know that the last error event is the correct one, because it's not\n      // possible for anything else to have happened in between our callback\n      // erroring and the code that follows the `dispatchEvent` call below. If\n      // the callback doesn't error, but the error event was fired, we know to\n      // ignore it because `didError` will be false, as described above.\n\n\n      var error; // Use this to track whether the error event is ever called.\n\n      var didSetError = false;\n      var isCrossOriginError = false;\n\n      function handleWindowError(event) {\n        error = event.error;\n        didSetError = true;\n\n        if (error === null && event.colno === 0 && event.lineno === 0) {\n          isCrossOriginError = true;\n        }\n\n        if (event.defaultPrevented) {\n          // Some other error handler has prevented default.\n          // Browsers silence the error report if this happens.\n          // We'll remember this to later decide whether to log it or not.\n          if (error != null && typeof error === 'object') {\n            try {\n              error._suppressLogging = true;\n            } catch (inner) {// Ignore.\n            }\n          }\n        }\n      } // Create a fake event type.\n\n\n      var evtType = \"react-\" + (name ? name : 'invokeguardedcallback'); // Attach our event handlers\n\n      window.addEventListener('error', handleWindowError);\n      fakeNode.addEventListener(evtType, callCallback, false); // Synchronously dispatch our fake event. If the user-provided function\n      // errors, it will trigger our global error handler.\n\n      evt.initEvent(evtType, false, false);\n      fakeNode.dispatchEvent(evt);\n\n      if (windowEventDescriptor) {\n        Object.defineProperty(window, 'event', windowEventDescriptor);\n      }\n\n      if (didCall && didError) {\n        if (!didSetError) {\n          // The callback errored, but the error event never fired.\n          error = new Error('An error was thrown inside one of your components, but React ' + \"doesn't know what it was. This is likely due to browser \" + 'flakiness. React does its best to preserve the \"Pause on ' + 'exceptions\" behavior of the DevTools, which requires some ' + \"DEV-mode only tricks. It's possible that these don't work in \" + 'your browser. Try triggering the error in production mode, ' + 'or switching to a modern browser. If you suspect that this is ' + 'actually an issue with React, please file an issue.');\n        } else if (isCrossOriginError) {\n          error = new Error(\"A cross-origin error was thrown. React doesn't have access to \" + 'the actual error object in development. ' + 'See https://reactjs.org/link/crossorigin-error for more information.');\n        }\n\n        this.onError(error);\n      } // Remove our event listeners\n\n\n      window.removeEventListener('error', handleWindowError);\n\n      if (!didCall) {\n        // Something went really wrong, and our event was not dispatched.\n        // https://github.com/facebook/react/issues/16734\n        // https://github.com/facebook/react/issues/16585\n        // Fall back to the production implementation.\n        restoreAfterDispatch();\n        return invokeGuardedCallbackProd.apply(this, arguments);\n      }\n    };\n  }\n}\n\nvar invokeGuardedCallbackImpl$1 = invokeGuardedCallbackImpl;\n\nvar hasError = false;\nvar caughtError = null; // Used by event system to capture/rethrow the first error.\n\nvar hasRethrowError = false;\nvar rethrowError = null;\nvar reporter = {\n  onError: function (error) {\n    hasError = true;\n    caughtError = error;\n  }\n};\n/**\n * Call a function while guarding against errors that happens within it.\n * Returns an error if it throws, otherwise null.\n *\n * In production, this is implemented using a try-catch. The reason we don't\n * use a try-catch directly is so that we can swap out a different\n * implementation in DEV mode.\n *\n * @param {String} name of the guard to use for logging or debugging\n * @param {Function} func The function to invoke\n * @param {*} context The context to use when calling the function\n * @param {...*} args Arguments for function\n */\n\nfunction invokeGuardedCallback(name, func, context, a, b, c, d, e, f) {\n  hasError = false;\n  caughtError = null;\n  invokeGuardedCallbackImpl$1.apply(reporter, arguments);\n}\n/**\n * Same as invokeGuardedCallback, but instead of returning an error, it stores\n * it in a global so it can be rethrown by `rethrowCaughtError` later.\n * TODO: See if caughtError and rethrowError can be unified.\n *\n * @param {String} name of the guard to use for logging or debugging\n * @param {Function} func The function to invoke\n * @param {*} context The context to use when calling the function\n * @param {...*} args Arguments for function\n */\n\nfunction invokeGuardedCallbackAndCatchFirstError(name, func, context, a, b, c, d, e, f) {\n  invokeGuardedCallback.apply(this, arguments);\n\n  if (hasError) {\n    var error = clearCaughtError();\n\n    if (!hasRethrowError) {\n      hasRethrowError = true;\n      rethrowError = error;\n    }\n  }\n}\n/**\n * During execution of guarded functions we will capture the first error which\n * we will rethrow to be handled by the top level error handler.\n */\n\nfunction rethrowCaughtError() {\n  if (hasRethrowError) {\n    var error = rethrowError;\n    hasRethrowError = false;\n    rethrowError = null;\n    throw error;\n  }\n}\nfunction hasCaughtError() {\n  return hasError;\n}\nfunction clearCaughtError() {\n  if (hasError) {\n    var error = caughtError;\n    hasError = false;\n    caughtError = null;\n    return error;\n  } else {\n    {\n      {\n        throw Error( \"clearCaughtError was called but no error was captured. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n  }\n}\n\n/**\n * `ReactInstanceMap` maintains a mapping from a public facing stateful\n * instance (key) and the internal representation (value). This allows public\n * methods to accept the user facing instance as an argument and map them back\n * to internal methods.\n *\n * Note that this module is currently shared and assumed to be stateless.\n * If this becomes an actual Map, that will break.\n */\nfunction get(key) {\n  return key._reactInternals;\n}\nfunction has(key) {\n  return key._reactInternals !== undefined;\n}\nfunction set(key, value) {\n  key._reactInternals = value;\n}\n\n// Don't change these two values. They're used by React Dev Tools.\nvar NoFlags =\n/*                      */\n0;\nvar PerformedWork =\n/*                */\n1; // You can change the rest (and add more).\n\nvar Placement =\n/*                    */\n2;\nvar Update =\n/*                       */\n4;\nvar PlacementAndUpdate =\n/*           */\n6;\nvar Deletion =\n/*                     */\n8;\nvar ContentReset =\n/*                 */\n16;\nvar Callback =\n/*                     */\n32;\nvar DidCapture =\n/*                   */\n64;\nvar Ref =\n/*                          */\n128;\nvar Snapshot =\n/*                     */\n256;\nvar Passive =\n/*                      */\n512; // TODO (effects) Remove this bit once the new reconciler is synced to the old.\n\nvar PassiveUnmountPendingDev =\n/*     */\n8192;\nvar Hydrating =\n/*                    */\n1024;\nvar HydratingAndUpdate =\n/*           */\n1028; // Passive & Update & Callback & Ref & Snapshot\n\nvar LifecycleEffectMask =\n/*          */\n932; // Union of all host effects\n\nvar HostEffectMask =\n/*               */\n2047; // These are not really side effects, but we still reuse this field.\n\nvar Incomplete =\n/*                   */\n2048;\nvar ShouldCapture =\n/*                */\n4096;\nvar ForceUpdateForLegacySuspense =\n/* */\n16384; // Static tags describe aspects of a fiber that are not specific to a render,\n\nvar ReactCurrentOwner = ReactSharedInternals.ReactCurrentOwner;\nfunction getNearestMountedFiber(fiber) {\n  var node = fiber;\n  var nearestMounted = fiber;\n\n  if (!fiber.alternate) {\n    // If there is no alternate, this might be a new tree that isn't inserted\n    // yet. If it is, then it will have a pending insertion effect on it.\n    var nextNode = node;\n\n    do {\n      node = nextNode;\n\n      if ((node.flags & (Placement | Hydrating)) !== NoFlags) {\n        // This is an insertion or in-progress hydration. The nearest possible\n        // mounted fiber is the parent but we need to continue to figure out\n        // if that one is still mounted.\n        nearestMounted = node.return;\n      }\n\n      nextNode = node.return;\n    } while (nextNode);\n  } else {\n    while (node.return) {\n      node = node.return;\n    }\n  }\n\n  if (node.tag === HostRoot) {\n    // TODO: Check if this was a nested HostRoot when used with\n    // renderContainerIntoSubtree.\n    return nearestMounted;\n  } // If we didn't hit the root, that means that we're in an disconnected tree\n  // that has been unmounted.\n\n\n  return null;\n}\nfunction getSuspenseInstanceFromFiber(fiber) {\n  if (fiber.tag === SuspenseComponent) {\n    var suspenseState = fiber.memoizedState;\n\n    if (suspenseState === null) {\n      var current = fiber.alternate;\n\n      if (current !== null) {\n        suspenseState = current.memoizedState;\n      }\n    }\n\n    if (suspenseState !== null) {\n      return suspenseState.dehydrated;\n    }\n  }\n\n  return null;\n}\nfunction getContainerFromFiber(fiber) {\n  return fiber.tag === HostRoot ? fiber.stateNode.containerInfo : null;\n}\nfunction isFiberMounted(fiber) {\n  return getNearestMountedFiber(fiber) === fiber;\n}\nfunction isMounted(component) {\n  {\n    var owner = ReactCurrentOwner.current;\n\n    if (owner !== null && owner.tag === ClassComponent) {\n      var ownerFiber = owner;\n      var instance = ownerFiber.stateNode;\n\n      if (!instance._warnedAboutRefsInRender) {\n        error('%s is accessing isMounted inside its render() function. ' + 'render() should be a pure function of props and state. It should ' + 'never access something that requires stale data from the previous ' + 'render, such as refs. Move this logic to componentDidMount and ' + 'componentDidUpdate instead.', getComponentName(ownerFiber.type) || 'A component');\n      }\n\n      instance._warnedAboutRefsInRender = true;\n    }\n  }\n\n  var fiber = get(component);\n\n  if (!fiber) {\n    return false;\n  }\n\n  return getNearestMountedFiber(fiber) === fiber;\n}\n\nfunction assertIsMounted(fiber) {\n  if (!(getNearestMountedFiber(fiber) === fiber)) {\n    {\n      throw Error( \"Unable to find node on an unmounted component.\" );\n    }\n  }\n}\n\nfunction findCurrentFiberUsingSlowPath(fiber) {\n  var alternate = fiber.alternate;\n\n  if (!alternate) {\n    // If there is no alternate, then we only need to check if it is mounted.\n    var nearestMounted = getNearestMountedFiber(fiber);\n\n    if (!(nearestMounted !== null)) {\n      {\n        throw Error( \"Unable to find node on an unmounted component.\" );\n      }\n    }\n\n    if (nearestMounted !== fiber) {\n      return null;\n    }\n\n    return fiber;\n  } // If we have two possible branches, we'll walk backwards up to the root\n  // to see what path the root points to. On the way we may hit one of the\n  // special cases and we'll deal with them.\n\n\n  var a = fiber;\n  var b = alternate;\n\n  while (true) {\n    var parentA = a.return;\n\n    if (parentA === null) {\n      // We're at the root.\n      break;\n    }\n\n    var parentB = parentA.alternate;\n\n    if (parentB === null) {\n      // There is no alternate. This is an unusual case. Currently, it only\n      // happens when a Suspense component is hidden. An extra fragment fiber\n      // is inserted in between the Suspense fiber and its children. Skip\n      // over this extra fragment fiber and proceed to the next parent.\n      var nextParent = parentA.return;\n\n      if (nextParent !== null) {\n        a = b = nextParent;\n        continue;\n      } // If there's no parent, we're at the root.\n\n\n      break;\n    } // If both copies of the parent fiber point to the same child, we can\n    // assume that the child is current. This happens when we bailout on low\n    // priority: the bailed out fiber's child reuses the current child.\n\n\n    if (parentA.child === parentB.child) {\n      var child = parentA.child;\n\n      while (child) {\n        if (child === a) {\n          // We've determined that A is the current branch.\n          assertIsMounted(parentA);\n          return fiber;\n        }\n\n        if (child === b) {\n          // We've determined that B is the current branch.\n          assertIsMounted(parentA);\n          return alternate;\n        }\n\n        child = child.sibling;\n      } // We should never have an alternate for any mounting node. So the only\n      // way this could possibly happen is if this was unmounted, if at all.\n\n\n      {\n        {\n          throw Error( \"Unable to find node on an unmounted component.\" );\n        }\n      }\n    }\n\n    if (a.return !== b.return) {\n      // The return pointer of A and the return pointer of B point to different\n      // fibers. We assume that return pointers never criss-cross, so A must\n      // belong to the child set of A.return, and B must belong to the child\n      // set of B.return.\n      a = parentA;\n      b = parentB;\n    } else {\n      // The return pointers point to the same fiber. We'll have to use the\n      // default, slow path: scan the child sets of each parent alternate to see\n      // which child belongs to which set.\n      //\n      // Search parent A's child set\n      var didFindChild = false;\n      var _child = parentA.child;\n\n      while (_child) {\n        if (_child === a) {\n          didFindChild = true;\n          a = parentA;\n          b = parentB;\n          break;\n        }\n\n        if (_child === b) {\n          didFindChild = true;\n          b = parentA;\n          a = parentB;\n          break;\n        }\n\n        _child = _child.sibling;\n      }\n\n      if (!didFindChild) {\n        // Search parent B's child set\n        _child = parentB.child;\n\n        while (_child) {\n          if (_child === a) {\n            didFindChild = true;\n            a = parentB;\n            b = parentA;\n            break;\n          }\n\n          if (_child === b) {\n            didFindChild = true;\n            b = parentB;\n            a = parentA;\n            break;\n          }\n\n          _child = _child.sibling;\n        }\n\n        if (!didFindChild) {\n          {\n            throw Error( \"Child was not found in either parent set. This indicates a bug in React related to the return pointer. Please file an issue.\" );\n          }\n        }\n      }\n    }\n\n    if (!(a.alternate === b)) {\n      {\n        throw Error( \"Return fibers should always be each others' alternates. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n  } // If the root is not a host container, we're in a disconnected tree. I.e.\n  // unmounted.\n\n\n  if (!(a.tag === HostRoot)) {\n    {\n      throw Error( \"Unable to find node on an unmounted component.\" );\n    }\n  }\n\n  if (a.stateNode.current === a) {\n    // We've determined that A is the current branch.\n    return fiber;\n  } // Otherwise B has to be current branch.\n\n\n  return alternate;\n}\nfunction findCurrentHostFiber(parent) {\n  var currentParent = findCurrentFiberUsingSlowPath(parent);\n\n  if (!currentParent) {\n    return null;\n  } // Next we'll drill down this component to find the first HostComponent/Text.\n\n\n  var node = currentParent;\n\n  while (true) {\n    if (node.tag === HostComponent || node.tag === HostText) {\n      return node;\n    } else if (node.child) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === currentParent) {\n      return null;\n    }\n\n    while (!node.sibling) {\n      if (!node.return || node.return === currentParent) {\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  } // Flow needs the return null here, but ESLint complains about it.\n  // eslint-disable-next-line no-unreachable\n\n\n  return null;\n}\nfunction findCurrentHostFiberWithNoPortals(parent) {\n  var currentParent = findCurrentFiberUsingSlowPath(parent);\n\n  if (!currentParent) {\n    return null;\n  } // Next we'll drill down this component to find the first HostComponent/Text.\n\n\n  var node = currentParent;\n\n  while (true) {\n    if (node.tag === HostComponent || node.tag === HostText || enableFundamentalAPI ) {\n      return node;\n    } else if (node.child && node.tag !== HostPortal) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === currentParent) {\n      return null;\n    }\n\n    while (!node.sibling) {\n      if (!node.return || node.return === currentParent) {\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  } // Flow needs the return null here, but ESLint complains about it.\n  // eslint-disable-next-line no-unreachable\n\n\n  return null;\n}\nfunction doesFiberContain(parentFiber, childFiber) {\n  var node = childFiber;\n  var parentFiberAlternate = parentFiber.alternate;\n\n  while (node !== null) {\n    if (node === parentFiber || node === parentFiberAlternate) {\n      return true;\n    }\n\n    node = node.return;\n  }\n\n  return false;\n}\n\nvar attemptUserBlockingHydration;\nfunction setAttemptUserBlockingHydration(fn) {\n  attemptUserBlockingHydration = fn;\n}\nvar attemptContinuousHydration;\nfunction setAttemptContinuousHydration(fn) {\n  attemptContinuousHydration = fn;\n}\nvar attemptHydrationAtCurrentPriority;\nfunction setAttemptHydrationAtCurrentPriority(fn) {\n  attemptHydrationAtCurrentPriority = fn;\n}\nvar attemptHydrationAtPriority;\nfunction setAttemptHydrationAtPriority(fn) {\n  attemptHydrationAtPriority = fn;\n} // TODO: Upgrade this definition once we're on a newer version of Flow that\nvar hasScheduledReplayAttempt = false; // The queue of discrete events to be replayed.\n\nvar queuedDiscreteEvents = []; // Indicates if any continuous event targets are non-null for early bailout.\n// if the last target was dehydrated.\n\nvar queuedFocus = null;\nvar queuedDrag = null;\nvar queuedMouse = null; // For pointer events there can be one latest event per pointerId.\n\nvar queuedPointers = new Map();\nvar queuedPointerCaptures = new Map(); // We could consider replaying selectionchange and touchmoves too.\n\nvar queuedExplicitHydrationTargets = [];\nfunction hasQueuedDiscreteEvents() {\n  return queuedDiscreteEvents.length > 0;\n}\nvar discreteReplayableEvents = ['mousedown', 'mouseup', 'touchcancel', 'touchend', 'touchstart', 'auxclick', 'dblclick', 'pointercancel', 'pointerdown', 'pointerup', 'dragend', 'dragstart', 'drop', 'compositionend', 'compositionstart', 'keydown', 'keypress', 'keyup', 'input', 'textInput', // Intentionally camelCase\n'copy', 'cut', 'paste', 'click', 'change', 'contextmenu', 'reset', 'submit'];\nfunction isReplayableDiscreteEvent(eventType) {\n  return discreteReplayableEvents.indexOf(eventType) > -1;\n}\n\nfunction createQueuedReplayableEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  return {\n    blockedOn: blockedOn,\n    domEventName: domEventName,\n    eventSystemFlags: eventSystemFlags | IS_REPLAYED,\n    nativeEvent: nativeEvent,\n    targetContainers: [targetContainer]\n  };\n}\n\nfunction queueDiscreteEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  var queuedEvent = createQueuedReplayableEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent);\n  queuedDiscreteEvents.push(queuedEvent);\n} // Resets the replaying for this type of continuous event to no event.\n\nfunction clearIfContinuousEvent(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'focusin':\n    case 'focusout':\n      queuedFocus = null;\n      break;\n\n    case 'dragenter':\n    case 'dragleave':\n      queuedDrag = null;\n      break;\n\n    case 'mouseover':\n    case 'mouseout':\n      queuedMouse = null;\n      break;\n\n    case 'pointerover':\n    case 'pointerout':\n      {\n        var pointerId = nativeEvent.pointerId;\n        queuedPointers.delete(pointerId);\n        break;\n      }\n\n    case 'gotpointercapture':\n    case 'lostpointercapture':\n      {\n        var _pointerId = nativeEvent.pointerId;\n        queuedPointerCaptures.delete(_pointerId);\n        break;\n      }\n  }\n}\n\nfunction accumulateOrCreateContinuousQueuedReplayableEvent(existingQueuedEvent, blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  if (existingQueuedEvent === null || existingQueuedEvent.nativeEvent !== nativeEvent) {\n    var queuedEvent = createQueuedReplayableEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent);\n\n    if (blockedOn !== null) {\n      var _fiber2 = getInstanceFromNode(blockedOn);\n\n      if (_fiber2 !== null) {\n        // Attempt to increase the priority of this target.\n        attemptContinuousHydration(_fiber2);\n      }\n    }\n\n    return queuedEvent;\n  } // If we have already queued this exact event, then it's because\n  // the different event systems have different DOM event listeners.\n  // We can accumulate the flags, and the targetContainers, and\n  // store a single event to be replayed.\n\n\n  existingQueuedEvent.eventSystemFlags |= eventSystemFlags;\n  var targetContainers = existingQueuedEvent.targetContainers;\n\n  if (targetContainer !== null && targetContainers.indexOf(targetContainer) === -1) {\n    targetContainers.push(targetContainer);\n  }\n\n  return existingQueuedEvent;\n}\n\nfunction queueIfContinuousEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  // These set relatedTarget to null because the replayed event will be treated as if we\n  // moved from outside the window (no target) onto the target once it hydrates.\n  // Instead of mutating we could clone the event.\n  switch (domEventName) {\n    case 'focusin':\n      {\n        var focusEvent = nativeEvent;\n        queuedFocus = accumulateOrCreateContinuousQueuedReplayableEvent(queuedFocus, blockedOn, domEventName, eventSystemFlags, targetContainer, focusEvent);\n        return true;\n      }\n\n    case 'dragenter':\n      {\n        var dragEvent = nativeEvent;\n        queuedDrag = accumulateOrCreateContinuousQueuedReplayableEvent(queuedDrag, blockedOn, domEventName, eventSystemFlags, targetContainer, dragEvent);\n        return true;\n      }\n\n    case 'mouseover':\n      {\n        var mouseEvent = nativeEvent;\n        queuedMouse = accumulateOrCreateContinuousQueuedReplayableEvent(queuedMouse, blockedOn, domEventName, eventSystemFlags, targetContainer, mouseEvent);\n        return true;\n      }\n\n    case 'pointerover':\n      {\n        var pointerEvent = nativeEvent;\n        var pointerId = pointerEvent.pointerId;\n        queuedPointers.set(pointerId, accumulateOrCreateContinuousQueuedReplayableEvent(queuedPointers.get(pointerId) || null, blockedOn, domEventName, eventSystemFlags, targetContainer, pointerEvent));\n        return true;\n      }\n\n    case 'gotpointercapture':\n      {\n        var _pointerEvent = nativeEvent;\n        var _pointerId2 = _pointerEvent.pointerId;\n        queuedPointerCaptures.set(_pointerId2, accumulateOrCreateContinuousQueuedReplayableEvent(queuedPointerCaptures.get(_pointerId2) || null, blockedOn, domEventName, eventSystemFlags, targetContainer, _pointerEvent));\n        return true;\n      }\n  }\n\n  return false;\n} // Check if this target is unblocked. Returns true if it's unblocked.\n\nfunction attemptExplicitHydrationTarget(queuedTarget) {\n  // TODO: This function shares a lot of logic with attemptToDispatchEvent.\n  // Try to unify them. It's a bit tricky since it would require two return\n  // values.\n  var targetInst = getClosestInstanceFromNode(queuedTarget.target);\n\n  if (targetInst !== null) {\n    var nearestMounted = getNearestMountedFiber(targetInst);\n\n    if (nearestMounted !== null) {\n      var tag = nearestMounted.tag;\n\n      if (tag === SuspenseComponent) {\n        var instance = getSuspenseInstanceFromFiber(nearestMounted);\n\n        if (instance !== null) {\n          // We're blocked on hydrating this boundary.\n          // Increase its priority.\n          queuedTarget.blockedOn = instance;\n          attemptHydrationAtPriority(queuedTarget.lanePriority, function () {\n            Scheduler.unstable_runWithPriority(queuedTarget.priority, function () {\n              attemptHydrationAtCurrentPriority(nearestMounted);\n            });\n          });\n          return;\n        }\n      } else if (tag === HostRoot) {\n        var root = nearestMounted.stateNode;\n\n        if (root.hydrate) {\n          queuedTarget.blockedOn = getContainerFromFiber(nearestMounted); // We don't currently have a way to increase the priority of\n          // a root other than sync.\n\n          return;\n        }\n      }\n    }\n  }\n\n  queuedTarget.blockedOn = null;\n}\n\nfunction attemptReplayContinuousQueuedEvent(queuedEvent) {\n  if (queuedEvent.blockedOn !== null) {\n    return false;\n  }\n\n  var targetContainers = queuedEvent.targetContainers;\n\n  while (targetContainers.length > 0) {\n    var targetContainer = targetContainers[0];\n    var nextBlockedOn = attemptToDispatchEvent(queuedEvent.domEventName, queuedEvent.eventSystemFlags, targetContainer, queuedEvent.nativeEvent);\n\n    if (nextBlockedOn !== null) {\n      // We're still blocked. Try again later.\n      var _fiber3 = getInstanceFromNode(nextBlockedOn);\n\n      if (_fiber3 !== null) {\n        attemptContinuousHydration(_fiber3);\n      }\n\n      queuedEvent.blockedOn = nextBlockedOn;\n      return false;\n    } // This target container was successfully dispatched. Try the next.\n\n\n    targetContainers.shift();\n  }\n\n  return true;\n}\n\nfunction attemptReplayContinuousQueuedEventInMap(queuedEvent, key, map) {\n  if (attemptReplayContinuousQueuedEvent(queuedEvent)) {\n    map.delete(key);\n  }\n}\n\nfunction replayUnblockedEvents() {\n  hasScheduledReplayAttempt = false; // First replay discrete events.\n\n  while (queuedDiscreteEvents.length > 0) {\n    var nextDiscreteEvent = queuedDiscreteEvents[0];\n\n    if (nextDiscreteEvent.blockedOn !== null) {\n      // We're still blocked.\n      // Increase the priority of this boundary to unblock\n      // the next discrete event.\n      var _fiber4 = getInstanceFromNode(nextDiscreteEvent.blockedOn);\n\n      if (_fiber4 !== null) {\n        attemptUserBlockingHydration(_fiber4);\n      }\n\n      break;\n    }\n\n    var targetContainers = nextDiscreteEvent.targetContainers;\n\n    while (targetContainers.length > 0) {\n      var targetContainer = targetContainers[0];\n      var nextBlockedOn = attemptToDispatchEvent(nextDiscreteEvent.domEventName, nextDiscreteEvent.eventSystemFlags, targetContainer, nextDiscreteEvent.nativeEvent);\n\n      if (nextBlockedOn !== null) {\n        // We're still blocked. Try again later.\n        nextDiscreteEvent.blockedOn = nextBlockedOn;\n        break;\n      } // This target container was successfully dispatched. Try the next.\n\n\n      targetContainers.shift();\n    }\n\n    if (nextDiscreteEvent.blockedOn === null) {\n      // We've successfully replayed the first event. Let's try the next one.\n      queuedDiscreteEvents.shift();\n    }\n  } // Next replay any continuous events.\n\n\n  if (queuedFocus !== null && attemptReplayContinuousQueuedEvent(queuedFocus)) {\n    queuedFocus = null;\n  }\n\n  if (queuedDrag !== null && attemptReplayContinuousQueuedEvent(queuedDrag)) {\n    queuedDrag = null;\n  }\n\n  if (queuedMouse !== null && attemptReplayContinuousQueuedEvent(queuedMouse)) {\n    queuedMouse = null;\n  }\n\n  queuedPointers.forEach(attemptReplayContinuousQueuedEventInMap);\n  queuedPointerCaptures.forEach(attemptReplayContinuousQueuedEventInMap);\n}\n\nfunction scheduleCallbackIfUnblocked(queuedEvent, unblocked) {\n  if (queuedEvent.blockedOn === unblocked) {\n    queuedEvent.blockedOn = null;\n\n    if (!hasScheduledReplayAttempt) {\n      hasScheduledReplayAttempt = true; // Schedule a callback to attempt replaying as many events as are\n      // now unblocked. This first might not actually be unblocked yet.\n      // We could check it early to avoid scheduling an unnecessary callback.\n\n      Scheduler.unstable_scheduleCallback(Scheduler.unstable_NormalPriority, replayUnblockedEvents);\n    }\n  }\n}\n\nfunction retryIfBlockedOn(unblocked) {\n  // Mark anything that was blocked on this as no longer blocked\n  // and eligible for a replay.\n  if (queuedDiscreteEvents.length > 0) {\n    scheduleCallbackIfUnblocked(queuedDiscreteEvents[0], unblocked); // This is a exponential search for each boundary that commits. I think it's\n    // worth it because we expect very few discrete events to queue up and once\n    // we are actually fully unblocked it will be fast to replay them.\n\n    for (var i = 1; i < queuedDiscreteEvents.length; i++) {\n      var queuedEvent = queuedDiscreteEvents[i];\n\n      if (queuedEvent.blockedOn === unblocked) {\n        queuedEvent.blockedOn = null;\n      }\n    }\n  }\n\n  if (queuedFocus !== null) {\n    scheduleCallbackIfUnblocked(queuedFocus, unblocked);\n  }\n\n  if (queuedDrag !== null) {\n    scheduleCallbackIfUnblocked(queuedDrag, unblocked);\n  }\n\n  if (queuedMouse !== null) {\n    scheduleCallbackIfUnblocked(queuedMouse, unblocked);\n  }\n\n  var unblock = function (queuedEvent) {\n    return scheduleCallbackIfUnblocked(queuedEvent, unblocked);\n  };\n\n  queuedPointers.forEach(unblock);\n  queuedPointerCaptures.forEach(unblock);\n\n  for (var _i = 0; _i < queuedExplicitHydrationTargets.length; _i++) {\n    var queuedTarget = queuedExplicitHydrationTargets[_i];\n\n    if (queuedTarget.blockedOn === unblocked) {\n      queuedTarget.blockedOn = null;\n    }\n  }\n\n  while (queuedExplicitHydrationTargets.length > 0) {\n    var nextExplicitTarget = queuedExplicitHydrationTargets[0];\n\n    if (nextExplicitTarget.blockedOn !== null) {\n      // We're still blocked.\n      break;\n    } else {\n      attemptExplicitHydrationTarget(nextExplicitTarget);\n\n      if (nextExplicitTarget.blockedOn === null) {\n        // We're unblocked.\n        queuedExplicitHydrationTargets.shift();\n      }\n    }\n  }\n}\n\nvar DiscreteEvent = 0;\nvar UserBlockingEvent = 1;\nvar ContinuousEvent = 2;\n\n/**\n * Generate a mapping of standard vendor prefixes using the defined style property and event name.\n *\n * @param {string} styleProp\n * @param {string} eventName\n * @returns {object}\n */\n\nfunction makePrefixMap(styleProp, eventName) {\n  var prefixes = {};\n  prefixes[styleProp.toLowerCase()] = eventName.toLowerCase();\n  prefixes['Webkit' + styleProp] = 'webkit' + eventName;\n  prefixes['Moz' + styleProp] = 'moz' + eventName;\n  return prefixes;\n}\n/**\n * A list of event names to a configurable list of vendor prefixes.\n */\n\n\nvar vendorPrefixes = {\n  animationend: makePrefixMap('Animation', 'AnimationEnd'),\n  animationiteration: makePrefixMap('Animation', 'AnimationIteration'),\n  animationstart: makePrefixMap('Animation', 'AnimationStart'),\n  transitionend: makePrefixMap('Transition', 'TransitionEnd')\n};\n/**\n * Event names that have already been detected and prefixed (if applicable).\n */\n\nvar prefixedEventNames = {};\n/**\n * Element to check for prefixes on.\n */\n\nvar style = {};\n/**\n * Bootstrap if a DOM exists.\n */\n\nif (canUseDOM) {\n  style = document.createElement('div').style; // On some platforms, in particular some releases of Android 4.x,\n  // the un-prefixed \"animation\" and \"transition\" properties are defined on the\n  // style object but the events that fire will still be prefixed, so we need\n  // to check if the un-prefixed events are usable, and if not remove them from the map.\n\n  if (!('AnimationEvent' in window)) {\n    delete vendorPrefixes.animationend.animation;\n    delete vendorPrefixes.animationiteration.animation;\n    delete vendorPrefixes.animationstart.animation;\n  } // Same as above\n\n\n  if (!('TransitionEvent' in window)) {\n    delete vendorPrefixes.transitionend.transition;\n  }\n}\n/**\n * Attempts to determine the correct vendor prefixed event name.\n *\n * @param {string} eventName\n * @returns {string}\n */\n\n\nfunction getVendorPrefixedEventName(eventName) {\n  if (prefixedEventNames[eventName]) {\n    return prefixedEventNames[eventName];\n  } else if (!vendorPrefixes[eventName]) {\n    return eventName;\n  }\n\n  var prefixMap = vendorPrefixes[eventName];\n\n  for (var styleProp in prefixMap) {\n    if (prefixMap.hasOwnProperty(styleProp) && styleProp in style) {\n      return prefixedEventNames[eventName] = prefixMap[styleProp];\n    }\n  }\n\n  return eventName;\n}\n\nvar ANIMATION_END = getVendorPrefixedEventName('animationend');\nvar ANIMATION_ITERATION = getVendorPrefixedEventName('animationiteration');\nvar ANIMATION_START = getVendorPrefixedEventName('animationstart');\nvar TRANSITION_END = getVendorPrefixedEventName('transitionend');\n\nvar topLevelEventsToReactNames = new Map();\nvar eventPriorities = new Map(); // We store most of the events in this module in pairs of two strings so we can re-use\n// the code required to apply the same logic for event prioritization and that of the\n// SimpleEventPlugin. This complicates things slightly, but the aim is to reduce code\n// duplication (for which there would be quite a bit). For the events that are not needed\n// for the SimpleEventPlugin (otherDiscreteEvents) we process them separately as an\n// array of top level events.\n// Lastly, we ignore prettier so we can keep the formatting sane.\n// prettier-ignore\n\nvar discreteEventPairsForSimpleEventPlugin = ['cancel', 'cancel', 'click', 'click', 'close', 'close', 'contextmenu', 'contextMenu', 'copy', 'copy', 'cut', 'cut', 'auxclick', 'auxClick', 'dblclick', 'doubleClick', // Careful!\n'dragend', 'dragEnd', 'dragstart', 'dragStart', 'drop', 'drop', 'focusin', 'focus', // Careful!\n'focusout', 'blur', // Careful!\n'input', 'input', 'invalid', 'invalid', 'keydown', 'keyDown', 'keypress', 'keyPress', 'keyup', 'keyUp', 'mousedown', 'mouseDown', 'mouseup', 'mouseUp', 'paste', 'paste', 'pause', 'pause', 'play', 'play', 'pointercancel', 'pointerCancel', 'pointerdown', 'pointerDown', 'pointerup', 'pointerUp', 'ratechange', 'rateChange', 'reset', 'reset', 'seeked', 'seeked', 'submit', 'submit', 'touchcancel', 'touchCancel', 'touchend', 'touchEnd', 'touchstart', 'touchStart', 'volumechange', 'volumeChange'];\nvar otherDiscreteEvents = ['change', 'selectionchange', 'textInput', 'compositionstart', 'compositionend', 'compositionupdate'];\n\n\nvar userBlockingPairsForSimpleEventPlugin = ['drag', 'drag', 'dragenter', 'dragEnter', 'dragexit', 'dragExit', 'dragleave', 'dragLeave', 'dragover', 'dragOver', 'mousemove', 'mouseMove', 'mouseout', 'mouseOut', 'mouseover', 'mouseOver', 'pointermove', 'pointerMove', 'pointerout', 'pointerOut', 'pointerover', 'pointerOver', 'scroll', 'scroll', 'toggle', 'toggle', 'touchmove', 'touchMove', 'wheel', 'wheel']; // prettier-ignore\n\nvar continuousPairsForSimpleEventPlugin = ['abort', 'abort', ANIMATION_END, 'animationEnd', ANIMATION_ITERATION, 'animationIteration', ANIMATION_START, 'animationStart', 'canplay', 'canPlay', 'canplaythrough', 'canPlayThrough', 'durationchange', 'durationChange', 'emptied', 'emptied', 'encrypted', 'encrypted', 'ended', 'ended', 'error', 'error', 'gotpointercapture', 'gotPointerCapture', 'load', 'load', 'loadeddata', 'loadedData', 'loadedmetadata', 'loadedMetadata', 'loadstart', 'loadStart', 'lostpointercapture', 'lostPointerCapture', 'playing', 'playing', 'progress', 'progress', 'seeking', 'seeking', 'stalled', 'stalled', 'suspend', 'suspend', 'timeupdate', 'timeUpdate', TRANSITION_END, 'transitionEnd', 'waiting', 'waiting'];\n/**\n * Turns\n * ['abort', ...]\n *\n * into\n *\n * topLevelEventsToReactNames = new Map([\n *   ['abort', 'onAbort'],\n * ]);\n *\n * and registers them.\n */\n\nfunction registerSimplePluginEventsAndSetTheirPriorities(eventTypes, priority) {\n  // As the event types are in pairs of two, we need to iterate\n  // through in twos. The events are in pairs of two to save code\n  // and improve init perf of processing this array, as it will\n  // result in far fewer object allocations and property accesses\n  // if we only use three arrays to process all the categories of\n  // instead of tuples.\n  for (var i = 0; i < eventTypes.length; i += 2) {\n    var topEvent = eventTypes[i];\n    var event = eventTypes[i + 1];\n    var capitalizedEvent = event[0].toUpperCase() + event.slice(1);\n    var reactName = 'on' + capitalizedEvent;\n    eventPriorities.set(topEvent, priority);\n    topLevelEventsToReactNames.set(topEvent, reactName);\n    registerTwoPhaseEvent(reactName, [topEvent]);\n  }\n}\n\nfunction setEventPriorities(eventTypes, priority) {\n  for (var i = 0; i < eventTypes.length; i++) {\n    eventPriorities.set(eventTypes[i], priority);\n  }\n}\n\nfunction getEventPriorityForPluginSystem(domEventName) {\n  var priority = eventPriorities.get(domEventName); // Default to a ContinuousEvent. Note: we might\n  // want to warn if we can't detect the priority\n  // for the event.\n\n  return priority === undefined ? ContinuousEvent : priority;\n}\nfunction registerSimpleEvents() {\n  registerSimplePluginEventsAndSetTheirPriorities(discreteEventPairsForSimpleEventPlugin, DiscreteEvent);\n  registerSimplePluginEventsAndSetTheirPriorities(userBlockingPairsForSimpleEventPlugin, UserBlockingEvent);\n  registerSimplePluginEventsAndSetTheirPriorities(continuousPairsForSimpleEventPlugin, ContinuousEvent);\n  setEventPriorities(otherDiscreteEvents, DiscreteEvent);\n}\n\nvar Scheduler_now = Scheduler.unstable_now;\n\n{\n  // Provide explicit error message when production+profiling bundle of e.g.\n  // react-dom is used with production (non-profiling) bundle of\n  // scheduler/tracing\n  if (!(tracing.__interactionsRef != null && tracing.__interactionsRef.current != null)) {\n    {\n      throw Error( \"It is not supported to run the profiling version of a renderer (for example, `react-dom/profiling`) without also replacing the `scheduler/tracing` module with `scheduler/tracing-profiling`. Your bundler might have a setting for aliasing both modules. Learn more at https://reactjs.org/link/profiling\" );\n    }\n  }\n}\n// ascending numbers so we can compare them like numbers. They start at 90 to\n// avoid clashing with Scheduler's priorities.\n\nvar ImmediatePriority = 99;\nvar UserBlockingPriority = 98;\nvar NormalPriority = 97;\nvar LowPriority = 96;\nvar IdlePriority = 95; // NoPriority is the absence of priority. Also React-only.\n\nvar NoPriority = 90;\nvar initialTimeMs = Scheduler_now(); // If the initial timestamp is reasonably small, use Scheduler's `now` directly.\n\nvar SyncLanePriority = 15;\nvar SyncBatchedLanePriority = 14;\nvar InputDiscreteHydrationLanePriority = 13;\nvar InputDiscreteLanePriority = 12;\nvar InputContinuousHydrationLanePriority = 11;\nvar InputContinuousLanePriority = 10;\nvar DefaultHydrationLanePriority = 9;\nvar DefaultLanePriority = 8;\nvar TransitionHydrationPriority = 7;\nvar TransitionPriority = 6;\nvar RetryLanePriority = 5;\nvar SelectiveHydrationLanePriority = 4;\nvar IdleHydrationLanePriority = 3;\nvar IdleLanePriority = 2;\nvar OffscreenLanePriority = 1;\nvar NoLanePriority = 0;\nvar TotalLanes = 31;\nvar NoLanes =\n/*                        */\n0;\nvar NoLane =\n/*                          */\n0;\nvar SyncLane =\n/*                        */\n1;\nvar SyncBatchedLane =\n/*                 */\n2;\nvar InputDiscreteHydrationLane =\n/*      */\n4;\nvar InputDiscreteLanes =\n/*                    */\n24;\nvar InputContinuousHydrationLane =\n/*           */\n32;\nvar InputContinuousLanes =\n/*                  */\n192;\nvar DefaultHydrationLane =\n/*            */\n256;\nvar DefaultLanes =\n/*                   */\n3584;\nvar TransitionHydrationLane =\n/*                */\n4096;\nvar TransitionLanes =\n/*                       */\n4186112;\nvar RetryLanes =\n/*                            */\n62914560;\nvar SomeRetryLane =\n/*                  */\n33554432;\nvar SelectiveHydrationLane =\n/*          */\n67108864;\nvar NonIdleLanes =\n/*                                 */\n134217727;\nvar IdleHydrationLane =\n/*               */\n134217728;\nvar IdleLanes =\n/*                             */\n805306368;\nvar OffscreenLane =\n/*                   */\n1073741824;\nvar NoTimestamp = -1;\nfunction setCurrentUpdateLanePriority(newLanePriority) {\n} // \"Registers\" used to \"return\" multiple values\n// Used by getHighestPriorityLanes and getNextLanes:\n\nvar return_highestLanePriority = DefaultLanePriority;\n\nfunction getHighestPriorityLanes(lanes) {\n  if ((SyncLane & lanes) !== NoLanes) {\n    return_highestLanePriority = SyncLanePriority;\n    return SyncLane;\n  }\n\n  if ((SyncBatchedLane & lanes) !== NoLanes) {\n    return_highestLanePriority = SyncBatchedLanePriority;\n    return SyncBatchedLane;\n  }\n\n  if ((InputDiscreteHydrationLane & lanes) !== NoLanes) {\n    return_highestLanePriority = InputDiscreteHydrationLanePriority;\n    return InputDiscreteHydrationLane;\n  }\n\n  var inputDiscreteLanes = InputDiscreteLanes & lanes;\n\n  if (inputDiscreteLanes !== NoLanes) {\n    return_highestLanePriority = InputDiscreteLanePriority;\n    return inputDiscreteLanes;\n  }\n\n  if ((lanes & InputContinuousHydrationLane) !== NoLanes) {\n    return_highestLanePriority = InputContinuousHydrationLanePriority;\n    return InputContinuousHydrationLane;\n  }\n\n  var inputContinuousLanes = InputContinuousLanes & lanes;\n\n  if (inputContinuousLanes !== NoLanes) {\n    return_highestLanePriority = InputContinuousLanePriority;\n    return inputContinuousLanes;\n  }\n\n  if ((lanes & DefaultHydrationLane) !== NoLanes) {\n    return_highestLanePriority = DefaultHydrationLanePriority;\n    return DefaultHydrationLane;\n  }\n\n  var defaultLanes = DefaultLanes & lanes;\n\n  if (defaultLanes !== NoLanes) {\n    return_highestLanePriority = DefaultLanePriority;\n    return defaultLanes;\n  }\n\n  if ((lanes & TransitionHydrationLane) !== NoLanes) {\n    return_highestLanePriority = TransitionHydrationPriority;\n    return TransitionHydrationLane;\n  }\n\n  var transitionLanes = TransitionLanes & lanes;\n\n  if (transitionLanes !== NoLanes) {\n    return_highestLanePriority = TransitionPriority;\n    return transitionLanes;\n  }\n\n  var retryLanes = RetryLanes & lanes;\n\n  if (retryLanes !== NoLanes) {\n    return_highestLanePriority = RetryLanePriority;\n    return retryLanes;\n  }\n\n  if (lanes & SelectiveHydrationLane) {\n    return_highestLanePriority = SelectiveHydrationLanePriority;\n    return SelectiveHydrationLane;\n  }\n\n  if ((lanes & IdleHydrationLane) !== NoLanes) {\n    return_highestLanePriority = IdleHydrationLanePriority;\n    return IdleHydrationLane;\n  }\n\n  var idleLanes = IdleLanes & lanes;\n\n  if (idleLanes !== NoLanes) {\n    return_highestLanePriority = IdleLanePriority;\n    return idleLanes;\n  }\n\n  if ((OffscreenLane & lanes) !== NoLanes) {\n    return_highestLanePriority = OffscreenLanePriority;\n    return OffscreenLane;\n  }\n\n  {\n    error('Should have found matching lanes. This is a bug in React.');\n  } // This shouldn't be reachable, but as a fallback, return the entire bitmask.\n\n\n  return_highestLanePriority = DefaultLanePriority;\n  return lanes;\n}\n\nfunction schedulerPriorityToLanePriority(schedulerPriorityLevel) {\n  switch (schedulerPriorityLevel) {\n    case ImmediatePriority:\n      return SyncLanePriority;\n\n    case UserBlockingPriority:\n      return InputContinuousLanePriority;\n\n    case NormalPriority:\n    case LowPriority:\n      // TODO: Handle LowSchedulerPriority, somehow. Maybe the same lane as hydration.\n      return DefaultLanePriority;\n\n    case IdlePriority:\n      return IdleLanePriority;\n\n    default:\n      return NoLanePriority;\n  }\n}\nfunction lanePriorityToSchedulerPriority(lanePriority) {\n  switch (lanePriority) {\n    case SyncLanePriority:\n    case SyncBatchedLanePriority:\n      return ImmediatePriority;\n\n    case InputDiscreteHydrationLanePriority:\n    case InputDiscreteLanePriority:\n    case InputContinuousHydrationLanePriority:\n    case InputContinuousLanePriority:\n      return UserBlockingPriority;\n\n    case DefaultHydrationLanePriority:\n    case DefaultLanePriority:\n    case TransitionHydrationPriority:\n    case TransitionPriority:\n    case SelectiveHydrationLanePriority:\n    case RetryLanePriority:\n      return NormalPriority;\n\n    case IdleHydrationLanePriority:\n    case IdleLanePriority:\n    case OffscreenLanePriority:\n      return IdlePriority;\n\n    case NoLanePriority:\n      return NoPriority;\n\n    default:\n      {\n        {\n          throw Error( \"Invalid update priority: \" + lanePriority + \". This is a bug in React.\" );\n        }\n      }\n\n  }\n}\nfunction getNextLanes(root, wipLanes) {\n  // Early bailout if there's no pending work left.\n  var pendingLanes = root.pendingLanes;\n\n  if (pendingLanes === NoLanes) {\n    return_highestLanePriority = NoLanePriority;\n    return NoLanes;\n  }\n\n  var nextLanes = NoLanes;\n  var nextLanePriority = NoLanePriority;\n  var expiredLanes = root.expiredLanes;\n  var suspendedLanes = root.suspendedLanes;\n  var pingedLanes = root.pingedLanes; // Check if any work has expired.\n\n  if (expiredLanes !== NoLanes) {\n    nextLanes = expiredLanes;\n    nextLanePriority = return_highestLanePriority = SyncLanePriority;\n  } else {\n    // Do not work on any idle work until all the non-idle work has finished,\n    // even if the work is suspended.\n    var nonIdlePendingLanes = pendingLanes & NonIdleLanes;\n\n    if (nonIdlePendingLanes !== NoLanes) {\n      var nonIdleUnblockedLanes = nonIdlePendingLanes & ~suspendedLanes;\n\n      if (nonIdleUnblockedLanes !== NoLanes) {\n        nextLanes = getHighestPriorityLanes(nonIdleUnblockedLanes);\n        nextLanePriority = return_highestLanePriority;\n      } else {\n        var nonIdlePingedLanes = nonIdlePendingLanes & pingedLanes;\n\n        if (nonIdlePingedLanes !== NoLanes) {\n          nextLanes = getHighestPriorityLanes(nonIdlePingedLanes);\n          nextLanePriority = return_highestLanePriority;\n        }\n      }\n    } else {\n      // The only remaining work is Idle.\n      var unblockedLanes = pendingLanes & ~suspendedLanes;\n\n      if (unblockedLanes !== NoLanes) {\n        nextLanes = getHighestPriorityLanes(unblockedLanes);\n        nextLanePriority = return_highestLanePriority;\n      } else {\n        if (pingedLanes !== NoLanes) {\n          nextLanes = getHighestPriorityLanes(pingedLanes);\n          nextLanePriority = return_highestLanePriority;\n        }\n      }\n    }\n  }\n\n  if (nextLanes === NoLanes) {\n    // This should only be reachable if we're suspended\n    // TODO: Consider warning in this path if a fallback timer is not scheduled.\n    return NoLanes;\n  } // If there are higher priority lanes, we'll include them even if they\n  // are suspended.\n\n\n  nextLanes = pendingLanes & getEqualOrHigherPriorityLanes(nextLanes); // If we're already in the middle of a render, switching lanes will interrupt\n  // it and we'll lose our progress. We should only do this if the new lanes are\n  // higher priority.\n\n  if (wipLanes !== NoLanes && wipLanes !== nextLanes && // If we already suspended with a delay, then interrupting is fine. Don't\n  // bother waiting until the root is complete.\n  (wipLanes & suspendedLanes) === NoLanes) {\n    getHighestPriorityLanes(wipLanes);\n    var wipLanePriority = return_highestLanePriority;\n\n    if (nextLanePriority <= wipLanePriority) {\n      return wipLanes;\n    } else {\n      return_highestLanePriority = nextLanePriority;\n    }\n  } // Check for entangled lanes and add them to the batch.\n  //\n  // A lane is said to be entangled with another when it's not allowed to render\n  // in a batch that does not also include the other lane. Typically we do this\n  // when multiple updates have the same source, and we only want to respond to\n  // the most recent event from that source.\n  //\n  // Note that we apply entanglements *after* checking for partial work above.\n  // This means that if a lane is entangled during an interleaved event while\n  // it's already rendering, we won't interrupt it. This is intentional, since\n  // entanglement is usually \"best effort\": we'll try our best to render the\n  // lanes in the same batch, but it's not worth throwing out partially\n  // completed work in order to do it.\n  //\n  // For those exceptions where entanglement is semantically important, like\n  // useMutableSource, we should ensure that there is no partial work at the\n  // time we apply the entanglement.\n\n\n  var entangledLanes = root.entangledLanes;\n\n  if (entangledLanes !== NoLanes) {\n    var entanglements = root.entanglements;\n    var lanes = nextLanes & entangledLanes;\n\n    while (lanes > 0) {\n      var index = pickArbitraryLaneIndex(lanes);\n      var lane = 1 << index;\n      nextLanes |= entanglements[index];\n      lanes &= ~lane;\n    }\n  }\n\n  return nextLanes;\n}\nfunction getMostRecentEventTime(root, lanes) {\n  var eventTimes = root.eventTimes;\n  var mostRecentEventTime = NoTimestamp;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    var eventTime = eventTimes[index];\n\n    if (eventTime > mostRecentEventTime) {\n      mostRecentEventTime = eventTime;\n    }\n\n    lanes &= ~lane;\n  }\n\n  return mostRecentEventTime;\n}\n\nfunction computeExpirationTime(lane, currentTime) {\n  // TODO: Expiration heuristic is constant per lane, so could use a map.\n  getHighestPriorityLanes(lane);\n  var priority = return_highestLanePriority;\n\n  if (priority >= InputContinuousLanePriority) {\n    // User interactions should expire slightly more quickly.\n    //\n    // NOTE: This is set to the corresponding constant as in Scheduler.js. When\n    // we made it larger, a product metric in www regressed, suggesting there's\n    // a user interaction that's being starved by a series of synchronous\n    // updates. If that theory is correct, the proper solution is to fix the\n    // starvation. However, this scenario supports the idea that expiration\n    // times are an important safeguard when starvation does happen.\n    //\n    // Also note that, in the case of user input specifically, this will soon no\n    // longer be an issue because we plan to make user input synchronous by\n    // default (until you enter `startTransition`, of course.)\n    //\n    // If weren't planning to make these updates synchronous soon anyway, I\n    // would probably make this number a configurable parameter.\n    return currentTime + 250;\n  } else if (priority >= TransitionPriority) {\n    return currentTime + 5000;\n  } else {\n    // Anything idle priority or lower should never expire.\n    return NoTimestamp;\n  }\n}\n\nfunction markStarvedLanesAsExpired(root, currentTime) {\n  // TODO: This gets called every time we yield. We can optimize by storing\n  // the earliest expiration time on the root. Then use that to quickly bail out\n  // of this function.\n  var pendingLanes = root.pendingLanes;\n  var suspendedLanes = root.suspendedLanes;\n  var pingedLanes = root.pingedLanes;\n  var expirationTimes = root.expirationTimes; // Iterate through the pending lanes and check if we've reached their\n  // expiration time. If so, we'll assume the update is being starved and mark\n  // it as expired to force it to finish.\n\n  var lanes = pendingLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    var expirationTime = expirationTimes[index];\n\n    if (expirationTime === NoTimestamp) {\n      // Found a pending lane with no expiration time. If it's not suspended, or\n      // if it's pinged, assume it's CPU-bound. Compute a new expiration time\n      // using the current time.\n      if ((lane & suspendedLanes) === NoLanes || (lane & pingedLanes) !== NoLanes) {\n        // Assumes timestamps are monotonically increasing.\n        expirationTimes[index] = computeExpirationTime(lane, currentTime);\n      }\n    } else if (expirationTime <= currentTime) {\n      // This lane expired\n      root.expiredLanes |= lane;\n    }\n\n    lanes &= ~lane;\n  }\n} // This returns the highest priority pending lanes regardless of whether they\nfunction getLanesToRetrySynchronouslyOnError(root) {\n  var everythingButOffscreen = root.pendingLanes & ~OffscreenLane;\n\n  if (everythingButOffscreen !== NoLanes) {\n    return everythingButOffscreen;\n  }\n\n  if (everythingButOffscreen & OffscreenLane) {\n    return OffscreenLane;\n  }\n\n  return NoLanes;\n}\nfunction returnNextLanesPriority() {\n  return return_highestLanePriority;\n}\nfunction includesNonIdleWork(lanes) {\n  return (lanes & NonIdleLanes) !== NoLanes;\n}\nfunction includesOnlyRetries(lanes) {\n  return (lanes & RetryLanes) === lanes;\n}\nfunction includesOnlyTransitions(lanes) {\n  return (lanes & TransitionLanes) === lanes;\n} // To ensure consistency across multiple updates in the same event, this should\n// be a pure function, so that it always returns the same lane for given inputs.\n\nfunction findUpdateLane(lanePriority, wipLanes) {\n  switch (lanePriority) {\n    case NoLanePriority:\n      break;\n\n    case SyncLanePriority:\n      return SyncLane;\n\n    case SyncBatchedLanePriority:\n      return SyncBatchedLane;\n\n    case InputDiscreteLanePriority:\n      {\n        var _lane = pickArbitraryLane(InputDiscreteLanes & ~wipLanes);\n\n        if (_lane === NoLane) {\n          // Shift to the next priority level\n          return findUpdateLane(InputContinuousLanePriority, wipLanes);\n        }\n\n        return _lane;\n      }\n\n    case InputContinuousLanePriority:\n      {\n        var _lane2 = pickArbitraryLane(InputContinuousLanes & ~wipLanes);\n\n        if (_lane2 === NoLane) {\n          // Shift to the next priority level\n          return findUpdateLane(DefaultLanePriority, wipLanes);\n        }\n\n        return _lane2;\n      }\n\n    case DefaultLanePriority:\n      {\n        var _lane3 = pickArbitraryLane(DefaultLanes & ~wipLanes);\n\n        if (_lane3 === NoLane) {\n          // If all the default lanes are already being worked on, look for a\n          // lane in the transition range.\n          _lane3 = pickArbitraryLane(TransitionLanes & ~wipLanes);\n\n          if (_lane3 === NoLane) {\n            // All the transition lanes are taken, too. This should be very\n            // rare, but as a last resort, pick a default lane. This will have\n            // the effect of interrupting the current work-in-progress render.\n            _lane3 = pickArbitraryLane(DefaultLanes);\n          }\n        }\n\n        return _lane3;\n      }\n\n    case TransitionPriority: // Should be handled by findTransitionLane instead\n\n    case RetryLanePriority:\n      // Should be handled by findRetryLane instead\n      break;\n\n    case IdleLanePriority:\n      var lane = pickArbitraryLane(IdleLanes & ~wipLanes);\n\n      if (lane === NoLane) {\n        lane = pickArbitraryLane(IdleLanes);\n      }\n\n      return lane;\n  }\n\n  {\n    {\n      throw Error( \"Invalid update priority: \" + lanePriority + \". This is a bug in React.\" );\n    }\n  }\n} // To ensure consistency across multiple updates in the same event, this should\n// be pure function, so that it always returns the same lane for given inputs.\n\nfunction findTransitionLane(wipLanes, pendingLanes) {\n  // First look for lanes that are completely unclaimed, i.e. have no\n  // pending work.\n  var lane = pickArbitraryLane(TransitionLanes & ~pendingLanes);\n\n  if (lane === NoLane) {\n    // If all lanes have pending work, look for a lane that isn't currently\n    // being worked on.\n    lane = pickArbitraryLane(TransitionLanes & ~wipLanes);\n\n    if (lane === NoLane) {\n      // If everything is being worked on, pick any lane. This has the\n      // effect of interrupting the current work-in-progress.\n      lane = pickArbitraryLane(TransitionLanes);\n    }\n  }\n\n  return lane;\n} // To ensure consistency across multiple updates in the same event, this should\n// be pure function, so that it always returns the same lane for given inputs.\n\nfunction findRetryLane(wipLanes) {\n  // This is a fork of `findUpdateLane` designed specifically for Suspense\n  // \"retries\" — a special update that attempts to flip a Suspense boundary\n  // from its placeholder state to its primary/resolved state.\n  var lane = pickArbitraryLane(RetryLanes & ~wipLanes);\n\n  if (lane === NoLane) {\n    lane = pickArbitraryLane(RetryLanes);\n  }\n\n  return lane;\n}\n\nfunction getHighestPriorityLane(lanes) {\n  return lanes & -lanes;\n}\n\nfunction getLowestPriorityLane(lanes) {\n  // This finds the most significant non-zero bit.\n  var index = 31 - clz32(lanes);\n  return index < 0 ? NoLanes : 1 << index;\n}\n\nfunction getEqualOrHigherPriorityLanes(lanes) {\n  return (getLowestPriorityLane(lanes) << 1) - 1;\n}\n\nfunction pickArbitraryLane(lanes) {\n  // This wrapper function gets inlined. Only exists so to communicate that it\n  // doesn't matter which bit is selected; you can pick any bit without\n  // affecting the algorithms where its used. Here I'm using\n  // getHighestPriorityLane because it requires the fewest operations.\n  return getHighestPriorityLane(lanes);\n}\n\nfunction pickArbitraryLaneIndex(lanes) {\n  return 31 - clz32(lanes);\n}\n\nfunction laneToIndex(lane) {\n  return pickArbitraryLaneIndex(lane);\n}\n\nfunction includesSomeLane(a, b) {\n  return (a & b) !== NoLanes;\n}\nfunction isSubsetOfLanes(set, subset) {\n  return (set & subset) === subset;\n}\nfunction mergeLanes(a, b) {\n  return a | b;\n}\nfunction removeLanes(set, subset) {\n  return set & ~subset;\n} // Seems redundant, but it changes the type from a single lane (used for\n// updates) to a group of lanes (used for flushing work).\n\nfunction laneToLanes(lane) {\n  return lane;\n}\nfunction higherPriorityLane(a, b) {\n  // This works because the bit ranges decrease in priority as you go left.\n  return a !== NoLane && a < b ? a : b;\n}\nfunction createLaneMap(initial) {\n  // Intentionally pushing one by one.\n  // https://v8.dev/blog/elements-kinds#avoid-creating-holes\n  var laneMap = [];\n\n  for (var i = 0; i < TotalLanes; i++) {\n    laneMap.push(initial);\n  }\n\n  return laneMap;\n}\nfunction markRootUpdated(root, updateLane, eventTime) {\n  root.pendingLanes |= updateLane; // TODO: Theoretically, any update to any lane can unblock any other lane. But\n  // it's not practical to try every single possible combination. We need a\n  // heuristic to decide which lanes to attempt to render, and in which batches.\n  // For now, we use the same heuristic as in the old ExpirationTimes model:\n  // retry any lane at equal or lower priority, but don't try updates at higher\n  // priority without also including the lower priority updates. This works well\n  // when considering updates across different priority levels, but isn't\n  // sufficient for updates within the same priority, since we want to treat\n  // those updates as parallel.\n  // Unsuspend any update at equal or lower priority.\n\n  var higherPriorityLanes = updateLane - 1; // Turns 0b1000 into 0b0111\n\n  root.suspendedLanes &= higherPriorityLanes;\n  root.pingedLanes &= higherPriorityLanes;\n  var eventTimes = root.eventTimes;\n  var index = laneToIndex(updateLane); // We can always overwrite an existing timestamp because we prefer the most\n  // recent event, and we assume time is monotonically increasing.\n\n  eventTimes[index] = eventTime;\n}\nfunction markRootSuspended(root, suspendedLanes) {\n  root.suspendedLanes |= suspendedLanes;\n  root.pingedLanes &= ~suspendedLanes; // The suspended lanes are no longer CPU-bound. Clear their expiration times.\n\n  var expirationTimes = root.expirationTimes;\n  var lanes = suspendedLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    expirationTimes[index] = NoTimestamp;\n    lanes &= ~lane;\n  }\n}\nfunction markRootPinged(root, pingedLanes, eventTime) {\n  root.pingedLanes |= root.suspendedLanes & pingedLanes;\n}\nfunction markDiscreteUpdatesExpired(root) {\n  root.expiredLanes |= InputDiscreteLanes & root.pendingLanes;\n}\nfunction hasDiscreteLanes(lanes) {\n  return (lanes & InputDiscreteLanes) !== NoLanes;\n}\nfunction markRootMutableRead(root, updateLane) {\n  root.mutableReadLanes |= updateLane & root.pendingLanes;\n}\nfunction markRootFinished(root, remainingLanes) {\n  var noLongerPendingLanes = root.pendingLanes & ~remainingLanes;\n  root.pendingLanes = remainingLanes; // Let's try everything again\n\n  root.suspendedLanes = 0;\n  root.pingedLanes = 0;\n  root.expiredLanes &= remainingLanes;\n  root.mutableReadLanes &= remainingLanes;\n  root.entangledLanes &= remainingLanes;\n  var entanglements = root.entanglements;\n  var eventTimes = root.eventTimes;\n  var expirationTimes = root.expirationTimes; // Clear the lanes that no longer have pending work\n\n  var lanes = noLongerPendingLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    entanglements[index] = NoLanes;\n    eventTimes[index] = NoTimestamp;\n    expirationTimes[index] = NoTimestamp;\n    lanes &= ~lane;\n  }\n}\nfunction markRootEntangled(root, entangledLanes) {\n  root.entangledLanes |= entangledLanes;\n  var entanglements = root.entanglements;\n  var lanes = entangledLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    entanglements[index] |= entangledLanes;\n    lanes &= ~lane;\n  }\n}\nvar clz32 = Math.clz32 ? Math.clz32 : clz32Fallback; // Count leading zeros. Only used on lanes, so assume input is an integer.\n// Based on:\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/clz32\n\nvar log = Math.log;\nvar LN2 = Math.LN2;\n\nfunction clz32Fallback(lanes) {\n  if (lanes === 0) {\n    return 32;\n  }\n\n  return 31 - (log(lanes) / LN2 | 0) | 0;\n}\n\n// Intentionally not named imports because Rollup would use dynamic dispatch for\nvar UserBlockingPriority$1 = Scheduler.unstable_UserBlockingPriority,\n    runWithPriority = Scheduler.unstable_runWithPriority; // TODO: can we stop exporting these?\n\nvar _enabled = true; // This is exported in FB builds for use by legacy FB layer infra.\n// We'd like to remove this but it's not clear if this is safe.\n\nfunction setEnabled(enabled) {\n  _enabled = !!enabled;\n}\nfunction isEnabled() {\n  return _enabled;\n}\nfunction createEventListenerWrapperWithPriority(targetContainer, domEventName, eventSystemFlags) {\n  var eventPriority = getEventPriorityForPluginSystem(domEventName);\n  var listenerWrapper;\n\n  switch (eventPriority) {\n    case DiscreteEvent:\n      listenerWrapper = dispatchDiscreteEvent;\n      break;\n\n    case UserBlockingEvent:\n      listenerWrapper = dispatchUserBlockingUpdate;\n      break;\n\n    case ContinuousEvent:\n    default:\n      listenerWrapper = dispatchEvent;\n      break;\n  }\n\n  return listenerWrapper.bind(null, domEventName, eventSystemFlags, targetContainer);\n}\n\nfunction dispatchDiscreteEvent(domEventName, eventSystemFlags, container, nativeEvent) {\n  {\n    flushDiscreteUpdatesIfNeeded(nativeEvent.timeStamp);\n  }\n\n  discreteUpdates(dispatchEvent, domEventName, eventSystemFlags, container, nativeEvent);\n}\n\nfunction dispatchUserBlockingUpdate(domEventName, eventSystemFlags, container, nativeEvent) {\n  {\n    runWithPriority(UserBlockingPriority$1, dispatchEvent.bind(null, domEventName, eventSystemFlags, container, nativeEvent));\n  }\n}\n\nfunction dispatchEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  if (!_enabled) {\n    return;\n  }\n\n  var allowReplay = true;\n\n  {\n    // TODO: replaying capture phase events is currently broken\n    // because we used to do it during top-level native bubble handlers\n    // but now we use different bubble and capture handlers.\n    // In eager mode, we attach capture listeners early, so we need\n    // to filter them out until we fix the logic to handle them correctly.\n    // This could've been outside the flag but I put it inside to reduce risk.\n    allowReplay = (eventSystemFlags & IS_CAPTURE_PHASE) === 0;\n  }\n\n  if (allowReplay && hasQueuedDiscreteEvents() && isReplayableDiscreteEvent(domEventName)) {\n    // If we already have a queue of discrete events, and this is another discrete\n    // event, then we can't dispatch it regardless of its target, since they\n    // need to dispatch in order.\n    queueDiscreteEvent(null, // Flags that we're not actually blocked on anything as far as we know.\n    domEventName, eventSystemFlags, targetContainer, nativeEvent);\n    return;\n  }\n\n  var blockedOn = attemptToDispatchEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent);\n\n  if (blockedOn === null) {\n    // We successfully dispatched this event.\n    if (allowReplay) {\n      clearIfContinuousEvent(domEventName, nativeEvent);\n    }\n\n    return;\n  }\n\n  if (allowReplay) {\n    if (isReplayableDiscreteEvent(domEventName)) {\n      // This this to be replayed later once the target is available.\n      queueDiscreteEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent);\n      return;\n    }\n\n    if (queueIfContinuousEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent)) {\n      return;\n    } // We need to clear only if we didn't queue because\n    // queueing is accummulative.\n\n\n    clearIfContinuousEvent(domEventName, nativeEvent);\n  } // This is not replayable so we'll invoke it but without a target,\n  // in case the event system needs to trace it.\n\n\n  dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, null, targetContainer);\n} // Attempt dispatching an event. Returns a SuspenseInstance or Container if it's blocked.\n\nfunction attemptToDispatchEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  // TODO: Warn if _enabled is false.\n  var nativeEventTarget = getEventTarget(nativeEvent);\n  var targetInst = getClosestInstanceFromNode(nativeEventTarget);\n\n  if (targetInst !== null) {\n    var nearestMounted = getNearestMountedFiber(targetInst);\n\n    if (nearestMounted === null) {\n      // This tree has been unmounted already. Dispatch without a target.\n      targetInst = null;\n    } else {\n      var tag = nearestMounted.tag;\n\n      if (tag === SuspenseComponent) {\n        var instance = getSuspenseInstanceFromFiber(nearestMounted);\n\n        if (instance !== null) {\n          // Queue the event to be replayed later. Abort dispatching since we\n          // don't want this event dispatched twice through the event system.\n          // TODO: If this is the first discrete event in the queue. Schedule an increased\n          // priority for this boundary.\n          return instance;\n        } // This shouldn't happen, something went wrong but to avoid blocking\n        // the whole system, dispatch the event without a target.\n        // TODO: Warn.\n\n\n        targetInst = null;\n      } else if (tag === HostRoot) {\n        var root = nearestMounted.stateNode;\n\n        if (root.hydrate) {\n          // If this happens during a replay something went wrong and it might block\n          // the whole system.\n          return getContainerFromFiber(nearestMounted);\n        }\n\n        targetInst = null;\n      } else if (nearestMounted !== targetInst) {\n        // If we get an event (ex: img onload) before committing that\n        // component's mount, ignore it for now (that is, treat it as if it was an\n        // event on a non-React tree). We might also consider queueing events and\n        // dispatching them after the mount.\n        targetInst = null;\n      }\n    }\n  }\n\n  dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, targetInst, targetContainer); // We're not blocked on anything.\n\n  return null;\n}\n\nfunction addEventBubbleListener(target, eventType, listener) {\n  target.addEventListener(eventType, listener, false);\n  return listener;\n}\nfunction addEventCaptureListener(target, eventType, listener) {\n  target.addEventListener(eventType, listener, true);\n  return listener;\n}\nfunction addEventCaptureListenerWithPassiveFlag(target, eventType, listener, passive) {\n  target.addEventListener(eventType, listener, {\n    capture: true,\n    passive: passive\n  });\n  return listener;\n}\nfunction addEventBubbleListenerWithPassiveFlag(target, eventType, listener, passive) {\n  target.addEventListener(eventType, listener, {\n    passive: passive\n  });\n  return listener;\n}\n\n/**\n * These variables store information about text content of a target node,\n * allowing comparison of content before and after a given event.\n *\n * Identify the node where selection currently begins, then observe\n * both its text content and its current position in the DOM. Since the\n * browser may natively replace the target node during composition, we can\n * use its position to find its replacement.\n *\n *\n */\nvar root = null;\nvar startText = null;\nvar fallbackText = null;\nfunction initialize(nativeEventTarget) {\n  root = nativeEventTarget;\n  startText = getText();\n  return true;\n}\nfunction reset() {\n  root = null;\n  startText = null;\n  fallbackText = null;\n}\nfunction getData() {\n  if (fallbackText) {\n    return fallbackText;\n  }\n\n  var start;\n  var startValue = startText;\n  var startLength = startValue.length;\n  var end;\n  var endValue = getText();\n  var endLength = endValue.length;\n\n  for (start = 0; start < startLength; start++) {\n    if (startValue[start] !== endValue[start]) {\n      break;\n    }\n  }\n\n  var minEnd = startLength - start;\n\n  for (end = 1; end <= minEnd; end++) {\n    if (startValue[startLength - end] !== endValue[endLength - end]) {\n      break;\n    }\n  }\n\n  var sliceTail = end > 1 ? 1 - end : undefined;\n  fallbackText = endValue.slice(start, sliceTail);\n  return fallbackText;\n}\nfunction getText() {\n  if ('value' in root) {\n    return root.value;\n  }\n\n  return root.textContent;\n}\n\n/**\n * `charCode` represents the actual \"character code\" and is safe to use with\n * `String.fromCharCode`. As such, only keys that correspond to printable\n * characters produce a valid `charCode`, the only exception to this is Enter.\n * The Tab-key is considered non-printable and does not have a `charCode`,\n * presumably because it does not produce a tab-character in browsers.\n *\n * @param {object} nativeEvent Native browser event.\n * @return {number} Normalized `charCode` property.\n */\nfunction getEventCharCode(nativeEvent) {\n  var charCode;\n  var keyCode = nativeEvent.keyCode;\n\n  if ('charCode' in nativeEvent) {\n    charCode = nativeEvent.charCode; // FF does not set `charCode` for the Enter-key, check against `keyCode`.\n\n    if (charCode === 0 && keyCode === 13) {\n      charCode = 13;\n    }\n  } else {\n    // IE8 does not implement `charCode`, but `keyCode` has the correct value.\n    charCode = keyCode;\n  } // IE and Edge (on Windows) and Chrome / Safari (on Windows and Linux)\n  // report Enter as charCode 10 when ctrl is pressed.\n\n\n  if (charCode === 10) {\n    charCode = 13;\n  } // Some non-printable keys are reported in `charCode`/`keyCode`, discard them.\n  // Must not discard the (non-)printable Enter-key.\n\n\n  if (charCode >= 32 || charCode === 13) {\n    return charCode;\n  }\n\n  return 0;\n}\n\nfunction functionThatReturnsTrue() {\n  return true;\n}\n\nfunction functionThatReturnsFalse() {\n  return false;\n} // This is intentionally a factory so that we have different returned constructors.\n// If we had a single constructor, it would be megamorphic and engines would deopt.\n\n\nfunction createSyntheticEvent(Interface) {\n  /**\n   * Synthetic events are dispatched by event plugins, typically in response to a\n   * top-level event delegation handler.\n   *\n   * These systems should generally use pooling to reduce the frequency of garbage\n   * collection. The system should check `isPersistent` to determine whether the\n   * event should be released into the pool after being dispatched. Users that\n   * need a persisted event should invoke `persist`.\n   *\n   * Synthetic events (and subclasses) implement the DOM Level 3 Events API by\n   * normalizing browser quirks. Subclasses do not necessarily have to implement a\n   * DOM interface; custom application-specific events can also subclass this.\n   */\n  function SyntheticBaseEvent(reactName, reactEventType, targetInst, nativeEvent, nativeEventTarget) {\n    this._reactName = reactName;\n    this._targetInst = targetInst;\n    this.type = reactEventType;\n    this.nativeEvent = nativeEvent;\n    this.target = nativeEventTarget;\n    this.currentTarget = null;\n\n    for (var _propName in Interface) {\n      if (!Interface.hasOwnProperty(_propName)) {\n        continue;\n      }\n\n      var normalize = Interface[_propName];\n\n      if (normalize) {\n        this[_propName] = normalize(nativeEvent);\n      } else {\n        this[_propName] = nativeEvent[_propName];\n      }\n    }\n\n    var defaultPrevented = nativeEvent.defaultPrevented != null ? nativeEvent.defaultPrevented : nativeEvent.returnValue === false;\n\n    if (defaultPrevented) {\n      this.isDefaultPrevented = functionThatReturnsTrue;\n    } else {\n      this.isDefaultPrevented = functionThatReturnsFalse;\n    }\n\n    this.isPropagationStopped = functionThatReturnsFalse;\n    return this;\n  }\n\n  _assign(SyntheticBaseEvent.prototype, {\n    preventDefault: function () {\n      this.defaultPrevented = true;\n      var event = this.nativeEvent;\n\n      if (!event) {\n        return;\n      }\n\n      if (event.preventDefault) {\n        event.preventDefault(); // $FlowFixMe - flow is not aware of `unknown` in IE\n      } else if (typeof event.returnValue !== 'unknown') {\n        event.returnValue = false;\n      }\n\n      this.isDefaultPrevented = functionThatReturnsTrue;\n    },\n    stopPropagation: function () {\n      var event = this.nativeEvent;\n\n      if (!event) {\n        return;\n      }\n\n      if (event.stopPropagation) {\n        event.stopPropagation(); // $FlowFixMe - flow is not aware of `unknown` in IE\n      } else if (typeof event.cancelBubble !== 'unknown') {\n        // The ChangeEventPlugin registers a \"propertychange\" event for\n        // IE. This event does not support bubbling or cancelling, and\n        // any references to cancelBubble throw \"Member not found\".  A\n        // typeof check of \"unknown\" circumvents this issue (and is also\n        // IE specific).\n        event.cancelBubble = true;\n      }\n\n      this.isPropagationStopped = functionThatReturnsTrue;\n    },\n\n    /**\n     * We release all dispatched `SyntheticEvent`s after each event loop, adding\n     * them back into the pool. This allows a way to hold onto a reference that\n     * won't be added back into the pool.\n     */\n    persist: function () {// Modern event system doesn't use pooling.\n    },\n\n    /**\n     * Checks if this event should be released back into the pool.\n     *\n     * @return {boolean} True if this should not be released, false otherwise.\n     */\n    isPersistent: functionThatReturnsTrue\n  });\n\n  return SyntheticBaseEvent;\n}\n/**\n * @interface Event\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar EventInterface = {\n  eventPhase: 0,\n  bubbles: 0,\n  cancelable: 0,\n  timeStamp: function (event) {\n    return event.timeStamp || Date.now();\n  },\n  defaultPrevented: 0,\n  isTrusted: 0\n};\nvar SyntheticEvent = createSyntheticEvent(EventInterface);\n\nvar UIEventInterface = _assign({}, EventInterface, {\n  view: 0,\n  detail: 0\n});\n\nvar SyntheticUIEvent = createSyntheticEvent(UIEventInterface);\nvar lastMovementX;\nvar lastMovementY;\nvar lastMouseEvent;\n\nfunction updateMouseMovementPolyfillState(event) {\n  if (event !== lastMouseEvent) {\n    if (lastMouseEvent && event.type === 'mousemove') {\n      lastMovementX = event.screenX - lastMouseEvent.screenX;\n      lastMovementY = event.screenY - lastMouseEvent.screenY;\n    } else {\n      lastMovementX = 0;\n      lastMovementY = 0;\n    }\n\n    lastMouseEvent = event;\n  }\n}\n/**\n * @interface MouseEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar MouseEventInterface = _assign({}, UIEventInterface, {\n  screenX: 0,\n  screenY: 0,\n  clientX: 0,\n  clientY: 0,\n  pageX: 0,\n  pageY: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  altKey: 0,\n  metaKey: 0,\n  getModifierState: getEventModifierState,\n  button: 0,\n  buttons: 0,\n  relatedTarget: function (event) {\n    if (event.relatedTarget === undefined) return event.fromElement === event.srcElement ? event.toElement : event.fromElement;\n    return event.relatedTarget;\n  },\n  movementX: function (event) {\n    if ('movementX' in event) {\n      return event.movementX;\n    }\n\n    updateMouseMovementPolyfillState(event);\n    return lastMovementX;\n  },\n  movementY: function (event) {\n    if ('movementY' in event) {\n      return event.movementY;\n    } // Don't need to call updateMouseMovementPolyfillState() here\n    // because it's guaranteed to have already run when movementX\n    // was copied.\n\n\n    return lastMovementY;\n  }\n});\n\nvar SyntheticMouseEvent = createSyntheticEvent(MouseEventInterface);\n/**\n * @interface DragEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar DragEventInterface = _assign({}, MouseEventInterface, {\n  dataTransfer: 0\n});\n\nvar SyntheticDragEvent = createSyntheticEvent(DragEventInterface);\n/**\n * @interface FocusEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar FocusEventInterface = _assign({}, UIEventInterface, {\n  relatedTarget: 0\n});\n\nvar SyntheticFocusEvent = createSyntheticEvent(FocusEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/css3-animations/#AnimationEvent-interface\n * @see https://developer.mozilla.org/en-US/docs/Web/API/AnimationEvent\n */\n\nvar AnimationEventInterface = _assign({}, EventInterface, {\n  animationName: 0,\n  elapsedTime: 0,\n  pseudoElement: 0\n});\n\nvar SyntheticAnimationEvent = createSyntheticEvent(AnimationEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/clipboard-apis/\n */\n\nvar ClipboardEventInterface = _assign({}, EventInterface, {\n  clipboardData: function (event) {\n    return 'clipboardData' in event ? event.clipboardData : window.clipboardData;\n  }\n});\n\nvar SyntheticClipboardEvent = createSyntheticEvent(ClipboardEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/DOM-Level-3-Events/#events-compositionevents\n */\n\nvar CompositionEventInterface = _assign({}, EventInterface, {\n  data: 0\n});\n\nvar SyntheticCompositionEvent = createSyntheticEvent(CompositionEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/2013/WD-DOM-Level-3-Events-20131105\n *      /#events-inputevents\n */\n// Happens to share the same list for now.\n\nvar SyntheticInputEvent = SyntheticCompositionEvent;\n/**\n * Normalization of deprecated HTML5 `key` values\n * @see https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent#Key_names\n */\n\nvar normalizeKey = {\n  Esc: 'Escape',\n  Spacebar: ' ',\n  Left: 'ArrowLeft',\n  Up: 'ArrowUp',\n  Right: 'ArrowRight',\n  Down: 'ArrowDown',\n  Del: 'Delete',\n  Win: 'OS',\n  Menu: 'ContextMenu',\n  Apps: 'ContextMenu',\n  Scroll: 'ScrollLock',\n  MozPrintableKey: 'Unidentified'\n};\n/**\n * Translation from legacy `keyCode` to HTML5 `key`\n * Only special keys supported, all others depend on keyboard layout or browser\n * @see https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent#Key_names\n */\n\nvar translateToKey = {\n  '8': 'Backspace',\n  '9': 'Tab',\n  '12': 'Clear',\n  '13': 'Enter',\n  '16': 'Shift',\n  '17': 'Control',\n  '18': 'Alt',\n  '19': 'Pause',\n  '20': 'CapsLock',\n  '27': 'Escape',\n  '32': ' ',\n  '33': 'PageUp',\n  '34': 'PageDown',\n  '35': 'End',\n  '36': 'Home',\n  '37': 'ArrowLeft',\n  '38': 'ArrowUp',\n  '39': 'ArrowRight',\n  '40': 'ArrowDown',\n  '45': 'Insert',\n  '46': 'Delete',\n  '112': 'F1',\n  '113': 'F2',\n  '114': 'F3',\n  '115': 'F4',\n  '116': 'F5',\n  '117': 'F6',\n  '118': 'F7',\n  '119': 'F8',\n  '120': 'F9',\n  '121': 'F10',\n  '122': 'F11',\n  '123': 'F12',\n  '144': 'NumLock',\n  '145': 'ScrollLock',\n  '224': 'Meta'\n};\n/**\n * @param {object} nativeEvent Native browser event.\n * @return {string} Normalized `key` property.\n */\n\nfunction getEventKey(nativeEvent) {\n  if (nativeEvent.key) {\n    // Normalize inconsistent values reported by browsers due to\n    // implementations of a working draft specification.\n    // FireFox implements `key` but returns `MozPrintableKey` for all\n    // printable characters (normalized to `Unidentified`), ignore it.\n    var key = normalizeKey[nativeEvent.key] || nativeEvent.key;\n\n    if (key !== 'Unidentified') {\n      return key;\n    }\n  } // Browser does not implement `key`, polyfill as much of it as we can.\n\n\n  if (nativeEvent.type === 'keypress') {\n    var charCode = getEventCharCode(nativeEvent); // The enter-key is technically both printable and non-printable and can\n    // thus be captured by `keypress`, no other non-printable key should.\n\n    return charCode === 13 ? 'Enter' : String.fromCharCode(charCode);\n  }\n\n  if (nativeEvent.type === 'keydown' || nativeEvent.type === 'keyup') {\n    // While user keyboard layout determines the actual meaning of each\n    // `keyCode` value, almost all function keys have a universal value.\n    return translateToKey[nativeEvent.keyCode] || 'Unidentified';\n  }\n\n  return '';\n}\n/**\n * Translation from modifier key to the associated property in the event.\n * @see http://www.w3.org/TR/DOM-Level-3-Events/#keys-Modifiers\n */\n\n\nvar modifierKeyToProp = {\n  Alt: 'altKey',\n  Control: 'ctrlKey',\n  Meta: 'metaKey',\n  Shift: 'shiftKey'\n}; // Older browsers (Safari <= 10, iOS Safari <= 10.2) do not support\n// getModifierState. If getModifierState is not supported, we map it to a set of\n// modifier keys exposed by the event. In this case, Lock-keys are not supported.\n\nfunction modifierStateGetter(keyArg) {\n  var syntheticEvent = this;\n  var nativeEvent = syntheticEvent.nativeEvent;\n\n  if (nativeEvent.getModifierState) {\n    return nativeEvent.getModifierState(keyArg);\n  }\n\n  var keyProp = modifierKeyToProp[keyArg];\n  return keyProp ? !!nativeEvent[keyProp] : false;\n}\n\nfunction getEventModifierState(nativeEvent) {\n  return modifierStateGetter;\n}\n/**\n * @interface KeyboardEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar KeyboardEventInterface = _assign({}, UIEventInterface, {\n  key: getEventKey,\n  code: 0,\n  location: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  altKey: 0,\n  metaKey: 0,\n  repeat: 0,\n  locale: 0,\n  getModifierState: getEventModifierState,\n  // Legacy Interface\n  charCode: function (event) {\n    // `charCode` is the result of a KeyPress event and represents the value of\n    // the actual printable character.\n    // KeyPress is deprecated, but its replacement is not yet final and not\n    // implemented in any major browser. Only KeyPress has charCode.\n    if (event.type === 'keypress') {\n      return getEventCharCode(event);\n    }\n\n    return 0;\n  },\n  keyCode: function (event) {\n    // `keyCode` is the result of a KeyDown/Up event and represents the value of\n    // physical keyboard key.\n    // The actual meaning of the value depends on the users' keyboard layout\n    // which cannot be detected. Assuming that it is a US keyboard layout\n    // provides a surprisingly accurate mapping for US and European users.\n    // Due to this, it is left to the user to implement at this time.\n    if (event.type === 'keydown' || event.type === 'keyup') {\n      return event.keyCode;\n    }\n\n    return 0;\n  },\n  which: function (event) {\n    // `which` is an alias for either `keyCode` or `charCode` depending on the\n    // type of the event.\n    if (event.type === 'keypress') {\n      return getEventCharCode(event);\n    }\n\n    if (event.type === 'keydown' || event.type === 'keyup') {\n      return event.keyCode;\n    }\n\n    return 0;\n  }\n});\n\nvar SyntheticKeyboardEvent = createSyntheticEvent(KeyboardEventInterface);\n/**\n * @interface PointerEvent\n * @see http://www.w3.org/TR/pointerevents/\n */\n\nvar PointerEventInterface = _assign({}, MouseEventInterface, {\n  pointerId: 0,\n  width: 0,\n  height: 0,\n  pressure: 0,\n  tangentialPressure: 0,\n  tiltX: 0,\n  tiltY: 0,\n  twist: 0,\n  pointerType: 0,\n  isPrimary: 0\n});\n\nvar SyntheticPointerEvent = createSyntheticEvent(PointerEventInterface);\n/**\n * @interface TouchEvent\n * @see http://www.w3.org/TR/touch-events/\n */\n\nvar TouchEventInterface = _assign({}, UIEventInterface, {\n  touches: 0,\n  targetTouches: 0,\n  changedTouches: 0,\n  altKey: 0,\n  metaKey: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  getModifierState: getEventModifierState\n});\n\nvar SyntheticTouchEvent = createSyntheticEvent(TouchEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/2009/WD-css3-transitions-20090320/#transition-events-\n * @see https://developer.mozilla.org/en-US/docs/Web/API/TransitionEvent\n */\n\nvar TransitionEventInterface = _assign({}, EventInterface, {\n  propertyName: 0,\n  elapsedTime: 0,\n  pseudoElement: 0\n});\n\nvar SyntheticTransitionEvent = createSyntheticEvent(TransitionEventInterface);\n/**\n * @interface WheelEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar WheelEventInterface = _assign({}, MouseEventInterface, {\n  deltaX: function (event) {\n    return 'deltaX' in event ? event.deltaX : // Fallback to `wheelDeltaX` for Webkit and normalize (right is positive).\n    'wheelDeltaX' in event ? -event.wheelDeltaX : 0;\n  },\n  deltaY: function (event) {\n    return 'deltaY' in event ? event.deltaY : // Fallback to `wheelDeltaY` for Webkit and normalize (down is positive).\n    'wheelDeltaY' in event ? -event.wheelDeltaY : // Fallback to `wheelDelta` for IE<9 and normalize (down is positive).\n    'wheelDelta' in event ? -event.wheelDelta : 0;\n  },\n  deltaZ: 0,\n  // Browsers without \"deltaMode\" is reporting in raw wheel delta where one\n  // notch on the scroll is always +/- 120, roughly equivalent to pixels.\n  // A good approximation of DOM_DELTA_LINE (1) is 5% of viewport size or\n  // ~40 pixels, for DOM_DELTA_SCREEN (2) it is 87.5% of viewport size.\n  deltaMode: 0\n});\n\nvar SyntheticWheelEvent = createSyntheticEvent(WheelEventInterface);\n\nvar END_KEYCODES = [9, 13, 27, 32]; // Tab, Return, Esc, Space\n\nvar START_KEYCODE = 229;\nvar canUseCompositionEvent = canUseDOM && 'CompositionEvent' in window;\nvar documentMode = null;\n\nif (canUseDOM && 'documentMode' in document) {\n  documentMode = document.documentMode;\n} // Webkit offers a very useful `textInput` event that can be used to\n// directly represent `beforeInput`. The IE `textinput` event is not as\n// useful, so we don't use it.\n\n\nvar canUseTextInputEvent = canUseDOM && 'TextEvent' in window && !documentMode; // In IE9+, we have access to composition events, but the data supplied\n// by the native compositionend event may be incorrect. Japanese ideographic\n// spaces, for instance (\\u3000) are not recorded correctly.\n\nvar useFallbackCompositionData = canUseDOM && (!canUseCompositionEvent || documentMode && documentMode > 8 && documentMode <= 11);\nvar SPACEBAR_CODE = 32;\nvar SPACEBAR_CHAR = String.fromCharCode(SPACEBAR_CODE);\n\nfunction registerEvents() {\n  registerTwoPhaseEvent('onBeforeInput', ['compositionend', 'keypress', 'textInput', 'paste']);\n  registerTwoPhaseEvent('onCompositionEnd', ['compositionend', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n  registerTwoPhaseEvent('onCompositionStart', ['compositionstart', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n  registerTwoPhaseEvent('onCompositionUpdate', ['compositionupdate', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n} // Track whether we've ever handled a keypress on the space key.\n\n\nvar hasSpaceKeypress = false;\n/**\n * Return whether a native keypress event is assumed to be a command.\n * This is required because Firefox fires `keypress` events for key commands\n * (cut, copy, select-all, etc.) even though no character is inserted.\n */\n\nfunction isKeypressCommand(nativeEvent) {\n  return (nativeEvent.ctrlKey || nativeEvent.altKey || nativeEvent.metaKey) && // ctrlKey && altKey is equivalent to AltGr, and is not a command.\n  !(nativeEvent.ctrlKey && nativeEvent.altKey);\n}\n/**\n * Translate native top level events into event types.\n */\n\n\nfunction getCompositionEventType(domEventName) {\n  switch (domEventName) {\n    case 'compositionstart':\n      return 'onCompositionStart';\n\n    case 'compositionend':\n      return 'onCompositionEnd';\n\n    case 'compositionupdate':\n      return 'onCompositionUpdate';\n  }\n}\n/**\n * Does our fallback best-guess model think this event signifies that\n * composition has begun?\n */\n\n\nfunction isFallbackCompositionStart(domEventName, nativeEvent) {\n  return domEventName === 'keydown' && nativeEvent.keyCode === START_KEYCODE;\n}\n/**\n * Does our fallback mode think that this event is the end of composition?\n */\n\n\nfunction isFallbackCompositionEnd(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'keyup':\n      // Command keys insert or clear IME input.\n      return END_KEYCODES.indexOf(nativeEvent.keyCode) !== -1;\n\n    case 'keydown':\n      // Expect IME keyCode on each keydown. If we get any other\n      // code we must have exited earlier.\n      return nativeEvent.keyCode !== START_KEYCODE;\n\n    case 'keypress':\n    case 'mousedown':\n    case 'focusout':\n      // Events are not possible without cancelling IME.\n      return true;\n\n    default:\n      return false;\n  }\n}\n/**\n * Google Input Tools provides composition data via a CustomEvent,\n * with the `data` property populated in the `detail` object. If this\n * is available on the event object, use it. If not, this is a plain\n * composition event and we have nothing special to extract.\n *\n * @param {object} nativeEvent\n * @return {?string}\n */\n\n\nfunction getDataFromCustomEvent(nativeEvent) {\n  var detail = nativeEvent.detail;\n\n  if (typeof detail === 'object' && 'data' in detail) {\n    return detail.data;\n  }\n\n  return null;\n}\n/**\n * Check if a composition event was triggered by Korean IME.\n * Our fallback mode does not work well with IE's Korean IME,\n * so just use native composition events when Korean IME is used.\n * Although CompositionEvent.locale property is deprecated,\n * it is available in IE, where our fallback mode is enabled.\n *\n * @param {object} nativeEvent\n * @return {boolean}\n */\n\n\nfunction isUsingKoreanIME(nativeEvent) {\n  return nativeEvent.locale === 'ko';\n} // Track the current IME composition status, if any.\n\n\nvar isComposing = false;\n/**\n * @return {?object} A SyntheticCompositionEvent.\n */\n\nfunction extractCompositionEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget) {\n  var eventType;\n  var fallbackData;\n\n  if (canUseCompositionEvent) {\n    eventType = getCompositionEventType(domEventName);\n  } else if (!isComposing) {\n    if (isFallbackCompositionStart(domEventName, nativeEvent)) {\n      eventType = 'onCompositionStart';\n    }\n  } else if (isFallbackCompositionEnd(domEventName, nativeEvent)) {\n    eventType = 'onCompositionEnd';\n  }\n\n  if (!eventType) {\n    return null;\n  }\n\n  if (useFallbackCompositionData && !isUsingKoreanIME(nativeEvent)) {\n    // The current composition is stored statically and must not be\n    // overwritten while composition continues.\n    if (!isComposing && eventType === 'onCompositionStart') {\n      isComposing = initialize(nativeEventTarget);\n    } else if (eventType === 'onCompositionEnd') {\n      if (isComposing) {\n        fallbackData = getData();\n      }\n    }\n  }\n\n  var listeners = accumulateTwoPhaseListeners(targetInst, eventType);\n\n  if (listeners.length > 0) {\n    var event = new SyntheticCompositionEvent(eventType, domEventName, null, nativeEvent, nativeEventTarget);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n\n    if (fallbackData) {\n      // Inject data generated from fallback path into the synthetic event.\n      // This matches the property of native CompositionEventInterface.\n      event.data = fallbackData;\n    } else {\n      var customData = getDataFromCustomEvent(nativeEvent);\n\n      if (customData !== null) {\n        event.data = customData;\n      }\n    }\n  }\n}\n\nfunction getNativeBeforeInputChars(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'compositionend':\n      return getDataFromCustomEvent(nativeEvent);\n\n    case 'keypress':\n      /**\n       * If native `textInput` events are available, our goal is to make\n       * use of them. However, there is a special case: the spacebar key.\n       * In Webkit, preventing default on a spacebar `textInput` event\n       * cancels character insertion, but it *also* causes the browser\n       * to fall back to its default spacebar behavior of scrolling the\n       * page.\n       *\n       * Tracking at:\n       * https://code.google.com/p/chromium/issues/detail?id=355103\n       *\n       * To avoid this issue, use the keypress event as if no `textInput`\n       * event is available.\n       */\n      var which = nativeEvent.which;\n\n      if (which !== SPACEBAR_CODE) {\n        return null;\n      }\n\n      hasSpaceKeypress = true;\n      return SPACEBAR_CHAR;\n\n    case 'textInput':\n      // Record the characters to be added to the DOM.\n      var chars = nativeEvent.data; // If it's a spacebar character, assume that we have already handled\n      // it at the keypress level and bail immediately. Android Chrome\n      // doesn't give us keycodes, so we need to ignore it.\n\n      if (chars === SPACEBAR_CHAR && hasSpaceKeypress) {\n        return null;\n      }\n\n      return chars;\n\n    default:\n      // For other native event types, do nothing.\n      return null;\n  }\n}\n/**\n * For browsers that do not provide the `textInput` event, extract the\n * appropriate string to use for SyntheticInputEvent.\n */\n\n\nfunction getFallbackBeforeInputChars(domEventName, nativeEvent) {\n  // If we are currently composing (IME) and using a fallback to do so,\n  // try to extract the composed characters from the fallback object.\n  // If composition event is available, we extract a string only at\n  // compositionevent, otherwise extract it at fallback events.\n  if (isComposing) {\n    if (domEventName === 'compositionend' || !canUseCompositionEvent && isFallbackCompositionEnd(domEventName, nativeEvent)) {\n      var chars = getData();\n      reset();\n      isComposing = false;\n      return chars;\n    }\n\n    return null;\n  }\n\n  switch (domEventName) {\n    case 'paste':\n      // If a paste event occurs after a keypress, throw out the input\n      // chars. Paste events should not lead to BeforeInput events.\n      return null;\n\n    case 'keypress':\n      /**\n       * As of v27, Firefox may fire keypress events even when no character\n       * will be inserted. A few possibilities:\n       *\n       * - `which` is `0`. Arrow keys, Esc key, etc.\n       *\n       * - `which` is the pressed key code, but no char is available.\n       *   Ex: 'AltGr + d` in Polish. There is no modified character for\n       *   this key combination and no character is inserted into the\n       *   document, but FF fires the keypress for char code `100` anyway.\n       *   No `input` event will occur.\n       *\n       * - `which` is the pressed key code, but a command combination is\n       *   being used. Ex: `Cmd+C`. No character is inserted, and no\n       *   `input` event will occur.\n       */\n      if (!isKeypressCommand(nativeEvent)) {\n        // IE fires the `keypress` event when a user types an emoji via\n        // Touch keyboard of Windows.  In such a case, the `char` property\n        // holds an emoji character like `\\uD83D\\uDE0A`.  Because its length\n        // is 2, the property `which` does not represent an emoji correctly.\n        // In such a case, we directly return the `char` property instead of\n        // using `which`.\n        if (nativeEvent.char && nativeEvent.char.length > 1) {\n          return nativeEvent.char;\n        } else if (nativeEvent.which) {\n          return String.fromCharCode(nativeEvent.which);\n        }\n      }\n\n      return null;\n\n    case 'compositionend':\n      return useFallbackCompositionData && !isUsingKoreanIME(nativeEvent) ? null : nativeEvent.data;\n\n    default:\n      return null;\n  }\n}\n/**\n * Extract a SyntheticInputEvent for `beforeInput`, based on either native\n * `textInput` or fallback behavior.\n *\n * @return {?object} A SyntheticInputEvent.\n */\n\n\nfunction extractBeforeInputEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget) {\n  var chars;\n\n  if (canUseTextInputEvent) {\n    chars = getNativeBeforeInputChars(domEventName, nativeEvent);\n  } else {\n    chars = getFallbackBeforeInputChars(domEventName, nativeEvent);\n  } // If no characters are being inserted, no BeforeInput event should\n  // be fired.\n\n\n  if (!chars) {\n    return null;\n  }\n\n  var listeners = accumulateTwoPhaseListeners(targetInst, 'onBeforeInput');\n\n  if (listeners.length > 0) {\n    var event = new SyntheticInputEvent('onBeforeInput', 'beforeinput', null, nativeEvent, nativeEventTarget);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n    event.data = chars;\n  }\n}\n/**\n * Create an `onBeforeInput` event to match\n * http://www.w3.org/TR/2013/WD-DOM-Level-3-Events-20131105/#events-inputevents.\n *\n * This event plugin is based on the native `textInput` event\n * available in Chrome, Safari, Opera, and IE. This event fires after\n * `onKeyPress` and `onCompositionEnd`, but before `onInput`.\n *\n * `beforeInput` is spec'd but not implemented in any browsers, and\n * the `input` event does not provide any useful information about what has\n * actually been added, contrary to the spec. Thus, `textInput` is the best\n * available event to identify the characters that have actually been inserted\n * into the target node.\n *\n * This plugin is also responsible for emitting `composition` events, thus\n * allowing us to share composition fallback code for both `beforeInput` and\n * `composition` event types.\n */\n\n\nfunction extractEvents(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  extractCompositionEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n  extractBeforeInputEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n}\n\n/**\n * @see http://www.whatwg.org/specs/web-apps/current-work/multipage/the-input-element.html#input-type-attr-summary\n */\nvar supportedInputTypes = {\n  color: true,\n  date: true,\n  datetime: true,\n  'datetime-local': true,\n  email: true,\n  month: true,\n  number: true,\n  password: true,\n  range: true,\n  search: true,\n  tel: true,\n  text: true,\n  time: true,\n  url: true,\n  week: true\n};\n\nfunction isTextInputElement(elem) {\n  var nodeName = elem && elem.nodeName && elem.nodeName.toLowerCase();\n\n  if (nodeName === 'input') {\n    return !!supportedInputTypes[elem.type];\n  }\n\n  if (nodeName === 'textarea') {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Checks if an event is supported in the current execution environment.\n *\n * NOTE: This will not work correctly for non-generic events such as `change`,\n * `reset`, `load`, `error`, and `select`.\n *\n * Borrows from Modernizr.\n *\n * @param {string} eventNameSuffix Event name, e.g. \"click\".\n * @return {boolean} True if the event is supported.\n * @internal\n * @license Modernizr 3.0.0pre (Custom Build) | MIT\n */\n\nfunction isEventSupported(eventNameSuffix) {\n  if (!canUseDOM) {\n    return false;\n  }\n\n  var eventName = 'on' + eventNameSuffix;\n  var isSupported = (eventName in document);\n\n  if (!isSupported) {\n    var element = document.createElement('div');\n    element.setAttribute(eventName, 'return;');\n    isSupported = typeof element[eventName] === 'function';\n  }\n\n  return isSupported;\n}\n\nfunction registerEvents$1() {\n  registerTwoPhaseEvent('onChange', ['change', 'click', 'focusin', 'focusout', 'input', 'keydown', 'keyup', 'selectionchange']);\n}\n\nfunction createAndAccumulateChangeEvent(dispatchQueue, inst, nativeEvent, target) {\n  // Flag this event loop as needing state restore.\n  enqueueStateRestore(target);\n  var listeners = accumulateTwoPhaseListeners(inst, 'onChange');\n\n  if (listeners.length > 0) {\n    var event = new SyntheticEvent('onChange', 'change', null, nativeEvent, target);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n  }\n}\n/**\n * For IE shims\n */\n\n\nvar activeElement = null;\nvar activeElementInst = null;\n/**\n * SECTION: handle `change` event\n */\n\nfunction shouldUseChangeEvent(elem) {\n  var nodeName = elem.nodeName && elem.nodeName.toLowerCase();\n  return nodeName === 'select' || nodeName === 'input' && elem.type === 'file';\n}\n\nfunction manualDispatchChangeEvent(nativeEvent) {\n  var dispatchQueue = [];\n  createAndAccumulateChangeEvent(dispatchQueue, activeElementInst, nativeEvent, getEventTarget(nativeEvent)); // If change and propertychange bubbled, we'd just bind to it like all the\n  // other events and have it go through ReactBrowserEventEmitter. Since it\n  // doesn't, we manually listen for the events and so we have to enqueue and\n  // process the abstract event manually.\n  //\n  // Batching is necessary here in order to ensure that all event handlers run\n  // before the next rerender (including event handlers attached to ancestor\n  // elements instead of directly on the input). Without this, controlled\n  // components don't work properly in conjunction with event bubbling because\n  // the component is rerendered and the value reverted before all the event\n  // handlers can run. See https://github.com/facebook/react/issues/708.\n\n  batchedUpdates(runEventInBatch, dispatchQueue);\n}\n\nfunction runEventInBatch(dispatchQueue) {\n  processDispatchQueue(dispatchQueue, 0);\n}\n\nfunction getInstIfValueChanged(targetInst) {\n  var targetNode = getNodeFromInstance(targetInst);\n\n  if (updateValueIfChanged(targetNode)) {\n    return targetInst;\n  }\n}\n\nfunction getTargetInstForChangeEvent(domEventName, targetInst) {\n  if (domEventName === 'change') {\n    return targetInst;\n  }\n}\n/**\n * SECTION: handle `input` event\n */\n\n\nvar isInputEventSupported = false;\n\nif (canUseDOM) {\n  // IE9 claims to support the input event but fails to trigger it when\n  // deleting text, so we ignore its input events.\n  isInputEventSupported = isEventSupported('input') && (!document.documentMode || document.documentMode > 9);\n}\n/**\n * (For IE <=9) Starts tracking propertychange events on the passed-in element\n * and override the value property so that we can distinguish user events from\n * value changes in JS.\n */\n\n\nfunction startWatchingForValueChange(target, targetInst) {\n  activeElement = target;\n  activeElementInst = targetInst;\n  activeElement.attachEvent('onpropertychange', handlePropertyChange);\n}\n/**\n * (For IE <=9) Removes the event listeners from the currently-tracked element,\n * if any exists.\n */\n\n\nfunction stopWatchingForValueChange() {\n  if (!activeElement) {\n    return;\n  }\n\n  activeElement.detachEvent('onpropertychange', handlePropertyChange);\n  activeElement = null;\n  activeElementInst = null;\n}\n/**\n * (For IE <=9) Handles a propertychange event, sending a `change` event if\n * the value of the active element has changed.\n */\n\n\nfunction handlePropertyChange(nativeEvent) {\n  if (nativeEvent.propertyName !== 'value') {\n    return;\n  }\n\n  if (getInstIfValueChanged(activeElementInst)) {\n    manualDispatchChangeEvent(nativeEvent);\n  }\n}\n\nfunction handleEventsForInputEventPolyfill(domEventName, target, targetInst) {\n  if (domEventName === 'focusin') {\n    // In IE9, propertychange fires for most input events but is buggy and\n    // doesn't fire when text is deleted, but conveniently, selectionchange\n    // appears to fire in all of the remaining cases so we catch those and\n    // forward the event if the value has changed\n    // In either case, we don't want to call the event handler if the value\n    // is changed from JS so we redefine a setter for `.value` that updates\n    // our activeElementValue variable, allowing us to ignore those changes\n    //\n    // stopWatching() should be a noop here but we call it just in case we\n    // missed a blur event somehow.\n    stopWatchingForValueChange();\n    startWatchingForValueChange(target, targetInst);\n  } else if (domEventName === 'focusout') {\n    stopWatchingForValueChange();\n  }\n} // For IE8 and IE9.\n\n\nfunction getTargetInstForInputEventPolyfill(domEventName, targetInst) {\n  if (domEventName === 'selectionchange' || domEventName === 'keyup' || domEventName === 'keydown') {\n    // On the selectionchange event, the target is just document which isn't\n    // helpful for us so just check activeElement instead.\n    //\n    // 99% of the time, keydown and keyup aren't necessary. IE8 fails to fire\n    // propertychange on the first input event after setting `value` from a\n    // script and fires only keydown, keypress, keyup. Catching keyup usually\n    // gets it and catching keydown lets us fire an event for the first\n    // keystroke if user does a key repeat (it'll be a little delayed: right\n    // before the second keystroke). Other input methods (e.g., paste) seem to\n    // fire selectionchange normally.\n    return getInstIfValueChanged(activeElementInst);\n  }\n}\n/**\n * SECTION: handle `click` event\n */\n\n\nfunction shouldUseClickEvent(elem) {\n  // Use the `click` event to detect changes to checkbox and radio inputs.\n  // This approach works across all browsers, whereas `change` does not fire\n  // until `blur` in IE8.\n  var nodeName = elem.nodeName;\n  return nodeName && nodeName.toLowerCase() === 'input' && (elem.type === 'checkbox' || elem.type === 'radio');\n}\n\nfunction getTargetInstForClickEvent(domEventName, targetInst) {\n  if (domEventName === 'click') {\n    return getInstIfValueChanged(targetInst);\n  }\n}\n\nfunction getTargetInstForInputOrChangeEvent(domEventName, targetInst) {\n  if (domEventName === 'input' || domEventName === 'change') {\n    return getInstIfValueChanged(targetInst);\n  }\n}\n\nfunction handleControlledInputBlur(node) {\n  var state = node._wrapperState;\n\n  if (!state || !state.controlled || node.type !== 'number') {\n    return;\n  }\n\n  {\n    // If controlled, assign the value attribute to the current value on blur\n    setDefaultValue(node, 'number', node.value);\n  }\n}\n/**\n * This plugin creates an `onChange` event that normalizes change events\n * across form elements. This event fires at a time when it's possible to\n * change the element's value without seeing a flicker.\n *\n * Supported elements are:\n * - input (see `isTextInputElement`)\n * - textarea\n * - select\n */\n\n\nfunction extractEvents$1(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var targetNode = targetInst ? getNodeFromInstance(targetInst) : window;\n  var getTargetInstFunc, handleEventFunc;\n\n  if (shouldUseChangeEvent(targetNode)) {\n    getTargetInstFunc = getTargetInstForChangeEvent;\n  } else if (isTextInputElement(targetNode)) {\n    if (isInputEventSupported) {\n      getTargetInstFunc = getTargetInstForInputOrChangeEvent;\n    } else {\n      getTargetInstFunc = getTargetInstForInputEventPolyfill;\n      handleEventFunc = handleEventsForInputEventPolyfill;\n    }\n  } else if (shouldUseClickEvent(targetNode)) {\n    getTargetInstFunc = getTargetInstForClickEvent;\n  }\n\n  if (getTargetInstFunc) {\n    var inst = getTargetInstFunc(domEventName, targetInst);\n\n    if (inst) {\n      createAndAccumulateChangeEvent(dispatchQueue, inst, nativeEvent, nativeEventTarget);\n      return;\n    }\n  }\n\n  if (handleEventFunc) {\n    handleEventFunc(domEventName, targetNode, targetInst);\n  } // When blurring, set the value attribute for number inputs\n\n\n  if (domEventName === 'focusout') {\n    handleControlledInputBlur(targetNode);\n  }\n}\n\nfunction registerEvents$2() {\n  registerDirectEvent('onMouseEnter', ['mouseout', 'mouseover']);\n  registerDirectEvent('onMouseLeave', ['mouseout', 'mouseover']);\n  registerDirectEvent('onPointerEnter', ['pointerout', 'pointerover']);\n  registerDirectEvent('onPointerLeave', ['pointerout', 'pointerover']);\n}\n/**\n * For almost every interaction we care about, there will be both a top-level\n * `mouseover` and `mouseout` event that occurs. Only use `mouseout` so that\n * we do not extract duplicate events. However, moving the mouse into the\n * browser from outside will not fire a `mouseout` event. In this case, we use\n * the `mouseover` top-level event.\n */\n\n\nfunction extractEvents$2(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var isOverEvent = domEventName === 'mouseover' || domEventName === 'pointerover';\n  var isOutEvent = domEventName === 'mouseout' || domEventName === 'pointerout';\n\n  if (isOverEvent && (eventSystemFlags & IS_REPLAYED) === 0) {\n    // If this is an over event with a target, we might have already dispatched\n    // the event in the out event of the other target. If this is replayed,\n    // then it's because we couldn't dispatch against this target previously\n    // so we have to do it now instead.\n    var related = nativeEvent.relatedTarget || nativeEvent.fromElement;\n\n    if (related) {\n      // If the related node is managed by React, we can assume that we have\n      // already dispatched the corresponding events during its mouseout.\n      if (getClosestInstanceFromNode(related) || isContainerMarkedAsRoot(related)) {\n        return;\n      }\n    }\n  }\n\n  if (!isOutEvent && !isOverEvent) {\n    // Must not be a mouse or pointer in or out - ignoring.\n    return;\n  }\n\n  var win; // TODO: why is this nullable in the types but we read from it?\n\n  if (nativeEventTarget.window === nativeEventTarget) {\n    // `nativeEventTarget` is probably a window object.\n    win = nativeEventTarget;\n  } else {\n    // TODO: Figure out why `ownerDocument` is sometimes undefined in IE8.\n    var doc = nativeEventTarget.ownerDocument;\n\n    if (doc) {\n      win = doc.defaultView || doc.parentWindow;\n    } else {\n      win = window;\n    }\n  }\n\n  var from;\n  var to;\n\n  if (isOutEvent) {\n    var _related = nativeEvent.relatedTarget || nativeEvent.toElement;\n\n    from = targetInst;\n    to = _related ? getClosestInstanceFromNode(_related) : null;\n\n    if (to !== null) {\n      var nearestMounted = getNearestMountedFiber(to);\n\n      if (to !== nearestMounted || to.tag !== HostComponent && to.tag !== HostText) {\n        to = null;\n      }\n    }\n  } else {\n    // Moving to a node from outside the window.\n    from = null;\n    to = targetInst;\n  }\n\n  if (from === to) {\n    // Nothing pertains to our managed components.\n    return;\n  }\n\n  var SyntheticEventCtor = SyntheticMouseEvent;\n  var leaveEventType = 'onMouseLeave';\n  var enterEventType = 'onMouseEnter';\n  var eventTypePrefix = 'mouse';\n\n  if (domEventName === 'pointerout' || domEventName === 'pointerover') {\n    SyntheticEventCtor = SyntheticPointerEvent;\n    leaveEventType = 'onPointerLeave';\n    enterEventType = 'onPointerEnter';\n    eventTypePrefix = 'pointer';\n  }\n\n  var fromNode = from == null ? win : getNodeFromInstance(from);\n  var toNode = to == null ? win : getNodeFromInstance(to);\n  var leave = new SyntheticEventCtor(leaveEventType, eventTypePrefix + 'leave', from, nativeEvent, nativeEventTarget);\n  leave.target = fromNode;\n  leave.relatedTarget = toNode;\n  var enter = null; // We should only process this nativeEvent if we are processing\n  // the first ancestor. Next time, we will ignore the event.\n\n  var nativeTargetInst = getClosestInstanceFromNode(nativeEventTarget);\n\n  if (nativeTargetInst === targetInst) {\n    var enterEvent = new SyntheticEventCtor(enterEventType, eventTypePrefix + 'enter', to, nativeEvent, nativeEventTarget);\n    enterEvent.target = toNode;\n    enterEvent.relatedTarget = fromNode;\n    enter = enterEvent;\n  }\n\n  accumulateEnterLeaveTwoPhaseListeners(dispatchQueue, leave, enter, from, to);\n}\n\n/**\n * inlined Object.is polyfill to avoid requiring consumers ship their own\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n */\nfunction is(x, y) {\n  return x === y && (x !== 0 || 1 / x === 1 / y) || x !== x && y !== y // eslint-disable-line no-self-compare\n  ;\n}\n\nvar objectIs = typeof Object.is === 'function' ? Object.is : is;\n\nvar hasOwnProperty$2 = Object.prototype.hasOwnProperty;\n/**\n * Performs equality by iterating through keys on an object and returning false\n * when any key has values which are not strictly equal between the arguments.\n * Returns true when the values of all keys are strictly equal.\n */\n\nfunction shallowEqual(objA, objB) {\n  if (objectIs(objA, objB)) {\n    return true;\n  }\n\n  if (typeof objA !== 'object' || objA === null || typeof objB !== 'object' || objB === null) {\n    return false;\n  }\n\n  var keysA = Object.keys(objA);\n  var keysB = Object.keys(objB);\n\n  if (keysA.length !== keysB.length) {\n    return false;\n  } // Test for A's keys different from B.\n\n\n  for (var i = 0; i < keysA.length; i++) {\n    if (!hasOwnProperty$2.call(objB, keysA[i]) || !objectIs(objA[keysA[i]], objB[keysA[i]])) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Given any node return the first leaf node without children.\n *\n * @param {DOMElement|DOMTextNode} node\n * @return {DOMElement|DOMTextNode}\n */\n\nfunction getLeafNode(node) {\n  while (node && node.firstChild) {\n    node = node.firstChild;\n  }\n\n  return node;\n}\n/**\n * Get the next sibling within a container. This will walk up the\n * DOM if a node's siblings have been exhausted.\n *\n * @param {DOMElement|DOMTextNode} node\n * @return {?DOMElement|DOMTextNode}\n */\n\n\nfunction getSiblingNode(node) {\n  while (node) {\n    if (node.nextSibling) {\n      return node.nextSibling;\n    }\n\n    node = node.parentNode;\n  }\n}\n/**\n * Get object describing the nodes which contain characters at offset.\n *\n * @param {DOMElement|DOMTextNode} root\n * @param {number} offset\n * @return {?object}\n */\n\n\nfunction getNodeForCharacterOffset(root, offset) {\n  var node = getLeafNode(root);\n  var nodeStart = 0;\n  var nodeEnd = 0;\n\n  while (node) {\n    if (node.nodeType === TEXT_NODE) {\n      nodeEnd = nodeStart + node.textContent.length;\n\n      if (nodeStart <= offset && nodeEnd >= offset) {\n        return {\n          node: node,\n          offset: offset - nodeStart\n        };\n      }\n\n      nodeStart = nodeEnd;\n    }\n\n    node = getLeafNode(getSiblingNode(node));\n  }\n}\n\n/**\n * @param {DOMElement} outerNode\n * @return {?object}\n */\n\nfunction getOffsets(outerNode) {\n  var ownerDocument = outerNode.ownerDocument;\n  var win = ownerDocument && ownerDocument.defaultView || window;\n  var selection = win.getSelection && win.getSelection();\n\n  if (!selection || selection.rangeCount === 0) {\n    return null;\n  }\n\n  var anchorNode = selection.anchorNode,\n      anchorOffset = selection.anchorOffset,\n      focusNode = selection.focusNode,\n      focusOffset = selection.focusOffset; // In Firefox, anchorNode and focusNode can be \"anonymous divs\", e.g. the\n  // up/down buttons on an <input type=\"number\">. Anonymous divs do not seem to\n  // expose properties, triggering a \"Permission denied error\" if any of its\n  // properties are accessed. The only seemingly possible way to avoid erroring\n  // is to access a property that typically works for non-anonymous divs and\n  // catch any error that may otherwise arise. See\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=208427\n\n  try {\n    /* eslint-disable no-unused-expressions */\n    anchorNode.nodeType;\n    focusNode.nodeType;\n    /* eslint-enable no-unused-expressions */\n  } catch (e) {\n    return null;\n  }\n\n  return getModernOffsetsFromPoints(outerNode, anchorNode, anchorOffset, focusNode, focusOffset);\n}\n/**\n * Returns {start, end} where `start` is the character/codepoint index of\n * (anchorNode, anchorOffset) within the textContent of `outerNode`, and\n * `end` is the index of (focusNode, focusOffset).\n *\n * Returns null if you pass in garbage input but we should probably just crash.\n *\n * Exported only for testing.\n */\n\nfunction getModernOffsetsFromPoints(outerNode, anchorNode, anchorOffset, focusNode, focusOffset) {\n  var length = 0;\n  var start = -1;\n  var end = -1;\n  var indexWithinAnchor = 0;\n  var indexWithinFocus = 0;\n  var node = outerNode;\n  var parentNode = null;\n\n  outer: while (true) {\n    var next = null;\n\n    while (true) {\n      if (node === anchorNode && (anchorOffset === 0 || node.nodeType === TEXT_NODE)) {\n        start = length + anchorOffset;\n      }\n\n      if (node === focusNode && (focusOffset === 0 || node.nodeType === TEXT_NODE)) {\n        end = length + focusOffset;\n      }\n\n      if (node.nodeType === TEXT_NODE) {\n        length += node.nodeValue.length;\n      }\n\n      if ((next = node.firstChild) === null) {\n        break;\n      } // Moving from `node` to its first child `next`.\n\n\n      parentNode = node;\n      node = next;\n    }\n\n    while (true) {\n      if (node === outerNode) {\n        // If `outerNode` has children, this is always the second time visiting\n        // it. If it has no children, this is still the first loop, and the only\n        // valid selection is anchorNode and focusNode both equal to this node\n        // and both offsets 0, in which case we will have handled above.\n        break outer;\n      }\n\n      if (parentNode === anchorNode && ++indexWithinAnchor === anchorOffset) {\n        start = length;\n      }\n\n      if (parentNode === focusNode && ++indexWithinFocus === focusOffset) {\n        end = length;\n      }\n\n      if ((next = node.nextSibling) !== null) {\n        break;\n      }\n\n      node = parentNode;\n      parentNode = node.parentNode;\n    } // Moving from `node` to its next sibling `next`.\n\n\n    node = next;\n  }\n\n  if (start === -1 || end === -1) {\n    // This should never happen. (Would happen if the anchor/focus nodes aren't\n    // actually inside the passed-in node.)\n    return null;\n  }\n\n  return {\n    start: start,\n    end: end\n  };\n}\n/**\n * In modern non-IE browsers, we can support both forward and backward\n * selections.\n *\n * Note: IE10+ supports the Selection object, but it does not support\n * the `extend` method, which means that even in modern IE, it's not possible\n * to programmatically create a backward selection. Thus, for all IE\n * versions, we use the old IE API to create our selections.\n *\n * @param {DOMElement|DOMTextNode} node\n * @param {object} offsets\n */\n\nfunction setOffsets(node, offsets) {\n  var doc = node.ownerDocument || document;\n  var win = doc && doc.defaultView || window; // Edge fails with \"Object expected\" in some scenarios.\n  // (For instance: TinyMCE editor used in a list component that supports pasting to add more,\n  // fails when pasting 100+ items)\n\n  if (!win.getSelection) {\n    return;\n  }\n\n  var selection = win.getSelection();\n  var length = node.textContent.length;\n  var start = Math.min(offsets.start, length);\n  var end = offsets.end === undefined ? start : Math.min(offsets.end, length); // IE 11 uses modern selection, but doesn't support the extend method.\n  // Flip backward selections, so we can set with a single range.\n\n  if (!selection.extend && start > end) {\n    var temp = end;\n    end = start;\n    start = temp;\n  }\n\n  var startMarker = getNodeForCharacterOffset(node, start);\n  var endMarker = getNodeForCharacterOffset(node, end);\n\n  if (startMarker && endMarker) {\n    if (selection.rangeCount === 1 && selection.anchorNode === startMarker.node && selection.anchorOffset === startMarker.offset && selection.focusNode === endMarker.node && selection.focusOffset === endMarker.offset) {\n      return;\n    }\n\n    var range = doc.createRange();\n    range.setStart(startMarker.node, startMarker.offset);\n    selection.removeAllRanges();\n\n    if (start > end) {\n      selection.addRange(range);\n      selection.extend(endMarker.node, endMarker.offset);\n    } else {\n      range.setEnd(endMarker.node, endMarker.offset);\n      selection.addRange(range);\n    }\n  }\n}\n\nfunction isTextNode(node) {\n  return node && node.nodeType === TEXT_NODE;\n}\n\nfunction containsNode(outerNode, innerNode) {\n  if (!outerNode || !innerNode) {\n    return false;\n  } else if (outerNode === innerNode) {\n    return true;\n  } else if (isTextNode(outerNode)) {\n    return false;\n  } else if (isTextNode(innerNode)) {\n    return containsNode(outerNode, innerNode.parentNode);\n  } else if ('contains' in outerNode) {\n    return outerNode.contains(innerNode);\n  } else if (outerNode.compareDocumentPosition) {\n    return !!(outerNode.compareDocumentPosition(innerNode) & 16);\n  } else {\n    return false;\n  }\n}\n\nfunction isInDocument(node) {\n  return node && node.ownerDocument && containsNode(node.ownerDocument.documentElement, node);\n}\n\nfunction isSameOriginFrame(iframe) {\n  try {\n    // Accessing the contentDocument of a HTMLIframeElement can cause the browser\n    // to throw, e.g. if it has a cross-origin src attribute.\n    // Safari will show an error in the console when the access results in \"Blocked a frame with origin\". e.g:\n    // iframe.contentDocument.defaultView;\n    // A safety way is to access one of the cross origin properties: Window or Location\n    // Which might result in \"SecurityError\" DOM Exception and it is compatible to Safari.\n    // https://html.spec.whatwg.org/multipage/browsers.html#integration-with-idl\n    return typeof iframe.contentWindow.location.href === 'string';\n  } catch (err) {\n    return false;\n  }\n}\n\nfunction getActiveElementDeep() {\n  var win = window;\n  var element = getActiveElement();\n\n  while (element instanceof win.HTMLIFrameElement) {\n    if (isSameOriginFrame(element)) {\n      win = element.contentWindow;\n    } else {\n      return element;\n    }\n\n    element = getActiveElement(win.document);\n  }\n\n  return element;\n}\n/**\n * @ReactInputSelection: React input selection module. Based on Selection.js,\n * but modified to be suitable for react and has a couple of bug fixes (doesn't\n * assume buttons have range selections allowed).\n * Input selection module for React.\n */\n\n/**\n * @hasSelectionCapabilities: we get the element types that support selection\n * from https://html.spec.whatwg.org/#do-not-apply, looking at `selectionStart`\n * and `selectionEnd` rows.\n */\n\n\nfunction hasSelectionCapabilities(elem) {\n  var nodeName = elem && elem.nodeName && elem.nodeName.toLowerCase();\n  return nodeName && (nodeName === 'input' && (elem.type === 'text' || elem.type === 'search' || elem.type === 'tel' || elem.type === 'url' || elem.type === 'password') || nodeName === 'textarea' || elem.contentEditable === 'true');\n}\nfunction getSelectionInformation() {\n  var focusedElem = getActiveElementDeep();\n  return {\n    focusedElem: focusedElem,\n    selectionRange: hasSelectionCapabilities(focusedElem) ? getSelection(focusedElem) : null\n  };\n}\n/**\n * @restoreSelection: If any selection information was potentially lost,\n * restore it. This is useful when performing operations that could remove dom\n * nodes and place them back in, resulting in focus being lost.\n */\n\nfunction restoreSelection(priorSelectionInformation) {\n  var curFocusedElem = getActiveElementDeep();\n  var priorFocusedElem = priorSelectionInformation.focusedElem;\n  var priorSelectionRange = priorSelectionInformation.selectionRange;\n\n  if (curFocusedElem !== priorFocusedElem && isInDocument(priorFocusedElem)) {\n    if (priorSelectionRange !== null && hasSelectionCapabilities(priorFocusedElem)) {\n      setSelection(priorFocusedElem, priorSelectionRange);\n    } // Focusing a node can change the scroll position, which is undesirable\n\n\n    var ancestors = [];\n    var ancestor = priorFocusedElem;\n\n    while (ancestor = ancestor.parentNode) {\n      if (ancestor.nodeType === ELEMENT_NODE) {\n        ancestors.push({\n          element: ancestor,\n          left: ancestor.scrollLeft,\n          top: ancestor.scrollTop\n        });\n      }\n    }\n\n    if (typeof priorFocusedElem.focus === 'function') {\n      priorFocusedElem.focus();\n    }\n\n    for (var i = 0; i < ancestors.length; i++) {\n      var info = ancestors[i];\n      info.element.scrollLeft = info.left;\n      info.element.scrollTop = info.top;\n    }\n  }\n}\n/**\n * @getSelection: Gets the selection bounds of a focused textarea, input or\n * contentEditable node.\n * -@input: Look up selection bounds of this input\n * -@return {start: selectionStart, end: selectionEnd}\n */\n\nfunction getSelection(input) {\n  var selection;\n\n  if ('selectionStart' in input) {\n    // Modern browser with input or textarea.\n    selection = {\n      start: input.selectionStart,\n      end: input.selectionEnd\n    };\n  } else {\n    // Content editable or old IE textarea.\n    selection = getOffsets(input);\n  }\n\n  return selection || {\n    start: 0,\n    end: 0\n  };\n}\n/**\n * @setSelection: Sets the selection bounds of a textarea or input and focuses\n * the input.\n * -@input     Set selection bounds of this input or textarea\n * -@offsets   Object of same form that is returned from get*\n */\n\nfunction setSelection(input, offsets) {\n  var start = offsets.start;\n  var end = offsets.end;\n\n  if (end === undefined) {\n    end = start;\n  }\n\n  if ('selectionStart' in input) {\n    input.selectionStart = start;\n    input.selectionEnd = Math.min(end, input.value.length);\n  } else {\n    setOffsets(input, offsets);\n  }\n}\n\nvar skipSelectionChangeEvent = canUseDOM && 'documentMode' in document && document.documentMode <= 11;\n\nfunction registerEvents$3() {\n  registerTwoPhaseEvent('onSelect', ['focusout', 'contextmenu', 'dragend', 'focusin', 'keydown', 'keyup', 'mousedown', 'mouseup', 'selectionchange']);\n}\n\nvar activeElement$1 = null;\nvar activeElementInst$1 = null;\nvar lastSelection = null;\nvar mouseDown = false;\n/**\n * Get an object which is a unique representation of the current selection.\n *\n * The return value will not be consistent across nodes or browsers, but\n * two identical selections on the same node will return identical objects.\n */\n\nfunction getSelection$1(node) {\n  if ('selectionStart' in node && hasSelectionCapabilities(node)) {\n    return {\n      start: node.selectionStart,\n      end: node.selectionEnd\n    };\n  } else {\n    var win = node.ownerDocument && node.ownerDocument.defaultView || window;\n    var selection = win.getSelection();\n    return {\n      anchorNode: selection.anchorNode,\n      anchorOffset: selection.anchorOffset,\n      focusNode: selection.focusNode,\n      focusOffset: selection.focusOffset\n    };\n  }\n}\n/**\n * Get document associated with the event target.\n */\n\n\nfunction getEventTargetDocument(eventTarget) {\n  return eventTarget.window === eventTarget ? eventTarget.document : eventTarget.nodeType === DOCUMENT_NODE ? eventTarget : eventTarget.ownerDocument;\n}\n/**\n * Poll selection to see whether it's changed.\n *\n * @param {object} nativeEvent\n * @param {object} nativeEventTarget\n * @return {?SyntheticEvent}\n */\n\n\nfunction constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget) {\n  // Ensure we have the right element, and that the user is not dragging a\n  // selection (this matches native `select` event behavior). In HTML5, select\n  // fires only on input and textarea thus if there's no focused element we\n  // won't dispatch.\n  var doc = getEventTargetDocument(nativeEventTarget);\n\n  if (mouseDown || activeElement$1 == null || activeElement$1 !== getActiveElement(doc)) {\n    return;\n  } // Only fire when selection has actually changed.\n\n\n  var currentSelection = getSelection$1(activeElement$1);\n\n  if (!lastSelection || !shallowEqual(lastSelection, currentSelection)) {\n    lastSelection = currentSelection;\n    var listeners = accumulateTwoPhaseListeners(activeElementInst$1, 'onSelect');\n\n    if (listeners.length > 0) {\n      var event = new SyntheticEvent('onSelect', 'select', null, nativeEvent, nativeEventTarget);\n      dispatchQueue.push({\n        event: event,\n        listeners: listeners\n      });\n      event.target = activeElement$1;\n    }\n  }\n}\n/**\n * This plugin creates an `onSelect` event that normalizes select events\n * across form elements.\n *\n * Supported elements are:\n * - input (see `isTextInputElement`)\n * - textarea\n * - contentEditable\n *\n * This differs from native browser implementations in the following ways:\n * - Fires on contentEditable fields as well as inputs.\n * - Fires for collapsed selection.\n * - Fires after user input.\n */\n\n\nfunction extractEvents$3(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n\n  var targetNode = targetInst ? getNodeFromInstance(targetInst) : window;\n\n  switch (domEventName) {\n    // Track the input node that has focus.\n    case 'focusin':\n      if (isTextInputElement(targetNode) || targetNode.contentEditable === 'true') {\n        activeElement$1 = targetNode;\n        activeElementInst$1 = targetInst;\n        lastSelection = null;\n      }\n\n      break;\n\n    case 'focusout':\n      activeElement$1 = null;\n      activeElementInst$1 = null;\n      lastSelection = null;\n      break;\n    // Don't fire the event while the user is dragging. This matches the\n    // semantics of the native select event.\n\n    case 'mousedown':\n      mouseDown = true;\n      break;\n\n    case 'contextmenu':\n    case 'mouseup':\n    case 'dragend':\n      mouseDown = false;\n      constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget);\n      break;\n    // Chrome and IE fire non-standard event when selection is changed (and\n    // sometimes when it hasn't). IE's event fires out of order with respect\n    // to key and input events on deletion, so we discard it.\n    //\n    // Firefox doesn't support selectionchange, so check selection status\n    // after each key entry. The selection changes after keydown and before\n    // keyup, but we check on keydown as well in the case of holding down a\n    // key, when multiple keydown events are fired but only one keyup is.\n    // This is also our approach for IE handling, for the reason above.\n\n    case 'selectionchange':\n      if (skipSelectionChangeEvent) {\n        break;\n      }\n\n    // falls through\n\n    case 'keydown':\n    case 'keyup':\n      constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget);\n  }\n}\n\nfunction extractEvents$4(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var reactName = topLevelEventsToReactNames.get(domEventName);\n\n  if (reactName === undefined) {\n    return;\n  }\n\n  var SyntheticEventCtor = SyntheticEvent;\n  var reactEventType = domEventName;\n\n  switch (domEventName) {\n    case 'keypress':\n      // Firefox creates a keypress event for function keys too. This removes\n      // the unwanted keypress events. Enter is however both printable and\n      // non-printable. One would expect Tab to be as well (but it isn't).\n      if (getEventCharCode(nativeEvent) === 0) {\n        return;\n      }\n\n    /* falls through */\n\n    case 'keydown':\n    case 'keyup':\n      SyntheticEventCtor = SyntheticKeyboardEvent;\n      break;\n\n    case 'focusin':\n      reactEventType = 'focus';\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'focusout':\n      reactEventType = 'blur';\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'beforeblur':\n    case 'afterblur':\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'click':\n      // Firefox creates a click event on right mouse clicks. This removes the\n      // unwanted click events.\n      if (nativeEvent.button === 2) {\n        return;\n      }\n\n    /* falls through */\n\n    case 'auxclick':\n    case 'dblclick':\n    case 'mousedown':\n    case 'mousemove':\n    case 'mouseup': // TODO: Disabled elements should not respond to mouse events\n\n    /* falls through */\n\n    case 'mouseout':\n    case 'mouseover':\n    case 'contextmenu':\n      SyntheticEventCtor = SyntheticMouseEvent;\n      break;\n\n    case 'drag':\n    case 'dragend':\n    case 'dragenter':\n    case 'dragexit':\n    case 'dragleave':\n    case 'dragover':\n    case 'dragstart':\n    case 'drop':\n      SyntheticEventCtor = SyntheticDragEvent;\n      break;\n\n    case 'touchcancel':\n    case 'touchend':\n    case 'touchmove':\n    case 'touchstart':\n      SyntheticEventCtor = SyntheticTouchEvent;\n      break;\n\n    case ANIMATION_END:\n    case ANIMATION_ITERATION:\n    case ANIMATION_START:\n      SyntheticEventCtor = SyntheticAnimationEvent;\n      break;\n\n    case TRANSITION_END:\n      SyntheticEventCtor = SyntheticTransitionEvent;\n      break;\n\n    case 'scroll':\n      SyntheticEventCtor = SyntheticUIEvent;\n      break;\n\n    case 'wheel':\n      SyntheticEventCtor = SyntheticWheelEvent;\n      break;\n\n    case 'copy':\n    case 'cut':\n    case 'paste':\n      SyntheticEventCtor = SyntheticClipboardEvent;\n      break;\n\n    case 'gotpointercapture':\n    case 'lostpointercapture':\n    case 'pointercancel':\n    case 'pointerdown':\n    case 'pointermove':\n    case 'pointerout':\n    case 'pointerover':\n    case 'pointerup':\n      SyntheticEventCtor = SyntheticPointerEvent;\n      break;\n  }\n\n  var inCapturePhase = (eventSystemFlags & IS_CAPTURE_PHASE) !== 0;\n\n  {\n    // Some events don't bubble in the browser.\n    // In the past, React has always bubbled them, but this can be surprising.\n    // We're going to try aligning closer to the browser behavior by not bubbling\n    // them in React either. We'll start by not bubbling onScroll, and then expand.\n    var accumulateTargetOnly = !inCapturePhase && // TODO: ideally, we'd eventually add all events from\n    // nonDelegatedEvents list in DOMPluginEventSystem.\n    // Then we can remove this special list.\n    // This is a breaking change that can wait until React 18.\n    domEventName === 'scroll';\n\n    var _listeners = accumulateSinglePhaseListeners(targetInst, reactName, nativeEvent.type, inCapturePhase, accumulateTargetOnly);\n\n    if (_listeners.length > 0) {\n      // Intentionally create event lazily.\n      var _event = new SyntheticEventCtor(reactName, reactEventType, null, nativeEvent, nativeEventTarget);\n\n      dispatchQueue.push({\n        event: _event,\n        listeners: _listeners\n      });\n    }\n  }\n}\n\n// TODO: remove top-level side effect.\nregisterSimpleEvents();\nregisterEvents$2();\nregisterEvents$1();\nregisterEvents$3();\nregisterEvents();\n\nfunction extractEvents$5(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  // TODO: we should remove the concept of a \"SimpleEventPlugin\".\n  // This is the basic functionality of the event system. All\n  // the other plugins are essentially polyfills. So the plugin\n  // should probably be inlined somewhere and have its logic\n  // be core the to event system. This would potentially allow\n  // us to ship builds of React without the polyfilled plugins below.\n  extractEvents$4(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags);\n  var shouldProcessPolyfillPlugins = (eventSystemFlags & SHOULD_NOT_PROCESS_POLYFILL_EVENT_PLUGINS) === 0; // We don't process these events unless we are in the\n  // event's native \"bubble\" phase, which means that we're\n  // not in the capture phase. That's because we emulate\n  // the capture phase here still. This is a trade-off,\n  // because in an ideal world we would not emulate and use\n  // the phases properly, like we do with the SimpleEvent\n  // plugin. However, the plugins below either expect\n  // emulation (EnterLeave) or use state localized to that\n  // plugin (BeforeInput, Change, Select). The state in\n  // these modules complicates things, as you'll essentially\n  // get the case where the capture phase event might change\n  // state, only for the following bubble event to come in\n  // later and not trigger anything as the state now\n  // invalidates the heuristics of the event plugin. We\n  // could alter all these plugins to work in such ways, but\n  // that might cause other unknown side-effects that we\n  // can't forsee right now.\n\n  if (shouldProcessPolyfillPlugins) {\n    extractEvents$2(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags);\n    extractEvents$1(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n    extractEvents$3(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n    extractEvents(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n  }\n} // List of events that need to be individually attached to media elements.\n\n\nvar mediaEventTypes = ['abort', 'canplay', 'canplaythrough', 'durationchange', 'emptied', 'encrypted', 'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play', 'playing', 'progress', 'ratechange', 'seeked', 'seeking', 'stalled', 'suspend', 'timeupdate', 'volumechange', 'waiting']; // We should not delegate these events to the container, but rather\n// set them on the actual target element itself. This is primarily\n// because these events do not consistently bubble in the DOM.\n\nvar nonDelegatedEvents = new Set(['cancel', 'close', 'invalid', 'load', 'scroll', 'toggle'].concat(mediaEventTypes));\n\nfunction executeDispatch(event, listener, currentTarget) {\n  var type = event.type || 'unknown-event';\n  event.currentTarget = currentTarget;\n  invokeGuardedCallbackAndCatchFirstError(type, listener, undefined, event);\n  event.currentTarget = null;\n}\n\nfunction processDispatchQueueItemsInOrder(event, dispatchListeners, inCapturePhase) {\n  var previousInstance;\n\n  if (inCapturePhase) {\n    for (var i = dispatchListeners.length - 1; i >= 0; i--) {\n      var _dispatchListeners$i = dispatchListeners[i],\n          instance = _dispatchListeners$i.instance,\n          currentTarget = _dispatchListeners$i.currentTarget,\n          listener = _dispatchListeners$i.listener;\n\n      if (instance !== previousInstance && event.isPropagationStopped()) {\n        return;\n      }\n\n      executeDispatch(event, listener, currentTarget);\n      previousInstance = instance;\n    }\n  } else {\n    for (var _i = 0; _i < dispatchListeners.length; _i++) {\n      var _dispatchListeners$_i = dispatchListeners[_i],\n          _instance = _dispatchListeners$_i.instance,\n          _currentTarget = _dispatchListeners$_i.currentTarget,\n          _listener = _dispatchListeners$_i.listener;\n\n      if (_instance !== previousInstance && event.isPropagationStopped()) {\n        return;\n      }\n\n      executeDispatch(event, _listener, _currentTarget);\n      previousInstance = _instance;\n    }\n  }\n}\n\nfunction processDispatchQueue(dispatchQueue, eventSystemFlags) {\n  var inCapturePhase = (eventSystemFlags & IS_CAPTURE_PHASE) !== 0;\n\n  for (var i = 0; i < dispatchQueue.length; i++) {\n    var _dispatchQueue$i = dispatchQueue[i],\n        event = _dispatchQueue$i.event,\n        listeners = _dispatchQueue$i.listeners;\n    processDispatchQueueItemsInOrder(event, listeners, inCapturePhase); //  event system doesn't use pooling.\n  } // This would be a good time to rethrow if any of the event handlers threw.\n\n\n  rethrowCaughtError();\n}\n\nfunction dispatchEventsForPlugins(domEventName, eventSystemFlags, nativeEvent, targetInst, targetContainer) {\n  var nativeEventTarget = getEventTarget(nativeEvent);\n  var dispatchQueue = [];\n  extractEvents$5(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags);\n  processDispatchQueue(dispatchQueue, eventSystemFlags);\n}\n\nfunction listenToNonDelegatedEvent(domEventName, targetElement) {\n  var isCapturePhaseListener = false;\n  var listenerSet = getEventListenerSet(targetElement);\n  var listenerSetKey = getListenerSetKey(domEventName, isCapturePhaseListener);\n\n  if (!listenerSet.has(listenerSetKey)) {\n    addTrappedEventListener(targetElement, domEventName, IS_NON_DELEGATED, isCapturePhaseListener);\n    listenerSet.add(listenerSetKey);\n  }\n}\nvar listeningMarker = '_reactListening' + Math.random().toString(36).slice(2);\nfunction listenToAllSupportedEvents(rootContainerElement) {\n  {\n    if (rootContainerElement[listeningMarker]) {\n      // Performance optimization: don't iterate through events\n      // for the same portal container or root node more than once.\n      // TODO: once we remove the flag, we may be able to also\n      // remove some of the bookkeeping maps used for laziness.\n      return;\n    }\n\n    rootContainerElement[listeningMarker] = true;\n    allNativeEvents.forEach(function (domEventName) {\n      if (!nonDelegatedEvents.has(domEventName)) {\n        listenToNativeEvent(domEventName, false, rootContainerElement, null);\n      }\n\n      listenToNativeEvent(domEventName, true, rootContainerElement, null);\n    });\n  }\n}\nfunction listenToNativeEvent(domEventName, isCapturePhaseListener, rootContainerElement, targetElement) {\n  var eventSystemFlags = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;\n  var target = rootContainerElement; // selectionchange needs to be attached to the document\n  // otherwise it won't capture incoming events that are only\n  // triggered on the document directly.\n\n  if (domEventName === 'selectionchange' && rootContainerElement.nodeType !== DOCUMENT_NODE) {\n    target = rootContainerElement.ownerDocument;\n  } // If the event can be delegated (or is capture phase), we can\n  // register it to the root container. Otherwise, we should\n  // register the event to the target element and mark it as\n  // a non-delegated event.\n\n\n  if (targetElement !== null && !isCapturePhaseListener && nonDelegatedEvents.has(domEventName)) {\n    // For all non-delegated events, apart from scroll, we attach\n    // their event listeners to the respective elements that their\n    // events fire on. That means we can skip this step, as event\n    // listener has already been added previously. However, we\n    // special case the scroll event because the reality is that any\n    // element can scroll.\n    // TODO: ideally, we'd eventually apply the same logic to all\n    // events from the nonDelegatedEvents list. Then we can remove\n    // this special case and use the same logic for all events.\n    if (domEventName !== 'scroll') {\n      return;\n    }\n\n    eventSystemFlags |= IS_NON_DELEGATED;\n    target = targetElement;\n  }\n\n  var listenerSet = getEventListenerSet(target);\n  var listenerSetKey = getListenerSetKey(domEventName, isCapturePhaseListener); // If the listener entry is empty or we should upgrade, then\n  // we need to trap an event listener onto the target.\n\n  if (!listenerSet.has(listenerSetKey)) {\n    if (isCapturePhaseListener) {\n      eventSystemFlags |= IS_CAPTURE_PHASE;\n    }\n\n    addTrappedEventListener(target, domEventName, eventSystemFlags, isCapturePhaseListener);\n    listenerSet.add(listenerSetKey);\n  }\n}\n\nfunction addTrappedEventListener(targetContainer, domEventName, eventSystemFlags, isCapturePhaseListener, isDeferredListenerForLegacyFBSupport) {\n  var listener = createEventListenerWrapperWithPriority(targetContainer, domEventName, eventSystemFlags); // If passive option is not supported, then the event will be\n  // active and not passive.\n\n  var isPassiveListener = undefined;\n\n  if (passiveBrowserEventsSupported) {\n    // Browsers introduced an intervention, making these events\n    // passive by default on document. React doesn't bind them\n    // to document anymore, but changing this now would undo\n    // the performance wins from the change. So we emulate\n    // the existing behavior manually on the roots now.\n    // https://github.com/facebook/react/issues/19651\n    if (domEventName === 'touchstart' || domEventName === 'touchmove' || domEventName === 'wheel') {\n      isPassiveListener = true;\n    }\n  }\n\n  targetContainer =  targetContainer;\n  var unsubscribeListener; // When legacyFBSupport is enabled, it's for when we\n\n\n  if (isCapturePhaseListener) {\n    if (isPassiveListener !== undefined) {\n      unsubscribeListener = addEventCaptureListenerWithPassiveFlag(targetContainer, domEventName, listener, isPassiveListener);\n    } else {\n      unsubscribeListener = addEventCaptureListener(targetContainer, domEventName, listener);\n    }\n  } else {\n    if (isPassiveListener !== undefined) {\n      unsubscribeListener = addEventBubbleListenerWithPassiveFlag(targetContainer, domEventName, listener, isPassiveListener);\n    } else {\n      unsubscribeListener = addEventBubbleListener(targetContainer, domEventName, listener);\n    }\n  }\n}\n\nfunction isMatchingRootContainer(grandContainer, targetContainer) {\n  return grandContainer === targetContainer || grandContainer.nodeType === COMMENT_NODE && grandContainer.parentNode === targetContainer;\n}\n\nfunction dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, targetInst, targetContainer) {\n  var ancestorInst = targetInst;\n\n  if ((eventSystemFlags & IS_EVENT_HANDLE_NON_MANAGED_NODE) === 0 && (eventSystemFlags & IS_NON_DELEGATED) === 0) {\n    var targetContainerNode = targetContainer; // If we are using the legacy FB support flag, we\n\n    if (targetInst !== null) {\n      // The below logic attempts to work out if we need to change\n      // the target fiber to a different ancestor. We had similar logic\n      // in the legacy event system, except the big difference between\n      // systems is that the modern event system now has an event listener\n      // attached to each React Root and React Portal Root. Together,\n      // the DOM nodes representing these roots are the \"rootContainer\".\n      // To figure out which ancestor instance we should use, we traverse\n      // up the fiber tree from the target instance and attempt to find\n      // root boundaries that match that of our current \"rootContainer\".\n      // If we find that \"rootContainer\", we find the parent fiber\n      // sub-tree for that root and make that our ancestor instance.\n      var node = targetInst;\n\n      mainLoop: while (true) {\n        if (node === null) {\n          return;\n        }\n\n        var nodeTag = node.tag;\n\n        if (nodeTag === HostRoot || nodeTag === HostPortal) {\n          var container = node.stateNode.containerInfo;\n\n          if (isMatchingRootContainer(container, targetContainerNode)) {\n            break;\n          }\n\n          if (nodeTag === HostPortal) {\n            // The target is a portal, but it's not the rootContainer we're looking for.\n            // Normally portals handle their own events all the way down to the root.\n            // So we should be able to stop now. However, we don't know if this portal\n            // was part of *our* root.\n            var grandNode = node.return;\n\n            while (grandNode !== null) {\n              var grandTag = grandNode.tag;\n\n              if (grandTag === HostRoot || grandTag === HostPortal) {\n                var grandContainer = grandNode.stateNode.containerInfo;\n\n                if (isMatchingRootContainer(grandContainer, targetContainerNode)) {\n                  // This is the rootContainer we're looking for and we found it as\n                  // a parent of the Portal. That means we can ignore it because the\n                  // Portal will bubble through to us.\n                  return;\n                }\n              }\n\n              grandNode = grandNode.return;\n            }\n          } // Now we need to find it's corresponding host fiber in the other\n          // tree. To do this we can use getClosestInstanceFromNode, but we\n          // need to validate that the fiber is a host instance, otherwise\n          // we need to traverse up through the DOM till we find the correct\n          // node that is from the other tree.\n\n\n          while (container !== null) {\n            var parentNode = getClosestInstanceFromNode(container);\n\n            if (parentNode === null) {\n              return;\n            }\n\n            var parentTag = parentNode.tag;\n\n            if (parentTag === HostComponent || parentTag === HostText) {\n              node = ancestorInst = parentNode;\n              continue mainLoop;\n            }\n\n            container = container.parentNode;\n          }\n        }\n\n        node = node.return;\n      }\n    }\n  }\n\n  batchedEventUpdates(function () {\n    return dispatchEventsForPlugins(domEventName, eventSystemFlags, nativeEvent, ancestorInst);\n  });\n}\n\nfunction createDispatchListener(instance, listener, currentTarget) {\n  return {\n    instance: instance,\n    listener: listener,\n    currentTarget: currentTarget\n  };\n}\n\nfunction accumulateSinglePhaseListeners(targetFiber, reactName, nativeEventType, inCapturePhase, accumulateTargetOnly) {\n  var captureName = reactName !== null ? reactName + 'Capture' : null;\n  var reactEventName = inCapturePhase ? captureName : reactName;\n  var listeners = [];\n  var instance = targetFiber;\n  var lastHostComponent = null; // Accumulate all instances and listeners via the target -> root path.\n\n  while (instance !== null) {\n    var _instance2 = instance,\n        stateNode = _instance2.stateNode,\n        tag = _instance2.tag; // Handle listeners that are on HostComponents (i.e. <div>)\n\n    if (tag === HostComponent && stateNode !== null) {\n      lastHostComponent = stateNode; // createEventHandle listeners\n\n\n      if (reactEventName !== null) {\n        var listener = getListener(instance, reactEventName);\n\n        if (listener != null) {\n          listeners.push(createDispatchListener(instance, listener, lastHostComponent));\n        }\n      }\n    } // If we are only accumulating events for the target, then we don't\n    // continue to propagate through the React fiber tree to find other\n    // listeners.\n\n\n    if (accumulateTargetOnly) {\n      break;\n    }\n\n    instance = instance.return;\n  }\n\n  return listeners;\n} // We should only use this function for:\n// - BeforeInputEventPlugin\n// - ChangeEventPlugin\n// - SelectEventPlugin\n// This is because we only process these plugins\n// in the bubble phase, so we need to accumulate two\n// phase event listeners (via emulation).\n\nfunction accumulateTwoPhaseListeners(targetFiber, reactName) {\n  var captureName = reactName + 'Capture';\n  var listeners = [];\n  var instance = targetFiber; // Accumulate all instances and listeners via the target -> root path.\n\n  while (instance !== null) {\n    var _instance3 = instance,\n        stateNode = _instance3.stateNode,\n        tag = _instance3.tag; // Handle listeners that are on HostComponents (i.e. <div>)\n\n    if (tag === HostComponent && stateNode !== null) {\n      var currentTarget = stateNode;\n      var captureListener = getListener(instance, captureName);\n\n      if (captureListener != null) {\n        listeners.unshift(createDispatchListener(instance, captureListener, currentTarget));\n      }\n\n      var bubbleListener = getListener(instance, reactName);\n\n      if (bubbleListener != null) {\n        listeners.push(createDispatchListener(instance, bubbleListener, currentTarget));\n      }\n    }\n\n    instance = instance.return;\n  }\n\n  return listeners;\n}\n\nfunction getParent(inst) {\n  if (inst === null) {\n    return null;\n  }\n\n  do {\n    inst = inst.return; // TODO: If this is a HostRoot we might want to bail out.\n    // That is depending on if we want nested subtrees (layers) to bubble\n    // events to their parent. We could also go through parentNode on the\n    // host node but that wouldn't work for React Native and doesn't let us\n    // do the portal feature.\n  } while (inst && inst.tag !== HostComponent);\n\n  if (inst) {\n    return inst;\n  }\n\n  return null;\n}\n/**\n * Return the lowest common ancestor of A and B, or null if they are in\n * different trees.\n */\n\n\nfunction getLowestCommonAncestor(instA, instB) {\n  var nodeA = instA;\n  var nodeB = instB;\n  var depthA = 0;\n\n  for (var tempA = nodeA; tempA; tempA = getParent(tempA)) {\n    depthA++;\n  }\n\n  var depthB = 0;\n\n  for (var tempB = nodeB; tempB; tempB = getParent(tempB)) {\n    depthB++;\n  } // If A is deeper, crawl up.\n\n\n  while (depthA - depthB > 0) {\n    nodeA = getParent(nodeA);\n    depthA--;\n  } // If B is deeper, crawl up.\n\n\n  while (depthB - depthA > 0) {\n    nodeB = getParent(nodeB);\n    depthB--;\n  } // Walk in lockstep until we find a match.\n\n\n  var depth = depthA;\n\n  while (depth--) {\n    if (nodeA === nodeB || nodeB !== null && nodeA === nodeB.alternate) {\n      return nodeA;\n    }\n\n    nodeA = getParent(nodeA);\n    nodeB = getParent(nodeB);\n  }\n\n  return null;\n}\n\nfunction accumulateEnterLeaveListenersForEvent(dispatchQueue, event, target, common, inCapturePhase) {\n  var registrationName = event._reactName;\n  var listeners = [];\n  var instance = target;\n\n  while (instance !== null) {\n    if (instance === common) {\n      break;\n    }\n\n    var _instance4 = instance,\n        alternate = _instance4.alternate,\n        stateNode = _instance4.stateNode,\n        tag = _instance4.tag;\n\n    if (alternate !== null && alternate === common) {\n      break;\n    }\n\n    if (tag === HostComponent && stateNode !== null) {\n      var currentTarget = stateNode;\n\n      if (inCapturePhase) {\n        var captureListener = getListener(instance, registrationName);\n\n        if (captureListener != null) {\n          listeners.unshift(createDispatchListener(instance, captureListener, currentTarget));\n        }\n      } else if (!inCapturePhase) {\n        var bubbleListener = getListener(instance, registrationName);\n\n        if (bubbleListener != null) {\n          listeners.push(createDispatchListener(instance, bubbleListener, currentTarget));\n        }\n      }\n    }\n\n    instance = instance.return;\n  }\n\n  if (listeners.length !== 0) {\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n  }\n} // We should only use this function for:\n// - EnterLeaveEventPlugin\n// This is because we only process this plugin\n// in the bubble phase, so we need to accumulate two\n// phase event listeners.\n\n\nfunction accumulateEnterLeaveTwoPhaseListeners(dispatchQueue, leaveEvent, enterEvent, from, to) {\n  var common = from && to ? getLowestCommonAncestor(from, to) : null;\n\n  if (from !== null) {\n    accumulateEnterLeaveListenersForEvent(dispatchQueue, leaveEvent, from, common, false);\n  }\n\n  if (to !== null && enterEvent !== null) {\n    accumulateEnterLeaveListenersForEvent(dispatchQueue, enterEvent, to, common, true);\n  }\n}\nfunction getListenerSetKey(domEventName, capture) {\n  return domEventName + \"__\" + (capture ? 'capture' : 'bubble');\n}\n\nvar didWarnInvalidHydration = false;\nvar DANGEROUSLY_SET_INNER_HTML = 'dangerouslySetInnerHTML';\nvar SUPPRESS_CONTENT_EDITABLE_WARNING = 'suppressContentEditableWarning';\nvar SUPPRESS_HYDRATION_WARNING = 'suppressHydrationWarning';\nvar AUTOFOCUS = 'autoFocus';\nvar CHILDREN = 'children';\nvar STYLE = 'style';\nvar HTML$1 = '__html';\nvar HTML_NAMESPACE$1 = Namespaces.html;\nvar warnedUnknownTags;\nvar suppressHydrationWarning;\nvar validatePropertiesInDevelopment;\nvar warnForTextDifference;\nvar warnForPropDifference;\nvar warnForExtraAttributes;\nvar warnForInvalidEventListener;\nvar canDiffStyleForHydrationWarning;\nvar normalizeMarkupForTextOrAttribute;\nvar normalizeHTML;\n\n{\n  warnedUnknownTags = {\n    // There are working polyfills for <dialog>. Let people use it.\n    dialog: true,\n    // Electron ships a custom <webview> tag to display external web content in\n    // an isolated frame and process.\n    // This tag is not present in non Electron environments such as JSDom which\n    // is often used for testing purposes.\n    // @see https://electronjs.org/docs/api/webview-tag\n    webview: true\n  };\n\n  validatePropertiesInDevelopment = function (type, props) {\n    validateProperties(type, props);\n    validateProperties$1(type, props);\n    validateProperties$2(type, props, {\n      registrationNameDependencies: registrationNameDependencies,\n      possibleRegistrationNames: possibleRegistrationNames\n    });\n  }; // IE 11 parses & normalizes the style attribute as opposed to other\n  // browsers. It adds spaces and sorts the properties in some\n  // non-alphabetical order. Handling that would require sorting CSS\n  // properties in the client & server versions or applying\n  // `expectedStyle` to a temporary DOM node to read its `style` attribute\n  // normalized. Since it only affects IE, we're skipping style warnings\n  // in that browser completely in favor of doing all that work.\n  // See https://github.com/facebook/react/issues/11807\n\n\n  canDiffStyleForHydrationWarning = canUseDOM && !document.documentMode; // HTML parsing normalizes CR and CRLF to LF.\n  // It also can turn \\u0000 into \\uFFFD inside attributes.\n  // https://www.w3.org/TR/html5/single-page.html#preprocessing-the-input-stream\n  // If we have a mismatch, it might be caused by that.\n  // We will still patch up in this case but not fire the warning.\n\n  var NORMALIZE_NEWLINES_REGEX = /\\r\\n?/g;\n  var NORMALIZE_NULL_AND_REPLACEMENT_REGEX = /\\u0000|\\uFFFD/g;\n\n  normalizeMarkupForTextOrAttribute = function (markup) {\n    var markupString = typeof markup === 'string' ? markup : '' + markup;\n    return markupString.replace(NORMALIZE_NEWLINES_REGEX, '\\n').replace(NORMALIZE_NULL_AND_REPLACEMENT_REGEX, '');\n  };\n\n  warnForTextDifference = function (serverText, clientText) {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    var normalizedClientText = normalizeMarkupForTextOrAttribute(clientText);\n    var normalizedServerText = normalizeMarkupForTextOrAttribute(serverText);\n\n    if (normalizedServerText === normalizedClientText) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Text content did not match. Server: \"%s\" Client: \"%s\"', normalizedServerText, normalizedClientText);\n  };\n\n  warnForPropDifference = function (propName, serverValue, clientValue) {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    var normalizedClientValue = normalizeMarkupForTextOrAttribute(clientValue);\n    var normalizedServerValue = normalizeMarkupForTextOrAttribute(serverValue);\n\n    if (normalizedServerValue === normalizedClientValue) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Prop `%s` did not match. Server: %s Client: %s', propName, JSON.stringify(normalizedServerValue), JSON.stringify(normalizedClientValue));\n  };\n\n  warnForExtraAttributes = function (attributeNames) {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n    var names = [];\n    attributeNames.forEach(function (name) {\n      names.push(name);\n    });\n\n    error('Extra attributes from the server: %s', names);\n  };\n\n  warnForInvalidEventListener = function (registrationName, listener) {\n    if (listener === false) {\n      error('Expected `%s` listener to be a function, instead got `false`.\\n\\n' + 'If you used to conditionally omit it with %s={condition && value}, ' + 'pass %s={condition ? value : undefined} instead.', registrationName, registrationName, registrationName);\n    } else {\n      error('Expected `%s` listener to be a function, instead got a value of `%s` type.', registrationName, typeof listener);\n    }\n  }; // Parse the HTML and read it back to normalize the HTML string so that it\n  // can be used for comparison.\n\n\n  normalizeHTML = function (parent, html) {\n    // We could have created a separate document here to avoid\n    // re-initializing custom elements if they exist. But this breaks\n    // how <noscript> is being handled. So we use the same document.\n    // See the discussion in https://github.com/facebook/react/pull/11157.\n    var testElement = parent.namespaceURI === HTML_NAMESPACE$1 ? parent.ownerDocument.createElement(parent.tagName) : parent.ownerDocument.createElementNS(parent.namespaceURI, parent.tagName);\n    testElement.innerHTML = html;\n    return testElement.innerHTML;\n  };\n}\n\nfunction getOwnerDocumentFromRootContainer(rootContainerElement) {\n  return rootContainerElement.nodeType === DOCUMENT_NODE ? rootContainerElement : rootContainerElement.ownerDocument;\n}\n\nfunction noop() {}\n\nfunction trapClickOnNonInteractiveElement(node) {\n  // Mobile Safari does not fire properly bubble click events on\n  // non-interactive elements, which means delegated click listeners do not\n  // fire. The workaround for this bug involves attaching an empty click\n  // listener on the target node.\n  // https://www.quirksmode.org/blog/archives/2010/09/click_event_del.html\n  // Just set it using the onclick property so that we don't have to manage any\n  // bookkeeping for it. Not sure if we need to clear it when the listener is\n  // removed.\n  // TODO: Only do this for the relevant Safaris maybe?\n  node.onclick = noop;\n}\n\nfunction setInitialDOMProperties(tag, domElement, rootContainerElement, nextProps, isCustomComponentTag) {\n  for (var propKey in nextProps) {\n    if (!nextProps.hasOwnProperty(propKey)) {\n      continue;\n    }\n\n    var nextProp = nextProps[propKey];\n\n    if (propKey === STYLE) {\n      {\n        if (nextProp) {\n          // Freeze the next style object so that we can assume it won't be\n          // mutated. We have already warned for this in the past.\n          Object.freeze(nextProp);\n        }\n      } // Relies on `updateStylesByID` not mutating `styleUpdates`.\n\n\n      setValueForStyles(domElement, nextProp);\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n\n      if (nextHtml != null) {\n        setInnerHTML(domElement, nextHtml);\n      }\n    } else if (propKey === CHILDREN) {\n      if (typeof nextProp === 'string') {\n        // Avoid setting initial textContent when the text is empty. In IE11 setting\n        // textContent on a <textarea> will cause the placeholder to not\n        // show within the <textarea> until it has been focused and blurred again.\n        // https://github.com/facebook/react/issues/6731#issuecomment-254874553\n        var canSetTextContent = tag !== 'textarea' || nextProp !== '';\n\n        if (canSetTextContent) {\n          setTextContent(domElement, nextProp);\n        }\n      } else if (typeof nextProp === 'number') {\n        setTextContent(domElement, '' + nextProp);\n      }\n    } else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (propKey === AUTOFOCUS) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n    } else if (nextProp != null) {\n      setValueForProperty(domElement, propKey, nextProp, isCustomComponentTag);\n    }\n  }\n}\n\nfunction updateDOMProperties(domElement, updatePayload, wasCustomComponentTag, isCustomComponentTag) {\n  // TODO: Handle wasCustomComponentTag\n  for (var i = 0; i < updatePayload.length; i += 2) {\n    var propKey = updatePayload[i];\n    var propValue = updatePayload[i + 1];\n\n    if (propKey === STYLE) {\n      setValueForStyles(domElement, propValue);\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      setInnerHTML(domElement, propValue);\n    } else if (propKey === CHILDREN) {\n      setTextContent(domElement, propValue);\n    } else {\n      setValueForProperty(domElement, propKey, propValue, isCustomComponentTag);\n    }\n  }\n}\n\nfunction createElement(type, props, rootContainerElement, parentNamespace) {\n  var isCustomComponentTag; // We create tags in the namespace of their parent container, except HTML\n  // tags get no namespace.\n\n  var ownerDocument = getOwnerDocumentFromRootContainer(rootContainerElement);\n  var domElement;\n  var namespaceURI = parentNamespace;\n\n  if (namespaceURI === HTML_NAMESPACE$1) {\n    namespaceURI = getIntrinsicNamespace(type);\n  }\n\n  if (namespaceURI === HTML_NAMESPACE$1) {\n    {\n      isCustomComponentTag = isCustomComponent(type, props); // Should this check be gated by parent namespace? Not sure we want to\n      // allow <SVG> or <mATH>.\n\n      if (!isCustomComponentTag && type !== type.toLowerCase()) {\n        error('<%s /> is using incorrect casing. ' + 'Use PascalCase for React components, ' + 'or lowercase for HTML elements.', type);\n      }\n    }\n\n    if (type === 'script') {\n      // Create the script via .innerHTML so its \"parser-inserted\" flag is\n      // set to true and it does not execute\n      var div = ownerDocument.createElement('div');\n\n      div.innerHTML = '<script><' + '/script>'; // eslint-disable-line\n      // This is guaranteed to yield a script element.\n\n      var firstChild = div.firstChild;\n      domElement = div.removeChild(firstChild);\n    } else if (typeof props.is === 'string') {\n      // $FlowIssue `createElement` should be updated for Web Components\n      domElement = ownerDocument.createElement(type, {\n        is: props.is\n      });\n    } else {\n      // Separate else branch instead of using `props.is || undefined` above because of a Firefox bug.\n      // See discussion in https://github.com/facebook/react/pull/6896\n      // and discussion in https://bugzilla.mozilla.org/show_bug.cgi?id=1276240\n      domElement = ownerDocument.createElement(type); // Normally attributes are assigned in `setInitialDOMProperties`, however the `multiple` and `size`\n      // attributes on `select`s needs to be added before `option`s are inserted.\n      // This prevents:\n      // - a bug where the `select` does not scroll to the correct option because singular\n      //  `select` elements automatically pick the first item #13222\n      // - a bug where the `select` set the first item as selected despite the `size` attribute #14239\n      // See https://github.com/facebook/react/issues/13222\n      // and https://github.com/facebook/react/issues/14239\n\n      if (type === 'select') {\n        var node = domElement;\n\n        if (props.multiple) {\n          node.multiple = true;\n        } else if (props.size) {\n          // Setting a size greater than 1 causes a select to behave like `multiple=true`, where\n          // it is possible that no option is selected.\n          //\n          // This is only necessary when a select in \"single selection mode\".\n          node.size = props.size;\n        }\n      }\n    }\n  } else {\n    domElement = ownerDocument.createElementNS(namespaceURI, type);\n  }\n\n  {\n    if (namespaceURI === HTML_NAMESPACE$1) {\n      if (!isCustomComponentTag && Object.prototype.toString.call(domElement) === '[object HTMLUnknownElement]' && !Object.prototype.hasOwnProperty.call(warnedUnknownTags, type)) {\n        warnedUnknownTags[type] = true;\n\n        error('The tag <%s> is unrecognized in this browser. ' + 'If you meant to render a React component, start its name with ' + 'an uppercase letter.', type);\n      }\n    }\n  }\n\n  return domElement;\n}\nfunction createTextNode(text, rootContainerElement) {\n  return getOwnerDocumentFromRootContainer(rootContainerElement).createTextNode(text);\n}\nfunction setInitialProperties(domElement, tag, rawProps, rootContainerElement) {\n  var isCustomComponentTag = isCustomComponent(tag, rawProps);\n\n  {\n    validatePropertiesInDevelopment(tag, rawProps);\n  } // TODO: Make sure that we check isMounted before firing any of these events.\n\n\n  var props;\n\n  switch (tag) {\n    case 'dialog':\n      listenToNonDelegatedEvent('cancel', domElement);\n      listenToNonDelegatedEvent('close', domElement);\n      props = rawProps;\n      break;\n\n    case 'iframe':\n    case 'object':\n    case 'embed':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the load event.\n      listenToNonDelegatedEvent('load', domElement);\n      props = rawProps;\n      break;\n\n    case 'video':\n    case 'audio':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for all the media events.\n      for (var i = 0; i < mediaEventTypes.length; i++) {\n        listenToNonDelegatedEvent(mediaEventTypes[i], domElement);\n      }\n\n      props = rawProps;\n      break;\n\n    case 'source':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the error event.\n      listenToNonDelegatedEvent('error', domElement);\n      props = rawProps;\n      break;\n\n    case 'img':\n    case 'image':\n    case 'link':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for error and load events.\n      listenToNonDelegatedEvent('error', domElement);\n      listenToNonDelegatedEvent('load', domElement);\n      props = rawProps;\n      break;\n\n    case 'details':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the toggle event.\n      listenToNonDelegatedEvent('toggle', domElement);\n      props = rawProps;\n      break;\n\n    case 'input':\n      initWrapperState(domElement, rawProps);\n      props = getHostProps(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n\n    case 'option':\n      validateProps(domElement, rawProps);\n      props = getHostProps$1(domElement, rawProps);\n      break;\n\n    case 'select':\n      initWrapperState$1(domElement, rawProps);\n      props = getHostProps$2(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n\n    case 'textarea':\n      initWrapperState$2(domElement, rawProps);\n      props = getHostProps$3(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n\n    default:\n      props = rawProps;\n  }\n\n  assertValidProps(tag, props);\n  setInitialDOMProperties(tag, domElement, rootContainerElement, props, isCustomComponentTag);\n\n  switch (tag) {\n    case 'input':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper(domElement, rawProps, false);\n      break;\n\n    case 'textarea':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper$3(domElement);\n      break;\n\n    case 'option':\n      postMountWrapper$1(domElement, rawProps);\n      break;\n\n    case 'select':\n      postMountWrapper$2(domElement, rawProps);\n      break;\n\n    default:\n      if (typeof props.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n} // Calculate the diff between the two objects.\n\nfunction diffProperties(domElement, tag, lastRawProps, nextRawProps, rootContainerElement) {\n  {\n    validatePropertiesInDevelopment(tag, nextRawProps);\n  }\n\n  var updatePayload = null;\n  var lastProps;\n  var nextProps;\n\n  switch (tag) {\n    case 'input':\n      lastProps = getHostProps(domElement, lastRawProps);\n      nextProps = getHostProps(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    case 'option':\n      lastProps = getHostProps$1(domElement, lastRawProps);\n      nextProps = getHostProps$1(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    case 'select':\n      lastProps = getHostProps$2(domElement, lastRawProps);\n      nextProps = getHostProps$2(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    case 'textarea':\n      lastProps = getHostProps$3(domElement, lastRawProps);\n      nextProps = getHostProps$3(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    default:\n      lastProps = lastRawProps;\n      nextProps = nextRawProps;\n\n      if (typeof lastProps.onClick !== 'function' && typeof nextProps.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n\n  assertValidProps(tag, nextProps);\n  var propKey;\n  var styleName;\n  var styleUpdates = null;\n\n  for (propKey in lastProps) {\n    if (nextProps.hasOwnProperty(propKey) || !lastProps.hasOwnProperty(propKey) || lastProps[propKey] == null) {\n      continue;\n    }\n\n    if (propKey === STYLE) {\n      var lastStyle = lastProps[propKey];\n\n      for (styleName in lastStyle) {\n        if (lastStyle.hasOwnProperty(styleName)) {\n          if (!styleUpdates) {\n            styleUpdates = {};\n          }\n\n          styleUpdates[styleName] = '';\n        }\n      }\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML || propKey === CHILDREN) ; else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (propKey === AUTOFOCUS) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      // This is a special case. If any listener updates we need to ensure\n      // that the \"current\" fiber pointer gets updated so we need a commit\n      // to update this element.\n      if (!updatePayload) {\n        updatePayload = [];\n      }\n    } else {\n      // For all other deleted properties we add it to the queue. We use\n      // the allowed property list in the commit phase instead.\n      (updatePayload = updatePayload || []).push(propKey, null);\n    }\n  }\n\n  for (propKey in nextProps) {\n    var nextProp = nextProps[propKey];\n    var lastProp = lastProps != null ? lastProps[propKey] : undefined;\n\n    if (!nextProps.hasOwnProperty(propKey) || nextProp === lastProp || nextProp == null && lastProp == null) {\n      continue;\n    }\n\n    if (propKey === STYLE) {\n      {\n        if (nextProp) {\n          // Freeze the next style object so that we can assume it won't be\n          // mutated. We have already warned for this in the past.\n          Object.freeze(nextProp);\n        }\n      }\n\n      if (lastProp) {\n        // Unset styles on `lastProp` but not on `nextProp`.\n        for (styleName in lastProp) {\n          if (lastProp.hasOwnProperty(styleName) && (!nextProp || !nextProp.hasOwnProperty(styleName))) {\n            if (!styleUpdates) {\n              styleUpdates = {};\n            }\n\n            styleUpdates[styleName] = '';\n          }\n        } // Update styles that changed since `lastProp`.\n\n\n        for (styleName in nextProp) {\n          if (nextProp.hasOwnProperty(styleName) && lastProp[styleName] !== nextProp[styleName]) {\n            if (!styleUpdates) {\n              styleUpdates = {};\n            }\n\n            styleUpdates[styleName] = nextProp[styleName];\n          }\n        }\n      } else {\n        // Relies on `updateStylesByID` not mutating `styleUpdates`.\n        if (!styleUpdates) {\n          if (!updatePayload) {\n            updatePayload = [];\n          }\n\n          updatePayload.push(propKey, styleUpdates);\n        }\n\n        styleUpdates = nextProp;\n      }\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n      var lastHtml = lastProp ? lastProp[HTML$1] : undefined;\n\n      if (nextHtml != null) {\n        if (lastHtml !== nextHtml) {\n          (updatePayload = updatePayload || []).push(propKey, nextHtml);\n        }\n      }\n    } else if (propKey === CHILDREN) {\n      if (typeof nextProp === 'string' || typeof nextProp === 'number') {\n        (updatePayload = updatePayload || []).push(propKey, '' + nextProp);\n      }\n    } else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        // We eagerly listen to this even though we haven't committed yet.\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n\n      if (!updatePayload && lastProp !== nextProp) {\n        // This is a special case. If any listener updates we need to ensure\n        // that the \"current\" props pointer gets updated so we need a commit\n        // to update this element.\n        updatePayload = [];\n      }\n    } else if (typeof nextProp === 'object' && nextProp !== null && nextProp.$$typeof === REACT_OPAQUE_ID_TYPE) {\n      // If we encounter useOpaqueReference's opaque object, this means we are hydrating.\n      // In this case, call the opaque object's toString function which generates a new client\n      // ID so client and server IDs match and throws to rerender.\n      nextProp.toString();\n    } else {\n      // For any other property we always add it to the queue and then we\n      // filter it out using the allowed property list during the commit.\n      (updatePayload = updatePayload || []).push(propKey, nextProp);\n    }\n  }\n\n  if (styleUpdates) {\n    {\n      validateShorthandPropertyCollisionInDev(styleUpdates, nextProps[STYLE]);\n    }\n\n    (updatePayload = updatePayload || []).push(STYLE, styleUpdates);\n  }\n\n  return updatePayload;\n} // Apply the diff.\n\nfunction updateProperties(domElement, updatePayload, tag, lastRawProps, nextRawProps) {\n  // Update checked *before* name.\n  // In the middle of an update, it is possible to have multiple checked.\n  // When a checked radio tries to change name, browser makes another radio's checked false.\n  if (tag === 'input' && nextRawProps.type === 'radio' && nextRawProps.name != null) {\n    updateChecked(domElement, nextRawProps);\n  }\n\n  var wasCustomComponentTag = isCustomComponent(tag, lastRawProps);\n  var isCustomComponentTag = isCustomComponent(tag, nextRawProps); // Apply the diff.\n\n  updateDOMProperties(domElement, updatePayload, wasCustomComponentTag, isCustomComponentTag); // TODO: Ensure that an update gets scheduled if any of the special props\n  // changed.\n\n  switch (tag) {\n    case 'input':\n      // Update the wrapper around inputs *after* updating props. This has to\n      // happen after `updateDOMProperties`. Otherwise HTML5 input validations\n      // raise warnings and prevent the new value from being assigned.\n      updateWrapper(domElement, nextRawProps);\n      break;\n\n    case 'textarea':\n      updateWrapper$1(domElement, nextRawProps);\n      break;\n\n    case 'select':\n      // <select> value update needs to occur after <option> children\n      // reconciliation\n      postUpdateWrapper(domElement, nextRawProps);\n      break;\n  }\n}\n\nfunction getPossibleStandardName(propName) {\n  {\n    var lowerCasedName = propName.toLowerCase();\n\n    if (!possibleStandardNames.hasOwnProperty(lowerCasedName)) {\n      return null;\n    }\n\n    return possibleStandardNames[lowerCasedName] || null;\n  }\n}\n\nfunction diffHydratedProperties(domElement, tag, rawProps, parentNamespace, rootContainerElement) {\n  var isCustomComponentTag;\n  var extraAttributeNames;\n\n  {\n    suppressHydrationWarning = rawProps[SUPPRESS_HYDRATION_WARNING] === true;\n    isCustomComponentTag = isCustomComponent(tag, rawProps);\n    validatePropertiesInDevelopment(tag, rawProps);\n  } // TODO: Make sure that we check isMounted before firing any of these events.\n\n\n  switch (tag) {\n    case 'dialog':\n      listenToNonDelegatedEvent('cancel', domElement);\n      listenToNonDelegatedEvent('close', domElement);\n      break;\n\n    case 'iframe':\n    case 'object':\n    case 'embed':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the load event.\n      listenToNonDelegatedEvent('load', domElement);\n      break;\n\n    case 'video':\n    case 'audio':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for all the media events.\n      for (var i = 0; i < mediaEventTypes.length; i++) {\n        listenToNonDelegatedEvent(mediaEventTypes[i], domElement);\n      }\n\n      break;\n\n    case 'source':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the error event.\n      listenToNonDelegatedEvent('error', domElement);\n      break;\n\n    case 'img':\n    case 'image':\n    case 'link':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for error and load events.\n      listenToNonDelegatedEvent('error', domElement);\n      listenToNonDelegatedEvent('load', domElement);\n      break;\n\n    case 'details':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the toggle event.\n      listenToNonDelegatedEvent('toggle', domElement);\n      break;\n\n    case 'input':\n      initWrapperState(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n\n    case 'option':\n      validateProps(domElement, rawProps);\n      break;\n\n    case 'select':\n      initWrapperState$1(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n\n    case 'textarea':\n      initWrapperState$2(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n\n      break;\n  }\n\n  assertValidProps(tag, rawProps);\n\n  {\n    extraAttributeNames = new Set();\n    var attributes = domElement.attributes;\n\n    for (var _i = 0; _i < attributes.length; _i++) {\n      var name = attributes[_i].name.toLowerCase();\n\n      switch (name) {\n        // Built-in SSR attribute is allowed\n        case 'data-reactroot':\n          break;\n        // Controlled attributes are not validated\n        // TODO: Only ignore them on controlled tags.\n\n        case 'value':\n          break;\n\n        case 'checked':\n          break;\n\n        case 'selected':\n          break;\n\n        default:\n          // Intentionally use the original name.\n          // See discussion in https://github.com/facebook/react/pull/10676.\n          extraAttributeNames.add(attributes[_i].name);\n      }\n    }\n  }\n\n  var updatePayload = null;\n\n  for (var propKey in rawProps) {\n    if (!rawProps.hasOwnProperty(propKey)) {\n      continue;\n    }\n\n    var nextProp = rawProps[propKey];\n\n    if (propKey === CHILDREN) {\n      // For text content children we compare against textContent. This\n      // might match additional HTML that is hidden when we read it using\n      // textContent. E.g. \"foo\" will match \"f<span>oo</span>\" but that still\n      // satisfies our requirement. Our requirement is not to produce perfect\n      // HTML and attributes. Ideally we should preserve structure but it's\n      // ok not to if the visible content is still enough to indicate what\n      // even listeners these nodes might be wired up to.\n      // TODO: Warn if there is more than a single textNode as a child.\n      // TODO: Should we use domElement.firstChild.nodeValue to compare?\n      if (typeof nextProp === 'string') {\n        if (domElement.textContent !== nextProp) {\n          if ( !suppressHydrationWarning) {\n            warnForTextDifference(domElement.textContent, nextProp);\n          }\n\n          updatePayload = [CHILDREN, nextProp];\n        }\n      } else if (typeof nextProp === 'number') {\n        if (domElement.textContent !== '' + nextProp) {\n          if ( !suppressHydrationWarning) {\n            warnForTextDifference(domElement.textContent, nextProp);\n          }\n\n          updatePayload = [CHILDREN, '' + nextProp];\n        }\n      }\n    } else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n    } else if ( // Convince Flow we've calculated it (it's DEV-only in this method.)\n    typeof isCustomComponentTag === 'boolean') {\n      // Validate that the properties correspond to their expected values.\n      var serverValue = void 0;\n      var propertyInfo = getPropertyInfo(propKey);\n\n      if (suppressHydrationWarning) ; else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING || // Controlled attributes are not validated\n      // TODO: Only ignore them on controlled tags.\n      propKey === 'value' || propKey === 'checked' || propKey === 'selected') ; else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n        var serverHTML = domElement.innerHTML;\n        var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n\n        if (nextHtml != null) {\n          var expectedHTML = normalizeHTML(domElement, nextHtml);\n\n          if (expectedHTML !== serverHTML) {\n            warnForPropDifference(propKey, serverHTML, expectedHTML);\n          }\n        }\n      } else if (propKey === STYLE) {\n        // $FlowFixMe - Should be inferred as not undefined.\n        extraAttributeNames.delete(propKey);\n\n        if (canDiffStyleForHydrationWarning) {\n          var expectedStyle = createDangerousStringForStyles(nextProp);\n          serverValue = domElement.getAttribute('style');\n\n          if (expectedStyle !== serverValue) {\n            warnForPropDifference(propKey, serverValue, expectedStyle);\n          }\n        }\n      } else if (isCustomComponentTag) {\n        // $FlowFixMe - Should be inferred as not undefined.\n        extraAttributeNames.delete(propKey.toLowerCase());\n        serverValue = getValueForAttribute(domElement, propKey, nextProp);\n\n        if (nextProp !== serverValue) {\n          warnForPropDifference(propKey, serverValue, nextProp);\n        }\n      } else if (!shouldIgnoreAttribute(propKey, propertyInfo, isCustomComponentTag) && !shouldRemoveAttribute(propKey, nextProp, propertyInfo, isCustomComponentTag)) {\n        var isMismatchDueToBadCasing = false;\n\n        if (propertyInfo !== null) {\n          // $FlowFixMe - Should be inferred as not undefined.\n          extraAttributeNames.delete(propertyInfo.attributeName);\n          serverValue = getValueForProperty(domElement, propKey, nextProp, propertyInfo);\n        } else {\n          var ownNamespace = parentNamespace;\n\n          if (ownNamespace === HTML_NAMESPACE$1) {\n            ownNamespace = getIntrinsicNamespace(tag);\n          }\n\n          if (ownNamespace === HTML_NAMESPACE$1) {\n            // $FlowFixMe - Should be inferred as not undefined.\n            extraAttributeNames.delete(propKey.toLowerCase());\n          } else {\n            var standardName = getPossibleStandardName(propKey);\n\n            if (standardName !== null && standardName !== propKey) {\n              // If an SVG prop is supplied with bad casing, it will\n              // be successfully parsed from HTML, but will produce a mismatch\n              // (and would be incorrectly rendered on the client).\n              // However, we already warn about bad casing elsewhere.\n              // So we'll skip the misleading extra mismatch warning in this case.\n              isMismatchDueToBadCasing = true; // $FlowFixMe - Should be inferred as not undefined.\n\n              extraAttributeNames.delete(standardName);\n            } // $FlowFixMe - Should be inferred as not undefined.\n\n\n            extraAttributeNames.delete(propKey);\n          }\n\n          serverValue = getValueForAttribute(domElement, propKey, nextProp);\n        }\n\n        if (nextProp !== serverValue && !isMismatchDueToBadCasing) {\n          warnForPropDifference(propKey, serverValue, nextProp);\n        }\n      }\n    }\n  }\n\n  {\n    // $FlowFixMe - Should be inferred as not undefined.\n    if (extraAttributeNames.size > 0 && !suppressHydrationWarning) {\n      // $FlowFixMe - Should be inferred as not undefined.\n      warnForExtraAttributes(extraAttributeNames);\n    }\n  }\n\n  switch (tag) {\n    case 'input':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper(domElement, rawProps, true);\n      break;\n\n    case 'textarea':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper$3(domElement);\n      break;\n\n    case 'select':\n    case 'option':\n      // For input and textarea we current always set the value property at\n      // post mount to force it to diverge from attributes. However, for\n      // option and select we don't quite do the same thing and select\n      // is not resilient to the DOM state changing so we don't do that here.\n      // TODO: Consider not doing this for input and textarea.\n      break;\n\n    default:\n      if (typeof rawProps.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n\n  return updatePayload;\n}\nfunction diffHydratedText(textNode, text) {\n  var isDifferent = textNode.nodeValue !== text;\n  return isDifferent;\n}\nfunction warnForUnmatchedText(textNode, text) {\n  {\n    warnForTextDifference(textNode.nodeValue, text);\n  }\n}\nfunction warnForDeletedHydratableElement(parentNode, child) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Did not expect server HTML to contain a <%s> in <%s>.', child.nodeName.toLowerCase(), parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForDeletedHydratableText(parentNode, child) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Did not expect server HTML to contain the text node \"%s\" in <%s>.', child.nodeValue, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForInsertedHydratedElement(parentNode, tag, props) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Expected server HTML to contain a matching <%s> in <%s>.', tag, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForInsertedHydratedText(parentNode, text) {\n  {\n    if (text === '') {\n      // We expect to insert empty text nodes since they're not represented in\n      // the HTML.\n      // TODO: Remove this special case if we can just avoid inserting empty\n      // text nodes.\n      return;\n    }\n\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Expected server HTML to contain a matching text node for \"%s\" in <%s>.', text, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction restoreControlledState$3(domElement, tag, props) {\n  switch (tag) {\n    case 'input':\n      restoreControlledState(domElement, props);\n      return;\n\n    case 'textarea':\n      restoreControlledState$2(domElement, props);\n      return;\n\n    case 'select':\n      restoreControlledState$1(domElement, props);\n      return;\n  }\n}\n\nvar validateDOMNesting = function () {};\n\nvar updatedAncestorInfo = function () {};\n\n{\n  // This validation code was written based on the HTML5 parsing spec:\n  // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-scope\n  //\n  // Note: this does not catch all invalid nesting, nor does it try to (as it's\n  // not clear what practical benefit doing so provides); instead, we warn only\n  // for cases where the parser will give a parse tree differing from what React\n  // intended. For example, <b><div></div></b> is invalid but we don't warn\n  // because it still parses correctly; we do warn for other cases like nested\n  // <p> tags where the beginning of the second element implicitly closes the\n  // first, causing a confusing mess.\n  // https://html.spec.whatwg.org/multipage/syntax.html#special\n  var specialTags = ['address', 'applet', 'area', 'article', 'aside', 'base', 'basefont', 'bgsound', 'blockquote', 'body', 'br', 'button', 'caption', 'center', 'col', 'colgroup', 'dd', 'details', 'dir', 'div', 'dl', 'dt', 'embed', 'fieldset', 'figcaption', 'figure', 'footer', 'form', 'frame', 'frameset', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'head', 'header', 'hgroup', 'hr', 'html', 'iframe', 'img', 'input', 'isindex', 'li', 'link', 'listing', 'main', 'marquee', 'menu', 'menuitem', 'meta', 'nav', 'noembed', 'noframes', 'noscript', 'object', 'ol', 'p', 'param', 'plaintext', 'pre', 'script', 'section', 'select', 'source', 'style', 'summary', 'table', 'tbody', 'td', 'template', 'textarea', 'tfoot', 'th', 'thead', 'title', 'tr', 'track', 'ul', 'wbr', 'xmp']; // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-scope\n\n  var inScopeTags = ['applet', 'caption', 'html', 'table', 'td', 'th', 'marquee', 'object', 'template', // https://html.spec.whatwg.org/multipage/syntax.html#html-integration-point\n  // TODO: Distinguish by namespace here -- for <title>, including it here\n  // errs on the side of fewer warnings\n  'foreignObject', 'desc', 'title']; // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-button-scope\n\n  var buttonScopeTags = inScopeTags.concat(['button']); // https://html.spec.whatwg.org/multipage/syntax.html#generate-implied-end-tags\n\n  var impliedEndTags = ['dd', 'dt', 'li', 'option', 'optgroup', 'p', 'rp', 'rt'];\n  var emptyAncestorInfo = {\n    current: null,\n    formTag: null,\n    aTagInScope: null,\n    buttonTagInScope: null,\n    nobrTagInScope: null,\n    pTagInButtonScope: null,\n    listItemTagAutoclosing: null,\n    dlItemTagAutoclosing: null\n  };\n\n  updatedAncestorInfo = function (oldInfo, tag) {\n    var ancestorInfo = _assign({}, oldInfo || emptyAncestorInfo);\n\n    var info = {\n      tag: tag\n    };\n\n    if (inScopeTags.indexOf(tag) !== -1) {\n      ancestorInfo.aTagInScope = null;\n      ancestorInfo.buttonTagInScope = null;\n      ancestorInfo.nobrTagInScope = null;\n    }\n\n    if (buttonScopeTags.indexOf(tag) !== -1) {\n      ancestorInfo.pTagInButtonScope = null;\n    } // See rules for 'li', 'dd', 'dt' start tags in\n    // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inbody\n\n\n    if (specialTags.indexOf(tag) !== -1 && tag !== 'address' && tag !== 'div' && tag !== 'p') {\n      ancestorInfo.listItemTagAutoclosing = null;\n      ancestorInfo.dlItemTagAutoclosing = null;\n    }\n\n    ancestorInfo.current = info;\n\n    if (tag === 'form') {\n      ancestorInfo.formTag = info;\n    }\n\n    if (tag === 'a') {\n      ancestorInfo.aTagInScope = info;\n    }\n\n    if (tag === 'button') {\n      ancestorInfo.buttonTagInScope = info;\n    }\n\n    if (tag === 'nobr') {\n      ancestorInfo.nobrTagInScope = info;\n    }\n\n    if (tag === 'p') {\n      ancestorInfo.pTagInButtonScope = info;\n    }\n\n    if (tag === 'li') {\n      ancestorInfo.listItemTagAutoclosing = info;\n    }\n\n    if (tag === 'dd' || tag === 'dt') {\n      ancestorInfo.dlItemTagAutoclosing = info;\n    }\n\n    return ancestorInfo;\n  };\n  /**\n   * Returns whether\n   */\n\n\n  var isTagValidWithParent = function (tag, parentTag) {\n    // First, let's check if we're in an unusual parsing mode...\n    switch (parentTag) {\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inselect\n      case 'select':\n        return tag === 'option' || tag === 'optgroup' || tag === '#text';\n\n      case 'optgroup':\n        return tag === 'option' || tag === '#text';\n      // Strictly speaking, seeing an <option> doesn't mean we're in a <select>\n      // but\n\n      case 'option':\n        return tag === '#text';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intd\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-incaption\n      // No special behavior since these rules fall back to \"in body\" mode for\n      // all except special table nodes which cause bad parsing behavior anyway.\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intr\n\n      case 'tr':\n        return tag === 'th' || tag === 'td' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intbody\n\n      case 'tbody':\n      case 'thead':\n      case 'tfoot':\n        return tag === 'tr' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-incolgroup\n\n      case 'colgroup':\n        return tag === 'col' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intable\n\n      case 'table':\n        return tag === 'caption' || tag === 'colgroup' || tag === 'tbody' || tag === 'tfoot' || tag === 'thead' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inhead\n\n      case 'head':\n        return tag === 'base' || tag === 'basefont' || tag === 'bgsound' || tag === 'link' || tag === 'meta' || tag === 'title' || tag === 'noscript' || tag === 'noframes' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/semantics.html#the-html-element\n\n      case 'html':\n        return tag === 'head' || tag === 'body' || tag === 'frameset';\n\n      case 'frameset':\n        return tag === 'frame';\n\n      case '#document':\n        return tag === 'html';\n    } // Probably in the \"in body\" parsing mode, so we outlaw only tag combos\n    // where the parsing rules cause implicit opens or closes to be added.\n    // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inbody\n\n\n    switch (tag) {\n      case 'h1':\n      case 'h2':\n      case 'h3':\n      case 'h4':\n      case 'h5':\n      case 'h6':\n        return parentTag !== 'h1' && parentTag !== 'h2' && parentTag !== 'h3' && parentTag !== 'h4' && parentTag !== 'h5' && parentTag !== 'h6';\n\n      case 'rp':\n      case 'rt':\n        return impliedEndTags.indexOf(parentTag) === -1;\n\n      case 'body':\n      case 'caption':\n      case 'col':\n      case 'colgroup':\n      case 'frameset':\n      case 'frame':\n      case 'head':\n      case 'html':\n      case 'tbody':\n      case 'td':\n      case 'tfoot':\n      case 'th':\n      case 'thead':\n      case 'tr':\n        // These tags are only valid with a few parents that have special child\n        // parsing rules -- if we're down here, then none of those matched and\n        // so we allow it only if we don't know what the parent is, as all other\n        // cases are invalid.\n        return parentTag == null;\n    }\n\n    return true;\n  };\n  /**\n   * Returns whether\n   */\n\n\n  var findInvalidAncestorForTag = function (tag, ancestorInfo) {\n    switch (tag) {\n      case 'address':\n      case 'article':\n      case 'aside':\n      case 'blockquote':\n      case 'center':\n      case 'details':\n      case 'dialog':\n      case 'dir':\n      case 'div':\n      case 'dl':\n      case 'fieldset':\n      case 'figcaption':\n      case 'figure':\n      case 'footer':\n      case 'header':\n      case 'hgroup':\n      case 'main':\n      case 'menu':\n      case 'nav':\n      case 'ol':\n      case 'p':\n      case 'section':\n      case 'summary':\n      case 'ul':\n      case 'pre':\n      case 'listing':\n      case 'table':\n      case 'hr':\n      case 'xmp':\n      case 'h1':\n      case 'h2':\n      case 'h3':\n      case 'h4':\n      case 'h5':\n      case 'h6':\n        return ancestorInfo.pTagInButtonScope;\n\n      case 'form':\n        return ancestorInfo.formTag || ancestorInfo.pTagInButtonScope;\n\n      case 'li':\n        return ancestorInfo.listItemTagAutoclosing;\n\n      case 'dd':\n      case 'dt':\n        return ancestorInfo.dlItemTagAutoclosing;\n\n      case 'button':\n        return ancestorInfo.buttonTagInScope;\n\n      case 'a':\n        // Spec says something about storing a list of markers, but it sounds\n        // equivalent to this check.\n        return ancestorInfo.aTagInScope;\n\n      case 'nobr':\n        return ancestorInfo.nobrTagInScope;\n    }\n\n    return null;\n  };\n\n  var didWarn$1 = {};\n\n  validateDOMNesting = function (childTag, childText, ancestorInfo) {\n    ancestorInfo = ancestorInfo || emptyAncestorInfo;\n    var parentInfo = ancestorInfo.current;\n    var parentTag = parentInfo && parentInfo.tag;\n\n    if (childText != null) {\n      if (childTag != null) {\n        error('validateDOMNesting: when childText is passed, childTag should be null');\n      }\n\n      childTag = '#text';\n    }\n\n    var invalidParent = isTagValidWithParent(childTag, parentTag) ? null : parentInfo;\n    var invalidAncestor = invalidParent ? null : findInvalidAncestorForTag(childTag, ancestorInfo);\n    var invalidParentOrAncestor = invalidParent || invalidAncestor;\n\n    if (!invalidParentOrAncestor) {\n      return;\n    }\n\n    var ancestorTag = invalidParentOrAncestor.tag;\n    var warnKey = !!invalidParent + '|' + childTag + '|' + ancestorTag;\n\n    if (didWarn$1[warnKey]) {\n      return;\n    }\n\n    didWarn$1[warnKey] = true;\n    var tagDisplayName = childTag;\n    var whitespaceInfo = '';\n\n    if (childTag === '#text') {\n      if (/\\S/.test(childText)) {\n        tagDisplayName = 'Text nodes';\n      } else {\n        tagDisplayName = 'Whitespace text nodes';\n        whitespaceInfo = \" Make sure you don't have any extra whitespace between tags on \" + 'each line of your source code.';\n      }\n    } else {\n      tagDisplayName = '<' + childTag + '>';\n    }\n\n    if (invalidParent) {\n      var info = '';\n\n      if (ancestorTag === 'table' && childTag === 'tr') {\n        info += ' Add a <tbody>, <thead> or <tfoot> to your code to match the DOM tree generated by ' + 'the browser.';\n      }\n\n      error('validateDOMNesting(...): %s cannot appear as a child of <%s>.%s%s', tagDisplayName, ancestorTag, whitespaceInfo, info);\n    } else {\n      error('validateDOMNesting(...): %s cannot appear as a descendant of ' + '<%s>.', tagDisplayName, ancestorTag);\n    }\n  };\n}\n\nvar SUPPRESS_HYDRATION_WARNING$1;\n\n{\n  SUPPRESS_HYDRATION_WARNING$1 = 'suppressHydrationWarning';\n}\n\nvar SUSPENSE_START_DATA = '$';\nvar SUSPENSE_END_DATA = '/$';\nvar SUSPENSE_PENDING_START_DATA = '$?';\nvar SUSPENSE_FALLBACK_START_DATA = '$!';\nvar STYLE$1 = 'style';\nvar eventsEnabled = null;\nvar selectionInformation = null;\n\nfunction shouldAutoFocusHostComponent(type, props) {\n  switch (type) {\n    case 'button':\n    case 'input':\n    case 'select':\n    case 'textarea':\n      return !!props.autoFocus;\n  }\n\n  return false;\n}\nfunction getRootHostContext(rootContainerInstance) {\n  var type;\n  var namespace;\n  var nodeType = rootContainerInstance.nodeType;\n\n  switch (nodeType) {\n    case DOCUMENT_NODE:\n    case DOCUMENT_FRAGMENT_NODE:\n      {\n        type = nodeType === DOCUMENT_NODE ? '#document' : '#fragment';\n        var root = rootContainerInstance.documentElement;\n        namespace = root ? root.namespaceURI : getChildNamespace(null, '');\n        break;\n      }\n\n    default:\n      {\n        var container = nodeType === COMMENT_NODE ? rootContainerInstance.parentNode : rootContainerInstance;\n        var ownNamespace = container.namespaceURI || null;\n        type = container.tagName;\n        namespace = getChildNamespace(ownNamespace, type);\n        break;\n      }\n  }\n\n  {\n    var validatedTag = type.toLowerCase();\n    var ancestorInfo = updatedAncestorInfo(null, validatedTag);\n    return {\n      namespace: namespace,\n      ancestorInfo: ancestorInfo\n    };\n  }\n}\nfunction getChildHostContext(parentHostContext, type, rootContainerInstance) {\n  {\n    var parentHostContextDev = parentHostContext;\n    var namespace = getChildNamespace(parentHostContextDev.namespace, type);\n    var ancestorInfo = updatedAncestorInfo(parentHostContextDev.ancestorInfo, type);\n    return {\n      namespace: namespace,\n      ancestorInfo: ancestorInfo\n    };\n  }\n}\nfunction getPublicInstance(instance) {\n  return instance;\n}\nfunction prepareForCommit(containerInfo) {\n  eventsEnabled = isEnabled();\n  selectionInformation = getSelectionInformation();\n  var activeInstance = null;\n\n  setEnabled(false);\n  return activeInstance;\n}\nfunction resetAfterCommit(containerInfo) {\n  restoreSelection(selectionInformation);\n  setEnabled(eventsEnabled);\n  eventsEnabled = null;\n  selectionInformation = null;\n}\nfunction createInstance(type, props, rootContainerInstance, hostContext, internalInstanceHandle) {\n  var parentNamespace;\n\n  {\n    // TODO: take namespace into account when validating.\n    var hostContextDev = hostContext;\n    validateDOMNesting(type, null, hostContextDev.ancestorInfo);\n\n    if (typeof props.children === 'string' || typeof props.children === 'number') {\n      var string = '' + props.children;\n      var ownAncestorInfo = updatedAncestorInfo(hostContextDev.ancestorInfo, type);\n      validateDOMNesting(null, string, ownAncestorInfo);\n    }\n\n    parentNamespace = hostContextDev.namespace;\n  }\n\n  var domElement = createElement(type, props, rootContainerInstance, parentNamespace);\n  precacheFiberNode(internalInstanceHandle, domElement);\n  updateFiberProps(domElement, props);\n  return domElement;\n}\nfunction appendInitialChild(parentInstance, child) {\n  parentInstance.appendChild(child);\n}\nfunction finalizeInitialChildren(domElement, type, props, rootContainerInstance, hostContext) {\n  setInitialProperties(domElement, type, props, rootContainerInstance);\n  return shouldAutoFocusHostComponent(type, props);\n}\nfunction prepareUpdate(domElement, type, oldProps, newProps, rootContainerInstance, hostContext) {\n  {\n    var hostContextDev = hostContext;\n\n    if (typeof newProps.children !== typeof oldProps.children && (typeof newProps.children === 'string' || typeof newProps.children === 'number')) {\n      var string = '' + newProps.children;\n      var ownAncestorInfo = updatedAncestorInfo(hostContextDev.ancestorInfo, type);\n      validateDOMNesting(null, string, ownAncestorInfo);\n    }\n  }\n\n  return diffProperties(domElement, type, oldProps, newProps);\n}\nfunction shouldSetTextContent(type, props) {\n  return type === 'textarea' || type === 'option' || type === 'noscript' || typeof props.children === 'string' || typeof props.children === 'number' || typeof props.dangerouslySetInnerHTML === 'object' && props.dangerouslySetInnerHTML !== null && props.dangerouslySetInnerHTML.__html != null;\n}\nfunction createTextInstance(text, rootContainerInstance, hostContext, internalInstanceHandle) {\n  {\n    var hostContextDev = hostContext;\n    validateDOMNesting(null, text, hostContextDev.ancestorInfo);\n  }\n\n  var textNode = createTextNode(text, rootContainerInstance);\n  precacheFiberNode(internalInstanceHandle, textNode);\n  return textNode;\n}\n// if a component just imports ReactDOM (e.g. for findDOMNode).\n// Some environments might not have setTimeout or clearTimeout.\n\nvar scheduleTimeout = typeof setTimeout === 'function' ? setTimeout : undefined;\nvar cancelTimeout = typeof clearTimeout === 'function' ? clearTimeout : undefined;\nvar noTimeout = -1; // -------------------\nfunction commitMount(domElement, type, newProps, internalInstanceHandle) {\n  // Despite the naming that might imply otherwise, this method only\n  // fires if there is an `Update` effect scheduled during mounting.\n  // This happens if `finalizeInitialChildren` returns `true` (which it\n  // does to implement the `autoFocus` attribute on the client). But\n  // there are also other cases when this might happen (such as patching\n  // up text content during hydration mismatch). So we'll check this again.\n  if (shouldAutoFocusHostComponent(type, newProps)) {\n    domElement.focus();\n  }\n}\nfunction commitUpdate(domElement, updatePayload, type, oldProps, newProps, internalInstanceHandle) {\n  // Update the props handle so that we know which props are the ones with\n  // with current event handlers.\n  updateFiberProps(domElement, newProps); // Apply the diff to the DOM node.\n\n  updateProperties(domElement, updatePayload, type, oldProps, newProps);\n}\nfunction resetTextContent(domElement) {\n  setTextContent(domElement, '');\n}\nfunction commitTextUpdate(textInstance, oldText, newText) {\n  textInstance.nodeValue = newText;\n}\nfunction appendChild(parentInstance, child) {\n  parentInstance.appendChild(child);\n}\nfunction appendChildToContainer(container, child) {\n  var parentNode;\n\n  if (container.nodeType === COMMENT_NODE) {\n    parentNode = container.parentNode;\n    parentNode.insertBefore(child, container);\n  } else {\n    parentNode = container;\n    parentNode.appendChild(child);\n  } // This container might be used for a portal.\n  // If something inside a portal is clicked, that click should bubble\n  // through the React tree. However, on Mobile Safari the click would\n  // never bubble through the *DOM* tree unless an ancestor with onclick\n  // event exists. So we wouldn't see it and dispatch it.\n  // This is why we ensure that non React root containers have inline onclick\n  // defined.\n  // https://github.com/facebook/react/issues/11918\n\n\n  var reactRootContainer = container._reactRootContainer;\n\n  if ((reactRootContainer === null || reactRootContainer === undefined) && parentNode.onclick === null) {\n    // TODO: This cast may not be sound for SVG, MathML or custom elements.\n    trapClickOnNonInteractiveElement(parentNode);\n  }\n}\nfunction insertBefore(parentInstance, child, beforeChild) {\n  parentInstance.insertBefore(child, beforeChild);\n}\nfunction insertInContainerBefore(container, child, beforeChild) {\n  if (container.nodeType === COMMENT_NODE) {\n    container.parentNode.insertBefore(child, beforeChild);\n  } else {\n    container.insertBefore(child, beforeChild);\n  }\n}\n\nfunction removeChild(parentInstance, child) {\n  parentInstance.removeChild(child);\n}\nfunction removeChildFromContainer(container, child) {\n  if (container.nodeType === COMMENT_NODE) {\n    container.parentNode.removeChild(child);\n  } else {\n    container.removeChild(child);\n  }\n}\nfunction hideInstance(instance) {\n  // TODO: Does this work for all element types? What about MathML? Should we\n  // pass host context to this method?\n  instance = instance;\n  var style = instance.style;\n\n  if (typeof style.setProperty === 'function') {\n    style.setProperty('display', 'none', 'important');\n  } else {\n    style.display = 'none';\n  }\n}\nfunction hideTextInstance(textInstance) {\n  textInstance.nodeValue = '';\n}\nfunction unhideInstance(instance, props) {\n  instance = instance;\n  var styleProp = props[STYLE$1];\n  var display = styleProp !== undefined && styleProp !== null && styleProp.hasOwnProperty('display') ? styleProp.display : null;\n  instance.style.display = dangerousStyleValue('display', display);\n}\nfunction unhideTextInstance(textInstance, text) {\n  textInstance.nodeValue = text;\n}\nfunction clearContainer(container) {\n  if (container.nodeType === ELEMENT_NODE) {\n    container.textContent = '';\n  } else if (container.nodeType === DOCUMENT_NODE) {\n    var body = container.body;\n\n    if (body != null) {\n      body.textContent = '';\n    }\n  }\n} // -------------------\nfunction canHydrateInstance(instance, type, props) {\n  if (instance.nodeType !== ELEMENT_NODE || type.toLowerCase() !== instance.nodeName.toLowerCase()) {\n    return null;\n  } // This has now been refined to an element node.\n\n\n  return instance;\n}\nfunction canHydrateTextInstance(instance, text) {\n  if (text === '' || instance.nodeType !== TEXT_NODE) {\n    // Empty strings are not parsed by HTML so there won't be a correct match here.\n    return null;\n  } // This has now been refined to a text node.\n\n\n  return instance;\n}\nfunction isSuspenseInstancePending(instance) {\n  return instance.data === SUSPENSE_PENDING_START_DATA;\n}\nfunction isSuspenseInstanceFallback(instance) {\n  return instance.data === SUSPENSE_FALLBACK_START_DATA;\n}\n\nfunction getNextHydratable(node) {\n  // Skip non-hydratable nodes.\n  for (; node != null; node = node.nextSibling) {\n    var nodeType = node.nodeType;\n\n    if (nodeType === ELEMENT_NODE || nodeType === TEXT_NODE) {\n      break;\n    }\n  }\n\n  return node;\n}\n\nfunction getNextHydratableSibling(instance) {\n  return getNextHydratable(instance.nextSibling);\n}\nfunction getFirstHydratableChild(parentInstance) {\n  return getNextHydratable(parentInstance.firstChild);\n}\nfunction hydrateInstance(instance, type, props, rootContainerInstance, hostContext, internalInstanceHandle) {\n  precacheFiberNode(internalInstanceHandle, instance); // TODO: Possibly defer this until the commit phase where all the events\n  // get attached.\n\n  updateFiberProps(instance, props);\n  var parentNamespace;\n\n  {\n    var hostContextDev = hostContext;\n    parentNamespace = hostContextDev.namespace;\n  }\n\n  return diffHydratedProperties(instance, type, props, parentNamespace);\n}\nfunction hydrateTextInstance(textInstance, text, internalInstanceHandle) {\n  precacheFiberNode(internalInstanceHandle, textInstance);\n  return diffHydratedText(textInstance, text);\n}\nfunction getNextHydratableInstanceAfterSuspenseInstance(suspenseInstance) {\n  var node = suspenseInstance.nextSibling; // Skip past all nodes within this suspense boundary.\n  // There might be nested nodes so we need to keep track of how\n  // deep we are and only break out when we're back on top.\n\n  var depth = 0;\n\n  while (node) {\n    if (node.nodeType === COMMENT_NODE) {\n      var data = node.data;\n\n      if (data === SUSPENSE_END_DATA) {\n        if (depth === 0) {\n          return getNextHydratableSibling(node);\n        } else {\n          depth--;\n        }\n      } else if (data === SUSPENSE_START_DATA || data === SUSPENSE_FALLBACK_START_DATA || data === SUSPENSE_PENDING_START_DATA) {\n        depth++;\n      }\n    }\n\n    node = node.nextSibling;\n  } // TODO: Warn, we didn't find the end comment boundary.\n\n\n  return null;\n} // Returns the SuspenseInstance if this node is a direct child of a\n// SuspenseInstance. I.e. if its previous sibling is a Comment with\n// SUSPENSE_x_START_DATA. Otherwise, null.\n\nfunction getParentSuspenseInstance(targetInstance) {\n  var node = targetInstance.previousSibling; // Skip past all nodes within this suspense boundary.\n  // There might be nested nodes so we need to keep track of how\n  // deep we are and only break out when we're back on top.\n\n  var depth = 0;\n\n  while (node) {\n    if (node.nodeType === COMMENT_NODE) {\n      var data = node.data;\n\n      if (data === SUSPENSE_START_DATA || data === SUSPENSE_FALLBACK_START_DATA || data === SUSPENSE_PENDING_START_DATA) {\n        if (depth === 0) {\n          return node;\n        } else {\n          depth--;\n        }\n      } else if (data === SUSPENSE_END_DATA) {\n        depth++;\n      }\n    }\n\n    node = node.previousSibling;\n  }\n\n  return null;\n}\nfunction commitHydratedContainer(container) {\n  // Retry if any event replaying was blocked on this.\n  retryIfBlockedOn(container);\n}\nfunction commitHydratedSuspenseInstance(suspenseInstance) {\n  // Retry if any event replaying was blocked on this.\n  retryIfBlockedOn(suspenseInstance);\n}\nfunction didNotMatchHydratedContainerTextInstance(parentContainer, textInstance, text) {\n  {\n    warnForUnmatchedText(textInstance, text);\n  }\n}\nfunction didNotMatchHydratedTextInstance(parentType, parentProps, parentInstance, textInstance, text) {\n  if ( parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n    warnForUnmatchedText(textInstance, text);\n  }\n}\nfunction didNotHydrateContainerInstance(parentContainer, instance) {\n  {\n    if (instance.nodeType === ELEMENT_NODE) {\n      warnForDeletedHydratableElement(parentContainer, instance);\n    } else if (instance.nodeType === COMMENT_NODE) ; else {\n      warnForDeletedHydratableText(parentContainer, instance);\n    }\n  }\n}\nfunction didNotHydrateInstance(parentType, parentProps, parentInstance, instance) {\n  if ( parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n    if (instance.nodeType === ELEMENT_NODE) {\n      warnForDeletedHydratableElement(parentInstance, instance);\n    } else if (instance.nodeType === COMMENT_NODE) ; else {\n      warnForDeletedHydratableText(parentInstance, instance);\n    }\n  }\n}\nfunction didNotFindHydratableContainerInstance(parentContainer, type, props) {\n  {\n    warnForInsertedHydratedElement(parentContainer, type);\n  }\n}\nfunction didNotFindHydratableContainerTextInstance(parentContainer, text) {\n  {\n    warnForInsertedHydratedText(parentContainer, text);\n  }\n}\nfunction didNotFindHydratableInstance(parentType, parentProps, parentInstance, type, props) {\n  if ( parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n    warnForInsertedHydratedElement(parentInstance, type);\n  }\n}\nfunction didNotFindHydratableTextInstance(parentType, parentProps, parentInstance, text) {\n  if ( parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n    warnForInsertedHydratedText(parentInstance, text);\n  }\n}\nfunction didNotFindHydratableSuspenseInstance(parentType, parentProps, parentInstance) {\n  if ( parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) ;\n}\nvar clientId = 0;\nfunction makeClientIdInDEV(warnOnAccessInDEV) {\n  var id = 'r:' + (clientId++).toString(36);\n  return {\n    toString: function () {\n      warnOnAccessInDEV();\n      return id;\n    },\n    valueOf: function () {\n      warnOnAccessInDEV();\n      return id;\n    }\n  };\n}\nfunction isOpaqueHydratingObject(value) {\n  return value !== null && typeof value === 'object' && value.$$typeof === REACT_OPAQUE_ID_TYPE;\n}\nfunction makeOpaqueHydratingObject(attemptToReadValue) {\n  return {\n    $$typeof: REACT_OPAQUE_ID_TYPE,\n    toString: attemptToReadValue,\n    valueOf: attemptToReadValue\n  };\n}\nfunction preparePortalMount(portalInstance) {\n  {\n    listenToAllSupportedEvents(portalInstance);\n  }\n}\n\nvar randomKey = Math.random().toString(36).slice(2);\nvar internalInstanceKey = '__reactFiber$' + randomKey;\nvar internalPropsKey = '__reactProps$' + randomKey;\nvar internalContainerInstanceKey = '__reactContainer$' + randomKey;\nvar internalEventHandlersKey = '__reactEvents$' + randomKey;\nfunction precacheFiberNode(hostInst, node) {\n  node[internalInstanceKey] = hostInst;\n}\nfunction markContainerAsRoot(hostRoot, node) {\n  node[internalContainerInstanceKey] = hostRoot;\n}\nfunction unmarkContainerAsRoot(node) {\n  node[internalContainerInstanceKey] = null;\n}\nfunction isContainerMarkedAsRoot(node) {\n  return !!node[internalContainerInstanceKey];\n} // Given a DOM node, return the closest HostComponent or HostText fiber ancestor.\n// If the target node is part of a hydrated or not yet rendered subtree, then\n// this may also return a SuspenseComponent or HostRoot to indicate that.\n// Conceptually the HostRoot fiber is a child of the Container node. So if you\n// pass the Container node as the targetNode, you will not actually get the\n// HostRoot back. To get to the HostRoot, you need to pass a child of it.\n// The same thing applies to Suspense boundaries.\n\nfunction getClosestInstanceFromNode(targetNode) {\n  var targetInst = targetNode[internalInstanceKey];\n\n  if (targetInst) {\n    // Don't return HostRoot or SuspenseComponent here.\n    return targetInst;\n  } // If the direct event target isn't a React owned DOM node, we need to look\n  // to see if one of its parents is a React owned DOM node.\n\n\n  var parentNode = targetNode.parentNode;\n\n  while (parentNode) {\n    // We'll check if this is a container root that could include\n    // React nodes in the future. We need to check this first because\n    // if we're a child of a dehydrated container, we need to first\n    // find that inner container before moving on to finding the parent\n    // instance. Note that we don't check this field on  the targetNode\n    // itself because the fibers are conceptually between the container\n    // node and the first child. It isn't surrounding the container node.\n    // If it's not a container, we check if it's an instance.\n    targetInst = parentNode[internalContainerInstanceKey] || parentNode[internalInstanceKey];\n\n    if (targetInst) {\n      // Since this wasn't the direct target of the event, we might have\n      // stepped past dehydrated DOM nodes to get here. However they could\n      // also have been non-React nodes. We need to answer which one.\n      // If we the instance doesn't have any children, then there can't be\n      // a nested suspense boundary within it. So we can use this as a fast\n      // bailout. Most of the time, when people add non-React children to\n      // the tree, it is using a ref to a child-less DOM node.\n      // Normally we'd only need to check one of the fibers because if it\n      // has ever gone from having children to deleting them or vice versa\n      // it would have deleted the dehydrated boundary nested inside already.\n      // However, since the HostRoot starts out with an alternate it might\n      // have one on the alternate so we need to check in case this was a\n      // root.\n      var alternate = targetInst.alternate;\n\n      if (targetInst.child !== null || alternate !== null && alternate.child !== null) {\n        // Next we need to figure out if the node that skipped past is\n        // nested within a dehydrated boundary and if so, which one.\n        var suspenseInstance = getParentSuspenseInstance(targetNode);\n\n        while (suspenseInstance !== null) {\n          // We found a suspense instance. That means that we haven't\n          // hydrated it yet. Even though we leave the comments in the\n          // DOM after hydrating, and there are boundaries in the DOM\n          // that could already be hydrated, we wouldn't have found them\n          // through this pass since if the target is hydrated it would\n          // have had an internalInstanceKey on it.\n          // Let's get the fiber associated with the SuspenseComponent\n          // as the deepest instance.\n          var targetSuspenseInst = suspenseInstance[internalInstanceKey];\n\n          if (targetSuspenseInst) {\n            return targetSuspenseInst;\n          } // If we don't find a Fiber on the comment, it might be because\n          // we haven't gotten to hydrate it yet. There might still be a\n          // parent boundary that hasn't above this one so we need to find\n          // the outer most that is known.\n\n\n          suspenseInstance = getParentSuspenseInstance(suspenseInstance); // If we don't find one, then that should mean that the parent\n          // host component also hasn't hydrated yet. We can return it\n          // below since it will bail out on the isMounted check later.\n        }\n      }\n\n      return targetInst;\n    }\n\n    targetNode = parentNode;\n    parentNode = targetNode.parentNode;\n  }\n\n  return null;\n}\n/**\n * Given a DOM node, return the ReactDOMComponent or ReactDOMTextComponent\n * instance, or null if the node was not rendered by this React.\n */\n\nfunction getInstanceFromNode(node) {\n  var inst = node[internalInstanceKey] || node[internalContainerInstanceKey];\n\n  if (inst) {\n    if (inst.tag === HostComponent || inst.tag === HostText || inst.tag === SuspenseComponent || inst.tag === HostRoot) {\n      return inst;\n    } else {\n      return null;\n    }\n  }\n\n  return null;\n}\n/**\n * Given a ReactDOMComponent or ReactDOMTextComponent, return the corresponding\n * DOM node.\n */\n\nfunction getNodeFromInstance(inst) {\n  if (inst.tag === HostComponent || inst.tag === HostText) {\n    // In Fiber this, is just the state node right now. We assume it will be\n    // a host component or host text.\n    return inst.stateNode;\n  } // Without this first invariant, passing a non-DOM-component triggers the next\n  // invariant for a missing parent, which is super confusing.\n\n\n  {\n    {\n      throw Error( \"getNodeFromInstance: Invalid argument.\" );\n    }\n  }\n}\nfunction getFiberCurrentPropsFromNode(node) {\n  return node[internalPropsKey] || null;\n}\nfunction updateFiberProps(node, props) {\n  node[internalPropsKey] = props;\n}\nfunction getEventListenerSet(node) {\n  var elementListenerSet = node[internalEventHandlersKey];\n\n  if (elementListenerSet === undefined) {\n    elementListenerSet = node[internalEventHandlersKey] = new Set();\n  }\n\n  return elementListenerSet;\n}\n\nvar loggedTypeFailures = {};\nvar ReactDebugCurrentFrame$1 = ReactSharedInternals.ReactDebugCurrentFrame;\n\nfunction setCurrentlyValidatingElement(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      ReactDebugCurrentFrame$1.setExtraStackFrame(stack);\n    } else {\n      ReactDebugCurrentFrame$1.setExtraStackFrame(null);\n    }\n  }\n}\n\nfunction checkPropTypes(typeSpecs, values, location, componentName, element) {\n  {\n    // $FlowFixMe This is okay but Flow doesn't know it.\n    var has = Function.call.bind(Object.prototype.hasOwnProperty);\n\n    for (var typeSpecName in typeSpecs) {\n      if (has(typeSpecs, typeSpecName)) {\n        var error$1 = void 0; // Prop type validation may throw. In case they do, we don't want to\n        // fail the render phase where it didn't fail before. So we log it.\n        // After these have been cleaned up, we'll let them throw.\n\n        try {\n          // This is intentionally an invariant that gets caught. It's the same\n          // behavior as without this statement except with a better message.\n          if (typeof typeSpecs[typeSpecName] !== 'function') {\n            var err = Error((componentName || 'React class') + ': ' + location + ' type `' + typeSpecName + '` is invalid; ' + 'it must be a function, usually from the `prop-types` package, but received `' + typeof typeSpecs[typeSpecName] + '`.' + 'This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.');\n            err.name = 'Invariant Violation';\n            throw err;\n          }\n\n          error$1 = typeSpecs[typeSpecName](values, typeSpecName, componentName, location, null, 'SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED');\n        } catch (ex) {\n          error$1 = ex;\n        }\n\n        if (error$1 && !(error$1 instanceof Error)) {\n          setCurrentlyValidatingElement(element);\n\n          error('%s: type specification of %s' + ' `%s` is invalid; the type checker ' + 'function must return `null` or an `Error` but returned a %s. ' + 'You may have forgotten to pass an argument to the type checker ' + 'creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and ' + 'shape all require an argument).', componentName || 'React class', location, typeSpecName, typeof error$1);\n\n          setCurrentlyValidatingElement(null);\n        }\n\n        if (error$1 instanceof Error && !(error$1.message in loggedTypeFailures)) {\n          // Only monitor this failure once because there tends to be a lot of the\n          // same error.\n          loggedTypeFailures[error$1.message] = true;\n          setCurrentlyValidatingElement(element);\n\n          error('Failed %s type: %s', location, error$1.message);\n\n          setCurrentlyValidatingElement(null);\n        }\n      }\n    }\n  }\n}\n\nvar valueStack = [];\nvar fiberStack;\n\n{\n  fiberStack = [];\n}\n\nvar index = -1;\n\nfunction createCursor(defaultValue) {\n  return {\n    current: defaultValue\n  };\n}\n\nfunction pop(cursor, fiber) {\n  if (index < 0) {\n    {\n      error('Unexpected pop.');\n    }\n\n    return;\n  }\n\n  {\n    if (fiber !== fiberStack[index]) {\n      error('Unexpected Fiber popped.');\n    }\n  }\n\n  cursor.current = valueStack[index];\n  valueStack[index] = null;\n\n  {\n    fiberStack[index] = null;\n  }\n\n  index--;\n}\n\nfunction push(cursor, value, fiber) {\n  index++;\n  valueStack[index] = cursor.current;\n\n  {\n    fiberStack[index] = fiber;\n  }\n\n  cursor.current = value;\n}\n\nvar warnedAboutMissingGetChildContext;\n\n{\n  warnedAboutMissingGetChildContext = {};\n}\n\nvar emptyContextObject = {};\n\n{\n  Object.freeze(emptyContextObject);\n} // A cursor to the current merged context object on the stack.\n\n\nvar contextStackCursor = createCursor(emptyContextObject); // A cursor to a boolean indicating whether the context has changed.\n\nvar didPerformWorkStackCursor = createCursor(false); // Keep track of the previous context object that was on the stack.\n// We use this to get access to the parent context after we have already\n// pushed the next context provider, and now need to merge their contexts.\n\nvar previousContext = emptyContextObject;\n\nfunction getUnmaskedContext(workInProgress, Component, didPushOwnContextIfProvider) {\n  {\n    if (didPushOwnContextIfProvider && isContextProvider(Component)) {\n      // If the fiber is a context provider itself, when we read its context\n      // we may have already pushed its own child context on the stack. A context\n      // provider should not \"see\" its own child context. Therefore we read the\n      // previous (parent) context instead for a context provider.\n      return previousContext;\n    }\n\n    return contextStackCursor.current;\n  }\n}\n\nfunction cacheContext(workInProgress, unmaskedContext, maskedContext) {\n  {\n    var instance = workInProgress.stateNode;\n    instance.__reactInternalMemoizedUnmaskedChildContext = unmaskedContext;\n    instance.__reactInternalMemoizedMaskedChildContext = maskedContext;\n  }\n}\n\nfunction getMaskedContext(workInProgress, unmaskedContext) {\n  {\n    var type = workInProgress.type;\n    var contextTypes = type.contextTypes;\n\n    if (!contextTypes) {\n      return emptyContextObject;\n    } // Avoid recreating masked context unless unmasked context has changed.\n    // Failing to do this will result in unnecessary calls to componentWillReceiveProps.\n    // This may trigger infinite loops if componentWillReceiveProps calls setState.\n\n\n    var instance = workInProgress.stateNode;\n\n    if (instance && instance.__reactInternalMemoizedUnmaskedChildContext === unmaskedContext) {\n      return instance.__reactInternalMemoizedMaskedChildContext;\n    }\n\n    var context = {};\n\n    for (var key in contextTypes) {\n      context[key] = unmaskedContext[key];\n    }\n\n    {\n      var name = getComponentName(type) || 'Unknown';\n      checkPropTypes(contextTypes, context, 'context', name);\n    } // Cache unmasked context so we can avoid recreating masked context unless necessary.\n    // Context is created before the class component is instantiated so check for instance.\n\n\n    if (instance) {\n      cacheContext(workInProgress, unmaskedContext, context);\n    }\n\n    return context;\n  }\n}\n\nfunction hasContextChanged() {\n  {\n    return didPerformWorkStackCursor.current;\n  }\n}\n\nfunction isContextProvider(type) {\n  {\n    var childContextTypes = type.childContextTypes;\n    return childContextTypes !== null && childContextTypes !== undefined;\n  }\n}\n\nfunction popContext(fiber) {\n  {\n    pop(didPerformWorkStackCursor, fiber);\n    pop(contextStackCursor, fiber);\n  }\n}\n\nfunction popTopLevelContextObject(fiber) {\n  {\n    pop(didPerformWorkStackCursor, fiber);\n    pop(contextStackCursor, fiber);\n  }\n}\n\nfunction pushTopLevelContextObject(fiber, context, didChange) {\n  {\n    if (!(contextStackCursor.current === emptyContextObject)) {\n      {\n        throw Error( \"Unexpected context found on stack. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n\n    push(contextStackCursor, context, fiber);\n    push(didPerformWorkStackCursor, didChange, fiber);\n  }\n}\n\nfunction processChildContext(fiber, type, parentContext) {\n  {\n    var instance = fiber.stateNode;\n    var childContextTypes = type.childContextTypes; // TODO (bvaughn) Replace this behavior with an invariant() in the future.\n    // It has only been added in Fiber to match the (unintentional) behavior in Stack.\n\n    if (typeof instance.getChildContext !== 'function') {\n      {\n        var componentName = getComponentName(type) || 'Unknown';\n\n        if (!warnedAboutMissingGetChildContext[componentName]) {\n          warnedAboutMissingGetChildContext[componentName] = true;\n\n          error('%s.childContextTypes is specified but there is no getChildContext() method ' + 'on the instance. You can either define getChildContext() on %s or remove ' + 'childContextTypes from it.', componentName, componentName);\n        }\n      }\n\n      return parentContext;\n    }\n\n    var childContext = instance.getChildContext();\n\n    for (var contextKey in childContext) {\n      if (!(contextKey in childContextTypes)) {\n        {\n          throw Error( (getComponentName(type) || 'Unknown') + \".getChildContext(): key \\\"\" + contextKey + \"\\\" is not defined in childContextTypes.\" );\n        }\n      }\n    }\n\n    {\n      var name = getComponentName(type) || 'Unknown';\n      checkPropTypes(childContextTypes, childContext, 'child context', name);\n    }\n\n    return _assign({}, parentContext, childContext);\n  }\n}\n\nfunction pushContextProvider(workInProgress) {\n  {\n    var instance = workInProgress.stateNode; // We push the context as early as possible to ensure stack integrity.\n    // If the instance does not exist yet, we will push null at first,\n    // and replace it on the stack later when invalidating the context.\n\n    var memoizedMergedChildContext = instance && instance.__reactInternalMemoizedMergedChildContext || emptyContextObject; // Remember the parent context so we can merge with it later.\n    // Inherit the parent's did-perform-work value to avoid inadvertently blocking updates.\n\n    previousContext = contextStackCursor.current;\n    push(contextStackCursor, memoizedMergedChildContext, workInProgress);\n    push(didPerformWorkStackCursor, didPerformWorkStackCursor.current, workInProgress);\n    return true;\n  }\n}\n\nfunction invalidateContextProvider(workInProgress, type, didChange) {\n  {\n    var instance = workInProgress.stateNode;\n\n    if (!instance) {\n      {\n        throw Error( \"Expected to have an instance by this point. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n\n    if (didChange) {\n      // Merge parent and own context.\n      // Skip this if we're not updating due to sCU.\n      // This avoids unnecessarily recomputing memoized values.\n      var mergedContext = processChildContext(workInProgress, type, previousContext);\n      instance.__reactInternalMemoizedMergedChildContext = mergedContext; // Replace the old (or empty) context with the new one.\n      // It is important to unwind the context in the reverse order.\n\n      pop(didPerformWorkStackCursor, workInProgress);\n      pop(contextStackCursor, workInProgress); // Now push the new context and mark that it has changed.\n\n      push(contextStackCursor, mergedContext, workInProgress);\n      push(didPerformWorkStackCursor, didChange, workInProgress);\n    } else {\n      pop(didPerformWorkStackCursor, workInProgress);\n      push(didPerformWorkStackCursor, didChange, workInProgress);\n    }\n  }\n}\n\nfunction findCurrentUnmaskedContext(fiber) {\n  {\n    // Currently this is only used with renderSubtreeIntoContainer; not sure if it\n    // makes sense elsewhere\n    if (!(isFiberMounted(fiber) && fiber.tag === ClassComponent)) {\n      {\n        throw Error( \"Expected subtree parent to be a mounted class component. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n\n    var node = fiber;\n\n    do {\n      switch (node.tag) {\n        case HostRoot:\n          return node.stateNode.context;\n\n        case ClassComponent:\n          {\n            var Component = node.type;\n\n            if (isContextProvider(Component)) {\n              return node.stateNode.__reactInternalMemoizedMergedChildContext;\n            }\n\n            break;\n          }\n      }\n\n      node = node.return;\n    } while (node !== null);\n\n    {\n      {\n        throw Error( \"Found unexpected detached subtree parent. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n  }\n}\n\nvar LegacyRoot = 0;\nvar BlockingRoot = 1;\nvar ConcurrentRoot = 2;\n\nvar rendererID = null;\nvar injectedHook = null;\nvar hasLoggedError = false;\nvar isDevToolsPresent = typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined';\nfunction injectInternals(internals) {\n  if (typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ === 'undefined') {\n    // No DevTools\n    return false;\n  }\n\n  var hook = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n\n  if (hook.isDisabled) {\n    // This isn't a real property on the hook, but it can be set to opt out\n    // of DevTools integration and associated warnings and logs.\n    // https://github.com/facebook/react/issues/3877\n    return true;\n  }\n\n  if (!hook.supportsFiber) {\n    {\n      error('The installed version of React DevTools is too old and will not work ' + 'with the current version of React. Please update React DevTools. ' + 'https://reactjs.org/link/react-devtools');\n    } // DevTools exists, even though it doesn't support Fiber.\n\n\n    return true;\n  }\n\n  try {\n    rendererID = hook.inject(internals); // We have successfully injected, so now it is safe to set up hooks.\n\n    injectedHook = hook;\n  } catch (err) {\n    // Catch all errors because it is unsafe to throw during initialization.\n    {\n      error('React instrumentation encountered an error: %s.', err);\n    }\n  } // DevTools exists\n\n\n  return true;\n}\nfunction onScheduleRoot(root, children) {\n  {\n    if (injectedHook && typeof injectedHook.onScheduleFiberRoot === 'function') {\n      try {\n        injectedHook.onScheduleFiberRoot(rendererID, root, children);\n      } catch (err) {\n        if ( !hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction onCommitRoot(root, priorityLevel) {\n  if (injectedHook && typeof injectedHook.onCommitFiberRoot === 'function') {\n    try {\n      var didError = (root.current.flags & DidCapture) === DidCapture;\n\n      if (enableProfilerTimer) {\n        injectedHook.onCommitFiberRoot(rendererID, root, priorityLevel, didError);\n      } else {\n        injectedHook.onCommitFiberRoot(rendererID, root, undefined, didError);\n      }\n    } catch (err) {\n      {\n        if (!hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction onCommitUnmount(fiber) {\n  if (injectedHook && typeof injectedHook.onCommitFiberUnmount === 'function') {\n    try {\n      injectedHook.onCommitFiberUnmount(rendererID, fiber);\n    } catch (err) {\n      {\n        if (!hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\n\nvar Scheduler_runWithPriority = Scheduler.unstable_runWithPriority,\n    Scheduler_scheduleCallback = Scheduler.unstable_scheduleCallback,\n    Scheduler_cancelCallback = Scheduler.unstable_cancelCallback,\n    Scheduler_shouldYield = Scheduler.unstable_shouldYield,\n    Scheduler_requestPaint = Scheduler.unstable_requestPaint,\n    Scheduler_now$1 = Scheduler.unstable_now,\n    Scheduler_getCurrentPriorityLevel = Scheduler.unstable_getCurrentPriorityLevel,\n    Scheduler_ImmediatePriority = Scheduler.unstable_ImmediatePriority,\n    Scheduler_UserBlockingPriority = Scheduler.unstable_UserBlockingPriority,\n    Scheduler_NormalPriority = Scheduler.unstable_NormalPriority,\n    Scheduler_LowPriority = Scheduler.unstable_LowPriority,\n    Scheduler_IdlePriority = Scheduler.unstable_IdlePriority;\n\n{\n  // Provide explicit error message when production+profiling bundle of e.g.\n  // react-dom is used with production (non-profiling) bundle of\n  // scheduler/tracing\n  if (!(tracing.__interactionsRef != null && tracing.__interactionsRef.current != null)) {\n    {\n      throw Error( \"It is not supported to run the profiling version of a renderer (for example, `react-dom/profiling`) without also replacing the `scheduler/tracing` module with `scheduler/tracing-profiling`. Your bundler might have a setting for aliasing both modules. Learn more at https://reactjs.org/link/profiling\" );\n    }\n  }\n}\n\nvar fakeCallbackNode = {}; // Except for NoPriority, these correspond to Scheduler priorities. We use\n// ascending numbers so we can compare them like numbers. They start at 90 to\n// avoid clashing with Scheduler's priorities.\n\nvar ImmediatePriority$1 = 99;\nvar UserBlockingPriority$2 = 98;\nvar NormalPriority$1 = 97;\nvar LowPriority$1 = 96;\nvar IdlePriority$1 = 95; // NoPriority is the absence of priority. Also React-only.\n\nvar NoPriority$1 = 90;\nvar shouldYield = Scheduler_shouldYield;\nvar requestPaint = // Fall back gracefully if we're running an older version of Scheduler.\nScheduler_requestPaint !== undefined ? Scheduler_requestPaint : function () {};\nvar syncQueue = null;\nvar immediateQueueCallbackNode = null;\nvar isFlushingSyncQueue = false;\nvar initialTimeMs$1 = Scheduler_now$1(); // If the initial timestamp is reasonably small, use Scheduler's `now` directly.\n// This will be the case for modern browsers that support `performance.now`. In\n// older browsers, Scheduler falls back to `Date.now`, which returns a Unix\n// timestamp. In that case, subtract the module initialization time to simulate\n// the behavior of performance.now and keep our times small enough to fit\n// within 32 bits.\n// TODO: Consider lifting this into Scheduler.\n\nvar now = initialTimeMs$1 < 10000 ? Scheduler_now$1 : function () {\n  return Scheduler_now$1() - initialTimeMs$1;\n};\nfunction getCurrentPriorityLevel() {\n  switch (Scheduler_getCurrentPriorityLevel()) {\n    case Scheduler_ImmediatePriority:\n      return ImmediatePriority$1;\n\n    case Scheduler_UserBlockingPriority:\n      return UserBlockingPriority$2;\n\n    case Scheduler_NormalPriority:\n      return NormalPriority$1;\n\n    case Scheduler_LowPriority:\n      return LowPriority$1;\n\n    case Scheduler_IdlePriority:\n      return IdlePriority$1;\n\n    default:\n      {\n        {\n          throw Error( \"Unknown priority level.\" );\n        }\n      }\n\n  }\n}\n\nfunction reactPriorityToSchedulerPriority(reactPriorityLevel) {\n  switch (reactPriorityLevel) {\n    case ImmediatePriority$1:\n      return Scheduler_ImmediatePriority;\n\n    case UserBlockingPriority$2:\n      return Scheduler_UserBlockingPriority;\n\n    case NormalPriority$1:\n      return Scheduler_NormalPriority;\n\n    case LowPriority$1:\n      return Scheduler_LowPriority;\n\n    case IdlePriority$1:\n      return Scheduler_IdlePriority;\n\n    default:\n      {\n        {\n          throw Error( \"Unknown priority level.\" );\n        }\n      }\n\n  }\n}\n\nfunction runWithPriority$1(reactPriorityLevel, fn) {\n  var priorityLevel = reactPriorityToSchedulerPriority(reactPriorityLevel);\n  return Scheduler_runWithPriority(priorityLevel, fn);\n}\nfunction scheduleCallback(reactPriorityLevel, callback, options) {\n  var priorityLevel = reactPriorityToSchedulerPriority(reactPriorityLevel);\n  return Scheduler_scheduleCallback(priorityLevel, callback, options);\n}\nfunction scheduleSyncCallback(callback) {\n  // Push this callback into an internal queue. We'll flush these either in\n  // the next tick, or earlier if something calls `flushSyncCallbackQueue`.\n  if (syncQueue === null) {\n    syncQueue = [callback]; // Flush the queue in the next tick, at the earliest.\n\n    immediateQueueCallbackNode = Scheduler_scheduleCallback(Scheduler_ImmediatePriority, flushSyncCallbackQueueImpl);\n  } else {\n    // Push onto existing queue. Don't need to schedule a callback because\n    // we already scheduled one when we created the queue.\n    syncQueue.push(callback);\n  }\n\n  return fakeCallbackNode;\n}\nfunction cancelCallback(callbackNode) {\n  if (callbackNode !== fakeCallbackNode) {\n    Scheduler_cancelCallback(callbackNode);\n  }\n}\nfunction flushSyncCallbackQueue() {\n  if (immediateQueueCallbackNode !== null) {\n    var node = immediateQueueCallbackNode;\n    immediateQueueCallbackNode = null;\n    Scheduler_cancelCallback(node);\n  }\n\n  flushSyncCallbackQueueImpl();\n}\n\nfunction flushSyncCallbackQueueImpl() {\n  if (!isFlushingSyncQueue && syncQueue !== null) {\n    // Prevent re-entrancy.\n    isFlushingSyncQueue = true;\n    var i = 0;\n\n    {\n      try {\n        var _isSync2 = true;\n        var _queue = syncQueue;\n        runWithPriority$1(ImmediatePriority$1, function () {\n          for (; i < _queue.length; i++) {\n            var callback = _queue[i];\n\n            do {\n              callback = callback(_isSync2);\n            } while (callback !== null);\n          }\n        });\n        syncQueue = null;\n      } catch (error) {\n        // If something throws, leave the remaining callbacks on the queue.\n        if (syncQueue !== null) {\n          syncQueue = syncQueue.slice(i + 1);\n        } // Resume flushing in the next tick\n\n\n        Scheduler_scheduleCallback(Scheduler_ImmediatePriority, flushSyncCallbackQueue);\n        throw error;\n      } finally {\n        isFlushingSyncQueue = false;\n      }\n    }\n  }\n}\n\n// TODO: this is special because it gets imported during build.\nvar ReactVersion = '17.0.2';\n\nvar NoMode = 0;\nvar StrictMode = 1; // TODO: Remove BlockingMode and ConcurrentMode by reading from the root\n// tag instead\n\nvar BlockingMode = 2;\nvar ConcurrentMode = 4;\nvar ProfileMode = 8;\nvar DebugTracingMode = 16;\n\nvar ReactCurrentBatchConfig = ReactSharedInternals.ReactCurrentBatchConfig;\nvar NoTransition = 0;\nfunction requestCurrentTransition() {\n  return ReactCurrentBatchConfig.transition;\n}\n\nvar ReactStrictModeWarnings = {\n  recordUnsafeLifecycleWarnings: function (fiber, instance) {},\n  flushPendingUnsafeLifecycleWarnings: function () {},\n  recordLegacyContextWarning: function (fiber, instance) {},\n  flushLegacyContextWarning: function () {},\n  discardPendingWarnings: function () {}\n};\n\n{\n  var findStrictRoot = function (fiber) {\n    var maybeStrictRoot = null;\n    var node = fiber;\n\n    while (node !== null) {\n      if (node.mode & StrictMode) {\n        maybeStrictRoot = node;\n      }\n\n      node = node.return;\n    }\n\n    return maybeStrictRoot;\n  };\n\n  var setToSortedString = function (set) {\n    var array = [];\n    set.forEach(function (value) {\n      array.push(value);\n    });\n    return array.sort().join(', ');\n  };\n\n  var pendingComponentWillMountWarnings = [];\n  var pendingUNSAFE_ComponentWillMountWarnings = [];\n  var pendingComponentWillReceivePropsWarnings = [];\n  var pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n  var pendingComponentWillUpdateWarnings = [];\n  var pendingUNSAFE_ComponentWillUpdateWarnings = []; // Tracks components we have already warned about.\n\n  var didWarnAboutUnsafeLifecycles = new Set();\n\n  ReactStrictModeWarnings.recordUnsafeLifecycleWarnings = function (fiber, instance) {\n    // Dedup strategy: Warn once per component.\n    if (didWarnAboutUnsafeLifecycles.has(fiber.type)) {\n      return;\n    }\n\n    if (typeof instance.componentWillMount === 'function' && // Don't warn about react-lifecycles-compat polyfilled components.\n    instance.componentWillMount.__suppressDeprecationWarning !== true) {\n      pendingComponentWillMountWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictMode && typeof instance.UNSAFE_componentWillMount === 'function') {\n      pendingUNSAFE_ComponentWillMountWarnings.push(fiber);\n    }\n\n    if (typeof instance.componentWillReceiveProps === 'function' && instance.componentWillReceiveProps.__suppressDeprecationWarning !== true) {\n      pendingComponentWillReceivePropsWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictMode && typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n      pendingUNSAFE_ComponentWillReceivePropsWarnings.push(fiber);\n    }\n\n    if (typeof instance.componentWillUpdate === 'function' && instance.componentWillUpdate.__suppressDeprecationWarning !== true) {\n      pendingComponentWillUpdateWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictMode && typeof instance.UNSAFE_componentWillUpdate === 'function') {\n      pendingUNSAFE_ComponentWillUpdateWarnings.push(fiber);\n    }\n  };\n\n  ReactStrictModeWarnings.flushPendingUnsafeLifecycleWarnings = function () {\n    // We do an initial pass to gather component names\n    var componentWillMountUniqueNames = new Set();\n\n    if (pendingComponentWillMountWarnings.length > 0) {\n      pendingComponentWillMountWarnings.forEach(function (fiber) {\n        componentWillMountUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillMountWarnings = [];\n    }\n\n    var UNSAFE_componentWillMountUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillMountWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillMountWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillMountUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillMountWarnings = [];\n    }\n\n    var componentWillReceivePropsUniqueNames = new Set();\n\n    if (pendingComponentWillReceivePropsWarnings.length > 0) {\n      pendingComponentWillReceivePropsWarnings.forEach(function (fiber) {\n        componentWillReceivePropsUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillReceivePropsWarnings = [];\n    }\n\n    var UNSAFE_componentWillReceivePropsUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillReceivePropsWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillReceivePropsWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillReceivePropsUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n    }\n\n    var componentWillUpdateUniqueNames = new Set();\n\n    if (pendingComponentWillUpdateWarnings.length > 0) {\n      pendingComponentWillUpdateWarnings.forEach(function (fiber) {\n        componentWillUpdateUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillUpdateWarnings = [];\n    }\n\n    var UNSAFE_componentWillUpdateUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillUpdateWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillUpdateWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillUpdateUniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillUpdateWarnings = [];\n    } // Finally, we flush all the warnings\n    // UNSAFE_ ones before the deprecated ones, since they'll be 'louder'\n\n\n    if (UNSAFE_componentWillMountUniqueNames.size > 0) {\n      var sortedNames = setToSortedString(UNSAFE_componentWillMountUniqueNames);\n\n      error('Using UNSAFE_componentWillMount in strict mode is not recommended and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move code with side effects to componentDidMount, and set initial state in the constructor.\\n' + '\\nPlease update the following components: %s', sortedNames);\n    }\n\n    if (UNSAFE_componentWillReceivePropsUniqueNames.size > 0) {\n      var _sortedNames = setToSortedString(UNSAFE_componentWillReceivePropsUniqueNames);\n\n      error('Using UNSAFE_componentWillReceiveProps in strict mode is not recommended ' + 'and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + \"* If you're updating state whenever props change, \" + 'refactor your code to use memoization techniques or move it to ' + 'static getDerivedStateFromProps. Learn more at: https://reactjs.org/link/derived-state\\n' + '\\nPlease update the following components: %s', _sortedNames);\n    }\n\n    if (UNSAFE_componentWillUpdateUniqueNames.size > 0) {\n      var _sortedNames2 = setToSortedString(UNSAFE_componentWillUpdateUniqueNames);\n\n      error('Using UNSAFE_componentWillUpdate in strict mode is not recommended ' + 'and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + '\\nPlease update the following components: %s', _sortedNames2);\n    }\n\n    if (componentWillMountUniqueNames.size > 0) {\n      var _sortedNames3 = setToSortedString(componentWillMountUniqueNames);\n\n      warn('componentWillMount has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move code with side effects to componentDidMount, and set initial state in the constructor.\\n' + '* Rename componentWillMount to UNSAFE_componentWillMount to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames3);\n    }\n\n    if (componentWillReceivePropsUniqueNames.size > 0) {\n      var _sortedNames4 = setToSortedString(componentWillReceivePropsUniqueNames);\n\n      warn('componentWillReceiveProps has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + \"* If you're updating state whenever props change, refactor your \" + 'code to use memoization techniques or move it to ' + 'static getDerivedStateFromProps. Learn more at: https://reactjs.org/link/derived-state\\n' + '* Rename componentWillReceiveProps to UNSAFE_componentWillReceiveProps to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames4);\n    }\n\n    if (componentWillUpdateUniqueNames.size > 0) {\n      var _sortedNames5 = setToSortedString(componentWillUpdateUniqueNames);\n\n      warn('componentWillUpdate has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + '* Rename componentWillUpdate to UNSAFE_componentWillUpdate to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames5);\n    }\n  };\n\n  var pendingLegacyContextWarning = new Map(); // Tracks components we have already warned about.\n\n  var didWarnAboutLegacyContext = new Set();\n\n  ReactStrictModeWarnings.recordLegacyContextWarning = function (fiber, instance) {\n    var strictRoot = findStrictRoot(fiber);\n\n    if (strictRoot === null) {\n      error('Expected to find a StrictMode component in a strict mode tree. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n\n      return;\n    } // Dedup strategy: Warn once per component.\n\n\n    if (didWarnAboutLegacyContext.has(fiber.type)) {\n      return;\n    }\n\n    var warningsForRoot = pendingLegacyContextWarning.get(strictRoot);\n\n    if (fiber.type.contextTypes != null || fiber.type.childContextTypes != null || instance !== null && typeof instance.getChildContext === 'function') {\n      if (warningsForRoot === undefined) {\n        warningsForRoot = [];\n        pendingLegacyContextWarning.set(strictRoot, warningsForRoot);\n      }\n\n      warningsForRoot.push(fiber);\n    }\n  };\n\n  ReactStrictModeWarnings.flushLegacyContextWarning = function () {\n    pendingLegacyContextWarning.forEach(function (fiberArray, strictRoot) {\n      if (fiberArray.length === 0) {\n        return;\n      }\n\n      var firstFiber = fiberArray[0];\n      var uniqueNames = new Set();\n      fiberArray.forEach(function (fiber) {\n        uniqueNames.add(getComponentName(fiber.type) || 'Component');\n        didWarnAboutLegacyContext.add(fiber.type);\n      });\n      var sortedNames = setToSortedString(uniqueNames);\n\n      try {\n        setCurrentFiber(firstFiber);\n\n        error('Legacy context API has been detected within a strict-mode tree.' + '\\n\\nThe old API will be supported in all 16.x releases, but applications ' + 'using it should migrate to the new version.' + '\\n\\nPlease update the following components: %s' + '\\n\\nLearn more about this warning here: https://reactjs.org/link/legacy-context', sortedNames);\n      } finally {\n        resetCurrentFiber();\n      }\n    });\n  };\n\n  ReactStrictModeWarnings.discardPendingWarnings = function () {\n    pendingComponentWillMountWarnings = [];\n    pendingUNSAFE_ComponentWillMountWarnings = [];\n    pendingComponentWillReceivePropsWarnings = [];\n    pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n    pendingComponentWillUpdateWarnings = [];\n    pendingUNSAFE_ComponentWillUpdateWarnings = [];\n    pendingLegacyContextWarning = new Map();\n  };\n}\n\nfunction resolveDefaultProps(Component, baseProps) {\n  if (Component && Component.defaultProps) {\n    // Resolve default props. Taken from ReactElement\n    var props = _assign({}, baseProps);\n\n    var defaultProps = Component.defaultProps;\n\n    for (var propName in defaultProps) {\n      if (props[propName] === undefined) {\n        props[propName] = defaultProps[propName];\n      }\n    }\n\n    return props;\n  }\n\n  return baseProps;\n}\n\n// Max 31 bit integer. The max integer size in V8 for 32-bit systems.\n// Math.pow(2, 30) - 1\n// 0b111111111111111111111111111111\nvar MAX_SIGNED_31_BIT_INT = 1073741823;\n\nvar valueCursor = createCursor(null);\nvar rendererSigil;\n\n{\n  // Use this to detect multiple renderers using the same context\n  rendererSigil = {};\n}\n\nvar currentlyRenderingFiber = null;\nvar lastContextDependency = null;\nvar lastContextWithAllBitsObserved = null;\nvar isDisallowedContextReadInDEV = false;\nfunction resetContextDependencies() {\n  // This is called right before React yields execution, to ensure `readContext`\n  // cannot be called outside the render phase.\n  currentlyRenderingFiber = null;\n  lastContextDependency = null;\n  lastContextWithAllBitsObserved = null;\n\n  {\n    isDisallowedContextReadInDEV = false;\n  }\n}\nfunction enterDisallowedContextReadInDEV() {\n  {\n    isDisallowedContextReadInDEV = true;\n  }\n}\nfunction exitDisallowedContextReadInDEV() {\n  {\n    isDisallowedContextReadInDEV = false;\n  }\n}\nfunction pushProvider(providerFiber, nextValue) {\n  var context = providerFiber.type._context;\n\n  {\n    push(valueCursor, context._currentValue, providerFiber);\n    context._currentValue = nextValue;\n\n    {\n      if (context._currentRenderer !== undefined && context._currentRenderer !== null && context._currentRenderer !== rendererSigil) {\n        error('Detected multiple renderers concurrently rendering the ' + 'same context provider. This is currently unsupported.');\n      }\n\n      context._currentRenderer = rendererSigil;\n    }\n  }\n}\nfunction popProvider(providerFiber) {\n  var currentValue = valueCursor.current;\n  pop(valueCursor, providerFiber);\n  var context = providerFiber.type._context;\n\n  {\n    context._currentValue = currentValue;\n  }\n}\nfunction calculateChangedBits(context, newValue, oldValue) {\n  if (objectIs(oldValue, newValue)) {\n    // No change\n    return 0;\n  } else {\n    var changedBits = typeof context._calculateChangedBits === 'function' ? context._calculateChangedBits(oldValue, newValue) : MAX_SIGNED_31_BIT_INT;\n\n    {\n      if ((changedBits & MAX_SIGNED_31_BIT_INT) !== changedBits) {\n        error('calculateChangedBits: Expected the return value to be a ' + '31-bit integer. Instead received: %s', changedBits);\n      }\n    }\n\n    return changedBits | 0;\n  }\n}\nfunction scheduleWorkOnParentPath(parent, renderLanes) {\n  // Update the child lanes of all the ancestors, including the alternates.\n  var node = parent;\n\n  while (node !== null) {\n    var alternate = node.alternate;\n\n    if (!isSubsetOfLanes(node.childLanes, renderLanes)) {\n      node.childLanes = mergeLanes(node.childLanes, renderLanes);\n\n      if (alternate !== null) {\n        alternate.childLanes = mergeLanes(alternate.childLanes, renderLanes);\n      }\n    } else if (alternate !== null && !isSubsetOfLanes(alternate.childLanes, renderLanes)) {\n      alternate.childLanes = mergeLanes(alternate.childLanes, renderLanes);\n    } else {\n      // Neither alternate was updated, which means the rest of the\n      // ancestor path already has sufficient priority.\n      break;\n    }\n\n    node = node.return;\n  }\n}\nfunction propagateContextChange(workInProgress, context, changedBits, renderLanes) {\n  var fiber = workInProgress.child;\n\n  if (fiber !== null) {\n    // Set the return pointer of the child to the work-in-progress fiber.\n    fiber.return = workInProgress;\n  }\n\n  while (fiber !== null) {\n    var nextFiber = void 0; // Visit this fiber.\n\n    var list = fiber.dependencies;\n\n    if (list !== null) {\n      nextFiber = fiber.child;\n      var dependency = list.firstContext;\n\n      while (dependency !== null) {\n        // Check if the context matches.\n        if (dependency.context === context && (dependency.observedBits & changedBits) !== 0) {\n          // Match! Schedule an update on this fiber.\n          if (fiber.tag === ClassComponent) {\n            // Schedule a force update on the work-in-progress.\n            var update = createUpdate(NoTimestamp, pickArbitraryLane(renderLanes));\n            update.tag = ForceUpdate; // TODO: Because we don't have a work-in-progress, this will add the\n            // update to the current fiber, too, which means it will persist even if\n            // this render is thrown away. Since it's a race condition, not sure it's\n            // worth fixing.\n\n            enqueueUpdate(fiber, update);\n          }\n\n          fiber.lanes = mergeLanes(fiber.lanes, renderLanes);\n          var alternate = fiber.alternate;\n\n          if (alternate !== null) {\n            alternate.lanes = mergeLanes(alternate.lanes, renderLanes);\n          }\n\n          scheduleWorkOnParentPath(fiber.return, renderLanes); // Mark the updated lanes on the list, too.\n\n          list.lanes = mergeLanes(list.lanes, renderLanes); // Since we already found a match, we can stop traversing the\n          // dependency list.\n\n          break;\n        }\n\n        dependency = dependency.next;\n      }\n    } else if (fiber.tag === ContextProvider) {\n      // Don't scan deeper if this is a matching provider\n      nextFiber = fiber.type === workInProgress.type ? null : fiber.child;\n    } else {\n      // Traverse down.\n      nextFiber = fiber.child;\n    }\n\n    if (nextFiber !== null) {\n      // Set the return pointer of the child to the work-in-progress fiber.\n      nextFiber.return = fiber;\n    } else {\n      // No child. Traverse to next sibling.\n      nextFiber = fiber;\n\n      while (nextFiber !== null) {\n        if (nextFiber === workInProgress) {\n          // We're back to the root of this subtree. Exit.\n          nextFiber = null;\n          break;\n        }\n\n        var sibling = nextFiber.sibling;\n\n        if (sibling !== null) {\n          // Set the return pointer of the sibling to the work-in-progress fiber.\n          sibling.return = nextFiber.return;\n          nextFiber = sibling;\n          break;\n        } // No more siblings. Traverse up.\n\n\n        nextFiber = nextFiber.return;\n      }\n    }\n\n    fiber = nextFiber;\n  }\n}\nfunction prepareToReadContext(workInProgress, renderLanes) {\n  currentlyRenderingFiber = workInProgress;\n  lastContextDependency = null;\n  lastContextWithAllBitsObserved = null;\n  var dependencies = workInProgress.dependencies;\n\n  if (dependencies !== null) {\n    var firstContext = dependencies.firstContext;\n\n    if (firstContext !== null) {\n      if (includesSomeLane(dependencies.lanes, renderLanes)) {\n        // Context list has a pending update. Mark that this fiber performed work.\n        markWorkInProgressReceivedUpdate();\n      } // Reset the work-in-progress list\n\n\n      dependencies.firstContext = null;\n    }\n  }\n}\nfunction readContext(context, observedBits) {\n  {\n    // This warning would fire if you read context inside a Hook like useMemo.\n    // Unlike the class check below, it's not enforced in production for perf.\n    if (isDisallowedContextReadInDEV) {\n      error('Context can only be read while React is rendering. ' + 'In classes, you can read it in the render method or getDerivedStateFromProps. ' + 'In function components, you can read it directly in the function body, but not ' + 'inside Hooks like useReducer() or useMemo().');\n    }\n  }\n\n  if (lastContextWithAllBitsObserved === context) ; else if (observedBits === false || observedBits === 0) ; else {\n    var resolvedObservedBits; // Avoid deopting on observable arguments or heterogeneous types.\n\n    if (typeof observedBits !== 'number' || observedBits === MAX_SIGNED_31_BIT_INT) {\n      // Observe all updates.\n      lastContextWithAllBitsObserved = context;\n      resolvedObservedBits = MAX_SIGNED_31_BIT_INT;\n    } else {\n      resolvedObservedBits = observedBits;\n    }\n\n    var contextItem = {\n      context: context,\n      observedBits: resolvedObservedBits,\n      next: null\n    };\n\n    if (lastContextDependency === null) {\n      if (!(currentlyRenderingFiber !== null)) {\n        {\n          throw Error( \"Context can only be read while React is rendering. In classes, you can read it in the render method or getDerivedStateFromProps. In function components, you can read it directly in the function body, but not inside Hooks like useReducer() or useMemo().\" );\n        }\n      } // This is the first dependency for this component. Create a new list.\n\n\n      lastContextDependency = contextItem;\n      currentlyRenderingFiber.dependencies = {\n        lanes: NoLanes,\n        firstContext: contextItem,\n        responders: null\n      };\n    } else {\n      // Append a new context item.\n      lastContextDependency = lastContextDependency.next = contextItem;\n    }\n  }\n\n  return  context._currentValue ;\n}\n\nvar UpdateState = 0;\nvar ReplaceState = 1;\nvar ForceUpdate = 2;\nvar CaptureUpdate = 3; // Global state that is reset at the beginning of calling `processUpdateQueue`.\n// It should only be read right after calling `processUpdateQueue`, via\n// `checkHasForceUpdateAfterProcessing`.\n\nvar hasForceUpdate = false;\nvar didWarnUpdateInsideUpdate;\nvar currentlyProcessingQueue;\n\n{\n  didWarnUpdateInsideUpdate = false;\n  currentlyProcessingQueue = null;\n}\n\nfunction initializeUpdateQueue(fiber) {\n  var queue = {\n    baseState: fiber.memoizedState,\n    firstBaseUpdate: null,\n    lastBaseUpdate: null,\n    shared: {\n      pending: null\n    },\n    effects: null\n  };\n  fiber.updateQueue = queue;\n}\nfunction cloneUpdateQueue(current, workInProgress) {\n  // Clone the update queue from current. Unless it's already a clone.\n  var queue = workInProgress.updateQueue;\n  var currentQueue = current.updateQueue;\n\n  if (queue === currentQueue) {\n    var clone = {\n      baseState: currentQueue.baseState,\n      firstBaseUpdate: currentQueue.firstBaseUpdate,\n      lastBaseUpdate: currentQueue.lastBaseUpdate,\n      shared: currentQueue.shared,\n      effects: currentQueue.effects\n    };\n    workInProgress.updateQueue = clone;\n  }\n}\nfunction createUpdate(eventTime, lane) {\n  var update = {\n    eventTime: eventTime,\n    lane: lane,\n    tag: UpdateState,\n    payload: null,\n    callback: null,\n    next: null\n  };\n  return update;\n}\nfunction enqueueUpdate(fiber, update) {\n  var updateQueue = fiber.updateQueue;\n\n  if (updateQueue === null) {\n    // Only occurs if the fiber has been unmounted.\n    return;\n  }\n\n  var sharedQueue = updateQueue.shared;\n  var pending = sharedQueue.pending;\n\n  if (pending === null) {\n    // This is the first update. Create a circular list.\n    update.next = update;\n  } else {\n    update.next = pending.next;\n    pending.next = update;\n  }\n\n  sharedQueue.pending = update;\n\n  {\n    if (currentlyProcessingQueue === sharedQueue && !didWarnUpdateInsideUpdate) {\n      error('An update (setState, replaceState, or forceUpdate) was scheduled ' + 'from inside an update function. Update functions should be pure, ' + 'with zero side-effects. Consider using componentDidUpdate or a ' + 'callback.');\n\n      didWarnUpdateInsideUpdate = true;\n    }\n  }\n}\nfunction enqueueCapturedUpdate(workInProgress, capturedUpdate) {\n  // Captured updates are updates that are thrown by a child during the render\n  // phase. They should be discarded if the render is aborted. Therefore,\n  // we should only put them on the work-in-progress queue, not the current one.\n  var queue = workInProgress.updateQueue; // Check if the work-in-progress queue is a clone.\n\n  var current = workInProgress.alternate;\n\n  if (current !== null) {\n    var currentQueue = current.updateQueue;\n\n    if (queue === currentQueue) {\n      // The work-in-progress queue is the same as current. This happens when\n      // we bail out on a parent fiber that then captures an error thrown by\n      // a child. Since we want to append the update only to the work-in\n      // -progress queue, we need to clone the updates. We usually clone during\n      // processUpdateQueue, but that didn't happen in this case because we\n      // skipped over the parent when we bailed out.\n      var newFirst = null;\n      var newLast = null;\n      var firstBaseUpdate = queue.firstBaseUpdate;\n\n      if (firstBaseUpdate !== null) {\n        // Loop through the updates and clone them.\n        var update = firstBaseUpdate;\n\n        do {\n          var clone = {\n            eventTime: update.eventTime,\n            lane: update.lane,\n            tag: update.tag,\n            payload: update.payload,\n            callback: update.callback,\n            next: null\n          };\n\n          if (newLast === null) {\n            newFirst = newLast = clone;\n          } else {\n            newLast.next = clone;\n            newLast = clone;\n          }\n\n          update = update.next;\n        } while (update !== null); // Append the captured update the end of the cloned list.\n\n\n        if (newLast === null) {\n          newFirst = newLast = capturedUpdate;\n        } else {\n          newLast.next = capturedUpdate;\n          newLast = capturedUpdate;\n        }\n      } else {\n        // There are no base updates.\n        newFirst = newLast = capturedUpdate;\n      }\n\n      queue = {\n        baseState: currentQueue.baseState,\n        firstBaseUpdate: newFirst,\n        lastBaseUpdate: newLast,\n        shared: currentQueue.shared,\n        effects: currentQueue.effects\n      };\n      workInProgress.updateQueue = queue;\n      return;\n    }\n  } // Append the update to the end of the list.\n\n\n  var lastBaseUpdate = queue.lastBaseUpdate;\n\n  if (lastBaseUpdate === null) {\n    queue.firstBaseUpdate = capturedUpdate;\n  } else {\n    lastBaseUpdate.next = capturedUpdate;\n  }\n\n  queue.lastBaseUpdate = capturedUpdate;\n}\n\nfunction getStateFromUpdate(workInProgress, queue, update, prevState, nextProps, instance) {\n  switch (update.tag) {\n    case ReplaceState:\n      {\n        var payload = update.payload;\n\n        if (typeof payload === 'function') {\n          // Updater function\n          {\n            enterDisallowedContextReadInDEV();\n          }\n\n          var nextState = payload.call(instance, prevState, nextProps);\n\n          {\n            if ( workInProgress.mode & StrictMode) {\n              disableLogs();\n\n              try {\n                payload.call(instance, prevState, nextProps);\n              } finally {\n                reenableLogs();\n              }\n            }\n\n            exitDisallowedContextReadInDEV();\n          }\n\n          return nextState;\n        } // State object\n\n\n        return payload;\n      }\n\n    case CaptureUpdate:\n      {\n        workInProgress.flags = workInProgress.flags & ~ShouldCapture | DidCapture;\n      }\n    // Intentional fallthrough\n\n    case UpdateState:\n      {\n        var _payload = update.payload;\n        var partialState;\n\n        if (typeof _payload === 'function') {\n          // Updater function\n          {\n            enterDisallowedContextReadInDEV();\n          }\n\n          partialState = _payload.call(instance, prevState, nextProps);\n\n          {\n            if ( workInProgress.mode & StrictMode) {\n              disableLogs();\n\n              try {\n                _payload.call(instance, prevState, nextProps);\n              } finally {\n                reenableLogs();\n              }\n            }\n\n            exitDisallowedContextReadInDEV();\n          }\n        } else {\n          // Partial state object\n          partialState = _payload;\n        }\n\n        if (partialState === null || partialState === undefined) {\n          // Null and undefined are treated as no-ops.\n          return prevState;\n        } // Merge the partial state and the previous state.\n\n\n        return _assign({}, prevState, partialState);\n      }\n\n    case ForceUpdate:\n      {\n        hasForceUpdate = true;\n        return prevState;\n      }\n  }\n\n  return prevState;\n}\n\nfunction processUpdateQueue(workInProgress, props, instance, renderLanes) {\n  // This is always non-null on a ClassComponent or HostRoot\n  var queue = workInProgress.updateQueue;\n  hasForceUpdate = false;\n\n  {\n    currentlyProcessingQueue = queue.shared;\n  }\n\n  var firstBaseUpdate = queue.firstBaseUpdate;\n  var lastBaseUpdate = queue.lastBaseUpdate; // Check if there are pending updates. If so, transfer them to the base queue.\n\n  var pendingQueue = queue.shared.pending;\n\n  if (pendingQueue !== null) {\n    queue.shared.pending = null; // The pending queue is circular. Disconnect the pointer between first\n    // and last so that it's non-circular.\n\n    var lastPendingUpdate = pendingQueue;\n    var firstPendingUpdate = lastPendingUpdate.next;\n    lastPendingUpdate.next = null; // Append pending updates to base queue\n\n    if (lastBaseUpdate === null) {\n      firstBaseUpdate = firstPendingUpdate;\n    } else {\n      lastBaseUpdate.next = firstPendingUpdate;\n    }\n\n    lastBaseUpdate = lastPendingUpdate; // If there's a current queue, and it's different from the base queue, then\n    // we need to transfer the updates to that queue, too. Because the base\n    // queue is a singly-linked list with no cycles, we can append to both\n    // lists and take advantage of structural sharing.\n    // TODO: Pass `current` as argument\n\n    var current = workInProgress.alternate;\n\n    if (current !== null) {\n      // This is always non-null on a ClassComponent or HostRoot\n      var currentQueue = current.updateQueue;\n      var currentLastBaseUpdate = currentQueue.lastBaseUpdate;\n\n      if (currentLastBaseUpdate !== lastBaseUpdate) {\n        if (currentLastBaseUpdate === null) {\n          currentQueue.firstBaseUpdate = firstPendingUpdate;\n        } else {\n          currentLastBaseUpdate.next = firstPendingUpdate;\n        }\n\n        currentQueue.lastBaseUpdate = lastPendingUpdate;\n      }\n    }\n  } // These values may change as we process the queue.\n\n\n  if (firstBaseUpdate !== null) {\n    // Iterate through the list of updates to compute the result.\n    var newState = queue.baseState; // TODO: Don't need to accumulate this. Instead, we can remove renderLanes\n    // from the original lanes.\n\n    var newLanes = NoLanes;\n    var newBaseState = null;\n    var newFirstBaseUpdate = null;\n    var newLastBaseUpdate = null;\n    var update = firstBaseUpdate;\n\n    do {\n      var updateLane = update.lane;\n      var updateEventTime = update.eventTime;\n\n      if (!isSubsetOfLanes(renderLanes, updateLane)) {\n        // Priority is insufficient. Skip this update. If this is the first\n        // skipped update, the previous update/state is the new base\n        // update/state.\n        var clone = {\n          eventTime: updateEventTime,\n          lane: updateLane,\n          tag: update.tag,\n          payload: update.payload,\n          callback: update.callback,\n          next: null\n        };\n\n        if (newLastBaseUpdate === null) {\n          newFirstBaseUpdate = newLastBaseUpdate = clone;\n          newBaseState = newState;\n        } else {\n          newLastBaseUpdate = newLastBaseUpdate.next = clone;\n        } // Update the remaining priority in the queue.\n\n\n        newLanes = mergeLanes(newLanes, updateLane);\n      } else {\n        // This update does have sufficient priority.\n        if (newLastBaseUpdate !== null) {\n          var _clone = {\n            eventTime: updateEventTime,\n            // This update is going to be committed so we never want uncommit\n            // it. Using NoLane works because 0 is a subset of all bitmasks, so\n            // this will never be skipped by the check above.\n            lane: NoLane,\n            tag: update.tag,\n            payload: update.payload,\n            callback: update.callback,\n            next: null\n          };\n          newLastBaseUpdate = newLastBaseUpdate.next = _clone;\n        } // Process this update.\n\n\n        newState = getStateFromUpdate(workInProgress, queue, update, newState, props, instance);\n        var callback = update.callback;\n\n        if (callback !== null) {\n          workInProgress.flags |= Callback;\n          var effects = queue.effects;\n\n          if (effects === null) {\n            queue.effects = [update];\n          } else {\n            effects.push(update);\n          }\n        }\n      }\n\n      update = update.next;\n\n      if (update === null) {\n        pendingQueue = queue.shared.pending;\n\n        if (pendingQueue === null) {\n          break;\n        } else {\n          // An update was scheduled from inside a reducer. Add the new\n          // pending updates to the end of the list and keep processing.\n          var _lastPendingUpdate = pendingQueue; // Intentionally unsound. Pending updates form a circular list, but we\n          // unravel them when transferring them to the base queue.\n\n          var _firstPendingUpdate = _lastPendingUpdate.next;\n          _lastPendingUpdate.next = null;\n          update = _firstPendingUpdate;\n          queue.lastBaseUpdate = _lastPendingUpdate;\n          queue.shared.pending = null;\n        }\n      }\n    } while (true);\n\n    if (newLastBaseUpdate === null) {\n      newBaseState = newState;\n    }\n\n    queue.baseState = newBaseState;\n    queue.firstBaseUpdate = newFirstBaseUpdate;\n    queue.lastBaseUpdate = newLastBaseUpdate; // Set the remaining expiration time to be whatever is remaining in the queue.\n    // This should be fine because the only two other things that contribute to\n    // expiration time are props and context. We're already in the middle of the\n    // begin phase by the time we start processing the queue, so we've already\n    // dealt with the props. Context in components that specify\n    // shouldComponentUpdate is tricky; but we'll have to account for\n    // that regardless.\n\n    markSkippedUpdateLanes(newLanes);\n    workInProgress.lanes = newLanes;\n    workInProgress.memoizedState = newState;\n  }\n\n  {\n    currentlyProcessingQueue = null;\n  }\n}\n\nfunction callCallback(callback, context) {\n  if (!(typeof callback === 'function')) {\n    {\n      throw Error( \"Invalid argument passed as callback. Expected a function. Instead received: \" + callback );\n    }\n  }\n\n  callback.call(context);\n}\n\nfunction resetHasForceUpdateBeforeProcessing() {\n  hasForceUpdate = false;\n}\nfunction checkHasForceUpdateAfterProcessing() {\n  return hasForceUpdate;\n}\nfunction commitUpdateQueue(finishedWork, finishedQueue, instance) {\n  // Commit the effects\n  var effects = finishedQueue.effects;\n  finishedQueue.effects = null;\n\n  if (effects !== null) {\n    for (var i = 0; i < effects.length; i++) {\n      var effect = effects[i];\n      var callback = effect.callback;\n\n      if (callback !== null) {\n        effect.callback = null;\n        callCallback(callback, instance);\n      }\n    }\n  }\n}\n\nvar fakeInternalInstance = {};\nvar isArray = Array.isArray; // React.Component uses a shared frozen object by default.\n// We'll use it to determine whether we need to initialize legacy refs.\n\nvar emptyRefsObject = new React.Component().refs;\nvar didWarnAboutStateAssignmentForComponent;\nvar didWarnAboutUninitializedState;\nvar didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate;\nvar didWarnAboutLegacyLifecyclesAndDerivedState;\nvar didWarnAboutUndefinedDerivedState;\nvar warnOnUndefinedDerivedState;\nvar warnOnInvalidCallback;\nvar didWarnAboutDirectlyAssigningPropsToState;\nvar didWarnAboutContextTypeAndContextTypes;\nvar didWarnAboutInvalidateContextType;\n\n{\n  didWarnAboutStateAssignmentForComponent = new Set();\n  didWarnAboutUninitializedState = new Set();\n  didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate = new Set();\n  didWarnAboutLegacyLifecyclesAndDerivedState = new Set();\n  didWarnAboutDirectlyAssigningPropsToState = new Set();\n  didWarnAboutUndefinedDerivedState = new Set();\n  didWarnAboutContextTypeAndContextTypes = new Set();\n  didWarnAboutInvalidateContextType = new Set();\n  var didWarnOnInvalidCallback = new Set();\n\n  warnOnInvalidCallback = function (callback, callerName) {\n    if (callback === null || typeof callback === 'function') {\n      return;\n    }\n\n    var key = callerName + '_' + callback;\n\n    if (!didWarnOnInvalidCallback.has(key)) {\n      didWarnOnInvalidCallback.add(key);\n\n      error('%s(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callerName, callback);\n    }\n  };\n\n  warnOnUndefinedDerivedState = function (type, partialState) {\n    if (partialState === undefined) {\n      var componentName = getComponentName(type) || 'Component';\n\n      if (!didWarnAboutUndefinedDerivedState.has(componentName)) {\n        didWarnAboutUndefinedDerivedState.add(componentName);\n\n        error('%s.getDerivedStateFromProps(): A valid state object (or null) must be returned. ' + 'You have returned undefined.', componentName);\n      }\n    }\n  }; // This is so gross but it's at least non-critical and can be removed if\n  // it causes problems. This is meant to give a nicer error message for\n  // ReactDOM15.unstable_renderSubtreeIntoContainer(reactDOM16Component,\n  // ...)) which otherwise throws a \"_processChildContext is not a function\"\n  // exception.\n\n\n  Object.defineProperty(fakeInternalInstance, '_processChildContext', {\n    enumerable: false,\n    value: function () {\n      {\n        {\n          throw Error( \"_processChildContext is not available in React 16+. This likely means you have multiple copies of React and are attempting to nest a React 15 tree inside a React 16 tree using unstable_renderSubtreeIntoContainer, which isn't supported. Try to make sure you have only one copy of React (and ideally, switch to ReactDOM.createPortal).\" );\n        }\n      }\n    }\n  });\n  Object.freeze(fakeInternalInstance);\n}\n\nfunction applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, nextProps) {\n  var prevState = workInProgress.memoizedState;\n\n  {\n    if ( workInProgress.mode & StrictMode) {\n      disableLogs();\n\n      try {\n        // Invoke the function an extra time to help detect side-effects.\n        getDerivedStateFromProps(nextProps, prevState);\n      } finally {\n        reenableLogs();\n      }\n    }\n  }\n\n  var partialState = getDerivedStateFromProps(nextProps, prevState);\n\n  {\n    warnOnUndefinedDerivedState(ctor, partialState);\n  } // Merge the partial state and the previous state.\n\n\n  var memoizedState = partialState === null || partialState === undefined ? prevState : _assign({}, prevState, partialState);\n  workInProgress.memoizedState = memoizedState; // Once the update queue is empty, persist the derived state onto the\n  // base state.\n\n  if (workInProgress.lanes === NoLanes) {\n    // Queue is always non-null for classes\n    var updateQueue = workInProgress.updateQueue;\n    updateQueue.baseState = memoizedState;\n  }\n}\nvar classComponentUpdater = {\n  isMounted: isMounted,\n  enqueueSetState: function (inst, payload, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.payload = payload;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'setState');\n      }\n\n      update.callback = callback;\n    }\n\n    enqueueUpdate(fiber, update);\n    scheduleUpdateOnFiber(fiber, lane, eventTime);\n  },\n  enqueueReplaceState: function (inst, payload, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.tag = ReplaceState;\n    update.payload = payload;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'replaceState');\n      }\n\n      update.callback = callback;\n    }\n\n    enqueueUpdate(fiber, update);\n    scheduleUpdateOnFiber(fiber, lane, eventTime);\n  },\n  enqueueForceUpdate: function (inst, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.tag = ForceUpdate;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'forceUpdate');\n      }\n\n      update.callback = callback;\n    }\n\n    enqueueUpdate(fiber, update);\n    scheduleUpdateOnFiber(fiber, lane, eventTime);\n  }\n};\n\nfunction checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext) {\n  var instance = workInProgress.stateNode;\n\n  if (typeof instance.shouldComponentUpdate === 'function') {\n    {\n      if ( workInProgress.mode & StrictMode) {\n        disableLogs();\n\n        try {\n          // Invoke the function an extra time to help detect side-effects.\n          instance.shouldComponentUpdate(newProps, newState, nextContext);\n        } finally {\n          reenableLogs();\n        }\n      }\n    }\n\n    var shouldUpdate = instance.shouldComponentUpdate(newProps, newState, nextContext);\n\n    {\n      if (shouldUpdate === undefined) {\n        error('%s.shouldComponentUpdate(): Returned undefined instead of a ' + 'boolean value. Make sure to return true or false.', getComponentName(ctor) || 'Component');\n      }\n    }\n\n    return shouldUpdate;\n  }\n\n  if (ctor.prototype && ctor.prototype.isPureReactComponent) {\n    return !shallowEqual(oldProps, newProps) || !shallowEqual(oldState, newState);\n  }\n\n  return true;\n}\n\nfunction checkClassInstance(workInProgress, ctor, newProps) {\n  var instance = workInProgress.stateNode;\n\n  {\n    var name = getComponentName(ctor) || 'Component';\n    var renderPresent = instance.render;\n\n    if (!renderPresent) {\n      if (ctor.prototype && typeof ctor.prototype.render === 'function') {\n        error('%s(...): No `render` method found on the returned component ' + 'instance: did you accidentally return an object from the constructor?', name);\n      } else {\n        error('%s(...): No `render` method found on the returned component ' + 'instance: you may have forgotten to define `render`.', name);\n      }\n    }\n\n    if (instance.getInitialState && !instance.getInitialState.isReactClassApproved && !instance.state) {\n      error('getInitialState was defined on %s, a plain JavaScript class. ' + 'This is only supported for classes created using React.createClass. ' + 'Did you mean to define a state property instead?', name);\n    }\n\n    if (instance.getDefaultProps && !instance.getDefaultProps.isReactClassApproved) {\n      error('getDefaultProps was defined on %s, a plain JavaScript class. ' + 'This is only supported for classes created using React.createClass. ' + 'Use a static property to define defaultProps instead.', name);\n    }\n\n    if (instance.propTypes) {\n      error('propTypes was defined as an instance property on %s. Use a static ' + 'property to define propTypes instead.', name);\n    }\n\n    if (instance.contextType) {\n      error('contextType was defined as an instance property on %s. Use a static ' + 'property to define contextType instead.', name);\n    }\n\n    {\n      if (instance.contextTypes) {\n        error('contextTypes was defined as an instance property on %s. Use a static ' + 'property to define contextTypes instead.', name);\n      }\n\n      if (ctor.contextType && ctor.contextTypes && !didWarnAboutContextTypeAndContextTypes.has(ctor)) {\n        didWarnAboutContextTypeAndContextTypes.add(ctor);\n\n        error('%s declares both contextTypes and contextType static properties. ' + 'The legacy contextTypes property will be ignored.', name);\n      }\n    }\n\n    if (typeof instance.componentShouldUpdate === 'function') {\n      error('%s has a method called ' + 'componentShouldUpdate(). Did you mean shouldComponentUpdate()? ' + 'The name is phrased as a question because the function is ' + 'expected to return a value.', name);\n    }\n\n    if (ctor.prototype && ctor.prototype.isPureReactComponent && typeof instance.shouldComponentUpdate !== 'undefined') {\n      error('%s has a method called shouldComponentUpdate(). ' + 'shouldComponentUpdate should not be used when extending React.PureComponent. ' + 'Please extend React.Component if shouldComponentUpdate is used.', getComponentName(ctor) || 'A pure component');\n    }\n\n    if (typeof instance.componentDidUnmount === 'function') {\n      error('%s has a method called ' + 'componentDidUnmount(). But there is no such lifecycle method. ' + 'Did you mean componentWillUnmount()?', name);\n    }\n\n    if (typeof instance.componentDidReceiveProps === 'function') {\n      error('%s has a method called ' + 'componentDidReceiveProps(). But there is no such lifecycle method. ' + 'If you meant to update the state in response to changing props, ' + 'use componentWillReceiveProps(). If you meant to fetch data or ' + 'run side-effects or mutations after React has updated the UI, use componentDidUpdate().', name);\n    }\n\n    if (typeof instance.componentWillRecieveProps === 'function') {\n      error('%s has a method called ' + 'componentWillRecieveProps(). Did you mean componentWillReceiveProps()?', name);\n    }\n\n    if (typeof instance.UNSAFE_componentWillRecieveProps === 'function') {\n      error('%s has a method called ' + 'UNSAFE_componentWillRecieveProps(). Did you mean UNSAFE_componentWillReceiveProps()?', name);\n    }\n\n    var hasMutatedProps = instance.props !== newProps;\n\n    if (instance.props !== undefined && hasMutatedProps) {\n      error('%s(...): When calling super() in `%s`, make sure to pass ' + \"up the same props that your component's constructor was passed.\", name, name);\n    }\n\n    if (instance.defaultProps) {\n      error('Setting defaultProps as an instance property on %s is not supported and will be ignored.' + ' Instead, define defaultProps as a static property on %s.', name, name);\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function' && typeof instance.componentDidUpdate !== 'function' && !didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate.has(ctor)) {\n      didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate.add(ctor);\n\n      error('%s: getSnapshotBeforeUpdate() should be used with componentDidUpdate(). ' + 'This component defines getSnapshotBeforeUpdate() only.', getComponentName(ctor));\n    }\n\n    if (typeof instance.getDerivedStateFromProps === 'function') {\n      error('%s: getDerivedStateFromProps() is defined as an instance method ' + 'and will be ignored. Instead, declare it as a static method.', name);\n    }\n\n    if (typeof instance.getDerivedStateFromError === 'function') {\n      error('%s: getDerivedStateFromError() is defined as an instance method ' + 'and will be ignored. Instead, declare it as a static method.', name);\n    }\n\n    if (typeof ctor.getSnapshotBeforeUpdate === 'function') {\n      error('%s: getSnapshotBeforeUpdate() is defined as a static method ' + 'and will be ignored. Instead, declare it as an instance method.', name);\n    }\n\n    var _state = instance.state;\n\n    if (_state && (typeof _state !== 'object' || isArray(_state))) {\n      error('%s.state: must be set to an object or null', name);\n    }\n\n    if (typeof instance.getChildContext === 'function' && typeof ctor.childContextTypes !== 'object') {\n      error('%s.getChildContext(): childContextTypes must be defined in order to ' + 'use getChildContext().', name);\n    }\n  }\n}\n\nfunction adoptClassInstance(workInProgress, instance) {\n  instance.updater = classComponentUpdater;\n  workInProgress.stateNode = instance; // The instance needs access to the fiber so that it can schedule updates\n\n  set(instance, workInProgress);\n\n  {\n    instance._reactInternalInstance = fakeInternalInstance;\n  }\n}\n\nfunction constructClassInstance(workInProgress, ctor, props) {\n  var isLegacyContextConsumer = false;\n  var unmaskedContext = emptyContextObject;\n  var context = emptyContextObject;\n  var contextType = ctor.contextType;\n\n  {\n    if ('contextType' in ctor) {\n      var isValid = // Allow null for conditional declaration\n      contextType === null || contextType !== undefined && contextType.$$typeof === REACT_CONTEXT_TYPE && contextType._context === undefined; // Not a <Context.Consumer>\n\n      if (!isValid && !didWarnAboutInvalidateContextType.has(ctor)) {\n        didWarnAboutInvalidateContextType.add(ctor);\n        var addendum = '';\n\n        if (contextType === undefined) {\n          addendum = ' However, it is set to undefined. ' + 'This can be caused by a typo or by mixing up named and default imports. ' + 'This can also happen due to a circular dependency, so ' + 'try moving the createContext() call to a separate file.';\n        } else if (typeof contextType !== 'object') {\n          addendum = ' However, it is set to a ' + typeof contextType + '.';\n        } else if (contextType.$$typeof === REACT_PROVIDER_TYPE) {\n          addendum = ' Did you accidentally pass the Context.Provider instead?';\n        } else if (contextType._context !== undefined) {\n          // <Context.Consumer>\n          addendum = ' Did you accidentally pass the Context.Consumer instead?';\n        } else {\n          addendum = ' However, it is set to an object with keys {' + Object.keys(contextType).join(', ') + '}.';\n        }\n\n        error('%s defines an invalid contextType. ' + 'contextType should point to the Context object returned by React.createContext().%s', getComponentName(ctor) || 'Component', addendum);\n      }\n    }\n  }\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    context = readContext(contextType);\n  } else {\n    unmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    var contextTypes = ctor.contextTypes;\n    isLegacyContextConsumer = contextTypes !== null && contextTypes !== undefined;\n    context = isLegacyContextConsumer ? getMaskedContext(workInProgress, unmaskedContext) : emptyContextObject;\n  } // Instantiate twice to help detect side-effects.\n\n\n  {\n    if ( workInProgress.mode & StrictMode) {\n      disableLogs();\n\n      try {\n        new ctor(props, context); // eslint-disable-line no-new\n      } finally {\n        reenableLogs();\n      }\n    }\n  }\n\n  var instance = new ctor(props, context);\n  var state = workInProgress.memoizedState = instance.state !== null && instance.state !== undefined ? instance.state : null;\n  adoptClassInstance(workInProgress, instance);\n\n  {\n    if (typeof ctor.getDerivedStateFromProps === 'function' && state === null) {\n      var componentName = getComponentName(ctor) || 'Component';\n\n      if (!didWarnAboutUninitializedState.has(componentName)) {\n        didWarnAboutUninitializedState.add(componentName);\n\n        error('`%s` uses `getDerivedStateFromProps` but its initial state is ' + '%s. This is not recommended. Instead, define the initial state by ' + 'assigning an object to `this.state` in the constructor of `%s`. ' + 'This ensures that `getDerivedStateFromProps` arguments have a consistent shape.', componentName, instance.state === null ? 'null' : 'undefined', componentName);\n      }\n    } // If new component APIs are defined, \"unsafe\" lifecycles won't be called.\n    // Warn about these lifecycles if they are present.\n    // Don't warn about react-lifecycles-compat polyfilled methods though.\n\n\n    if (typeof ctor.getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function') {\n      var foundWillMountName = null;\n      var foundWillReceivePropsName = null;\n      var foundWillUpdateName = null;\n\n      if (typeof instance.componentWillMount === 'function' && instance.componentWillMount.__suppressDeprecationWarning !== true) {\n        foundWillMountName = 'componentWillMount';\n      } else if (typeof instance.UNSAFE_componentWillMount === 'function') {\n        foundWillMountName = 'UNSAFE_componentWillMount';\n      }\n\n      if (typeof instance.componentWillReceiveProps === 'function' && instance.componentWillReceiveProps.__suppressDeprecationWarning !== true) {\n        foundWillReceivePropsName = 'componentWillReceiveProps';\n      } else if (typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n        foundWillReceivePropsName = 'UNSAFE_componentWillReceiveProps';\n      }\n\n      if (typeof instance.componentWillUpdate === 'function' && instance.componentWillUpdate.__suppressDeprecationWarning !== true) {\n        foundWillUpdateName = 'componentWillUpdate';\n      } else if (typeof instance.UNSAFE_componentWillUpdate === 'function') {\n        foundWillUpdateName = 'UNSAFE_componentWillUpdate';\n      }\n\n      if (foundWillMountName !== null || foundWillReceivePropsName !== null || foundWillUpdateName !== null) {\n        var _componentName = getComponentName(ctor) || 'Component';\n\n        var newApiName = typeof ctor.getDerivedStateFromProps === 'function' ? 'getDerivedStateFromProps()' : 'getSnapshotBeforeUpdate()';\n\n        if (!didWarnAboutLegacyLifecyclesAndDerivedState.has(_componentName)) {\n          didWarnAboutLegacyLifecyclesAndDerivedState.add(_componentName);\n\n          error('Unsafe legacy lifecycles will not be called for components using new component APIs.\\n\\n' + '%s uses %s but also contains the following legacy lifecycles:%s%s%s\\n\\n' + 'The above lifecycles should be removed. Learn more about this warning here:\\n' + 'https://reactjs.org/link/unsafe-component-lifecycles', _componentName, newApiName, foundWillMountName !== null ? \"\\n  \" + foundWillMountName : '', foundWillReceivePropsName !== null ? \"\\n  \" + foundWillReceivePropsName : '', foundWillUpdateName !== null ? \"\\n  \" + foundWillUpdateName : '');\n        }\n      }\n    }\n  } // Cache unmasked context so we can avoid recreating masked context unless necessary.\n  // ReactFiberContext usually updates this cache but can't for newly-created instances.\n\n\n  if (isLegacyContextConsumer) {\n    cacheContext(workInProgress, unmaskedContext, context);\n  }\n\n  return instance;\n}\n\nfunction callComponentWillMount(workInProgress, instance) {\n  var oldState = instance.state;\n\n  if (typeof instance.componentWillMount === 'function') {\n    instance.componentWillMount();\n  }\n\n  if (typeof instance.UNSAFE_componentWillMount === 'function') {\n    instance.UNSAFE_componentWillMount();\n  }\n\n  if (oldState !== instance.state) {\n    {\n      error('%s.componentWillMount(): Assigning directly to this.state is ' + \"deprecated (except inside a component's \" + 'constructor). Use setState instead.', getComponentName(workInProgress.type) || 'Component');\n    }\n\n    classComponentUpdater.enqueueReplaceState(instance, instance.state, null);\n  }\n}\n\nfunction callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext) {\n  var oldState = instance.state;\n\n  if (typeof instance.componentWillReceiveProps === 'function') {\n    instance.componentWillReceiveProps(newProps, nextContext);\n  }\n\n  if (typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n    instance.UNSAFE_componentWillReceiveProps(newProps, nextContext);\n  }\n\n  if (instance.state !== oldState) {\n    {\n      var componentName = getComponentName(workInProgress.type) || 'Component';\n\n      if (!didWarnAboutStateAssignmentForComponent.has(componentName)) {\n        didWarnAboutStateAssignmentForComponent.add(componentName);\n\n        error('%s.componentWillReceiveProps(): Assigning directly to ' + \"this.state is deprecated (except inside a component's \" + 'constructor). Use setState instead.', componentName);\n      }\n    }\n\n    classComponentUpdater.enqueueReplaceState(instance, instance.state, null);\n  }\n} // Invokes the mount life-cycles on a previously never rendered instance.\n\n\nfunction mountClassInstance(workInProgress, ctor, newProps, renderLanes) {\n  {\n    checkClassInstance(workInProgress, ctor, newProps);\n  }\n\n  var instance = workInProgress.stateNode;\n  instance.props = newProps;\n  instance.state = workInProgress.memoizedState;\n  instance.refs = emptyRefsObject;\n  initializeUpdateQueue(workInProgress);\n  var contextType = ctor.contextType;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    instance.context = readContext(contextType);\n  } else {\n    var unmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    instance.context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  {\n    if (instance.state === newProps) {\n      var componentName = getComponentName(ctor) || 'Component';\n\n      if (!didWarnAboutDirectlyAssigningPropsToState.has(componentName)) {\n        didWarnAboutDirectlyAssigningPropsToState.add(componentName);\n\n        error('%s: It is not recommended to assign props directly to state ' + \"because updates to props won't be reflected in state. \" + 'In most cases, it is better to use props directly.', componentName);\n      }\n    }\n\n    if (workInProgress.mode & StrictMode) {\n      ReactStrictModeWarnings.recordLegacyContextWarning(workInProgress, instance);\n    }\n\n    {\n      ReactStrictModeWarnings.recordUnsafeLifecycleWarnings(workInProgress, instance);\n    }\n  }\n\n  processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n  instance.state = workInProgress.memoizedState;\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    instance.state = workInProgress.memoizedState;\n  } // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n\n  if (typeof ctor.getDerivedStateFromProps !== 'function' && typeof instance.getSnapshotBeforeUpdate !== 'function' && (typeof instance.UNSAFE_componentWillMount === 'function' || typeof instance.componentWillMount === 'function')) {\n    callComponentWillMount(workInProgress, instance); // If we had additional state updates during this life-cycle, let's\n    // process them now.\n\n    processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n    instance.state = workInProgress.memoizedState;\n  }\n\n  if (typeof instance.componentDidMount === 'function') {\n    workInProgress.flags |= Update;\n  }\n}\n\nfunction resumeMountClassInstance(workInProgress, ctor, newProps, renderLanes) {\n  var instance = workInProgress.stateNode;\n  var oldProps = workInProgress.memoizedProps;\n  instance.props = oldProps;\n  var oldContext = instance.context;\n  var contextType = ctor.contextType;\n  var nextContext = emptyContextObject;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    nextContext = readContext(contextType);\n  } else {\n    var nextLegacyUnmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    nextContext = getMaskedContext(workInProgress, nextLegacyUnmaskedContext);\n  }\n\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n  var hasNewLifecycles = typeof getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function'; // Note: During these life-cycles, instance.props/instance.state are what\n  // ever the previously attempted to render - not the \"current\". However,\n  // during componentDidUpdate we pass the \"current\" props.\n  // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n  if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillReceiveProps === 'function' || typeof instance.componentWillReceiveProps === 'function')) {\n    if (oldProps !== newProps || oldContext !== nextContext) {\n      callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext);\n    }\n  }\n\n  resetHasForceUpdateBeforeProcessing();\n  var oldState = workInProgress.memoizedState;\n  var newState = instance.state = oldState;\n  processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n  newState = workInProgress.memoizedState;\n\n  if (oldProps === newProps && oldState === newState && !hasContextChanged() && !checkHasForceUpdateAfterProcessing()) {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidMount === 'function') {\n      workInProgress.flags |= Update;\n    }\n\n    return false;\n  }\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    newState = workInProgress.memoizedState;\n  }\n\n  var shouldUpdate = checkHasForceUpdateAfterProcessing() || checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext);\n\n  if (shouldUpdate) {\n    // In order to support react-lifecycles-compat polyfilled components,\n    // Unsafe lifecycles should not be invoked for components using the new APIs.\n    if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillMount === 'function' || typeof instance.componentWillMount === 'function')) {\n      if (typeof instance.componentWillMount === 'function') {\n        instance.componentWillMount();\n      }\n\n      if (typeof instance.UNSAFE_componentWillMount === 'function') {\n        instance.UNSAFE_componentWillMount();\n      }\n    }\n\n    if (typeof instance.componentDidMount === 'function') {\n      workInProgress.flags |= Update;\n    }\n  } else {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidMount === 'function') {\n      workInProgress.flags |= Update;\n    } // If shouldComponentUpdate returned false, we should still update the\n    // memoized state to indicate that this work can be reused.\n\n\n    workInProgress.memoizedProps = newProps;\n    workInProgress.memoizedState = newState;\n  } // Update the existing instance's state, props, and context pointers even\n  // if shouldComponentUpdate returns false.\n\n\n  instance.props = newProps;\n  instance.state = newState;\n  instance.context = nextContext;\n  return shouldUpdate;\n} // Invokes the update life-cycles and returns false if it shouldn't rerender.\n\n\nfunction updateClassInstance(current, workInProgress, ctor, newProps, renderLanes) {\n  var instance = workInProgress.stateNode;\n  cloneUpdateQueue(current, workInProgress);\n  var unresolvedOldProps = workInProgress.memoizedProps;\n  var oldProps = workInProgress.type === workInProgress.elementType ? unresolvedOldProps : resolveDefaultProps(workInProgress.type, unresolvedOldProps);\n  instance.props = oldProps;\n  var unresolvedNewProps = workInProgress.pendingProps;\n  var oldContext = instance.context;\n  var contextType = ctor.contextType;\n  var nextContext = emptyContextObject;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    nextContext = readContext(contextType);\n  } else {\n    var nextUnmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    nextContext = getMaskedContext(workInProgress, nextUnmaskedContext);\n  }\n\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n  var hasNewLifecycles = typeof getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function'; // Note: During these life-cycles, instance.props/instance.state are what\n  // ever the previously attempted to render - not the \"current\". However,\n  // during componentDidUpdate we pass the \"current\" props.\n  // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n  if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillReceiveProps === 'function' || typeof instance.componentWillReceiveProps === 'function')) {\n    if (unresolvedOldProps !== unresolvedNewProps || oldContext !== nextContext) {\n      callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext);\n    }\n  }\n\n  resetHasForceUpdateBeforeProcessing();\n  var oldState = workInProgress.memoizedState;\n  var newState = instance.state = oldState;\n  processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n  newState = workInProgress.memoizedState;\n\n  if (unresolvedOldProps === unresolvedNewProps && oldState === newState && !hasContextChanged() && !checkHasForceUpdateAfterProcessing()) {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Update;\n      }\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Snapshot;\n      }\n    }\n\n    return false;\n  }\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    newState = workInProgress.memoizedState;\n  }\n\n  var shouldUpdate = checkHasForceUpdateAfterProcessing() || checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext);\n\n  if (shouldUpdate) {\n    // In order to support react-lifecycles-compat polyfilled components,\n    // Unsafe lifecycles should not be invoked for components using the new APIs.\n    if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillUpdate === 'function' || typeof instance.componentWillUpdate === 'function')) {\n      if (typeof instance.componentWillUpdate === 'function') {\n        instance.componentWillUpdate(newProps, newState, nextContext);\n      }\n\n      if (typeof instance.UNSAFE_componentWillUpdate === 'function') {\n        instance.UNSAFE_componentWillUpdate(newProps, newState, nextContext);\n      }\n    }\n\n    if (typeof instance.componentDidUpdate === 'function') {\n      workInProgress.flags |= Update;\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      workInProgress.flags |= Snapshot;\n    }\n  } else {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Update;\n      }\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Snapshot;\n      }\n    } // If shouldComponentUpdate returned false, we should still update the\n    // memoized props/state to indicate that this work can be reused.\n\n\n    workInProgress.memoizedProps = newProps;\n    workInProgress.memoizedState = newState;\n  } // Update the existing instance's state, props, and context pointers even\n  // if shouldComponentUpdate returns false.\n\n\n  instance.props = newProps;\n  instance.state = newState;\n  instance.context = nextContext;\n  return shouldUpdate;\n}\n\nvar didWarnAboutMaps;\nvar didWarnAboutGenerators;\nvar didWarnAboutStringRefs;\nvar ownerHasKeyUseWarning;\nvar ownerHasFunctionTypeWarning;\n\nvar warnForMissingKey = function (child, returnFiber) {};\n\n{\n  didWarnAboutMaps = false;\n  didWarnAboutGenerators = false;\n  didWarnAboutStringRefs = {};\n  /**\n   * Warn if there's no key explicitly set on dynamic arrays of children or\n   * object keys are not valid. This allows us to keep track of children between\n   * updates.\n   */\n\n  ownerHasKeyUseWarning = {};\n  ownerHasFunctionTypeWarning = {};\n\n  warnForMissingKey = function (child, returnFiber) {\n    if (child === null || typeof child !== 'object') {\n      return;\n    }\n\n    if (!child._store || child._store.validated || child.key != null) {\n      return;\n    }\n\n    if (!(typeof child._store === 'object')) {\n      {\n        throw Error( \"React Component in warnForMissingKey should have a _store. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n\n    child._store.validated = true;\n    var componentName = getComponentName(returnFiber.type) || 'Component';\n\n    if (ownerHasKeyUseWarning[componentName]) {\n      return;\n    }\n\n    ownerHasKeyUseWarning[componentName] = true;\n\n    error('Each child in a list should have a unique ' + '\"key\" prop. See https://reactjs.org/link/warning-keys for ' + 'more information.');\n  };\n}\n\nvar isArray$1 = Array.isArray;\n\nfunction coerceRef(returnFiber, current, element) {\n  var mixedRef = element.ref;\n\n  if (mixedRef !== null && typeof mixedRef !== 'function' && typeof mixedRef !== 'object') {\n    {\n      // TODO: Clean this up once we turn on the string ref warning for\n      // everyone, because the strict mode case will no longer be relevant\n      if ((returnFiber.mode & StrictMode || warnAboutStringRefs) && // We warn in ReactElement.js if owner and self are equal for string refs\n      // because these cannot be automatically converted to an arrow function\n      // using a codemod. Therefore, we don't have to warn about string refs again.\n      !(element._owner && element._self && element._owner.stateNode !== element._self)) {\n        var componentName = getComponentName(returnFiber.type) || 'Component';\n\n        if (!didWarnAboutStringRefs[componentName]) {\n          {\n            error('A string ref, \"%s\", has been found within a strict mode tree. ' + 'String refs are a source of potential bugs and should be avoided. ' + 'We recommend using useRef() or createRef() instead. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-string-ref', mixedRef);\n          }\n\n          didWarnAboutStringRefs[componentName] = true;\n        }\n      }\n    }\n\n    if (element._owner) {\n      var owner = element._owner;\n      var inst;\n\n      if (owner) {\n        var ownerFiber = owner;\n\n        if (!(ownerFiber.tag === ClassComponent)) {\n          {\n            throw Error( \"Function components cannot have string refs. We recommend using useRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\" );\n          }\n        }\n\n        inst = ownerFiber.stateNode;\n      }\n\n      if (!inst) {\n        {\n          throw Error( \"Missing owner for string ref \" + mixedRef + \". This error is likely caused by a bug in React. Please file an issue.\" );\n        }\n      }\n\n      var stringRef = '' + mixedRef; // Check if previous string ref matches new string ref\n\n      if (current !== null && current.ref !== null && typeof current.ref === 'function' && current.ref._stringRef === stringRef) {\n        return current.ref;\n      }\n\n      var ref = function (value) {\n        var refs = inst.refs;\n\n        if (refs === emptyRefsObject) {\n          // This is a lazy pooled frozen object, so we need to initialize.\n          refs = inst.refs = {};\n        }\n\n        if (value === null) {\n          delete refs[stringRef];\n        } else {\n          refs[stringRef] = value;\n        }\n      };\n\n      ref._stringRef = stringRef;\n      return ref;\n    } else {\n      if (!(typeof mixedRef === 'string')) {\n        {\n          throw Error( \"Expected ref to be a function, a string, an object returned by React.createRef(), or null.\" );\n        }\n      }\n\n      if (!element._owner) {\n        {\n          throw Error( \"Element ref was specified as a string (\" + mixedRef + \") but no owner was set. This could happen for one of the following reasons:\\n1. You may be adding a ref to a function component\\n2. You may be adding a ref to a component that was not created inside a component's render method\\n3. You have multiple copies of React loaded\\nSee https://reactjs.org/link/refs-must-have-owner for more information.\" );\n        }\n      }\n    }\n  }\n\n  return mixedRef;\n}\n\nfunction throwOnInvalidObjectType(returnFiber, newChild) {\n  if (returnFiber.type !== 'textarea') {\n    {\n      {\n        throw Error( \"Objects are not valid as a React child (found: \" + (Object.prototype.toString.call(newChild) === '[object Object]' ? 'object with keys {' + Object.keys(newChild).join(', ') + '}' : newChild) + \"). If you meant to render a collection of children, use an array instead.\" );\n      }\n    }\n  }\n}\n\nfunction warnOnFunctionType(returnFiber) {\n  {\n    var componentName = getComponentName(returnFiber.type) || 'Component';\n\n    if (ownerHasFunctionTypeWarning[componentName]) {\n      return;\n    }\n\n    ownerHasFunctionTypeWarning[componentName] = true;\n\n    error('Functions are not valid as a React child. This may happen if ' + 'you return a Component instead of <Component /> from render. ' + 'Or maybe you meant to call this function rather than return it.');\n  }\n} // We avoid inlining this to avoid potential deopts from using try/catch.\n// to be able to optimize each path individually by branching early. This needs\n// a compiler or we can do it manually. Helpers that don't need this branching\n// live outside of this function.\n\n\nfunction ChildReconciler(shouldTrackSideEffects) {\n  function deleteChild(returnFiber, childToDelete) {\n    if (!shouldTrackSideEffects) {\n      // Noop.\n      return;\n    } // Deletions are added in reversed order so we add it to the front.\n    // At this point, the return fiber's effect list is empty except for\n    // deletions, so we can just append the deletion to the list. The remaining\n    // effects aren't added until the complete phase. Once we implement\n    // resuming, this may not be true.\n\n\n    var last = returnFiber.lastEffect;\n\n    if (last !== null) {\n      last.nextEffect = childToDelete;\n      returnFiber.lastEffect = childToDelete;\n    } else {\n      returnFiber.firstEffect = returnFiber.lastEffect = childToDelete;\n    }\n\n    childToDelete.nextEffect = null;\n    childToDelete.flags = Deletion;\n  }\n\n  function deleteRemainingChildren(returnFiber, currentFirstChild) {\n    if (!shouldTrackSideEffects) {\n      // Noop.\n      return null;\n    } // TODO: For the shouldClone case, this could be micro-optimized a bit by\n    // assuming that after the first child we've already added everything.\n\n\n    var childToDelete = currentFirstChild;\n\n    while (childToDelete !== null) {\n      deleteChild(returnFiber, childToDelete);\n      childToDelete = childToDelete.sibling;\n    }\n\n    return null;\n  }\n\n  function mapRemainingChildren(returnFiber, currentFirstChild) {\n    // Add the remaining children to a temporary map so that we can find them by\n    // keys quickly. Implicit (null) keys get added to this set with their index\n    // instead.\n    var existingChildren = new Map();\n    var existingChild = currentFirstChild;\n\n    while (existingChild !== null) {\n      if (existingChild.key !== null) {\n        existingChildren.set(existingChild.key, existingChild);\n      } else {\n        existingChildren.set(existingChild.index, existingChild);\n      }\n\n      existingChild = existingChild.sibling;\n    }\n\n    return existingChildren;\n  }\n\n  function useFiber(fiber, pendingProps) {\n    // We currently set sibling to null and index to 0 here because it is easy\n    // to forget to do before returning it. E.g. for the single child case.\n    var clone = createWorkInProgress(fiber, pendingProps);\n    clone.index = 0;\n    clone.sibling = null;\n    return clone;\n  }\n\n  function placeChild(newFiber, lastPlacedIndex, newIndex) {\n    newFiber.index = newIndex;\n\n    if (!shouldTrackSideEffects) {\n      // Noop.\n      return lastPlacedIndex;\n    }\n\n    var current = newFiber.alternate;\n\n    if (current !== null) {\n      var oldIndex = current.index;\n\n      if (oldIndex < lastPlacedIndex) {\n        // This is a move.\n        newFiber.flags = Placement;\n        return lastPlacedIndex;\n      } else {\n        // This item can stay in place.\n        return oldIndex;\n      }\n    } else {\n      // This is an insertion.\n      newFiber.flags = Placement;\n      return lastPlacedIndex;\n    }\n  }\n\n  function placeSingleChild(newFiber) {\n    // This is simpler for the single child case. We only need to do a\n    // placement for inserting new children.\n    if (shouldTrackSideEffects && newFiber.alternate === null) {\n      newFiber.flags = Placement;\n    }\n\n    return newFiber;\n  }\n\n  function updateTextNode(returnFiber, current, textContent, lanes) {\n    if (current === null || current.tag !== HostText) {\n      // Insert\n      var created = createFiberFromText(textContent, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, textContent);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function updateElement(returnFiber, current, element, lanes) {\n    if (current !== null) {\n      if (current.elementType === element.type || ( // Keep this check inline so it only runs on the false path:\n       isCompatibleFamilyForHotReloading(current, element) )) {\n        // Move based on index\n        var existing = useFiber(current, element.props);\n        existing.ref = coerceRef(returnFiber, current, element);\n        existing.return = returnFiber;\n\n        {\n          existing._debugSource = element._source;\n          existing._debugOwner = element._owner;\n        }\n\n        return existing;\n      }\n    } // Insert\n\n\n    var created = createFiberFromElement(element, returnFiber.mode, lanes);\n    created.ref = coerceRef(returnFiber, current, element);\n    created.return = returnFiber;\n    return created;\n  }\n\n  function updatePortal(returnFiber, current, portal, lanes) {\n    if (current === null || current.tag !== HostPortal || current.stateNode.containerInfo !== portal.containerInfo || current.stateNode.implementation !== portal.implementation) {\n      // Insert\n      var created = createFiberFromPortal(portal, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, portal.children || []);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function updateFragment(returnFiber, current, fragment, lanes, key) {\n    if (current === null || current.tag !== Fragment) {\n      // Insert\n      var created = createFiberFromFragment(fragment, returnFiber.mode, lanes, key);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, fragment);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function createChild(returnFiber, newChild, lanes) {\n    if (typeof newChild === 'string' || typeof newChild === 'number') {\n      // Text nodes don't have keys. If the previous node is implicitly keyed\n      // we can continue to replace it without aborting even if it is not a text\n      // node.\n      var created = createFiberFromText('' + newChild, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            var _created = createFiberFromElement(newChild, returnFiber.mode, lanes);\n\n            _created.ref = coerceRef(returnFiber, null, newChild);\n            _created.return = returnFiber;\n            return _created;\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            var _created2 = createFiberFromPortal(newChild, returnFiber.mode, lanes);\n\n            _created2.return = returnFiber;\n            return _created2;\n          }\n      }\n\n      if (isArray$1(newChild) || getIteratorFn(newChild)) {\n        var _created3 = createFiberFromFragment(newChild, returnFiber.mode, lanes, null);\n\n        _created3.return = returnFiber;\n        return _created3;\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n\n  function updateSlot(returnFiber, oldFiber, newChild, lanes) {\n    // Update the fiber if the keys match, otherwise return null.\n    var key = oldFiber !== null ? oldFiber.key : null;\n\n    if (typeof newChild === 'string' || typeof newChild === 'number') {\n      // Text nodes don't have keys. If the previous node is implicitly keyed\n      // we can continue to replace it without aborting even if it is not a text\n      // node.\n      if (key !== null) {\n        return null;\n      }\n\n      return updateTextNode(returnFiber, oldFiber, '' + newChild, lanes);\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            if (newChild.key === key) {\n              if (newChild.type === REACT_FRAGMENT_TYPE) {\n                return updateFragment(returnFiber, oldFiber, newChild.props.children, lanes, key);\n              }\n\n              return updateElement(returnFiber, oldFiber, newChild, lanes);\n            } else {\n              return null;\n            }\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            if (newChild.key === key) {\n              return updatePortal(returnFiber, oldFiber, newChild, lanes);\n            } else {\n              return null;\n            }\n          }\n      }\n\n      if (isArray$1(newChild) || getIteratorFn(newChild)) {\n        if (key !== null) {\n          return null;\n        }\n\n        return updateFragment(returnFiber, oldFiber, newChild, lanes, null);\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n\n  function updateFromMap(existingChildren, returnFiber, newIdx, newChild, lanes) {\n    if (typeof newChild === 'string' || typeof newChild === 'number') {\n      // Text nodes don't have keys, so we neither have to check the old nor\n      // new node for the key. If both are text nodes, they match.\n      var matchedFiber = existingChildren.get(newIdx) || null;\n      return updateTextNode(returnFiber, matchedFiber, '' + newChild, lanes);\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            var _matchedFiber = existingChildren.get(newChild.key === null ? newIdx : newChild.key) || null;\n\n            if (newChild.type === REACT_FRAGMENT_TYPE) {\n              return updateFragment(returnFiber, _matchedFiber, newChild.props.children, lanes, newChild.key);\n            }\n\n            return updateElement(returnFiber, _matchedFiber, newChild, lanes);\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            var _matchedFiber2 = existingChildren.get(newChild.key === null ? newIdx : newChild.key) || null;\n\n            return updatePortal(returnFiber, _matchedFiber2, newChild, lanes);\n          }\n\n      }\n\n      if (isArray$1(newChild) || getIteratorFn(newChild)) {\n        var _matchedFiber3 = existingChildren.get(newIdx) || null;\n\n        return updateFragment(returnFiber, _matchedFiber3, newChild, lanes, null);\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n  /**\n   * Warns if there is a duplicate or missing key\n   */\n\n\n  function warnOnInvalidKey(child, knownKeys, returnFiber) {\n    {\n      if (typeof child !== 'object' || child === null) {\n        return knownKeys;\n      }\n\n      switch (child.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n        case REACT_PORTAL_TYPE:\n          warnForMissingKey(child, returnFiber);\n          var key = child.key;\n\n          if (typeof key !== 'string') {\n            break;\n          }\n\n          if (knownKeys === null) {\n            knownKeys = new Set();\n            knownKeys.add(key);\n            break;\n          }\n\n          if (!knownKeys.has(key)) {\n            knownKeys.add(key);\n            break;\n          }\n\n          error('Encountered two children with the same key, `%s`. ' + 'Keys should be unique so that components maintain their identity ' + 'across updates. Non-unique keys may cause children to be ' + 'duplicated and/or omitted — the behavior is unsupported and ' + 'could change in a future version.', key);\n\n          break;\n      }\n    }\n\n    return knownKeys;\n  }\n\n  function reconcileChildrenArray(returnFiber, currentFirstChild, newChildren, lanes) {\n    // This algorithm can't optimize by searching from both ends since we\n    // don't have backpointers on fibers. I'm trying to see how far we can get\n    // with that model. If it ends up not being worth the tradeoffs, we can\n    // add it later.\n    // Even with a two ended optimization, we'd want to optimize for the case\n    // where there are few changes and brute force the comparison instead of\n    // going for the Map. It'd like to explore hitting that path first in\n    // forward-only mode and only go for the Map once we notice that we need\n    // lots of look ahead. This doesn't handle reversal as well as two ended\n    // search but that's unusual. Besides, for the two ended optimization to\n    // work on Iterables, we'd need to copy the whole set.\n    // In this first iteration, we'll just live with hitting the bad case\n    // (adding everything to a Map) in for every insert/move.\n    // If you change this code, also update reconcileChildrenIterator() which\n    // uses the same algorithm.\n    {\n      // First, validate keys.\n      var knownKeys = null;\n\n      for (var i = 0; i < newChildren.length; i++) {\n        var child = newChildren[i];\n        knownKeys = warnOnInvalidKey(child, knownKeys, returnFiber);\n      }\n    }\n\n    var resultingFirstChild = null;\n    var previousNewFiber = null;\n    var oldFiber = currentFirstChild;\n    var lastPlacedIndex = 0;\n    var newIdx = 0;\n    var nextOldFiber = null;\n\n    for (; oldFiber !== null && newIdx < newChildren.length; newIdx++) {\n      if (oldFiber.index > newIdx) {\n        nextOldFiber = oldFiber;\n        oldFiber = null;\n      } else {\n        nextOldFiber = oldFiber.sibling;\n      }\n\n      var newFiber = updateSlot(returnFiber, oldFiber, newChildren[newIdx], lanes);\n\n      if (newFiber === null) {\n        // TODO: This breaks on empty slots like null children. That's\n        // unfortunate because it triggers the slow path all the time. We need\n        // a better way to communicate whether this was a miss or null,\n        // boolean, undefined, etc.\n        if (oldFiber === null) {\n          oldFiber = nextOldFiber;\n        }\n\n        break;\n      }\n\n      if (shouldTrackSideEffects) {\n        if (oldFiber && newFiber.alternate === null) {\n          // We matched the slot, but we didn't reuse the existing fiber, so we\n          // need to delete the existing child.\n          deleteChild(returnFiber, oldFiber);\n        }\n      }\n\n      lastPlacedIndex = placeChild(newFiber, lastPlacedIndex, newIdx);\n\n      if (previousNewFiber === null) {\n        // TODO: Move out of the loop. This only happens for the first run.\n        resultingFirstChild = newFiber;\n      } else {\n        // TODO: Defer siblings if we're not at the right index for this slot.\n        // I.e. if we had null values before, then we want to defer this\n        // for each null value. However, we also don't want to call updateSlot\n        // with the previous one.\n        previousNewFiber.sibling = newFiber;\n      }\n\n      previousNewFiber = newFiber;\n      oldFiber = nextOldFiber;\n    }\n\n    if (newIdx === newChildren.length) {\n      // We've reached the end of the new children. We can delete the rest.\n      deleteRemainingChildren(returnFiber, oldFiber);\n      return resultingFirstChild;\n    }\n\n    if (oldFiber === null) {\n      // If we don't have any more existing children we can choose a fast path\n      // since the rest will all be insertions.\n      for (; newIdx < newChildren.length; newIdx++) {\n        var _newFiber = createChild(returnFiber, newChildren[newIdx], lanes);\n\n        if (_newFiber === null) {\n          continue;\n        }\n\n        lastPlacedIndex = placeChild(_newFiber, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          // TODO: Move out of the loop. This only happens for the first run.\n          resultingFirstChild = _newFiber;\n        } else {\n          previousNewFiber.sibling = _newFiber;\n        }\n\n        previousNewFiber = _newFiber;\n      }\n\n      return resultingFirstChild;\n    } // Add all children to a key map for quick lookups.\n\n\n    var existingChildren = mapRemainingChildren(returnFiber, oldFiber); // Keep scanning and use the map to restore deleted items as moves.\n\n    for (; newIdx < newChildren.length; newIdx++) {\n      var _newFiber2 = updateFromMap(existingChildren, returnFiber, newIdx, newChildren[newIdx], lanes);\n\n      if (_newFiber2 !== null) {\n        if (shouldTrackSideEffects) {\n          if (_newFiber2.alternate !== null) {\n            // The new fiber is a work in progress, but if there exists a\n            // current, that means that we reused the fiber. We need to delete\n            // it from the child list so that we don't add it to the deletion\n            // list.\n            existingChildren.delete(_newFiber2.key === null ? newIdx : _newFiber2.key);\n          }\n        }\n\n        lastPlacedIndex = placeChild(_newFiber2, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          resultingFirstChild = _newFiber2;\n        } else {\n          previousNewFiber.sibling = _newFiber2;\n        }\n\n        previousNewFiber = _newFiber2;\n      }\n    }\n\n    if (shouldTrackSideEffects) {\n      // Any existing children that weren't consumed above were deleted. We need\n      // to add them to the deletion list.\n      existingChildren.forEach(function (child) {\n        return deleteChild(returnFiber, child);\n      });\n    }\n\n    return resultingFirstChild;\n  }\n\n  function reconcileChildrenIterator(returnFiber, currentFirstChild, newChildrenIterable, lanes) {\n    // This is the same implementation as reconcileChildrenArray(),\n    // but using the iterator instead.\n    var iteratorFn = getIteratorFn(newChildrenIterable);\n\n    if (!(typeof iteratorFn === 'function')) {\n      {\n        throw Error( \"An object is not an iterable. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n\n    {\n      // We don't support rendering Generators because it's a mutation.\n      // See https://github.com/facebook/react/issues/12995\n      if (typeof Symbol === 'function' && // $FlowFixMe Flow doesn't know about toStringTag\n      newChildrenIterable[Symbol.toStringTag] === 'Generator') {\n        if (!didWarnAboutGenerators) {\n          error('Using Generators as children is unsupported and will likely yield ' + 'unexpected results because enumerating a generator mutates it. ' + 'You may convert it to an array with `Array.from()` or the ' + '`[...spread]` operator before rendering. Keep in mind ' + 'you might need to polyfill these features for older browsers.');\n        }\n\n        didWarnAboutGenerators = true;\n      } // Warn about using Maps as children\n\n\n      if (newChildrenIterable.entries === iteratorFn) {\n        if (!didWarnAboutMaps) {\n          error('Using Maps as children is not supported. ' + 'Use an array of keyed ReactElements instead.');\n        }\n\n        didWarnAboutMaps = true;\n      } // First, validate keys.\n      // We'll get a different iterator later for the main pass.\n\n\n      var _newChildren = iteratorFn.call(newChildrenIterable);\n\n      if (_newChildren) {\n        var knownKeys = null;\n\n        var _step = _newChildren.next();\n\n        for (; !_step.done; _step = _newChildren.next()) {\n          var child = _step.value;\n          knownKeys = warnOnInvalidKey(child, knownKeys, returnFiber);\n        }\n      }\n    }\n\n    var newChildren = iteratorFn.call(newChildrenIterable);\n\n    if (!(newChildren != null)) {\n      {\n        throw Error( \"An iterable object provided no iterator.\" );\n      }\n    }\n\n    var resultingFirstChild = null;\n    var previousNewFiber = null;\n    var oldFiber = currentFirstChild;\n    var lastPlacedIndex = 0;\n    var newIdx = 0;\n    var nextOldFiber = null;\n    var step = newChildren.next();\n\n    for (; oldFiber !== null && !step.done; newIdx++, step = newChildren.next()) {\n      if (oldFiber.index > newIdx) {\n        nextOldFiber = oldFiber;\n        oldFiber = null;\n      } else {\n        nextOldFiber = oldFiber.sibling;\n      }\n\n      var newFiber = updateSlot(returnFiber, oldFiber, step.value, lanes);\n\n      if (newFiber === null) {\n        // TODO: This breaks on empty slots like null children. That's\n        // unfortunate because it triggers the slow path all the time. We need\n        // a better way to communicate whether this was a miss or null,\n        // boolean, undefined, etc.\n        if (oldFiber === null) {\n          oldFiber = nextOldFiber;\n        }\n\n        break;\n      }\n\n      if (shouldTrackSideEffects) {\n        if (oldFiber && newFiber.alternate === null) {\n          // We matched the slot, but we didn't reuse the existing fiber, so we\n          // need to delete the existing child.\n          deleteChild(returnFiber, oldFiber);\n        }\n      }\n\n      lastPlacedIndex = placeChild(newFiber, lastPlacedIndex, newIdx);\n\n      if (previousNewFiber === null) {\n        // TODO: Move out of the loop. This only happens for the first run.\n        resultingFirstChild = newFiber;\n      } else {\n        // TODO: Defer siblings if we're not at the right index for this slot.\n        // I.e. if we had null values before, then we want to defer this\n        // for each null value. However, we also don't want to call updateSlot\n        // with the previous one.\n        previousNewFiber.sibling = newFiber;\n      }\n\n      previousNewFiber = newFiber;\n      oldFiber = nextOldFiber;\n    }\n\n    if (step.done) {\n      // We've reached the end of the new children. We can delete the rest.\n      deleteRemainingChildren(returnFiber, oldFiber);\n      return resultingFirstChild;\n    }\n\n    if (oldFiber === null) {\n      // If we don't have any more existing children we can choose a fast path\n      // since the rest will all be insertions.\n      for (; !step.done; newIdx++, step = newChildren.next()) {\n        var _newFiber3 = createChild(returnFiber, step.value, lanes);\n\n        if (_newFiber3 === null) {\n          continue;\n        }\n\n        lastPlacedIndex = placeChild(_newFiber3, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          // TODO: Move out of the loop. This only happens for the first run.\n          resultingFirstChild = _newFiber3;\n        } else {\n          previousNewFiber.sibling = _newFiber3;\n        }\n\n        previousNewFiber = _newFiber3;\n      }\n\n      return resultingFirstChild;\n    } // Add all children to a key map for quick lookups.\n\n\n    var existingChildren = mapRemainingChildren(returnFiber, oldFiber); // Keep scanning and use the map to restore deleted items as moves.\n\n    for (; !step.done; newIdx++, step = newChildren.next()) {\n      var _newFiber4 = updateFromMap(existingChildren, returnFiber, newIdx, step.value, lanes);\n\n      if (_newFiber4 !== null) {\n        if (shouldTrackSideEffects) {\n          if (_newFiber4.alternate !== null) {\n            // The new fiber is a work in progress, but if there exists a\n            // current, that means that we reused the fiber. We need to delete\n            // it from the child list so that we don't add it to the deletion\n            // list.\n            existingChildren.delete(_newFiber4.key === null ? newIdx : _newFiber4.key);\n          }\n        }\n\n        lastPlacedIndex = placeChild(_newFiber4, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          resultingFirstChild = _newFiber4;\n        } else {\n          previousNewFiber.sibling = _newFiber4;\n        }\n\n        previousNewFiber = _newFiber4;\n      }\n    }\n\n    if (shouldTrackSideEffects) {\n      // Any existing children that weren't consumed above were deleted. We need\n      // to add them to the deletion list.\n      existingChildren.forEach(function (child) {\n        return deleteChild(returnFiber, child);\n      });\n    }\n\n    return resultingFirstChild;\n  }\n\n  function reconcileSingleTextNode(returnFiber, currentFirstChild, textContent, lanes) {\n    // There's no need to check for keys on text nodes since we don't have a\n    // way to define them.\n    if (currentFirstChild !== null && currentFirstChild.tag === HostText) {\n      // We already have an existing node so let's just update it and delete\n      // the rest.\n      deleteRemainingChildren(returnFiber, currentFirstChild.sibling);\n      var existing = useFiber(currentFirstChild, textContent);\n      existing.return = returnFiber;\n      return existing;\n    } // The existing first child is not a text node so we need to create one\n    // and delete the existing ones.\n\n\n    deleteRemainingChildren(returnFiber, currentFirstChild);\n    var created = createFiberFromText(textContent, returnFiber.mode, lanes);\n    created.return = returnFiber;\n    return created;\n  }\n\n  function reconcileSingleElement(returnFiber, currentFirstChild, element, lanes) {\n    var key = element.key;\n    var child = currentFirstChild;\n\n    while (child !== null) {\n      // TODO: If key === null and child.key === null, then this only applies to\n      // the first item in the list.\n      if (child.key === key) {\n        switch (child.tag) {\n          case Fragment:\n            {\n              if (element.type === REACT_FRAGMENT_TYPE) {\n                deleteRemainingChildren(returnFiber, child.sibling);\n                var existing = useFiber(child, element.props.children);\n                existing.return = returnFiber;\n\n                {\n                  existing._debugSource = element._source;\n                  existing._debugOwner = element._owner;\n                }\n\n                return existing;\n              }\n\n              break;\n            }\n\n          case Block:\n\n          // We intentionally fallthrough here if enableBlocksAPI is not on.\n          // eslint-disable-next-lined no-fallthrough\n\n          default:\n            {\n              if (child.elementType === element.type || ( // Keep this check inline so it only runs on the false path:\n               isCompatibleFamilyForHotReloading(child, element) )) {\n                deleteRemainingChildren(returnFiber, child.sibling);\n\n                var _existing3 = useFiber(child, element.props);\n\n                _existing3.ref = coerceRef(returnFiber, child, element);\n                _existing3.return = returnFiber;\n\n                {\n                  _existing3._debugSource = element._source;\n                  _existing3._debugOwner = element._owner;\n                }\n\n                return _existing3;\n              }\n\n              break;\n            }\n        } // Didn't match.\n\n\n        deleteRemainingChildren(returnFiber, child);\n        break;\n      } else {\n        deleteChild(returnFiber, child);\n      }\n\n      child = child.sibling;\n    }\n\n    if (element.type === REACT_FRAGMENT_TYPE) {\n      var created = createFiberFromFragment(element.props.children, returnFiber.mode, lanes, element.key);\n      created.return = returnFiber;\n      return created;\n    } else {\n      var _created4 = createFiberFromElement(element, returnFiber.mode, lanes);\n\n      _created4.ref = coerceRef(returnFiber, currentFirstChild, element);\n      _created4.return = returnFiber;\n      return _created4;\n    }\n  }\n\n  function reconcileSinglePortal(returnFiber, currentFirstChild, portal, lanes) {\n    var key = portal.key;\n    var child = currentFirstChild;\n\n    while (child !== null) {\n      // TODO: If key === null and child.key === null, then this only applies to\n      // the first item in the list.\n      if (child.key === key) {\n        if (child.tag === HostPortal && child.stateNode.containerInfo === portal.containerInfo && child.stateNode.implementation === portal.implementation) {\n          deleteRemainingChildren(returnFiber, child.sibling);\n          var existing = useFiber(child, portal.children || []);\n          existing.return = returnFiber;\n          return existing;\n        } else {\n          deleteRemainingChildren(returnFiber, child);\n          break;\n        }\n      } else {\n        deleteChild(returnFiber, child);\n      }\n\n      child = child.sibling;\n    }\n\n    var created = createFiberFromPortal(portal, returnFiber.mode, lanes);\n    created.return = returnFiber;\n    return created;\n  } // This API will tag the children with the side-effect of the reconciliation\n  // itself. They will be added to the side-effect list as we pass through the\n  // children and the parent.\n\n\n  function reconcileChildFibers(returnFiber, currentFirstChild, newChild, lanes) {\n    // This function is not recursive.\n    // If the top level item is an array, we treat it as a set of children,\n    // not as a fragment. Nested arrays on the other hand will be treated as\n    // fragment nodes. Recursion happens at the normal flow.\n    // Handle top level unkeyed fragments as if they were arrays.\n    // This leads to an ambiguity between <>{[...]}</> and <>...</>.\n    // We treat the ambiguous cases above the same.\n    var isUnkeyedTopLevelFragment = typeof newChild === 'object' && newChild !== null && newChild.type === REACT_FRAGMENT_TYPE && newChild.key === null;\n\n    if (isUnkeyedTopLevelFragment) {\n      newChild = newChild.props.children;\n    } // Handle object types\n\n\n    var isObject = typeof newChild === 'object' && newChild !== null;\n\n    if (isObject) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          return placeSingleChild(reconcileSingleElement(returnFiber, currentFirstChild, newChild, lanes));\n\n        case REACT_PORTAL_TYPE:\n          return placeSingleChild(reconcileSinglePortal(returnFiber, currentFirstChild, newChild, lanes));\n\n      }\n    }\n\n    if (typeof newChild === 'string' || typeof newChild === 'number') {\n      return placeSingleChild(reconcileSingleTextNode(returnFiber, currentFirstChild, '' + newChild, lanes));\n    }\n\n    if (isArray$1(newChild)) {\n      return reconcileChildrenArray(returnFiber, currentFirstChild, newChild, lanes);\n    }\n\n    if (getIteratorFn(newChild)) {\n      return reconcileChildrenIterator(returnFiber, currentFirstChild, newChild, lanes);\n    }\n\n    if (isObject) {\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    if (typeof newChild === 'undefined' && !isUnkeyedTopLevelFragment) {\n      // If the new child is undefined, and the return fiber is a composite\n      // component, throw an error. If Fiber return types are disabled,\n      // we already threw above.\n      switch (returnFiber.tag) {\n        case ClassComponent:\n          {\n            {\n              var instance = returnFiber.stateNode;\n\n              if (instance.render._isMockFunction) {\n                // We allow auto-mocks to proceed as if they're returning null.\n                break;\n              }\n            }\n          }\n        // Intentionally fall through to the next case, which handles both\n        // functions and classes\n        // eslint-disable-next-lined no-fallthrough\n\n        case Block:\n        case FunctionComponent:\n        case ForwardRef:\n        case SimpleMemoComponent:\n          {\n            {\n              {\n                throw Error( (getComponentName(returnFiber.type) || 'Component') + \"(...): Nothing was returned from render. This usually means a return statement is missing. Or, to render nothing, return null.\" );\n              }\n            }\n          }\n      }\n    } // Remaining cases are all treated as empty.\n\n\n    return deleteRemainingChildren(returnFiber, currentFirstChild);\n  }\n\n  return reconcileChildFibers;\n}\n\nvar reconcileChildFibers = ChildReconciler(true);\nvar mountChildFibers = ChildReconciler(false);\nfunction cloneChildFibers(current, workInProgress) {\n  if (!(current === null || workInProgress.child === current.child)) {\n    {\n      throw Error( \"Resuming work not yet implemented.\" );\n    }\n  }\n\n  if (workInProgress.child === null) {\n    return;\n  }\n\n  var currentChild = workInProgress.child;\n  var newChild = createWorkInProgress(currentChild, currentChild.pendingProps);\n  workInProgress.child = newChild;\n  newChild.return = workInProgress;\n\n  while (currentChild.sibling !== null) {\n    currentChild = currentChild.sibling;\n    newChild = newChild.sibling = createWorkInProgress(currentChild, currentChild.pendingProps);\n    newChild.return = workInProgress;\n  }\n\n  newChild.sibling = null;\n} // Reset a workInProgress child set to prepare it for a second pass.\n\nfunction resetChildFibers(workInProgress, lanes) {\n  var child = workInProgress.child;\n\n  while (child !== null) {\n    resetWorkInProgress(child, lanes);\n    child = child.sibling;\n  }\n}\n\nvar NO_CONTEXT = {};\nvar contextStackCursor$1 = createCursor(NO_CONTEXT);\nvar contextFiberStackCursor = createCursor(NO_CONTEXT);\nvar rootInstanceStackCursor = createCursor(NO_CONTEXT);\n\nfunction requiredContext(c) {\n  if (!(c !== NO_CONTEXT)) {\n    {\n      throw Error( \"Expected host context to exist. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n\n  return c;\n}\n\nfunction getRootHostContainer() {\n  var rootInstance = requiredContext(rootInstanceStackCursor.current);\n  return rootInstance;\n}\n\nfunction pushHostContainer(fiber, nextRootInstance) {\n  // Push current root instance onto the stack;\n  // This allows us to reset root when portals are popped.\n  push(rootInstanceStackCursor, nextRootInstance, fiber); // Track the context and the Fiber that provided it.\n  // This enables us to pop only Fibers that provide unique contexts.\n\n  push(contextFiberStackCursor, fiber, fiber); // Finally, we need to push the host context to the stack.\n  // However, we can't just call getRootHostContext() and push it because\n  // we'd have a different number of entries on the stack depending on\n  // whether getRootHostContext() throws somewhere in renderer code or not.\n  // So we push an empty value first. This lets us safely unwind on errors.\n\n  push(contextStackCursor$1, NO_CONTEXT, fiber);\n  var nextRootContext = getRootHostContext(nextRootInstance); // Now that we know this function doesn't throw, replace it.\n\n  pop(contextStackCursor$1, fiber);\n  push(contextStackCursor$1, nextRootContext, fiber);\n}\n\nfunction popHostContainer(fiber) {\n  pop(contextStackCursor$1, fiber);\n  pop(contextFiberStackCursor, fiber);\n  pop(rootInstanceStackCursor, fiber);\n}\n\nfunction getHostContext() {\n  var context = requiredContext(contextStackCursor$1.current);\n  return context;\n}\n\nfunction pushHostContext(fiber) {\n  var rootInstance = requiredContext(rootInstanceStackCursor.current);\n  var context = requiredContext(contextStackCursor$1.current);\n  var nextContext = getChildHostContext(context, fiber.type); // Don't push this Fiber's context unless it's unique.\n\n  if (context === nextContext) {\n    return;\n  } // Track the context and the Fiber that provided it.\n  // This enables us to pop only Fibers that provide unique contexts.\n\n\n  push(contextFiberStackCursor, fiber, fiber);\n  push(contextStackCursor$1, nextContext, fiber);\n}\n\nfunction popHostContext(fiber) {\n  // Do not pop unless this Fiber provided the current context.\n  // pushHostContext() only pushes Fibers that provide unique contexts.\n  if (contextFiberStackCursor.current !== fiber) {\n    return;\n  }\n\n  pop(contextStackCursor$1, fiber);\n  pop(contextFiberStackCursor, fiber);\n}\n\nvar DefaultSuspenseContext = 0; // The Suspense Context is split into two parts. The lower bits is\n// inherited deeply down the subtree. The upper bits only affect\n// this immediate suspense boundary and gets reset each new\n// boundary or suspense list.\n\nvar SubtreeSuspenseContextMask = 1; // Subtree Flags:\n// InvisibleParentSuspenseContext indicates that one of our parent Suspense\n// boundaries is not currently showing visible main content.\n// Either because it is already showing a fallback or is not mounted at all.\n// We can use this to determine if it is desirable to trigger a fallback at\n// the parent. If not, then we might need to trigger undesirable boundaries\n// and/or suspend the commit to avoid hiding the parent content.\n\nvar InvisibleParentSuspenseContext = 1; // Shallow Flags:\n// ForceSuspenseFallback can be used by SuspenseList to force newly added\n// items into their fallback state during one of the render passes.\n\nvar ForceSuspenseFallback = 2;\nvar suspenseStackCursor = createCursor(DefaultSuspenseContext);\nfunction hasSuspenseContext(parentContext, flag) {\n  return (parentContext & flag) !== 0;\n}\nfunction setDefaultShallowSuspenseContext(parentContext) {\n  return parentContext & SubtreeSuspenseContextMask;\n}\nfunction setShallowSuspenseContext(parentContext, shallowContext) {\n  return parentContext & SubtreeSuspenseContextMask | shallowContext;\n}\nfunction addSubtreeSuspenseContext(parentContext, subtreeContext) {\n  return parentContext | subtreeContext;\n}\nfunction pushSuspenseContext(fiber, newContext) {\n  push(suspenseStackCursor, newContext, fiber);\n}\nfunction popSuspenseContext(fiber) {\n  pop(suspenseStackCursor, fiber);\n}\n\nfunction shouldCaptureSuspense(workInProgress, hasInvisibleParent) {\n  // If it was the primary children that just suspended, capture and render the\n  // fallback. Otherwise, don't capture and bubble to the next boundary.\n  var nextState = workInProgress.memoizedState;\n\n  if (nextState !== null) {\n    if (nextState.dehydrated !== null) {\n      // A dehydrated boundary always captures.\n      return true;\n    }\n\n    return false;\n  }\n\n  var props = workInProgress.memoizedProps; // In order to capture, the Suspense component must have a fallback prop.\n\n  if (props.fallback === undefined) {\n    return false;\n  } // Regular boundaries always capture.\n\n\n  if (props.unstable_avoidThisFallback !== true) {\n    return true;\n  } // If it's a boundary we should avoid, then we prefer to bubble up to the\n  // parent boundary if it is currently invisible.\n\n\n  if (hasInvisibleParent) {\n    return false;\n  } // If the parent is not able to handle it, we must handle it.\n\n\n  return true;\n}\nfunction findFirstSuspended(row) {\n  var node = row;\n\n  while (node !== null) {\n    if (node.tag === SuspenseComponent) {\n      var state = node.memoizedState;\n\n      if (state !== null) {\n        var dehydrated = state.dehydrated;\n\n        if (dehydrated === null || isSuspenseInstancePending(dehydrated) || isSuspenseInstanceFallback(dehydrated)) {\n          return node;\n        }\n      }\n    } else if (node.tag === SuspenseListComponent && // revealOrder undefined can't be trusted because it don't\n    // keep track of whether it suspended or not.\n    node.memoizedProps.revealOrder !== undefined) {\n      var didSuspend = (node.flags & DidCapture) !== NoFlags;\n\n      if (didSuspend) {\n        return node;\n      }\n    } else if (node.child !== null) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === row) {\n      return null;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === row) {\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n\n  return null;\n}\n\nvar NoFlags$1 =\n/*  */\n0; // Represents whether effect should fire.\n\nvar HasEffect =\n/* */\n1; // Represents the phase in which the effect (not the clean-up) fires.\n\nvar Layout =\n/*    */\n2;\nvar Passive$1 =\n/*   */\n4;\n\n// This may have been an insertion or a hydration.\n\nvar hydrationParentFiber = null;\nvar nextHydratableInstance = null;\nvar isHydrating = false;\n\nfunction enterHydrationState(fiber) {\n\n  var parentInstance = fiber.stateNode.containerInfo;\n  nextHydratableInstance = getFirstHydratableChild(parentInstance);\n  hydrationParentFiber = fiber;\n  isHydrating = true;\n  return true;\n}\n\nfunction deleteHydratableInstance(returnFiber, instance) {\n  {\n    switch (returnFiber.tag) {\n      case HostRoot:\n        didNotHydrateContainerInstance(returnFiber.stateNode.containerInfo, instance);\n        break;\n\n      case HostComponent:\n        didNotHydrateInstance(returnFiber.type, returnFiber.memoizedProps, returnFiber.stateNode, instance);\n        break;\n    }\n  }\n\n  var childToDelete = createFiberFromHostInstanceForDeletion();\n  childToDelete.stateNode = instance;\n  childToDelete.return = returnFiber;\n  childToDelete.flags = Deletion; // This might seem like it belongs on progressedFirstDeletion. However,\n  // these children are not part of the reconciliation list of children.\n  // Even if we abort and rereconcile the children, that will try to hydrate\n  // again and the nodes are still in the host tree so these will be\n  // recreated.\n\n  if (returnFiber.lastEffect !== null) {\n    returnFiber.lastEffect.nextEffect = childToDelete;\n    returnFiber.lastEffect = childToDelete;\n  } else {\n    returnFiber.firstEffect = returnFiber.lastEffect = childToDelete;\n  }\n}\n\nfunction insertNonHydratedInstance(returnFiber, fiber) {\n  fiber.flags = fiber.flags & ~Hydrating | Placement;\n\n  {\n    switch (returnFiber.tag) {\n      case HostRoot:\n        {\n          var parentContainer = returnFiber.stateNode.containerInfo;\n\n          switch (fiber.tag) {\n            case HostComponent:\n              var type = fiber.type;\n              var props = fiber.pendingProps;\n              didNotFindHydratableContainerInstance(parentContainer, type);\n              break;\n\n            case HostText:\n              var text = fiber.pendingProps;\n              didNotFindHydratableContainerTextInstance(parentContainer, text);\n              break;\n          }\n\n          break;\n        }\n\n      case HostComponent:\n        {\n          var parentType = returnFiber.type;\n          var parentProps = returnFiber.memoizedProps;\n          var parentInstance = returnFiber.stateNode;\n\n          switch (fiber.tag) {\n            case HostComponent:\n              var _type = fiber.type;\n              var _props = fiber.pendingProps;\n              didNotFindHydratableInstance(parentType, parentProps, parentInstance, _type);\n              break;\n\n            case HostText:\n              var _text = fiber.pendingProps;\n              didNotFindHydratableTextInstance(parentType, parentProps, parentInstance, _text);\n              break;\n\n            case SuspenseComponent:\n              didNotFindHydratableSuspenseInstance(parentType, parentProps);\n              break;\n          }\n\n          break;\n        }\n\n      default:\n        return;\n    }\n  }\n}\n\nfunction tryHydrate(fiber, nextInstance) {\n  switch (fiber.tag) {\n    case HostComponent:\n      {\n        var type = fiber.type;\n        var props = fiber.pendingProps;\n        var instance = canHydrateInstance(nextInstance, type);\n\n        if (instance !== null) {\n          fiber.stateNode = instance;\n          return true;\n        }\n\n        return false;\n      }\n\n    case HostText:\n      {\n        var text = fiber.pendingProps;\n        var textInstance = canHydrateTextInstance(nextInstance, text);\n\n        if (textInstance !== null) {\n          fiber.stateNode = textInstance;\n          return true;\n        }\n\n        return false;\n      }\n\n    case SuspenseComponent:\n      {\n\n        return false;\n      }\n\n    default:\n      return false;\n  }\n}\n\nfunction tryToClaimNextHydratableInstance(fiber) {\n  if (!isHydrating) {\n    return;\n  }\n\n  var nextInstance = nextHydratableInstance;\n\n  if (!nextInstance) {\n    // Nothing to hydrate. Make it an insertion.\n    insertNonHydratedInstance(hydrationParentFiber, fiber);\n    isHydrating = false;\n    hydrationParentFiber = fiber;\n    return;\n  }\n\n  var firstAttemptedInstance = nextInstance;\n\n  if (!tryHydrate(fiber, nextInstance)) {\n    // If we can't hydrate this instance let's try the next one.\n    // We use this as a heuristic. It's based on intuition and not data so it\n    // might be flawed or unnecessary.\n    nextInstance = getNextHydratableSibling(firstAttemptedInstance);\n\n    if (!nextInstance || !tryHydrate(fiber, nextInstance)) {\n      // Nothing to hydrate. Make it an insertion.\n      insertNonHydratedInstance(hydrationParentFiber, fiber);\n      isHydrating = false;\n      hydrationParentFiber = fiber;\n      return;\n    } // We matched the next one, we'll now assume that the first one was\n    // superfluous and we'll delete it. Since we can't eagerly delete it\n    // we'll have to schedule a deletion. To do that, this node needs a dummy\n    // fiber associated with it.\n\n\n    deleteHydratableInstance(hydrationParentFiber, firstAttemptedInstance);\n  }\n\n  hydrationParentFiber = fiber;\n  nextHydratableInstance = getFirstHydratableChild(nextInstance);\n}\n\nfunction prepareToHydrateHostInstance(fiber, rootContainerInstance, hostContext) {\n\n  var instance = fiber.stateNode;\n  var updatePayload = hydrateInstance(instance, fiber.type, fiber.memoizedProps, rootContainerInstance, hostContext, fiber); // TODO: Type this specific to this type of component.\n\n  fiber.updateQueue = updatePayload; // If the update payload indicates that there is a change or if there\n  // is a new ref we mark this as an update.\n\n  if (updatePayload !== null) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction prepareToHydrateHostTextInstance(fiber) {\n\n  var textInstance = fiber.stateNode;\n  var textContent = fiber.memoizedProps;\n  var shouldUpdate = hydrateTextInstance(textInstance, textContent, fiber);\n\n  {\n    if (shouldUpdate) {\n      // We assume that prepareToHydrateHostTextInstance is called in a context where the\n      // hydration parent is the parent host component of this host text.\n      var returnFiber = hydrationParentFiber;\n\n      if (returnFiber !== null) {\n        switch (returnFiber.tag) {\n          case HostRoot:\n            {\n              var parentContainer = returnFiber.stateNode.containerInfo;\n              didNotMatchHydratedContainerTextInstance(parentContainer, textInstance, textContent);\n              break;\n            }\n\n          case HostComponent:\n            {\n              var parentType = returnFiber.type;\n              var parentProps = returnFiber.memoizedProps;\n              var parentInstance = returnFiber.stateNode;\n              didNotMatchHydratedTextInstance(parentType, parentProps, parentInstance, textInstance, textContent);\n              break;\n            }\n        }\n      }\n    }\n  }\n\n  return shouldUpdate;\n}\n\nfunction skipPastDehydratedSuspenseInstance(fiber) {\n\n  var suspenseState = fiber.memoizedState;\n  var suspenseInstance = suspenseState !== null ? suspenseState.dehydrated : null;\n\n  if (!suspenseInstance) {\n    {\n      throw Error( \"Expected to have a hydrated suspense instance. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n\n  return getNextHydratableInstanceAfterSuspenseInstance(suspenseInstance);\n}\n\nfunction popToNextHostParent(fiber) {\n  var parent = fiber.return;\n\n  while (parent !== null && parent.tag !== HostComponent && parent.tag !== HostRoot && parent.tag !== SuspenseComponent) {\n    parent = parent.return;\n  }\n\n  hydrationParentFiber = parent;\n}\n\nfunction popHydrationState(fiber) {\n\n  if (fiber !== hydrationParentFiber) {\n    // We're deeper than the current hydration context, inside an inserted\n    // tree.\n    return false;\n  }\n\n  if (!isHydrating) {\n    // If we're not currently hydrating but we're in a hydration context, then\n    // we were an insertion and now need to pop up reenter hydration of our\n    // siblings.\n    popToNextHostParent(fiber);\n    isHydrating = true;\n    return false;\n  }\n\n  var type = fiber.type; // If we have any remaining hydratable nodes, we need to delete them now.\n  // We only do this deeper than head and body since they tend to have random\n  // other nodes in them. We also ignore components with pure text content in\n  // side of them.\n  // TODO: Better heuristic.\n\n  if (fiber.tag !== HostComponent || type !== 'head' && type !== 'body' && !shouldSetTextContent(type, fiber.memoizedProps)) {\n    var nextInstance = nextHydratableInstance;\n\n    while (nextInstance) {\n      deleteHydratableInstance(fiber, nextInstance);\n      nextInstance = getNextHydratableSibling(nextInstance);\n    }\n  }\n\n  popToNextHostParent(fiber);\n\n  if (fiber.tag === SuspenseComponent) {\n    nextHydratableInstance = skipPastDehydratedSuspenseInstance(fiber);\n  } else {\n    nextHydratableInstance = hydrationParentFiber ? getNextHydratableSibling(fiber.stateNode) : null;\n  }\n\n  return true;\n}\n\nfunction resetHydrationState() {\n\n  hydrationParentFiber = null;\n  nextHydratableInstance = null;\n  isHydrating = false;\n}\n\nfunction getIsHydrating() {\n  return isHydrating;\n}\n\n// and should be reset before starting a new render.\n// This tracks which mutable sources need to be reset after a render.\n\nvar workInProgressSources = [];\nvar rendererSigil$1;\n\n{\n  // Used to detect multiple renderers using the same mutable source.\n  rendererSigil$1 = {};\n}\n\nfunction markSourceAsDirty(mutableSource) {\n  workInProgressSources.push(mutableSource);\n}\nfunction resetWorkInProgressVersions() {\n  for (var i = 0; i < workInProgressSources.length; i++) {\n    var mutableSource = workInProgressSources[i];\n\n    {\n      mutableSource._workInProgressVersionPrimary = null;\n    }\n  }\n\n  workInProgressSources.length = 0;\n}\nfunction getWorkInProgressVersion(mutableSource) {\n  {\n    return mutableSource._workInProgressVersionPrimary;\n  }\n}\nfunction setWorkInProgressVersion(mutableSource, version) {\n  {\n    mutableSource._workInProgressVersionPrimary = version;\n  }\n\n  workInProgressSources.push(mutableSource);\n}\nfunction warnAboutMultipleRenderersDEV(mutableSource) {\n  {\n    {\n      if (mutableSource._currentPrimaryRenderer == null) {\n        mutableSource._currentPrimaryRenderer = rendererSigil$1;\n      } else if (mutableSource._currentPrimaryRenderer !== rendererSigil$1) {\n        error('Detected multiple renderers concurrently rendering the ' + 'same mutable source. This is currently unsupported.');\n      }\n    }\n  }\n} // Eager reads the version of a mutable source and stores it on the root.\n\nvar ReactCurrentDispatcher$1 = ReactSharedInternals.ReactCurrentDispatcher,\n    ReactCurrentBatchConfig$1 = ReactSharedInternals.ReactCurrentBatchConfig;\nvar didWarnAboutMismatchedHooksForComponent;\nvar didWarnAboutUseOpaqueIdentifier;\n\n{\n  didWarnAboutUseOpaqueIdentifier = {};\n  didWarnAboutMismatchedHooksForComponent = new Set();\n}\n\n// These are set right before calling the component.\nvar renderLanes = NoLanes; // The work-in-progress fiber. I've named it differently to distinguish it from\n// the work-in-progress hook.\n\nvar currentlyRenderingFiber$1 = null; // Hooks are stored as a linked list on the fiber's memoizedState field. The\n// current hook list is the list that belongs to the current fiber. The\n// work-in-progress hook list is a new list that will be added to the\n// work-in-progress fiber.\n\nvar currentHook = null;\nvar workInProgressHook = null; // Whether an update was scheduled at any point during the render phase. This\n// does not get reset if we do another render pass; only when we're completely\n// finished evaluating this component. This is an optimization so we know\n// whether we need to clear render phase updates after a throw.\n\nvar didScheduleRenderPhaseUpdate = false; // Where an update was scheduled only during the current render pass. This\n// gets reset after each attempt.\n// TODO: Maybe there's some way to consolidate this with\n// `didScheduleRenderPhaseUpdate`. Or with `numberOfReRenders`.\n\nvar didScheduleRenderPhaseUpdateDuringThisPass = false;\nvar RE_RENDER_LIMIT = 25; // In DEV, this is the name of the currently executing primitive hook\n\nvar currentHookNameInDev = null; // In DEV, this list ensures that hooks are called in the same order between renders.\n// The list stores the order of hooks used during the initial render (mount).\n// Subsequent renders (updates) reference this list.\n\nvar hookTypesDev = null;\nvar hookTypesUpdateIndexDev = -1; // In DEV, this tracks whether currently rendering component needs to ignore\n// the dependencies for Hooks that need them (e.g. useEffect or useMemo).\n// When true, such Hooks will always be \"remounted\". Only used during hot reload.\n\nvar ignorePreviousDependencies = false;\n\nfunction mountHookTypesDev() {\n  {\n    var hookName = currentHookNameInDev;\n\n    if (hookTypesDev === null) {\n      hookTypesDev = [hookName];\n    } else {\n      hookTypesDev.push(hookName);\n    }\n  }\n}\n\nfunction updateHookTypesDev() {\n  {\n    var hookName = currentHookNameInDev;\n\n    if (hookTypesDev !== null) {\n      hookTypesUpdateIndexDev++;\n\n      if (hookTypesDev[hookTypesUpdateIndexDev] !== hookName) {\n        warnOnHookMismatchInDev(hookName);\n      }\n    }\n  }\n}\n\nfunction checkDepsAreArrayDev(deps) {\n  {\n    if (deps !== undefined && deps !== null && !Array.isArray(deps)) {\n      // Verify deps, but only on mount to avoid extra checks.\n      // It's unlikely their type would change as usually you define them inline.\n      error('%s received a final argument that is not an array (instead, received `%s`). When ' + 'specified, the final argument must be an array.', currentHookNameInDev, typeof deps);\n    }\n  }\n}\n\nfunction warnOnHookMismatchInDev(currentHookName) {\n  {\n    var componentName = getComponentName(currentlyRenderingFiber$1.type);\n\n    if (!didWarnAboutMismatchedHooksForComponent.has(componentName)) {\n      didWarnAboutMismatchedHooksForComponent.add(componentName);\n\n      if (hookTypesDev !== null) {\n        var table = '';\n        var secondColumnStart = 30;\n\n        for (var i = 0; i <= hookTypesUpdateIndexDev; i++) {\n          var oldHookName = hookTypesDev[i];\n          var newHookName = i === hookTypesUpdateIndexDev ? currentHookName : oldHookName;\n          var row = i + 1 + \". \" + oldHookName; // Extra space so second column lines up\n          // lol @ IE not supporting String#repeat\n\n          while (row.length < secondColumnStart) {\n            row += ' ';\n          }\n\n          row += newHookName + '\\n';\n          table += row;\n        }\n\n        error('React has detected a change in the order of Hooks called by %s. ' + 'This will lead to bugs and errors if not fixed. ' + 'For more information, read the Rules of Hooks: https://reactjs.org/link/rules-of-hooks\\n\\n' + '   Previous render            Next render\\n' + '   ------------------------------------------------------\\n' + '%s' + '   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', componentName, table);\n      }\n    }\n  }\n}\n\nfunction throwInvalidHookError() {\n  {\n    {\n      throw Error( \"Invalid hook call. Hooks can only be called inside of the body of a function component. This could happen for one of the following reasons:\\n1. You might have mismatching versions of React and the renderer (such as React DOM)\\n2. You might be breaking the Rules of Hooks\\n3. You might have more than one copy of React in the same app\\nSee https://reactjs.org/link/invalid-hook-call for tips about how to debug and fix this problem.\" );\n    }\n  }\n}\n\nfunction areHookInputsEqual(nextDeps, prevDeps) {\n  {\n    if (ignorePreviousDependencies) {\n      // Only true when this component is being hot reloaded.\n      return false;\n    }\n  }\n\n  if (prevDeps === null) {\n    {\n      error('%s received a final argument during this render, but not during ' + 'the previous render. Even though the final argument is optional, ' + 'its type cannot change between renders.', currentHookNameInDev);\n    }\n\n    return false;\n  }\n\n  {\n    // Don't bother comparing lengths in prod because these arrays should be\n    // passed inline.\n    if (nextDeps.length !== prevDeps.length) {\n      error('The final argument passed to %s changed size between renders. The ' + 'order and size of this array must remain constant.\\n\\n' + 'Previous: %s\\n' + 'Incoming: %s', currentHookNameInDev, \"[\" + prevDeps.join(', ') + \"]\", \"[\" + nextDeps.join(', ') + \"]\");\n    }\n  }\n\n  for (var i = 0; i < prevDeps.length && i < nextDeps.length; i++) {\n    if (objectIs(nextDeps[i], prevDeps[i])) {\n      continue;\n    }\n\n    return false;\n  }\n\n  return true;\n}\n\nfunction renderWithHooks(current, workInProgress, Component, props, secondArg, nextRenderLanes) {\n  renderLanes = nextRenderLanes;\n  currentlyRenderingFiber$1 = workInProgress;\n\n  {\n    hookTypesDev = current !== null ? current._debugHookTypes : null;\n    hookTypesUpdateIndexDev = -1; // Used for hot reloading:\n\n    ignorePreviousDependencies = current !== null && current.type !== workInProgress.type;\n  }\n\n  workInProgress.memoizedState = null;\n  workInProgress.updateQueue = null;\n  workInProgress.lanes = NoLanes; // The following should have already been reset\n  // currentHook = null;\n  // workInProgressHook = null;\n  // didScheduleRenderPhaseUpdate = false;\n  // TODO Warn if no hooks are used at all during mount, then some are used during update.\n  // Currently we will identify the update render as a mount because memoizedState === null.\n  // This is tricky because it's valid for certain types of components (e.g. React.lazy)\n  // Using memoizedState to differentiate between mount/update only works if at least one stateful hook is used.\n  // Non-stateful hooks (e.g. context) don't get added to memoizedState,\n  // so memoizedState would be null during updates and mounts.\n\n  {\n    if (current !== null && current.memoizedState !== null) {\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnUpdateInDEV;\n    } else if (hookTypesDev !== null) {\n      // This dispatcher handles an edge case where a component is updating,\n      // but no stateful hooks have been used.\n      // We want to match the production code behavior (which will use HooksDispatcherOnMount),\n      // but with the extra DEV validation to ensure hooks ordering hasn't changed.\n      // This dispatcher does that.\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnMountWithHookTypesInDEV;\n    } else {\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnMountInDEV;\n    }\n  }\n\n  var children = Component(props, secondArg); // Check if there was a render phase update\n\n  if (didScheduleRenderPhaseUpdateDuringThisPass) {\n    // Keep rendering in a loop for as long as render phase updates continue to\n    // be scheduled. Use a counter to prevent infinite loops.\n    var numberOfReRenders = 0;\n\n    do {\n      didScheduleRenderPhaseUpdateDuringThisPass = false;\n\n      if (!(numberOfReRenders < RE_RENDER_LIMIT)) {\n        {\n          throw Error( \"Too many re-renders. React limits the number of renders to prevent an infinite loop.\" );\n        }\n      }\n\n      numberOfReRenders += 1;\n\n      {\n        // Even when hot reloading, allow dependencies to stabilize\n        // after first render to prevent infinite render phase updates.\n        ignorePreviousDependencies = false;\n      } // Start over from the beginning of the list\n\n\n      currentHook = null;\n      workInProgressHook = null;\n      workInProgress.updateQueue = null;\n\n      {\n        // Also validate hook order for cascading updates.\n        hookTypesUpdateIndexDev = -1;\n      }\n\n      ReactCurrentDispatcher$1.current =  HooksDispatcherOnRerenderInDEV ;\n      children = Component(props, secondArg);\n    } while (didScheduleRenderPhaseUpdateDuringThisPass);\n  } // We can assume the previous dispatcher is always this one, since we set it\n  // at the beginning of the render phase and there's no re-entrancy.\n\n\n  ReactCurrentDispatcher$1.current = ContextOnlyDispatcher;\n\n  {\n    workInProgress._debugHookTypes = hookTypesDev;\n  } // This check uses currentHook so that it works the same in DEV and prod bundles.\n  // hookTypesDev could catch more cases (e.g. context) but only in DEV bundles.\n\n\n  var didRenderTooFewHooks = currentHook !== null && currentHook.next !== null;\n  renderLanes = NoLanes;\n  currentlyRenderingFiber$1 = null;\n  currentHook = null;\n  workInProgressHook = null;\n\n  {\n    currentHookNameInDev = null;\n    hookTypesDev = null;\n    hookTypesUpdateIndexDev = -1;\n  }\n\n  didScheduleRenderPhaseUpdate = false;\n\n  if (!!didRenderTooFewHooks) {\n    {\n      throw Error( \"Rendered fewer hooks than expected. This may be caused by an accidental early return statement.\" );\n    }\n  }\n\n  return children;\n}\nfunction bailoutHooks(current, workInProgress, lanes) {\n  workInProgress.updateQueue = current.updateQueue;\n  workInProgress.flags &= ~(Passive | Update);\n  current.lanes = removeLanes(current.lanes, lanes);\n}\nfunction resetHooksAfterThrow() {\n  // We can assume the previous dispatcher is always this one, since we set it\n  // at the beginning of the render phase and there's no re-entrancy.\n  ReactCurrentDispatcher$1.current = ContextOnlyDispatcher;\n\n  if (didScheduleRenderPhaseUpdate) {\n    // There were render phase updates. These are only valid for this render\n    // phase, which we are now aborting. Remove the updates from the queues so\n    // they do not persist to the next render. Do not remove updates from hooks\n    // that weren't processed.\n    //\n    // Only reset the updates from the queue if it has a clone. If it does\n    // not have a clone, that means it wasn't processed, and the updates were\n    // scheduled before we entered the render phase.\n    var hook = currentlyRenderingFiber$1.memoizedState;\n\n    while (hook !== null) {\n      var queue = hook.queue;\n\n      if (queue !== null) {\n        queue.pending = null;\n      }\n\n      hook = hook.next;\n    }\n\n    didScheduleRenderPhaseUpdate = false;\n  }\n\n  renderLanes = NoLanes;\n  currentlyRenderingFiber$1 = null;\n  currentHook = null;\n  workInProgressHook = null;\n\n  {\n    hookTypesDev = null;\n    hookTypesUpdateIndexDev = -1;\n    currentHookNameInDev = null;\n    isUpdatingOpaqueValueInRenderPhase = false;\n  }\n\n  didScheduleRenderPhaseUpdateDuringThisPass = false;\n}\n\nfunction mountWorkInProgressHook() {\n  var hook = {\n    memoizedState: null,\n    baseState: null,\n    baseQueue: null,\n    queue: null,\n    next: null\n  };\n\n  if (workInProgressHook === null) {\n    // This is the first hook in the list\n    currentlyRenderingFiber$1.memoizedState = workInProgressHook = hook;\n  } else {\n    // Append to the end of the list\n    workInProgressHook = workInProgressHook.next = hook;\n  }\n\n  return workInProgressHook;\n}\n\nfunction updateWorkInProgressHook() {\n  // This function is used both for updates and for re-renders triggered by a\n  // render phase update. It assumes there is either a current hook we can\n  // clone, or a work-in-progress hook from a previous render pass that we can\n  // use as a base. When we reach the end of the base list, we must switch to\n  // the dispatcher used for mounts.\n  var nextCurrentHook;\n\n  if (currentHook === null) {\n    var current = currentlyRenderingFiber$1.alternate;\n\n    if (current !== null) {\n      nextCurrentHook = current.memoizedState;\n    } else {\n      nextCurrentHook = null;\n    }\n  } else {\n    nextCurrentHook = currentHook.next;\n  }\n\n  var nextWorkInProgressHook;\n\n  if (workInProgressHook === null) {\n    nextWorkInProgressHook = currentlyRenderingFiber$1.memoizedState;\n  } else {\n    nextWorkInProgressHook = workInProgressHook.next;\n  }\n\n  if (nextWorkInProgressHook !== null) {\n    // There's already a work-in-progress. Reuse it.\n    workInProgressHook = nextWorkInProgressHook;\n    nextWorkInProgressHook = workInProgressHook.next;\n    currentHook = nextCurrentHook;\n  } else {\n    // Clone from the current hook.\n    if (!(nextCurrentHook !== null)) {\n      {\n        throw Error( \"Rendered more hooks than during the previous render.\" );\n      }\n    }\n\n    currentHook = nextCurrentHook;\n    var newHook = {\n      memoizedState: currentHook.memoizedState,\n      baseState: currentHook.baseState,\n      baseQueue: currentHook.baseQueue,\n      queue: currentHook.queue,\n      next: null\n    };\n\n    if (workInProgressHook === null) {\n      // This is the first hook in the list.\n      currentlyRenderingFiber$1.memoizedState = workInProgressHook = newHook;\n    } else {\n      // Append to the end of the list.\n      workInProgressHook = workInProgressHook.next = newHook;\n    }\n  }\n\n  return workInProgressHook;\n}\n\nfunction createFunctionComponentUpdateQueue() {\n  return {\n    lastEffect: null\n  };\n}\n\nfunction basicStateReducer(state, action) {\n  // $FlowFixMe: Flow doesn't like mixed types\n  return typeof action === 'function' ? action(state) : action;\n}\n\nfunction mountReducer(reducer, initialArg, init) {\n  var hook = mountWorkInProgressHook();\n  var initialState;\n\n  if (init !== undefined) {\n    initialState = init(initialArg);\n  } else {\n    initialState = initialArg;\n  }\n\n  hook.memoizedState = hook.baseState = initialState;\n  var queue = hook.queue = {\n    pending: null,\n    dispatch: null,\n    lastRenderedReducer: reducer,\n    lastRenderedState: initialState\n  };\n  var dispatch = queue.dispatch = dispatchAction.bind(null, currentlyRenderingFiber$1, queue);\n  return [hook.memoizedState, dispatch];\n}\n\nfunction updateReducer(reducer, initialArg, init) {\n  var hook = updateWorkInProgressHook();\n  var queue = hook.queue;\n\n  if (!(queue !== null)) {\n    {\n      throw Error( \"Should have a queue. This is likely a bug in React. Please file an issue.\" );\n    }\n  }\n\n  queue.lastRenderedReducer = reducer;\n  var current = currentHook; // The last rebase update that is NOT part of the base state.\n\n  var baseQueue = current.baseQueue; // The last pending update that hasn't been processed yet.\n\n  var pendingQueue = queue.pending;\n\n  if (pendingQueue !== null) {\n    // We have new updates that haven't been processed yet.\n    // We'll add them to the base queue.\n    if (baseQueue !== null) {\n      // Merge the pending queue and the base queue.\n      var baseFirst = baseQueue.next;\n      var pendingFirst = pendingQueue.next;\n      baseQueue.next = pendingFirst;\n      pendingQueue.next = baseFirst;\n    }\n\n    {\n      if (current.baseQueue !== baseQueue) {\n        // Internal invariant that should never happen, but feasibly could in\n        // the future if we implement resuming, or some form of that.\n        error('Internal error: Expected work-in-progress queue to be a clone. ' + 'This is a bug in React.');\n      }\n    }\n\n    current.baseQueue = baseQueue = pendingQueue;\n    queue.pending = null;\n  }\n\n  if (baseQueue !== null) {\n    // We have a queue to process.\n    var first = baseQueue.next;\n    var newState = current.baseState;\n    var newBaseState = null;\n    var newBaseQueueFirst = null;\n    var newBaseQueueLast = null;\n    var update = first;\n\n    do {\n      var updateLane = update.lane;\n\n      if (!isSubsetOfLanes(renderLanes, updateLane)) {\n        // Priority is insufficient. Skip this update. If this is the first\n        // skipped update, the previous update/state is the new base\n        // update/state.\n        var clone = {\n          lane: updateLane,\n          action: update.action,\n          eagerReducer: update.eagerReducer,\n          eagerState: update.eagerState,\n          next: null\n        };\n\n        if (newBaseQueueLast === null) {\n          newBaseQueueFirst = newBaseQueueLast = clone;\n          newBaseState = newState;\n        } else {\n          newBaseQueueLast = newBaseQueueLast.next = clone;\n        } // Update the remaining priority in the queue.\n        // TODO: Don't need to accumulate this. Instead, we can remove\n        // renderLanes from the original lanes.\n\n\n        currentlyRenderingFiber$1.lanes = mergeLanes(currentlyRenderingFiber$1.lanes, updateLane);\n        markSkippedUpdateLanes(updateLane);\n      } else {\n        // This update does have sufficient priority.\n        if (newBaseQueueLast !== null) {\n          var _clone = {\n            // This update is going to be committed so we never want uncommit\n            // it. Using NoLane works because 0 is a subset of all bitmasks, so\n            // this will never be skipped by the check above.\n            lane: NoLane,\n            action: update.action,\n            eagerReducer: update.eagerReducer,\n            eagerState: update.eagerState,\n            next: null\n          };\n          newBaseQueueLast = newBaseQueueLast.next = _clone;\n        } // Process this update.\n\n\n        if (update.eagerReducer === reducer) {\n          // If this update was processed eagerly, and its reducer matches the\n          // current reducer, we can use the eagerly computed state.\n          newState = update.eagerState;\n        } else {\n          var action = update.action;\n          newState = reducer(newState, action);\n        }\n      }\n\n      update = update.next;\n    } while (update !== null && update !== first);\n\n    if (newBaseQueueLast === null) {\n      newBaseState = newState;\n    } else {\n      newBaseQueueLast.next = newBaseQueueFirst;\n    } // Mark that the fiber performed work, but only if the new state is\n    // different from the current state.\n\n\n    if (!objectIs(newState, hook.memoizedState)) {\n      markWorkInProgressReceivedUpdate();\n    }\n\n    hook.memoizedState = newState;\n    hook.baseState = newBaseState;\n    hook.baseQueue = newBaseQueueLast;\n    queue.lastRenderedState = newState;\n  }\n\n  var dispatch = queue.dispatch;\n  return [hook.memoizedState, dispatch];\n}\n\nfunction rerenderReducer(reducer, initialArg, init) {\n  var hook = updateWorkInProgressHook();\n  var queue = hook.queue;\n\n  if (!(queue !== null)) {\n    {\n      throw Error( \"Should have a queue. This is likely a bug in React. Please file an issue.\" );\n    }\n  }\n\n  queue.lastRenderedReducer = reducer; // This is a re-render. Apply the new render phase updates to the previous\n  // work-in-progress hook.\n\n  var dispatch = queue.dispatch;\n  var lastRenderPhaseUpdate = queue.pending;\n  var newState = hook.memoizedState;\n\n  if (lastRenderPhaseUpdate !== null) {\n    // The queue doesn't persist past this render pass.\n    queue.pending = null;\n    var firstRenderPhaseUpdate = lastRenderPhaseUpdate.next;\n    var update = firstRenderPhaseUpdate;\n\n    do {\n      // Process this render phase update. We don't have to check the\n      // priority because it will always be the same as the current\n      // render's.\n      var action = update.action;\n      newState = reducer(newState, action);\n      update = update.next;\n    } while (update !== firstRenderPhaseUpdate); // Mark that the fiber performed work, but only if the new state is\n    // different from the current state.\n\n\n    if (!objectIs(newState, hook.memoizedState)) {\n      markWorkInProgressReceivedUpdate();\n    }\n\n    hook.memoizedState = newState; // Don't persist the state accumulated from the render phase updates to\n    // the base state unless the queue is empty.\n    // TODO: Not sure if this is the desired semantics, but it's what we\n    // do for gDSFP. I can't remember why.\n\n    if (hook.baseQueue === null) {\n      hook.baseState = newState;\n    }\n\n    queue.lastRenderedState = newState;\n  }\n\n  return [newState, dispatch];\n}\n\nfunction readFromUnsubcribedMutableSource(root, source, getSnapshot) {\n  {\n    warnAboutMultipleRenderersDEV(source);\n  }\n\n  var getVersion = source._getVersion;\n  var version = getVersion(source._source); // Is it safe for this component to read from this source during the current render?\n\n  var isSafeToReadFromSource = false; // Check the version first.\n  // If this render has already been started with a specific version,\n  // we can use it alone to determine if we can safely read from the source.\n\n  var currentRenderVersion = getWorkInProgressVersion(source);\n\n  if (currentRenderVersion !== null) {\n    // It's safe to read if the store hasn't been mutated since the last time\n    // we read something.\n    isSafeToReadFromSource = currentRenderVersion === version;\n  } else {\n    // If there's no version, then this is the first time we've read from the\n    // source during the current render pass, so we need to do a bit more work.\n    // What we need to determine is if there are any hooks that already\n    // subscribed to the source, and if so, whether there are any pending\n    // mutations that haven't been synchronized yet.\n    //\n    // If there are no pending mutations, then `root.mutableReadLanes` will be\n    // empty, and we know we can safely read.\n    //\n    // If there *are* pending mutations, we may still be able to safely read\n    // if the currently rendering lanes are inclusive of the pending mutation\n    // lanes, since that guarantees that the value we're about to read from\n    // the source is consistent with the values that we read during the most\n    // recent mutation.\n    isSafeToReadFromSource = isSubsetOfLanes(renderLanes, root.mutableReadLanes);\n\n    if (isSafeToReadFromSource) {\n      // If it's safe to read from this source during the current render,\n      // store the version in case other components read from it.\n      // A changed version number will let those components know to throw and restart the render.\n      setWorkInProgressVersion(source, version);\n    }\n  }\n\n  if (isSafeToReadFromSource) {\n    var snapshot = getSnapshot(source._source);\n\n    {\n      if (typeof snapshot === 'function') {\n        error('Mutable source should not return a function as the snapshot value. ' + 'Functions may close over mutable values and cause tearing.');\n      }\n    }\n\n    return snapshot;\n  } else {\n    // This handles the special case of a mutable source being shared between renderers.\n    // In that case, if the source is mutated between the first and second renderer,\n    // The second renderer don't know that it needs to reset the WIP version during unwind,\n    // (because the hook only marks sources as dirty if it's written to their WIP version).\n    // That would cause this tear check to throw again and eventually be visible to the user.\n    // We can avoid this infinite loop by explicitly marking the source as dirty.\n    //\n    // This can lead to tearing in the first renderer when it resumes,\n    // but there's nothing we can do about that (short of throwing here and refusing to continue the render).\n    markSourceAsDirty(source);\n\n    {\n      {\n        throw Error( \"Cannot read from mutable source during the current render without tearing. This is a bug in React. Please file an issue.\" );\n      }\n    }\n  }\n}\n\nfunction useMutableSource(hook, source, getSnapshot, subscribe) {\n  var root = getWorkInProgressRoot();\n\n  if (!(root !== null)) {\n    {\n      throw Error( \"Expected a work-in-progress root. This is a bug in React. Please file an issue.\" );\n    }\n  }\n\n  var getVersion = source._getVersion;\n  var version = getVersion(source._source);\n  var dispatcher = ReactCurrentDispatcher$1.current; // eslint-disable-next-line prefer-const\n\n  var _dispatcher$useState = dispatcher.useState(function () {\n    return readFromUnsubcribedMutableSource(root, source, getSnapshot);\n  }),\n      currentSnapshot = _dispatcher$useState[0],\n      setSnapshot = _dispatcher$useState[1];\n\n  var snapshot = currentSnapshot; // Grab a handle to the state hook as well.\n  // We use it to clear the pending update queue if we have a new source.\n\n  var stateHook = workInProgressHook;\n  var memoizedState = hook.memoizedState;\n  var refs = memoizedState.refs;\n  var prevGetSnapshot = refs.getSnapshot;\n  var prevSource = memoizedState.source;\n  var prevSubscribe = memoizedState.subscribe;\n  var fiber = currentlyRenderingFiber$1;\n  hook.memoizedState = {\n    refs: refs,\n    source: source,\n    subscribe: subscribe\n  }; // Sync the values needed by our subscription handler after each commit.\n\n  dispatcher.useEffect(function () {\n    refs.getSnapshot = getSnapshot; // Normally the dispatch function for a state hook never changes,\n    // but this hook recreates the queue in certain cases  to avoid updates from stale sources.\n    // handleChange() below needs to reference the dispatch function without re-subscribing,\n    // so we use a ref to ensure that it always has the latest version.\n\n    refs.setSnapshot = setSnapshot; // Check for a possible change between when we last rendered now.\n\n    var maybeNewVersion = getVersion(source._source);\n\n    if (!objectIs(version, maybeNewVersion)) {\n      var maybeNewSnapshot = getSnapshot(source._source);\n\n      {\n        if (typeof maybeNewSnapshot === 'function') {\n          error('Mutable source should not return a function as the snapshot value. ' + 'Functions may close over mutable values and cause tearing.');\n        }\n      }\n\n      if (!objectIs(snapshot, maybeNewSnapshot)) {\n        setSnapshot(maybeNewSnapshot);\n        var lane = requestUpdateLane(fiber);\n        markRootMutableRead(root, lane);\n      } // If the source mutated between render and now,\n      // there may be state updates already scheduled from the old source.\n      // Entangle the updates so that they render in the same batch.\n\n\n      markRootEntangled(root, root.mutableReadLanes);\n    }\n  }, [getSnapshot, source, subscribe]); // If we got a new source or subscribe function, re-subscribe in a passive effect.\n\n  dispatcher.useEffect(function () {\n    var handleChange = function () {\n      var latestGetSnapshot = refs.getSnapshot;\n      var latestSetSnapshot = refs.setSnapshot;\n\n      try {\n        latestSetSnapshot(latestGetSnapshot(source._source)); // Record a pending mutable source update with the same expiration time.\n\n        var lane = requestUpdateLane(fiber);\n        markRootMutableRead(root, lane);\n      } catch (error) {\n        // A selector might throw after a source mutation.\n        // e.g. it might try to read from a part of the store that no longer exists.\n        // In this case we should still schedule an update with React.\n        // Worst case the selector will throw again and then an error boundary will handle it.\n        latestSetSnapshot(function () {\n          throw error;\n        });\n      }\n    };\n\n    var unsubscribe = subscribe(source._source, handleChange);\n\n    {\n      if (typeof unsubscribe !== 'function') {\n        error('Mutable source subscribe function must return an unsubscribe function.');\n      }\n    }\n\n    return unsubscribe;\n  }, [source, subscribe]); // If any of the inputs to useMutableSource change, reading is potentially unsafe.\n  //\n  // If either the source or the subscription have changed we can't can't trust the update queue.\n  // Maybe the source changed in a way that the old subscription ignored but the new one depends on.\n  //\n  // If the getSnapshot function changed, we also shouldn't rely on the update queue.\n  // It's possible that the underlying source was mutated between the when the last \"change\" event fired,\n  // and when the current render (with the new getSnapshot function) is processed.\n  //\n  // In both cases, we need to throw away pending updates (since they are no longer relevant)\n  // and treat reading from the source as we do in the mount case.\n\n  if (!objectIs(prevGetSnapshot, getSnapshot) || !objectIs(prevSource, source) || !objectIs(prevSubscribe, subscribe)) {\n    // Create a new queue and setState method,\n    // So if there are interleaved updates, they get pushed to the older queue.\n    // When this becomes current, the previous queue and dispatch method will be discarded,\n    // including any interleaving updates that occur.\n    var newQueue = {\n      pending: null,\n      dispatch: null,\n      lastRenderedReducer: basicStateReducer,\n      lastRenderedState: snapshot\n    };\n    newQueue.dispatch = setSnapshot = dispatchAction.bind(null, currentlyRenderingFiber$1, newQueue);\n    stateHook.queue = newQueue;\n    stateHook.baseQueue = null;\n    snapshot = readFromUnsubcribedMutableSource(root, source, getSnapshot);\n    stateHook.memoizedState = stateHook.baseState = snapshot;\n  }\n\n  return snapshot;\n}\n\nfunction mountMutableSource(source, getSnapshot, subscribe) {\n  var hook = mountWorkInProgressHook();\n  hook.memoizedState = {\n    refs: {\n      getSnapshot: getSnapshot,\n      setSnapshot: null\n    },\n    source: source,\n    subscribe: subscribe\n  };\n  return useMutableSource(hook, source, getSnapshot, subscribe);\n}\n\nfunction updateMutableSource(source, getSnapshot, subscribe) {\n  var hook = updateWorkInProgressHook();\n  return useMutableSource(hook, source, getSnapshot, subscribe);\n}\n\nfunction mountState(initialState) {\n  var hook = mountWorkInProgressHook();\n\n  if (typeof initialState === 'function') {\n    // $FlowFixMe: Flow doesn't like mixed types\n    initialState = initialState();\n  }\n\n  hook.memoizedState = hook.baseState = initialState;\n  var queue = hook.queue = {\n    pending: null,\n    dispatch: null,\n    lastRenderedReducer: basicStateReducer,\n    lastRenderedState: initialState\n  };\n  var dispatch = queue.dispatch = dispatchAction.bind(null, currentlyRenderingFiber$1, queue);\n  return [hook.memoizedState, dispatch];\n}\n\nfunction updateState(initialState) {\n  return updateReducer(basicStateReducer);\n}\n\nfunction rerenderState(initialState) {\n  return rerenderReducer(basicStateReducer);\n}\n\nfunction pushEffect(tag, create, destroy, deps) {\n  var effect = {\n    tag: tag,\n    create: create,\n    destroy: destroy,\n    deps: deps,\n    // Circular\n    next: null\n  };\n  var componentUpdateQueue = currentlyRenderingFiber$1.updateQueue;\n\n  if (componentUpdateQueue === null) {\n    componentUpdateQueue = createFunctionComponentUpdateQueue();\n    currentlyRenderingFiber$1.updateQueue = componentUpdateQueue;\n    componentUpdateQueue.lastEffect = effect.next = effect;\n  } else {\n    var lastEffect = componentUpdateQueue.lastEffect;\n\n    if (lastEffect === null) {\n      componentUpdateQueue.lastEffect = effect.next = effect;\n    } else {\n      var firstEffect = lastEffect.next;\n      lastEffect.next = effect;\n      effect.next = firstEffect;\n      componentUpdateQueue.lastEffect = effect;\n    }\n  }\n\n  return effect;\n}\n\nfunction mountRef(initialValue) {\n  var hook = mountWorkInProgressHook();\n  var ref = {\n    current: initialValue\n  };\n\n  {\n    Object.seal(ref);\n  }\n\n  hook.memoizedState = ref;\n  return ref;\n}\n\nfunction updateRef(initialValue) {\n  var hook = updateWorkInProgressHook();\n  return hook.memoizedState;\n}\n\nfunction mountEffectImpl(fiberFlags, hookFlags, create, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  currentlyRenderingFiber$1.flags |= fiberFlags;\n  hook.memoizedState = pushEffect(HasEffect | hookFlags, create, undefined, nextDeps);\n}\n\nfunction updateEffectImpl(fiberFlags, hookFlags, create, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var destroy = undefined;\n\n  if (currentHook !== null) {\n    var prevEffect = currentHook.memoizedState;\n    destroy = prevEffect.destroy;\n\n    if (nextDeps !== null) {\n      var prevDeps = prevEffect.deps;\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        pushEffect(hookFlags, create, destroy, nextDeps);\n        return;\n      }\n    }\n  }\n\n  currentlyRenderingFiber$1.flags |= fiberFlags;\n  hook.memoizedState = pushEffect(HasEffect | hookFlags, create, destroy, nextDeps);\n}\n\nfunction mountEffect(create, deps) {\n  {\n    // $FlowExpectedError - jest isn't a global, and isn't recognized outside of tests\n    if ('undefined' !== typeof jest) {\n      warnIfNotCurrentlyActingEffectsInDEV(currentlyRenderingFiber$1);\n    }\n  }\n\n  return mountEffectImpl(Update | Passive, Passive$1, create, deps);\n}\n\nfunction updateEffect(create, deps) {\n  {\n    // $FlowExpectedError - jest isn't a global, and isn't recognized outside of tests\n    if ('undefined' !== typeof jest) {\n      warnIfNotCurrentlyActingEffectsInDEV(currentlyRenderingFiber$1);\n    }\n  }\n\n  return updateEffectImpl(Update | Passive, Passive$1, create, deps);\n}\n\nfunction mountLayoutEffect(create, deps) {\n  return mountEffectImpl(Update, Layout, create, deps);\n}\n\nfunction updateLayoutEffect(create, deps) {\n  return updateEffectImpl(Update, Layout, create, deps);\n}\n\nfunction imperativeHandleEffect(create, ref) {\n  if (typeof ref === 'function') {\n    var refCallback = ref;\n\n    var _inst = create();\n\n    refCallback(_inst);\n    return function () {\n      refCallback(null);\n    };\n  } else if (ref !== null && ref !== undefined) {\n    var refObject = ref;\n\n    {\n      if (!refObject.hasOwnProperty('current')) {\n        error('Expected useImperativeHandle() first argument to either be a ' + 'ref callback or React.createRef() object. Instead received: %s.', 'an object with keys {' + Object.keys(refObject).join(', ') + '}');\n      }\n    }\n\n    var _inst2 = create();\n\n    refObject.current = _inst2;\n    return function () {\n      refObject.current = null;\n    };\n  }\n}\n\nfunction mountImperativeHandle(ref, create, deps) {\n  {\n    if (typeof create !== 'function') {\n      error('Expected useImperativeHandle() second argument to be a function ' + 'that creates a handle. Instead received: %s.', create !== null ? typeof create : 'null');\n    }\n  } // TODO: If deps are provided, should we skip comparing the ref itself?\n\n\n  var effectDeps = deps !== null && deps !== undefined ? deps.concat([ref]) : null;\n  return mountEffectImpl(Update, Layout, imperativeHandleEffect.bind(null, create, ref), effectDeps);\n}\n\nfunction updateImperativeHandle(ref, create, deps) {\n  {\n    if (typeof create !== 'function') {\n      error('Expected useImperativeHandle() second argument to be a function ' + 'that creates a handle. Instead received: %s.', create !== null ? typeof create : 'null');\n    }\n  } // TODO: If deps are provided, should we skip comparing the ref itself?\n\n\n  var effectDeps = deps !== null && deps !== undefined ? deps.concat([ref]) : null;\n  return updateEffectImpl(Update, Layout, imperativeHandleEffect.bind(null, create, ref), effectDeps);\n}\n\nfunction mountDebugValue(value, formatterFn) {// This hook is normally a no-op.\n  // The react-debug-hooks package injects its own implementation\n  // so that e.g. DevTools can display custom hook values.\n}\n\nvar updateDebugValue = mountDebugValue;\n\nfunction mountCallback(callback, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  hook.memoizedState = [callback, nextDeps];\n  return callback;\n}\n\nfunction updateCallback(callback, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var prevState = hook.memoizedState;\n\n  if (prevState !== null) {\n    if (nextDeps !== null) {\n      var prevDeps = prevState[1];\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        return prevState[0];\n      }\n    }\n  }\n\n  hook.memoizedState = [callback, nextDeps];\n  return callback;\n}\n\nfunction mountMemo(nextCreate, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var nextValue = nextCreate();\n  hook.memoizedState = [nextValue, nextDeps];\n  return nextValue;\n}\n\nfunction updateMemo(nextCreate, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var prevState = hook.memoizedState;\n\n  if (prevState !== null) {\n    // Assume these are defined. If they're not, areHookInputsEqual will warn.\n    if (nextDeps !== null) {\n      var prevDeps = prevState[1];\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        return prevState[0];\n      }\n    }\n  }\n\n  var nextValue = nextCreate();\n  hook.memoizedState = [nextValue, nextDeps];\n  return nextValue;\n}\n\nfunction mountDeferredValue(value) {\n  var _mountState = mountState(value),\n      prevValue = _mountState[0],\n      setValue = _mountState[1];\n\n  mountEffect(function () {\n    var prevTransition = ReactCurrentBatchConfig$1.transition;\n    ReactCurrentBatchConfig$1.transition = 1;\n\n    try {\n      setValue(value);\n    } finally {\n      ReactCurrentBatchConfig$1.transition = prevTransition;\n    }\n  }, [value]);\n  return prevValue;\n}\n\nfunction updateDeferredValue(value) {\n  var _updateState = updateState(),\n      prevValue = _updateState[0],\n      setValue = _updateState[1];\n\n  updateEffect(function () {\n    var prevTransition = ReactCurrentBatchConfig$1.transition;\n    ReactCurrentBatchConfig$1.transition = 1;\n\n    try {\n      setValue(value);\n    } finally {\n      ReactCurrentBatchConfig$1.transition = prevTransition;\n    }\n  }, [value]);\n  return prevValue;\n}\n\nfunction rerenderDeferredValue(value) {\n  var _rerenderState = rerenderState(),\n      prevValue = _rerenderState[0],\n      setValue = _rerenderState[1];\n\n  updateEffect(function () {\n    var prevTransition = ReactCurrentBatchConfig$1.transition;\n    ReactCurrentBatchConfig$1.transition = 1;\n\n    try {\n      setValue(value);\n    } finally {\n      ReactCurrentBatchConfig$1.transition = prevTransition;\n    }\n  }, [value]);\n  return prevValue;\n}\n\nfunction startTransition(setPending, callback) {\n  var priorityLevel = getCurrentPriorityLevel();\n\n  {\n    runWithPriority$1(priorityLevel < UserBlockingPriority$2 ? UserBlockingPriority$2 : priorityLevel, function () {\n      setPending(true);\n    });\n    runWithPriority$1(priorityLevel > NormalPriority$1 ? NormalPriority$1 : priorityLevel, function () {\n      var prevTransition = ReactCurrentBatchConfig$1.transition;\n      ReactCurrentBatchConfig$1.transition = 1;\n\n      try {\n        setPending(false);\n        callback();\n      } finally {\n        ReactCurrentBatchConfig$1.transition = prevTransition;\n      }\n    });\n  }\n}\n\nfunction mountTransition() {\n  var _mountState2 = mountState(false),\n      isPending = _mountState2[0],\n      setPending = _mountState2[1]; // The `start` method can be stored on a ref, since `setPending`\n  // never changes.\n\n\n  var start = startTransition.bind(null, setPending);\n  mountRef(start);\n  return [start, isPending];\n}\n\nfunction updateTransition() {\n  var _updateState2 = updateState(),\n      isPending = _updateState2[0];\n\n  var startRef = updateRef();\n  var start = startRef.current;\n  return [start, isPending];\n}\n\nfunction rerenderTransition() {\n  var _rerenderState2 = rerenderState(),\n      isPending = _rerenderState2[0];\n\n  var startRef = updateRef();\n  var start = startRef.current;\n  return [start, isPending];\n}\n\nvar isUpdatingOpaqueValueInRenderPhase = false;\nfunction getIsUpdatingOpaqueValueInRenderPhaseInDEV() {\n  {\n    return isUpdatingOpaqueValueInRenderPhase;\n  }\n}\n\nfunction warnOnOpaqueIdentifierAccessInDEV(fiber) {\n  {\n    // TODO: Should warn in effects and callbacks, too\n    var name = getComponentName(fiber.type) || 'Unknown';\n\n    if (getIsRendering() && !didWarnAboutUseOpaqueIdentifier[name]) {\n      error('The object passed back from useOpaqueIdentifier is meant to be ' + 'passed through to attributes only. Do not read the ' + 'value directly.');\n\n      didWarnAboutUseOpaqueIdentifier[name] = true;\n    }\n  }\n}\n\nfunction mountOpaqueIdentifier() {\n  var makeId =  makeClientIdInDEV.bind(null, warnOnOpaqueIdentifierAccessInDEV.bind(null, currentlyRenderingFiber$1)) ;\n\n  if (getIsHydrating()) {\n    var didUpgrade = false;\n    var fiber = currentlyRenderingFiber$1;\n\n    var readValue = function () {\n      if (!didUpgrade) {\n        // Only upgrade once. This works even inside the render phase because\n        // the update is added to a shared queue, which outlasts the\n        // in-progress render.\n        didUpgrade = true;\n\n        {\n          isUpdatingOpaqueValueInRenderPhase = true;\n          setId(makeId());\n          isUpdatingOpaqueValueInRenderPhase = false;\n          warnOnOpaqueIdentifierAccessInDEV(fiber);\n        }\n      }\n\n      {\n        {\n          throw Error( \"The object passed back from useOpaqueIdentifier is meant to be passed through to attributes only. Do not read the value directly.\" );\n        }\n      }\n    };\n\n    var id = makeOpaqueHydratingObject(readValue);\n    var setId = mountState(id)[1];\n\n    if ((currentlyRenderingFiber$1.mode & BlockingMode) === NoMode) {\n      currentlyRenderingFiber$1.flags |= Update | Passive;\n      pushEffect(HasEffect | Passive$1, function () {\n        setId(makeId());\n      }, undefined, null);\n    }\n\n    return id;\n  } else {\n    var _id = makeId();\n\n    mountState(_id);\n    return _id;\n  }\n}\n\nfunction updateOpaqueIdentifier() {\n  var id = updateState()[0];\n  return id;\n}\n\nfunction rerenderOpaqueIdentifier() {\n  var id = rerenderState()[0];\n  return id;\n}\n\nfunction dispatchAction(fiber, queue, action) {\n  {\n    if (typeof arguments[3] === 'function') {\n      error(\"State updates from the useState() and useReducer() Hooks don't support the \" + 'second callback argument. To execute a side effect after ' + 'rendering, declare it in the component body with useEffect().');\n    }\n  }\n\n  var eventTime = requestEventTime();\n  var lane = requestUpdateLane(fiber);\n  var update = {\n    lane: lane,\n    action: action,\n    eagerReducer: null,\n    eagerState: null,\n    next: null\n  }; // Append the update to the end of the list.\n\n  var pending = queue.pending;\n\n  if (pending === null) {\n    // This is the first update. Create a circular list.\n    update.next = update;\n  } else {\n    update.next = pending.next;\n    pending.next = update;\n  }\n\n  queue.pending = update;\n  var alternate = fiber.alternate;\n\n  if (fiber === currentlyRenderingFiber$1 || alternate !== null && alternate === currentlyRenderingFiber$1) {\n    // This is a render phase update. Stash it in a lazily-created map of\n    // queue -> linked list of updates. After this render pass, we'll restart\n    // and apply the stashed updates on top of the work-in-progress hook.\n    didScheduleRenderPhaseUpdateDuringThisPass = didScheduleRenderPhaseUpdate = true;\n  } else {\n    if (fiber.lanes === NoLanes && (alternate === null || alternate.lanes === NoLanes)) {\n      // The queue is currently empty, which means we can eagerly compute the\n      // next state before entering the render phase. If the new state is the\n      // same as the current state, we may be able to bail out entirely.\n      var lastRenderedReducer = queue.lastRenderedReducer;\n\n      if (lastRenderedReducer !== null) {\n        var prevDispatcher;\n\n        {\n          prevDispatcher = ReactCurrentDispatcher$1.current;\n          ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n        }\n\n        try {\n          var currentState = queue.lastRenderedState;\n          var eagerState = lastRenderedReducer(currentState, action); // Stash the eagerly computed state, and the reducer used to compute\n          // it, on the update object. If the reducer hasn't changed by the\n          // time we enter the render phase, then the eager state can be used\n          // without calling the reducer again.\n\n          update.eagerReducer = lastRenderedReducer;\n          update.eagerState = eagerState;\n\n          if (objectIs(eagerState, currentState)) {\n            // Fast path. We can bail out without scheduling React to re-render.\n            // It's still possible that we'll need to rebase this update later,\n            // if the component re-renders for a different reason and by that\n            // time the reducer has changed.\n            return;\n          }\n        } catch (error) {// Suppress the error. It will throw again in the render phase.\n        } finally {\n          {\n            ReactCurrentDispatcher$1.current = prevDispatcher;\n          }\n        }\n      }\n    }\n\n    {\n      // $FlowExpectedError - jest isn't a global, and isn't recognized outside of tests\n      if ('undefined' !== typeof jest) {\n        warnIfNotScopedWithMatchingAct(fiber);\n        warnIfNotCurrentlyActingUpdatesInDev(fiber);\n      }\n    }\n\n    scheduleUpdateOnFiber(fiber, lane, eventTime);\n  }\n}\n\nvar ContextOnlyDispatcher = {\n  readContext: readContext,\n  useCallback: throwInvalidHookError,\n  useContext: throwInvalidHookError,\n  useEffect: throwInvalidHookError,\n  useImperativeHandle: throwInvalidHookError,\n  useLayoutEffect: throwInvalidHookError,\n  useMemo: throwInvalidHookError,\n  useReducer: throwInvalidHookError,\n  useRef: throwInvalidHookError,\n  useState: throwInvalidHookError,\n  useDebugValue: throwInvalidHookError,\n  useDeferredValue: throwInvalidHookError,\n  useTransition: throwInvalidHookError,\n  useMutableSource: throwInvalidHookError,\n  useOpaqueIdentifier: throwInvalidHookError,\n  unstable_isNewReconciler: enableNewReconciler\n};\nvar HooksDispatcherOnMountInDEV = null;\nvar HooksDispatcherOnMountWithHookTypesInDEV = null;\nvar HooksDispatcherOnUpdateInDEV = null;\nvar HooksDispatcherOnRerenderInDEV = null;\nvar InvalidNestedHooksDispatcherOnMountInDEV = null;\nvar InvalidNestedHooksDispatcherOnUpdateInDEV = null;\nvar InvalidNestedHooksDispatcherOnRerenderInDEV = null;\n\n{\n  var warnInvalidContextAccess = function () {\n    error('Context can only be read while React is rendering. ' + 'In classes, you can read it in the render method or getDerivedStateFromProps. ' + 'In function components, you can read it directly in the function body, but not ' + 'inside Hooks like useReducer() or useMemo().');\n  };\n\n  var warnInvalidHookAccess = function () {\n    error('Do not call Hooks inside useEffect(...), useMemo(...), or other built-in Hooks. ' + 'You can only call Hooks at the top level of your React function. ' + 'For more information, see ' + 'https://reactjs.org/link/rules-of-hooks');\n  };\n\n  HooksDispatcherOnMountInDEV = {\n    readContext: function (context, observedBits) {\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      mountHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      mountHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      mountHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      mountHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      mountHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      mountHookTypesDev();\n      return mountMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      mountHookTypesDev();\n      return mountOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  HooksDispatcherOnMountWithHookTypesInDEV = {\n    readContext: function (context, observedBits) {\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return mountMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      updateHookTypesDev();\n      return mountOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  HooksDispatcherOnUpdateInDEV = {\n    readContext: function (context, observedBits) {\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return updateDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return updateTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return updateMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      updateHookTypesDev();\n      return updateOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  HooksDispatcherOnRerenderInDEV = {\n    readContext: function (context, observedBits) {\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return rerenderReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return rerenderState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return rerenderDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return rerenderTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return updateMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      updateHookTypesDev();\n      return rerenderOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  InvalidNestedHooksDispatcherOnMountInDEV = {\n    readContext: function (context, observedBits) {\n      warnInvalidContextAccess();\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  InvalidNestedHooksDispatcherOnUpdateInDEV = {\n    readContext: function (context, observedBits) {\n      warnInvalidContextAccess();\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n  InvalidNestedHooksDispatcherOnRerenderInDEV = {\n    readContext: function (context, observedBits) {\n      warnInvalidContextAccess();\n      return readContext(context, observedBits);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context, observedBits) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return readContext(context, observedBits);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return rerenderReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return rerenderState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return rerenderDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return rerenderTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateMutableSource(source, getSnapshot, subscribe);\n    },\n    useOpaqueIdentifier: function () {\n      currentHookNameInDev = 'useOpaqueIdentifier';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return rerenderOpaqueIdentifier();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n}\n\nvar now$1 = Scheduler.unstable_now;\nvar commitTime = 0;\nvar profilerStartTime = -1;\n\nfunction getCommitTime() {\n  return commitTime;\n}\n\nfunction recordCommitTime() {\n\n  commitTime = now$1();\n}\n\nfunction startProfilerTimer(fiber) {\n\n  profilerStartTime = now$1();\n\n  if (fiber.actualStartTime < 0) {\n    fiber.actualStartTime = now$1();\n  }\n}\n\nfunction stopProfilerTimerIfRunning(fiber) {\n\n  profilerStartTime = -1;\n}\n\nfunction stopProfilerTimerIfRunningAndRecordDelta(fiber, overrideBaseTime) {\n\n  if (profilerStartTime >= 0) {\n    var elapsedTime = now$1() - profilerStartTime;\n    fiber.actualDuration += elapsedTime;\n\n    if (overrideBaseTime) {\n      fiber.selfBaseDuration = elapsedTime;\n    }\n\n    profilerStartTime = -1;\n  }\n}\n\nfunction transferActualDuration(fiber) {\n  // Transfer time spent rendering these children so we don't lose it\n  // after we rerender. This is used as a helper in special cases\n  // where we should count the work of multiple passes.\n  var child = fiber.child;\n\n  while (child) {\n    fiber.actualDuration += child.actualDuration;\n    child = child.sibling;\n  }\n}\n\nvar ReactCurrentOwner$1 = ReactSharedInternals.ReactCurrentOwner;\nvar didReceiveUpdate = false;\nvar didWarnAboutBadClass;\nvar didWarnAboutModulePatternComponent;\nvar didWarnAboutContextTypeOnFunctionComponent;\nvar didWarnAboutGetDerivedStateOnFunctionComponent;\nvar didWarnAboutFunctionRefs;\nvar didWarnAboutReassigningProps;\nvar didWarnAboutRevealOrder;\nvar didWarnAboutTailOptions;\n\n{\n  didWarnAboutBadClass = {};\n  didWarnAboutModulePatternComponent = {};\n  didWarnAboutContextTypeOnFunctionComponent = {};\n  didWarnAboutGetDerivedStateOnFunctionComponent = {};\n  didWarnAboutFunctionRefs = {};\n  didWarnAboutReassigningProps = false;\n  didWarnAboutRevealOrder = {};\n  didWarnAboutTailOptions = {};\n}\n\nfunction reconcileChildren(current, workInProgress, nextChildren, renderLanes) {\n  if (current === null) {\n    // If this is a fresh new component that hasn't been rendered yet, we\n    // won't update its child set by applying minimal side-effects. Instead,\n    // we will add them all to the child before it gets rendered. That means\n    // we can optimize this reconciliation pass by not tracking side-effects.\n    workInProgress.child = mountChildFibers(workInProgress, null, nextChildren, renderLanes);\n  } else {\n    // If the current child is the same as the work in progress, it means that\n    // we haven't yet started any work on these children. Therefore, we use\n    // the clone algorithm to create a copy of all the current children.\n    // If we had any progressed work already, that is invalid at this point so\n    // let's throw it out.\n    workInProgress.child = reconcileChildFibers(workInProgress, current.child, nextChildren, renderLanes);\n  }\n}\n\nfunction forceUnmountCurrentAndReconcile(current, workInProgress, nextChildren, renderLanes) {\n  // This function is fork of reconcileChildren. It's used in cases where we\n  // want to reconcile without matching against the existing set. This has the\n  // effect of all current children being unmounted; even if the type and key\n  // are the same, the old child is unmounted and a new child is created.\n  //\n  // To do this, we're going to go through the reconcile algorithm twice. In\n  // the first pass, we schedule a deletion for all the current children by\n  // passing null.\n  workInProgress.child = reconcileChildFibers(workInProgress, current.child, null, renderLanes); // In the second pass, we mount the new children. The trick here is that we\n  // pass null in place of where we usually pass the current child set. This has\n  // the effect of remounting all children regardless of whether their\n  // identities match.\n\n  workInProgress.child = reconcileChildFibers(workInProgress, null, nextChildren, renderLanes);\n}\n\nfunction updateForwardRef(current, workInProgress, Component, nextProps, renderLanes) {\n  // TODO: current can be non-null here even if the component\n  // hasn't yet mounted. This happens after the first render suspends.\n  // We'll need to figure out if this is fine or can cause issues.\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentName(Component));\n      }\n    }\n  }\n\n  var render = Component.render;\n  var ref = workInProgress.ref; // The rest is a fork of updateFunctionComponent\n\n  var nextChildren;\n  prepareToReadContext(workInProgress, renderLanes);\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    nextChildren = renderWithHooks(current, workInProgress, render, nextProps, ref, renderLanes);\n\n    if ( workInProgress.mode & StrictMode) {\n      disableLogs();\n\n      try {\n        nextChildren = renderWithHooks(current, workInProgress, render, nextProps, ref, renderLanes);\n      } finally {\n        reenableLogs();\n      }\n    }\n\n    setIsRendering(false);\n  }\n\n  if (current !== null && !didReceiveUpdate) {\n    bailoutHooks(current, workInProgress, renderLanes);\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateMemoComponent(current, workInProgress, Component, nextProps, updateLanes, renderLanes) {\n  if (current === null) {\n    var type = Component.type;\n\n    if (isSimpleFunctionComponent(type) && Component.compare === null && // SimpleMemoComponent codepath doesn't resolve outer props either.\n    Component.defaultProps === undefined) {\n      var resolvedType = type;\n\n      {\n        resolvedType = resolveFunctionForHotReloading(type);\n      } // If this is a plain function component without default props,\n      // and with only the default shallow comparison, we upgrade it\n      // to a SimpleMemoComponent to allow fast path updates.\n\n\n      workInProgress.tag = SimpleMemoComponent;\n      workInProgress.type = resolvedType;\n\n      {\n        validateFunctionComponentInDev(workInProgress, type);\n      }\n\n      return updateSimpleMemoComponent(current, workInProgress, resolvedType, nextProps, updateLanes, renderLanes);\n    }\n\n    {\n      var innerPropTypes = type.propTypes;\n\n      if (innerPropTypes) {\n        // Inner memo component props aren't currently validated in createElement.\n        // We could move it there, but we'd still need this for lazy code path.\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentName(type));\n      }\n    }\n\n    var child = createFiberFromTypeAndProps(Component.type, null, nextProps, workInProgress, workInProgress.mode, renderLanes);\n    child.ref = workInProgress.ref;\n    child.return = workInProgress;\n    workInProgress.child = child;\n    return child;\n  }\n\n  {\n    var _type = Component.type;\n    var _innerPropTypes = _type.propTypes;\n\n    if (_innerPropTypes) {\n      // Inner memo component props aren't currently validated in createElement.\n      // We could move it there, but we'd still need this for lazy code path.\n      checkPropTypes(_innerPropTypes, nextProps, // Resolved props\n      'prop', getComponentName(_type));\n    }\n  }\n\n  var currentChild = current.child; // This is always exactly one child\n\n  if (!includesSomeLane(updateLanes, renderLanes)) {\n    // This will be the props with resolved defaultProps,\n    // unlike current.memoizedProps which will be the unresolved ones.\n    var prevProps = currentChild.memoizedProps; // Default to shallow comparison\n\n    var compare = Component.compare;\n    compare = compare !== null ? compare : shallowEqual;\n\n    if (compare(prevProps, nextProps) && current.ref === workInProgress.ref) {\n      return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n    }\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  var newChild = createWorkInProgress(currentChild, nextProps);\n  newChild.ref = workInProgress.ref;\n  newChild.return = workInProgress;\n  workInProgress.child = newChild;\n  return newChild;\n}\n\nfunction updateSimpleMemoComponent(current, workInProgress, Component, nextProps, updateLanes, renderLanes) {\n  // TODO: current can be non-null here even if the component\n  // hasn't yet mounted. This happens when the inner render suspends.\n  // We'll need to figure out if this is fine or can cause issues.\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var outerMemoType = workInProgress.elementType;\n\n      if (outerMemoType.$$typeof === REACT_LAZY_TYPE) {\n        // We warn when you define propTypes on lazy()\n        // so let's just skip over it to find memo() outer wrapper.\n        // Inner props for memo are validated later.\n        var lazyComponent = outerMemoType;\n        var payload = lazyComponent._payload;\n        var init = lazyComponent._init;\n\n        try {\n          outerMemoType = init(payload);\n        } catch (x) {\n          outerMemoType = null;\n        } // Inner propTypes will be validated in the function component path.\n\n\n        var outerPropTypes = outerMemoType && outerMemoType.propTypes;\n\n        if (outerPropTypes) {\n          checkPropTypes(outerPropTypes, nextProps, // Resolved (SimpleMemoComponent has no defaultProps)\n          'prop', getComponentName(outerMemoType));\n        }\n      }\n    }\n  }\n\n  if (current !== null) {\n    var prevProps = current.memoizedProps;\n\n    if (shallowEqual(prevProps, nextProps) && current.ref === workInProgress.ref && ( // Prevent bailout if the implementation changed due to hot reload.\n     workInProgress.type === current.type )) {\n      didReceiveUpdate = false;\n\n      if (!includesSomeLane(renderLanes, updateLanes)) {\n        // The pending lanes were cleared at the beginning of beginWork. We're\n        // about to bail out, but there might be other lanes that weren't\n        // included in the current render. Usually, the priority level of the\n        // remaining updates is accumlated during the evaluation of the\n        // component (i.e. when processing the update queue). But since since\n        // we're bailing out early *without* evaluating the component, we need\n        // to account for it here, too. Reset to the value of the current fiber.\n        // NOTE: This only applies to SimpleMemoComponent, not MemoComponent,\n        // because a MemoComponent fiber does not have hooks or an update queue;\n        // rather, it wraps around an inner component, which may or may not\n        // contains hooks.\n        // TODO: Move the reset at in beginWork out of the common path so that\n        // this is no longer necessary.\n        workInProgress.lanes = current.lanes;\n        return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n      } else if ((current.flags & ForceUpdateForLegacySuspense) !== NoFlags) {\n        // This is a special case that only exists for legacy mode.\n        // See https://github.com/facebook/react/pull/19216.\n        didReceiveUpdate = true;\n      }\n    }\n  }\n\n  return updateFunctionComponent(current, workInProgress, Component, nextProps, renderLanes);\n}\n\nfunction updateOffscreenComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps;\n  var nextChildren = nextProps.children;\n  var prevState = current !== null ? current.memoizedState : null;\n\n  if (nextProps.mode === 'hidden' || nextProps.mode === 'unstable-defer-without-hiding') {\n    if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n      // In legacy sync mode, don't defer the subtree. Render it now.\n      // TODO: Figure out what we should do in Blocking mode.\n      var nextState = {\n        baseLanes: NoLanes\n      };\n      workInProgress.memoizedState = nextState;\n      pushRenderLanes(workInProgress, renderLanes);\n    } else if (!includesSomeLane(renderLanes, OffscreenLane)) {\n      var nextBaseLanes;\n\n      if (prevState !== null) {\n        var prevBaseLanes = prevState.baseLanes;\n        nextBaseLanes = mergeLanes(prevBaseLanes, renderLanes);\n      } else {\n        nextBaseLanes = renderLanes;\n      } // Schedule this fiber to re-render at offscreen priority. Then bailout.\n\n\n      {\n        markSpawnedWork(OffscreenLane);\n      }\n\n      workInProgress.lanes = workInProgress.childLanes = laneToLanes(OffscreenLane);\n      var _nextState = {\n        baseLanes: nextBaseLanes\n      };\n      workInProgress.memoizedState = _nextState; // We're about to bail out, but we need to push this to the stack anyway\n      // to avoid a push/pop misalignment.\n\n      pushRenderLanes(workInProgress, nextBaseLanes);\n      return null;\n    } else {\n      // Rendering at offscreen, so we can clear the base lanes.\n      var _nextState2 = {\n        baseLanes: NoLanes\n      };\n      workInProgress.memoizedState = _nextState2; // Push the lanes that were skipped when we bailed out.\n\n      var subtreeRenderLanes = prevState !== null ? prevState.baseLanes : renderLanes;\n      pushRenderLanes(workInProgress, subtreeRenderLanes);\n    }\n  } else {\n    var _subtreeRenderLanes;\n\n    if (prevState !== null) {\n      _subtreeRenderLanes = mergeLanes(prevState.baseLanes, renderLanes); // Since we're not hidden anymore, reset the state\n\n      workInProgress.memoizedState = null;\n    } else {\n      // We weren't previously hidden, and we still aren't, so there's nothing\n      // special to do. Need to push to the stack regardless, though, to avoid\n      // a push/pop misalignment.\n      _subtreeRenderLanes = renderLanes;\n    }\n\n    pushRenderLanes(workInProgress, _subtreeRenderLanes);\n  }\n\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n} // Note: These happen to have identical begin phases, for now. We shouldn't hold\n// ourselves to this constraint, though. If the behavior diverges, we should\n// fork the function.\n\n\nvar updateLegacyHiddenComponent = updateOffscreenComponent;\n\nfunction updateFragment(current, workInProgress, renderLanes) {\n  var nextChildren = workInProgress.pendingProps;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateMode(current, workInProgress, renderLanes) {\n  var nextChildren = workInProgress.pendingProps.children;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateProfiler(current, workInProgress, renderLanes) {\n  {\n    workInProgress.flags |= Update; // Reset effect durations for the next eventual effect phase.\n    // These are reset during render to allow the DevTools commit hook a chance to read them,\n\n    var stateNode = workInProgress.stateNode;\n    stateNode.effectDuration = 0;\n    stateNode.passiveEffectDuration = 0;\n  }\n\n  var nextProps = workInProgress.pendingProps;\n  var nextChildren = nextProps.children;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction markRef(current, workInProgress) {\n  var ref = workInProgress.ref;\n\n  if (current === null && ref !== null || current !== null && current.ref !== ref) {\n    // Schedule a Ref effect\n    workInProgress.flags |= Ref;\n  }\n}\n\nfunction updateFunctionComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentName(Component));\n      }\n    }\n  }\n\n  var context;\n\n  {\n    var unmaskedContext = getUnmaskedContext(workInProgress, Component, true);\n    context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  var nextChildren;\n  prepareToReadContext(workInProgress, renderLanes);\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    nextChildren = renderWithHooks(current, workInProgress, Component, nextProps, context, renderLanes);\n\n    if ( workInProgress.mode & StrictMode) {\n      disableLogs();\n\n      try {\n        nextChildren = renderWithHooks(current, workInProgress, Component, nextProps, context, renderLanes);\n      } finally {\n        reenableLogs();\n      }\n    }\n\n    setIsRendering(false);\n  }\n\n  if (current !== null && !didReceiveUpdate) {\n    bailoutHooks(current, workInProgress, renderLanes);\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateClassComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentName(Component));\n      }\n    }\n  } // Push context providers early to prevent context stack mismatches.\n  // During mounting we don't know the child context yet as the instance doesn't exist.\n  // We will invalidate the child context in finishClassComponent() right after rendering.\n\n\n  var hasContext;\n\n  if (isContextProvider(Component)) {\n    hasContext = true;\n    pushContextProvider(workInProgress);\n  } else {\n    hasContext = false;\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var instance = workInProgress.stateNode;\n  var shouldUpdate;\n\n  if (instance === null) {\n    if (current !== null) {\n      // A class component without an instance only mounts if it suspended\n      // inside a non-concurrent tree, in an inconsistent state. We want to\n      // treat it like a new mount, even though an empty version of it already\n      // committed. Disconnect the alternate pointers.\n      current.alternate = null;\n      workInProgress.alternate = null; // Since this is conceptually a new fiber, schedule a Placement effect\n\n      workInProgress.flags |= Placement;\n    } // In the initial pass we might need to construct the instance.\n\n\n    constructClassInstance(workInProgress, Component, nextProps);\n    mountClassInstance(workInProgress, Component, nextProps, renderLanes);\n    shouldUpdate = true;\n  } else if (current === null) {\n    // In a resume, we'll already have an instance we can reuse.\n    shouldUpdate = resumeMountClassInstance(workInProgress, Component, nextProps, renderLanes);\n  } else {\n    shouldUpdate = updateClassInstance(current, workInProgress, Component, nextProps, renderLanes);\n  }\n\n  var nextUnitOfWork = finishClassComponent(current, workInProgress, Component, shouldUpdate, hasContext, renderLanes);\n\n  {\n    var inst = workInProgress.stateNode;\n\n    if (shouldUpdate && inst.props !== nextProps) {\n      if (!didWarnAboutReassigningProps) {\n        error('It looks like %s is reassigning its own `this.props` while rendering. ' + 'This is not supported and can lead to confusing bugs.', getComponentName(workInProgress.type) || 'a component');\n      }\n\n      didWarnAboutReassigningProps = true;\n    }\n  }\n\n  return nextUnitOfWork;\n}\n\nfunction finishClassComponent(current, workInProgress, Component, shouldUpdate, hasContext, renderLanes) {\n  // Refs should update even if shouldComponentUpdate returns false\n  markRef(current, workInProgress);\n  var didCaptureError = (workInProgress.flags & DidCapture) !== NoFlags;\n\n  if (!shouldUpdate && !didCaptureError) {\n    // Context providers should defer to sCU for rendering\n    if (hasContext) {\n      invalidateContextProvider(workInProgress, Component, false);\n    }\n\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  }\n\n  var instance = workInProgress.stateNode; // Rerender\n\n  ReactCurrentOwner$1.current = workInProgress;\n  var nextChildren;\n\n  if (didCaptureError && typeof Component.getDerivedStateFromError !== 'function') {\n    // If we captured an error, but getDerivedStateFromError is not defined,\n    // unmount all the children. componentDidCatch will schedule an update to\n    // re-render a fallback. This is temporary until we migrate everyone to\n    // the new API.\n    // TODO: Warn in a future release.\n    nextChildren = null;\n\n    {\n      stopProfilerTimerIfRunning();\n    }\n  } else {\n    {\n      setIsRendering(true);\n      nextChildren = instance.render();\n\n      if ( workInProgress.mode & StrictMode) {\n        disableLogs();\n\n        try {\n          instance.render();\n        } finally {\n          reenableLogs();\n        }\n      }\n\n      setIsRendering(false);\n    }\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n\n  if (current !== null && didCaptureError) {\n    // If we're recovering from an error, reconcile without reusing any of\n    // the existing children. Conceptually, the normal children and the children\n    // that are shown on error are two different sets, so we shouldn't reuse\n    // normal children even if their identities match.\n    forceUnmountCurrentAndReconcile(current, workInProgress, nextChildren, renderLanes);\n  } else {\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  } // Memoize state using the values we just used to render.\n  // TODO: Restructure so we never read values from the instance.\n\n\n  workInProgress.memoizedState = instance.state; // The context might have changed so we need to recalculate it.\n\n  if (hasContext) {\n    invalidateContextProvider(workInProgress, Component, true);\n  }\n\n  return workInProgress.child;\n}\n\nfunction pushHostRootContext(workInProgress) {\n  var root = workInProgress.stateNode;\n\n  if (root.pendingContext) {\n    pushTopLevelContextObject(workInProgress, root.pendingContext, root.pendingContext !== root.context);\n  } else if (root.context) {\n    // Should always be set\n    pushTopLevelContextObject(workInProgress, root.context, false);\n  }\n\n  pushHostContainer(workInProgress, root.containerInfo);\n}\n\nfunction updateHostRoot(current, workInProgress, renderLanes) {\n  pushHostRootContext(workInProgress);\n  var updateQueue = workInProgress.updateQueue;\n\n  if (!(current !== null && updateQueue !== null)) {\n    {\n      throw Error( \"If the root does not have an updateQueue, we should have already bailed out. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n\n  var nextProps = workInProgress.pendingProps;\n  var prevState = workInProgress.memoizedState;\n  var prevChildren = prevState !== null ? prevState.element : null;\n  cloneUpdateQueue(current, workInProgress);\n  processUpdateQueue(workInProgress, nextProps, null, renderLanes);\n  var nextState = workInProgress.memoizedState; // Caution: React DevTools currently depends on this property\n  // being called \"element\".\n\n  var nextChildren = nextState.element;\n\n  if (nextChildren === prevChildren) {\n    resetHydrationState();\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  }\n\n  var root = workInProgress.stateNode;\n\n  if (root.hydrate && enterHydrationState(workInProgress)) {\n    // If we don't have any current children this might be the first pass.\n    // We always try to hydrate. If this isn't a hydration pass there won't\n    // be any children to hydrate which is effectively the same thing as\n    // not hydrating.\n    {\n      var mutableSourceEagerHydrationData = root.mutableSourceEagerHydrationData;\n\n      if (mutableSourceEagerHydrationData != null) {\n        for (var i = 0; i < mutableSourceEagerHydrationData.length; i += 2) {\n          var mutableSource = mutableSourceEagerHydrationData[i];\n          var version = mutableSourceEagerHydrationData[i + 1];\n          setWorkInProgressVersion(mutableSource, version);\n        }\n      }\n    }\n\n    var child = mountChildFibers(workInProgress, null, nextChildren, renderLanes);\n    workInProgress.child = child;\n    var node = child;\n\n    while (node) {\n      // Mark each child as hydrating. This is a fast path to know whether this\n      // tree is part of a hydrating tree. This is used to determine if a child\n      // node has fully mounted yet, and for scheduling event replaying.\n      // Conceptually this is similar to Placement in that a new subtree is\n      // inserted into the React tree here. It just happens to not need DOM\n      // mutations because it already exists.\n      node.flags = node.flags & ~Placement | Hydrating;\n      node = node.sibling;\n    }\n  } else {\n    // Otherwise reset hydration state in case we aborted and resumed another\n    // root.\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n    resetHydrationState();\n  }\n\n  return workInProgress.child;\n}\n\nfunction updateHostComponent(current, workInProgress, renderLanes) {\n  pushHostContext(workInProgress);\n\n  if (current === null) {\n    tryToClaimNextHydratableInstance(workInProgress);\n  }\n\n  var type = workInProgress.type;\n  var nextProps = workInProgress.pendingProps;\n  var prevProps = current !== null ? current.memoizedProps : null;\n  var nextChildren = nextProps.children;\n  var isDirectTextChild = shouldSetTextContent(type, nextProps);\n\n  if (isDirectTextChild) {\n    // We special case a direct text child of a host node. This is a common\n    // case. We won't handle it as a reified child. We will instead handle\n    // this in the host environment that also has access to this prop. That\n    // avoids allocating another HostText fiber and traversing it.\n    nextChildren = null;\n  } else if (prevProps !== null && shouldSetTextContent(type, prevProps)) {\n    // If we're switching from a direct text child to a normal child, or to\n    // empty, we need to schedule the text content to be reset.\n    workInProgress.flags |= ContentReset;\n  }\n\n  markRef(current, workInProgress);\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateHostText(current, workInProgress) {\n  if (current === null) {\n    tryToClaimNextHydratableInstance(workInProgress);\n  } // Nothing to do here. This is terminal. We'll do the completion step\n  // immediately after.\n\n\n  return null;\n}\n\nfunction mountLazyComponent(_current, workInProgress, elementType, updateLanes, renderLanes) {\n  if (_current !== null) {\n    // A lazy component only mounts if it suspended inside a non-\n    // concurrent tree, in an inconsistent state. We want to treat it like\n    // a new mount, even though an empty version of it already committed.\n    // Disconnect the alternate pointers.\n    _current.alternate = null;\n    workInProgress.alternate = null; // Since this is conceptually a new fiber, schedule a Placement effect\n\n    workInProgress.flags |= Placement;\n  }\n\n  var props = workInProgress.pendingProps;\n  var lazyComponent = elementType;\n  var payload = lazyComponent._payload;\n  var init = lazyComponent._init;\n  var Component = init(payload); // Store the unwrapped component in the type.\n\n  workInProgress.type = Component;\n  var resolvedTag = workInProgress.tag = resolveLazyComponentTag(Component);\n  var resolvedProps = resolveDefaultProps(Component, props);\n  var child;\n\n  switch (resolvedTag) {\n    case FunctionComponent:\n      {\n        {\n          validateFunctionComponentInDev(workInProgress, Component);\n          workInProgress.type = Component = resolveFunctionForHotReloading(Component);\n        }\n\n        child = updateFunctionComponent(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case ClassComponent:\n      {\n        {\n          workInProgress.type = Component = resolveClassForHotReloading(Component);\n        }\n\n        child = updateClassComponent(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case ForwardRef:\n      {\n        {\n          workInProgress.type = Component = resolveForwardRefForHotReloading(Component);\n        }\n\n        child = updateForwardRef(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case MemoComponent:\n      {\n        {\n          if (workInProgress.type !== workInProgress.elementType) {\n            var outerPropTypes = Component.propTypes;\n\n            if (outerPropTypes) {\n              checkPropTypes(outerPropTypes, resolvedProps, // Resolved for outer only\n              'prop', getComponentName(Component));\n            }\n          }\n        }\n\n        child = updateMemoComponent(null, workInProgress, Component, resolveDefaultProps(Component.type, resolvedProps), // The inner type can have defaults too\n        updateLanes, renderLanes);\n        return child;\n      }\n  }\n\n  var hint = '';\n\n  {\n    if (Component !== null && typeof Component === 'object' && Component.$$typeof === REACT_LAZY_TYPE) {\n      hint = ' Did you wrap a component in React.lazy() more than once?';\n    }\n  } // This message intentionally doesn't mention ForwardRef or MemoComponent\n  // because the fact that it's a separate type of work is an\n  // implementation detail.\n\n\n  {\n    {\n      throw Error( \"Element type is invalid. Received a promise that resolves to: \" + Component + \". Lazy element type must resolve to a class or function.\" + hint );\n    }\n  }\n}\n\nfunction mountIncompleteClassComponent(_current, workInProgress, Component, nextProps, renderLanes) {\n  if (_current !== null) {\n    // An incomplete component only mounts if it suspended inside a non-\n    // concurrent tree, in an inconsistent state. We want to treat it like\n    // a new mount, even though an empty version of it already committed.\n    // Disconnect the alternate pointers.\n    _current.alternate = null;\n    workInProgress.alternate = null; // Since this is conceptually a new fiber, schedule a Placement effect\n\n    workInProgress.flags |= Placement;\n  } // Promote the fiber to a class and try rendering again.\n\n\n  workInProgress.tag = ClassComponent; // The rest of this function is a fork of `updateClassComponent`\n  // Push context providers early to prevent context stack mismatches.\n  // During mounting we don't know the child context yet as the instance doesn't exist.\n  // We will invalidate the child context in finishClassComponent() right after rendering.\n\n  var hasContext;\n\n  if (isContextProvider(Component)) {\n    hasContext = true;\n    pushContextProvider(workInProgress);\n  } else {\n    hasContext = false;\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  constructClassInstance(workInProgress, Component, nextProps);\n  mountClassInstance(workInProgress, Component, nextProps, renderLanes);\n  return finishClassComponent(null, workInProgress, Component, true, hasContext, renderLanes);\n}\n\nfunction mountIndeterminateComponent(_current, workInProgress, Component, renderLanes) {\n  if (_current !== null) {\n    // An indeterminate component only mounts if it suspended inside a non-\n    // concurrent tree, in an inconsistent state. We want to treat it like\n    // a new mount, even though an empty version of it already committed.\n    // Disconnect the alternate pointers.\n    _current.alternate = null;\n    workInProgress.alternate = null; // Since this is conceptually a new fiber, schedule a Placement effect\n\n    workInProgress.flags |= Placement;\n  }\n\n  var props = workInProgress.pendingProps;\n  var context;\n\n  {\n    var unmaskedContext = getUnmaskedContext(workInProgress, Component, false);\n    context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var value;\n\n  {\n    if (Component.prototype && typeof Component.prototype.render === 'function') {\n      var componentName = getComponentName(Component) || 'Unknown';\n\n      if (!didWarnAboutBadClass[componentName]) {\n        error(\"The <%s /> component appears to have a render method, but doesn't extend React.Component. \" + 'This is likely to cause errors. Change %s to extend React.Component instead.', componentName, componentName);\n\n        didWarnAboutBadClass[componentName] = true;\n      }\n    }\n\n    if (workInProgress.mode & StrictMode) {\n      ReactStrictModeWarnings.recordLegacyContextWarning(workInProgress, null);\n    }\n\n    setIsRendering(true);\n    ReactCurrentOwner$1.current = workInProgress;\n    value = renderWithHooks(null, workInProgress, Component, props, context, renderLanes);\n    setIsRendering(false);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n\n  {\n    // Support for module components is deprecated and is removed behind a flag.\n    // Whether or not it would crash later, we want to show a good message in DEV first.\n    if (typeof value === 'object' && value !== null && typeof value.render === 'function' && value.$$typeof === undefined) {\n      var _componentName = getComponentName(Component) || 'Unknown';\n\n      if (!didWarnAboutModulePatternComponent[_componentName]) {\n        error('The <%s /> component appears to be a function component that returns a class instance. ' + 'Change %s to a class that extends React.Component instead. ' + \"If you can't use a class try assigning the prototype on the function as a workaround. \" + \"`%s.prototype = React.Component.prototype`. Don't use an arrow function since it \" + 'cannot be called with `new` by React.', _componentName, _componentName, _componentName);\n\n        didWarnAboutModulePatternComponent[_componentName] = true;\n      }\n    }\n  }\n\n  if ( // Run these checks in production only if the flag is off.\n  // Eventually we'll delete this branch altogether.\n   typeof value === 'object' && value !== null && typeof value.render === 'function' && value.$$typeof === undefined) {\n    {\n      var _componentName2 = getComponentName(Component) || 'Unknown';\n\n      if (!didWarnAboutModulePatternComponent[_componentName2]) {\n        error('The <%s /> component appears to be a function component that returns a class instance. ' + 'Change %s to a class that extends React.Component instead. ' + \"If you can't use a class try assigning the prototype on the function as a workaround. \" + \"`%s.prototype = React.Component.prototype`. Don't use an arrow function since it \" + 'cannot be called with `new` by React.', _componentName2, _componentName2, _componentName2);\n\n        didWarnAboutModulePatternComponent[_componentName2] = true;\n      }\n    } // Proceed under the assumption that this is a class instance\n\n\n    workInProgress.tag = ClassComponent; // Throw out any hooks that were used.\n\n    workInProgress.memoizedState = null;\n    workInProgress.updateQueue = null; // Push context providers early to prevent context stack mismatches.\n    // During mounting we don't know the child context yet as the instance doesn't exist.\n    // We will invalidate the child context in finishClassComponent() right after rendering.\n\n    var hasContext = false;\n\n    if (isContextProvider(Component)) {\n      hasContext = true;\n      pushContextProvider(workInProgress);\n    } else {\n      hasContext = false;\n    }\n\n    workInProgress.memoizedState = value.state !== null && value.state !== undefined ? value.state : null;\n    initializeUpdateQueue(workInProgress);\n    var getDerivedStateFromProps = Component.getDerivedStateFromProps;\n\n    if (typeof getDerivedStateFromProps === 'function') {\n      applyDerivedStateFromProps(workInProgress, Component, getDerivedStateFromProps, props);\n    }\n\n    adoptClassInstance(workInProgress, value);\n    mountClassInstance(workInProgress, Component, props, renderLanes);\n    return finishClassComponent(null, workInProgress, Component, true, hasContext, renderLanes);\n  } else {\n    // Proceed under the assumption that this is a function component\n    workInProgress.tag = FunctionComponent;\n\n    {\n\n      if ( workInProgress.mode & StrictMode) {\n        disableLogs();\n\n        try {\n          value = renderWithHooks(null, workInProgress, Component, props, context, renderLanes);\n        } finally {\n          reenableLogs();\n        }\n      }\n    }\n\n    reconcileChildren(null, workInProgress, value, renderLanes);\n\n    {\n      validateFunctionComponentInDev(workInProgress, Component);\n    }\n\n    return workInProgress.child;\n  }\n}\n\nfunction validateFunctionComponentInDev(workInProgress, Component) {\n  {\n    if (Component) {\n      if (Component.childContextTypes) {\n        error('%s(...): childContextTypes cannot be defined on a function component.', Component.displayName || Component.name || 'Component');\n      }\n    }\n\n    if (workInProgress.ref !== null) {\n      var info = '';\n      var ownerName = getCurrentFiberOwnerNameInDevOrNull();\n\n      if (ownerName) {\n        info += '\\n\\nCheck the render method of `' + ownerName + '`.';\n      }\n\n      var warningKey = ownerName || workInProgress._debugID || '';\n      var debugSource = workInProgress._debugSource;\n\n      if (debugSource) {\n        warningKey = debugSource.fileName + ':' + debugSource.lineNumber;\n      }\n\n      if (!didWarnAboutFunctionRefs[warningKey]) {\n        didWarnAboutFunctionRefs[warningKey] = true;\n\n        error('Function components cannot be given refs. ' + 'Attempts to access this ref will fail. ' + 'Did you mean to use React.forwardRef()?%s', info);\n      }\n    }\n\n    if (typeof Component.getDerivedStateFromProps === 'function') {\n      var _componentName3 = getComponentName(Component) || 'Unknown';\n\n      if (!didWarnAboutGetDerivedStateOnFunctionComponent[_componentName3]) {\n        error('%s: Function components do not support getDerivedStateFromProps.', _componentName3);\n\n        didWarnAboutGetDerivedStateOnFunctionComponent[_componentName3] = true;\n      }\n    }\n\n    if (typeof Component.contextType === 'object' && Component.contextType !== null) {\n      var _componentName4 = getComponentName(Component) || 'Unknown';\n\n      if (!didWarnAboutContextTypeOnFunctionComponent[_componentName4]) {\n        error('%s: Function components do not support contextType.', _componentName4);\n\n        didWarnAboutContextTypeOnFunctionComponent[_componentName4] = true;\n      }\n    }\n  }\n}\n\nvar SUSPENDED_MARKER = {\n  dehydrated: null,\n  retryLane: NoLane\n};\n\nfunction mountSuspenseOffscreenState(renderLanes) {\n  return {\n    baseLanes: renderLanes\n  };\n}\n\nfunction updateSuspenseOffscreenState(prevOffscreenState, renderLanes) {\n  return {\n    baseLanes: mergeLanes(prevOffscreenState.baseLanes, renderLanes)\n  };\n} // TODO: Probably should inline this back\n\n\nfunction shouldRemainOnFallback(suspenseContext, current, workInProgress, renderLanes) {\n  // If we're already showing a fallback, there are cases where we need to\n  // remain on that fallback regardless of whether the content has resolved.\n  // For example, SuspenseList coordinates when nested content appears.\n  if (current !== null) {\n    var suspenseState = current.memoizedState;\n\n    if (suspenseState === null) {\n      // Currently showing content. Don't hide it, even if ForceSuspenseFallack\n      // is true. More precise name might be \"ForceRemainSuspenseFallback\".\n      // Note: This is a factoring smell. Can't remain on a fallback if there's\n      // no fallback to remain on.\n      return false;\n    }\n  } // Not currently showing content. Consult the Suspense context.\n\n\n  return hasSuspenseContext(suspenseContext, ForceSuspenseFallback);\n}\n\nfunction getRemainingWorkInPrimaryTree(current, renderLanes) {\n  // TODO: Should not remove render lanes that were pinged during this render\n  return removeLanes(current.childLanes, renderLanes);\n}\n\nfunction updateSuspenseComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps; // This is used by DevTools to force a boundary to suspend.\n\n  {\n    if (shouldSuspend(workInProgress)) {\n      workInProgress.flags |= DidCapture;\n    }\n  }\n\n  var suspenseContext = suspenseStackCursor.current;\n  var showFallback = false;\n  var didSuspend = (workInProgress.flags & DidCapture) !== NoFlags;\n\n  if (didSuspend || shouldRemainOnFallback(suspenseContext, current)) {\n    // Something in this boundary's subtree already suspended. Switch to\n    // rendering the fallback children.\n    showFallback = true;\n    workInProgress.flags &= ~DidCapture;\n  } else {\n    // Attempting the main content\n    if (current === null || current.memoizedState !== null) {\n      // This is a new mount or this boundary is already showing a fallback state.\n      // Mark this subtree context as having at least one invisible parent that could\n      // handle the fallback state.\n      // Boundaries without fallbacks or should be avoided are not considered since\n      // they cannot handle preferred fallback states.\n      if (nextProps.fallback !== undefined && nextProps.unstable_avoidThisFallback !== true) {\n        suspenseContext = addSubtreeSuspenseContext(suspenseContext, InvisibleParentSuspenseContext);\n      }\n    }\n  }\n\n  suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n  pushSuspenseContext(workInProgress, suspenseContext); // OK, the next part is confusing. We're about to reconcile the Suspense\n  // boundary's children. This involves some custom reconcilation logic. Two\n  // main reasons this is so complicated.\n  //\n  // First, Legacy Mode has different semantics for backwards compatibility. The\n  // primary tree will commit in an inconsistent state, so when we do the\n  // second pass to render the fallback, we do some exceedingly, uh, clever\n  // hacks to make that not totally break. Like transferring effects and\n  // deletions from hidden tree. In Concurrent Mode, it's much simpler,\n  // because we bailout on the primary tree completely and leave it in its old\n  // state, no effects. Same as what we do for Offscreen (except that\n  // Offscreen doesn't have the first render pass).\n  //\n  // Second is hydration. During hydration, the Suspense fiber has a slightly\n  // different layout, where the child points to a dehydrated fragment, which\n  // contains the DOM rendered by the server.\n  //\n  // Third, even if you set all that aside, Suspense is like error boundaries in\n  // that we first we try to render one tree, and if that fails, we render again\n  // and switch to a different tree. Like a try/catch block. So we have to track\n  // which branch we're currently rendering. Ideally we would model this using\n  // a stack.\n\n  if (current === null) {\n    // Initial mount\n    // If we're currently hydrating, try to hydrate this boundary.\n    // But only if this has a fallback.\n    if (nextProps.fallback !== undefined) {\n      tryToClaimNextHydratableInstance(workInProgress); // This could've been a dehydrated suspense component.\n    }\n\n    var nextPrimaryChildren = nextProps.children;\n    var nextFallbackChildren = nextProps.fallback;\n\n    if (showFallback) {\n      var fallbackFragment = mountSuspenseFallbackChildren(workInProgress, nextPrimaryChildren, nextFallbackChildren, renderLanes);\n      var primaryChildFragment = workInProgress.child;\n      primaryChildFragment.memoizedState = mountSuspenseOffscreenState(renderLanes);\n      workInProgress.memoizedState = SUSPENDED_MARKER;\n      return fallbackFragment;\n    } else if (typeof nextProps.unstable_expectedLoadTime === 'number') {\n      // This is a CPU-bound tree. Skip this tree and show a placeholder to\n      // unblock the surrounding content. Then immediately retry after the\n      // initial commit.\n      var _fallbackFragment = mountSuspenseFallbackChildren(workInProgress, nextPrimaryChildren, nextFallbackChildren, renderLanes);\n\n      var _primaryChildFragment = workInProgress.child;\n      _primaryChildFragment.memoizedState = mountSuspenseOffscreenState(renderLanes);\n      workInProgress.memoizedState = SUSPENDED_MARKER; // Since nothing actually suspended, there will nothing to ping this to\n      // get it started back up to attempt the next item. While in terms of\n      // priority this work has the same priority as this current render, it's\n      // not part of the same transition once the transition has committed. If\n      // it's sync, we still want to yield so that it can be painted.\n      // Conceptually, this is really the same as pinging. We can use any\n      // RetryLane even if it's the one currently rendering since we're leaving\n      // it behind on this node.\n\n      workInProgress.lanes = SomeRetryLane;\n\n      {\n        markSpawnedWork(SomeRetryLane);\n      }\n\n      return _fallbackFragment;\n    } else {\n      return mountSuspensePrimaryChildren(workInProgress, nextPrimaryChildren, renderLanes);\n    }\n  } else {\n    // This is an update.\n    // If the current fiber has a SuspenseState, that means it's already showing\n    // a fallback.\n    var prevState = current.memoizedState;\n\n    if (prevState !== null) {\n\n      if (showFallback) {\n        var _nextFallbackChildren2 = nextProps.fallback;\n        var _nextPrimaryChildren2 = nextProps.children;\n\n        var _fallbackChildFragment = updateSuspenseFallbackChildren(current, workInProgress, _nextPrimaryChildren2, _nextFallbackChildren2, renderLanes);\n\n        var _primaryChildFragment3 = workInProgress.child;\n        var prevOffscreenState = current.child.memoizedState;\n        _primaryChildFragment3.memoizedState = prevOffscreenState === null ? mountSuspenseOffscreenState(renderLanes) : updateSuspenseOffscreenState(prevOffscreenState, renderLanes);\n        _primaryChildFragment3.childLanes = getRemainingWorkInPrimaryTree(current, renderLanes);\n        workInProgress.memoizedState = SUSPENDED_MARKER;\n        return _fallbackChildFragment;\n      } else {\n        var _nextPrimaryChildren3 = nextProps.children;\n\n        var _primaryChildFragment4 = updateSuspensePrimaryChildren(current, workInProgress, _nextPrimaryChildren3, renderLanes);\n\n        workInProgress.memoizedState = null;\n        return _primaryChildFragment4;\n      }\n    } else {\n      // The current tree is not already showing a fallback.\n      if (showFallback) {\n        // Timed out.\n        var _nextFallbackChildren3 = nextProps.fallback;\n        var _nextPrimaryChildren4 = nextProps.children;\n\n        var _fallbackChildFragment2 = updateSuspenseFallbackChildren(current, workInProgress, _nextPrimaryChildren4, _nextFallbackChildren3, renderLanes);\n\n        var _primaryChildFragment5 = workInProgress.child;\n        var _prevOffscreenState = current.child.memoizedState;\n        _primaryChildFragment5.memoizedState = _prevOffscreenState === null ? mountSuspenseOffscreenState(renderLanes) : updateSuspenseOffscreenState(_prevOffscreenState, renderLanes);\n        _primaryChildFragment5.childLanes = getRemainingWorkInPrimaryTree(current, renderLanes); // Skip the primary children, and continue working on the\n        // fallback children.\n\n        workInProgress.memoizedState = SUSPENDED_MARKER;\n        return _fallbackChildFragment2;\n      } else {\n        // Still haven't timed out. Continue rendering the children, like we\n        // normally do.\n        var _nextPrimaryChildren5 = nextProps.children;\n\n        var _primaryChildFragment6 = updateSuspensePrimaryChildren(current, workInProgress, _nextPrimaryChildren5, renderLanes);\n\n        workInProgress.memoizedState = null;\n        return _primaryChildFragment6;\n      }\n    }\n  }\n}\n\nfunction mountSuspensePrimaryChildren(workInProgress, primaryChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var primaryChildProps = {\n    mode: 'visible',\n    children: primaryChildren\n  };\n  var primaryChildFragment = createFiberFromOffscreen(primaryChildProps, mode, renderLanes, null);\n  primaryChildFragment.return = workInProgress;\n  workInProgress.child = primaryChildFragment;\n  return primaryChildFragment;\n}\n\nfunction mountSuspenseFallbackChildren(workInProgress, primaryChildren, fallbackChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var progressedPrimaryFragment = workInProgress.child;\n  var primaryChildProps = {\n    mode: 'hidden',\n    children: primaryChildren\n  };\n  var primaryChildFragment;\n  var fallbackChildFragment;\n\n  if ((mode & BlockingMode) === NoMode && progressedPrimaryFragment !== null) {\n    // In legacy mode, we commit the primary tree as if it successfully\n    // completed, even though it's in an inconsistent state.\n    primaryChildFragment = progressedPrimaryFragment;\n    primaryChildFragment.childLanes = NoLanes;\n    primaryChildFragment.pendingProps = primaryChildProps;\n\n    if ( workInProgress.mode & ProfileMode) {\n      // Reset the durations from the first pass so they aren't included in the\n      // final amounts. This seems counterintuitive, since we're intentionally\n      // not measuring part of the render phase, but this makes it match what we\n      // do in Concurrent Mode.\n      primaryChildFragment.actualDuration = 0;\n      primaryChildFragment.actualStartTime = -1;\n      primaryChildFragment.selfBaseDuration = 0;\n      primaryChildFragment.treeBaseDuration = 0;\n    }\n\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null);\n  } else {\n    primaryChildFragment = createFiberFromOffscreen(primaryChildProps, mode, NoLanes, null);\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null);\n  }\n\n  primaryChildFragment.return = workInProgress;\n  fallbackChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = fallbackChildFragment;\n  workInProgress.child = primaryChildFragment;\n  return fallbackChildFragment;\n}\n\nfunction createWorkInProgressOffscreenFiber(current, offscreenProps) {\n  // The props argument to `createWorkInProgress` is `any` typed, so we use this\n  // wrapper function to constrain it.\n  return createWorkInProgress(current, offscreenProps);\n}\n\nfunction updateSuspensePrimaryChildren(current, workInProgress, primaryChildren, renderLanes) {\n  var currentPrimaryChildFragment = current.child;\n  var currentFallbackChildFragment = currentPrimaryChildFragment.sibling;\n  var primaryChildFragment = createWorkInProgressOffscreenFiber(currentPrimaryChildFragment, {\n    mode: 'visible',\n    children: primaryChildren\n  });\n\n  if ((workInProgress.mode & BlockingMode) === NoMode) {\n    primaryChildFragment.lanes = renderLanes;\n  }\n\n  primaryChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = null;\n\n  if (currentFallbackChildFragment !== null) {\n    // Delete the fallback child fragment\n    currentFallbackChildFragment.nextEffect = null;\n    currentFallbackChildFragment.flags = Deletion;\n    workInProgress.firstEffect = workInProgress.lastEffect = currentFallbackChildFragment;\n  }\n\n  workInProgress.child = primaryChildFragment;\n  return primaryChildFragment;\n}\n\nfunction updateSuspenseFallbackChildren(current, workInProgress, primaryChildren, fallbackChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var currentPrimaryChildFragment = current.child;\n  var currentFallbackChildFragment = currentPrimaryChildFragment.sibling;\n  var primaryChildProps = {\n    mode: 'hidden',\n    children: primaryChildren\n  };\n  var primaryChildFragment;\n\n  if ( // In legacy mode, we commit the primary tree as if it successfully\n  // completed, even though it's in an inconsistent state.\n  (mode & BlockingMode) === NoMode && // Make sure we're on the second pass, i.e. the primary child fragment was\n  // already cloned. In legacy mode, the only case where this isn't true is\n  // when DevTools forces us to display a fallback; we skip the first render\n  // pass entirely and go straight to rendering the fallback. (In Concurrent\n  // Mode, SuspenseList can also trigger this scenario, but this is a legacy-\n  // only codepath.)\n  workInProgress.child !== currentPrimaryChildFragment) {\n    var progressedPrimaryFragment = workInProgress.child;\n    primaryChildFragment = progressedPrimaryFragment;\n    primaryChildFragment.childLanes = NoLanes;\n    primaryChildFragment.pendingProps = primaryChildProps;\n\n    if ( workInProgress.mode & ProfileMode) {\n      // Reset the durations from the first pass so they aren't included in the\n      // final amounts. This seems counterintuitive, since we're intentionally\n      // not measuring part of the render phase, but this makes it match what we\n      // do in Concurrent Mode.\n      primaryChildFragment.actualDuration = 0;\n      primaryChildFragment.actualStartTime = -1;\n      primaryChildFragment.selfBaseDuration = currentPrimaryChildFragment.selfBaseDuration;\n      primaryChildFragment.treeBaseDuration = currentPrimaryChildFragment.treeBaseDuration;\n    } // The fallback fiber was added as a deletion effect during the first pass.\n    // However, since we're going to remain on the fallback, we no longer want\n    // to delete it. So we need to remove it from the list. Deletions are stored\n    // on the same list as effects. We want to keep the effects from the primary\n    // tree. So we copy the primary child fragment's effect list, which does not\n    // include the fallback deletion effect.\n\n\n    var progressedLastEffect = primaryChildFragment.lastEffect;\n\n    if (progressedLastEffect !== null) {\n      workInProgress.firstEffect = primaryChildFragment.firstEffect;\n      workInProgress.lastEffect = progressedLastEffect;\n      progressedLastEffect.nextEffect = null;\n    } else {\n      // TODO: Reset this somewhere else? Lol legacy mode is so weird.\n      workInProgress.firstEffect = workInProgress.lastEffect = null;\n    }\n  } else {\n    primaryChildFragment = createWorkInProgressOffscreenFiber(currentPrimaryChildFragment, primaryChildProps);\n  }\n\n  var fallbackChildFragment;\n\n  if (currentFallbackChildFragment !== null) {\n    fallbackChildFragment = createWorkInProgress(currentFallbackChildFragment, fallbackChildren);\n  } else {\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null); // Needs a placement effect because the parent (the Suspense boundary) already\n    // mounted but this is a new fiber.\n\n    fallbackChildFragment.flags |= Placement;\n  }\n\n  fallbackChildFragment.return = workInProgress;\n  primaryChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = fallbackChildFragment;\n  workInProgress.child = primaryChildFragment;\n  return fallbackChildFragment;\n}\n\nfunction scheduleWorkOnFiber(fiber, renderLanes) {\n  fiber.lanes = mergeLanes(fiber.lanes, renderLanes);\n  var alternate = fiber.alternate;\n\n  if (alternate !== null) {\n    alternate.lanes = mergeLanes(alternate.lanes, renderLanes);\n  }\n\n  scheduleWorkOnParentPath(fiber.return, renderLanes);\n}\n\nfunction propagateSuspenseContextChange(workInProgress, firstChild, renderLanes) {\n  // Mark any Suspense boundaries with fallbacks as having work to do.\n  // If they were previously forced into fallbacks, they may now be able\n  // to unblock.\n  var node = firstChild;\n\n  while (node !== null) {\n    if (node.tag === SuspenseComponent) {\n      var state = node.memoizedState;\n\n      if (state !== null) {\n        scheduleWorkOnFiber(node, renderLanes);\n      }\n    } else if (node.tag === SuspenseListComponent) {\n      // If the tail is hidden there might not be an Suspense boundaries\n      // to schedule work on. In this case we have to schedule it on the\n      // list itself.\n      // We don't have to traverse to the children of the list since\n      // the list will propagate the change when it rerenders.\n      scheduleWorkOnFiber(node, renderLanes);\n    } else if (node.child !== null) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === workInProgress) {\n      return;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === workInProgress) {\n        return;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n}\n\nfunction findLastContentRow(firstChild) {\n  // This is going to find the last row among these children that is already\n  // showing content on the screen, as opposed to being in fallback state or\n  // new. If a row has multiple Suspense boundaries, any of them being in the\n  // fallback state, counts as the whole row being in a fallback state.\n  // Note that the \"rows\" will be workInProgress, but any nested children\n  // will still be current since we haven't rendered them yet. The mounted\n  // order may not be the same as the new order. We use the new order.\n  var row = firstChild;\n  var lastContentRow = null;\n\n  while (row !== null) {\n    var currentRow = row.alternate; // New rows can't be content rows.\n\n    if (currentRow !== null && findFirstSuspended(currentRow) === null) {\n      lastContentRow = row;\n    }\n\n    row = row.sibling;\n  }\n\n  return lastContentRow;\n}\n\nfunction validateRevealOrder(revealOrder) {\n  {\n    if (revealOrder !== undefined && revealOrder !== 'forwards' && revealOrder !== 'backwards' && revealOrder !== 'together' && !didWarnAboutRevealOrder[revealOrder]) {\n      didWarnAboutRevealOrder[revealOrder] = true;\n\n      if (typeof revealOrder === 'string') {\n        switch (revealOrder.toLowerCase()) {\n          case 'together':\n          case 'forwards':\n          case 'backwards':\n            {\n              error('\"%s\" is not a valid value for revealOrder on <SuspenseList />. ' + 'Use lowercase \"%s\" instead.', revealOrder, revealOrder.toLowerCase());\n\n              break;\n            }\n\n          case 'forward':\n          case 'backward':\n            {\n              error('\"%s\" is not a valid value for revealOrder on <SuspenseList />. ' + 'React uses the -s suffix in the spelling. Use \"%ss\" instead.', revealOrder, revealOrder.toLowerCase());\n\n              break;\n            }\n\n          default:\n            error('\"%s\" is not a supported revealOrder on <SuspenseList />. ' + 'Did you mean \"together\", \"forwards\" or \"backwards\"?', revealOrder);\n\n            break;\n        }\n      } else {\n        error('%s is not a supported value for revealOrder on <SuspenseList />. ' + 'Did you mean \"together\", \"forwards\" or \"backwards\"?', revealOrder);\n      }\n    }\n  }\n}\n\nfunction validateTailOptions(tailMode, revealOrder) {\n  {\n    if (tailMode !== undefined && !didWarnAboutTailOptions[tailMode]) {\n      if (tailMode !== 'collapsed' && tailMode !== 'hidden') {\n        didWarnAboutTailOptions[tailMode] = true;\n\n        error('\"%s\" is not a supported value for tail on <SuspenseList />. ' + 'Did you mean \"collapsed\" or \"hidden\"?', tailMode);\n      } else if (revealOrder !== 'forwards' && revealOrder !== 'backwards') {\n        didWarnAboutTailOptions[tailMode] = true;\n\n        error('<SuspenseList tail=\"%s\" /> is only valid if revealOrder is ' + '\"forwards\" or \"backwards\". ' + 'Did you mean to specify revealOrder=\"forwards\"?', tailMode);\n      }\n    }\n  }\n}\n\nfunction validateSuspenseListNestedChild(childSlot, index) {\n  {\n    var isArray = Array.isArray(childSlot);\n    var isIterable = !isArray && typeof getIteratorFn(childSlot) === 'function';\n\n    if (isArray || isIterable) {\n      var type = isArray ? 'array' : 'iterable';\n\n      error('A nested %s was passed to row #%s in <SuspenseList />. Wrap it in ' + 'an additional SuspenseList to configure its revealOrder: ' + '<SuspenseList revealOrder=...> ... ' + '<SuspenseList revealOrder=...>{%s}</SuspenseList> ... ' + '</SuspenseList>', type, index, type);\n\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction validateSuspenseListChildren(children, revealOrder) {\n  {\n    if ((revealOrder === 'forwards' || revealOrder === 'backwards') && children !== undefined && children !== null && children !== false) {\n      if (Array.isArray(children)) {\n        for (var i = 0; i < children.length; i++) {\n          if (!validateSuspenseListNestedChild(children[i], i)) {\n            return;\n          }\n        }\n      } else {\n        var iteratorFn = getIteratorFn(children);\n\n        if (typeof iteratorFn === 'function') {\n          var childrenIterator = iteratorFn.call(children);\n\n          if (childrenIterator) {\n            var step = childrenIterator.next();\n            var _i = 0;\n\n            for (; !step.done; step = childrenIterator.next()) {\n              if (!validateSuspenseListNestedChild(step.value, _i)) {\n                return;\n              }\n\n              _i++;\n            }\n          }\n        } else {\n          error('A single row was passed to a <SuspenseList revealOrder=\"%s\" />. ' + 'This is not useful since it needs multiple rows. ' + 'Did you mean to pass multiple children or an array?', revealOrder);\n        }\n      }\n    }\n  }\n}\n\nfunction initSuspenseListRenderState(workInProgress, isBackwards, tail, lastContentRow, tailMode, lastEffectBeforeRendering) {\n  var renderState = workInProgress.memoizedState;\n\n  if (renderState === null) {\n    workInProgress.memoizedState = {\n      isBackwards: isBackwards,\n      rendering: null,\n      renderingStartTime: 0,\n      last: lastContentRow,\n      tail: tail,\n      tailMode: tailMode,\n      lastEffect: lastEffectBeforeRendering\n    };\n  } else {\n    // We can reuse the existing object from previous renders.\n    renderState.isBackwards = isBackwards;\n    renderState.rendering = null;\n    renderState.renderingStartTime = 0;\n    renderState.last = lastContentRow;\n    renderState.tail = tail;\n    renderState.tailMode = tailMode;\n    renderState.lastEffect = lastEffectBeforeRendering;\n  }\n} // This can end up rendering this component multiple passes.\n// The first pass splits the children fibers into two sets. A head and tail.\n// We first render the head. If anything is in fallback state, we do another\n// pass through beginWork to rerender all children (including the tail) with\n// the force suspend context. If the first render didn't have anything in\n// in fallback state. Then we render each row in the tail one-by-one.\n// That happens in the completeWork phase without going back to beginWork.\n\n\nfunction updateSuspenseListComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps;\n  var revealOrder = nextProps.revealOrder;\n  var tailMode = nextProps.tail;\n  var newChildren = nextProps.children;\n  validateRevealOrder(revealOrder);\n  validateTailOptions(tailMode, revealOrder);\n  validateSuspenseListChildren(newChildren, revealOrder);\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  var suspenseContext = suspenseStackCursor.current;\n  var shouldForceFallback = hasSuspenseContext(suspenseContext, ForceSuspenseFallback);\n\n  if (shouldForceFallback) {\n    suspenseContext = setShallowSuspenseContext(suspenseContext, ForceSuspenseFallback);\n    workInProgress.flags |= DidCapture;\n  } else {\n    var didSuspendBefore = current !== null && (current.flags & DidCapture) !== NoFlags;\n\n    if (didSuspendBefore) {\n      // If we previously forced a fallback, we need to schedule work\n      // on any nested boundaries to let them know to try to render\n      // again. This is the same as context updating.\n      propagateSuspenseContextChange(workInProgress, workInProgress.child, renderLanes);\n    }\n\n    suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n  }\n\n  pushSuspenseContext(workInProgress, suspenseContext);\n\n  if ((workInProgress.mode & BlockingMode) === NoMode) {\n    // In legacy mode, SuspenseList doesn't work so we just\n    // use make it a noop by treating it as the default revealOrder.\n    workInProgress.memoizedState = null;\n  } else {\n    switch (revealOrder) {\n      case 'forwards':\n        {\n          var lastContentRow = findLastContentRow(workInProgress.child);\n          var tail;\n\n          if (lastContentRow === null) {\n            // The whole list is part of the tail.\n            // TODO: We could fast path by just rendering the tail now.\n            tail = workInProgress.child;\n            workInProgress.child = null;\n          } else {\n            // Disconnect the tail rows after the content row.\n            // We're going to render them separately later.\n            tail = lastContentRow.sibling;\n            lastContentRow.sibling = null;\n          }\n\n          initSuspenseListRenderState(workInProgress, false, // isBackwards\n          tail, lastContentRow, tailMode, workInProgress.lastEffect);\n          break;\n        }\n\n      case 'backwards':\n        {\n          // We're going to find the first row that has existing content.\n          // At the same time we're going to reverse the list of everything\n          // we pass in the meantime. That's going to be our tail in reverse\n          // order.\n          var _tail = null;\n          var row = workInProgress.child;\n          workInProgress.child = null;\n\n          while (row !== null) {\n            var currentRow = row.alternate; // New rows can't be content rows.\n\n            if (currentRow !== null && findFirstSuspended(currentRow) === null) {\n              // This is the beginning of the main content.\n              workInProgress.child = row;\n              break;\n            }\n\n            var nextRow = row.sibling;\n            row.sibling = _tail;\n            _tail = row;\n            row = nextRow;\n          } // TODO: If workInProgress.child is null, we can continue on the tail immediately.\n\n\n          initSuspenseListRenderState(workInProgress, true, // isBackwards\n          _tail, null, // last\n          tailMode, workInProgress.lastEffect);\n          break;\n        }\n\n      case 'together':\n        {\n          initSuspenseListRenderState(workInProgress, false, // isBackwards\n          null, // tail\n          null, // last\n          undefined, workInProgress.lastEffect);\n          break;\n        }\n\n      default:\n        {\n          // The default reveal order is the same as not having\n          // a boundary.\n          workInProgress.memoizedState = null;\n        }\n    }\n  }\n\n  return workInProgress.child;\n}\n\nfunction updatePortalComponent(current, workInProgress, renderLanes) {\n  pushHostContainer(workInProgress, workInProgress.stateNode.containerInfo);\n  var nextChildren = workInProgress.pendingProps;\n\n  if (current === null) {\n    // Portals are special because we don't append the children during mount\n    // but at commit. Therefore we need to track insertions which the normal\n    // flow doesn't do during mount. This doesn't happen at the root because\n    // the root always starts with a \"current\" with a null child.\n    // TODO: Consider unifying this with how the root works.\n    workInProgress.child = reconcileChildFibers(workInProgress, null, nextChildren, renderLanes);\n  } else {\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  }\n\n  return workInProgress.child;\n}\n\nvar hasWarnedAboutUsingNoValuePropOnContextProvider = false;\n\nfunction updateContextProvider(current, workInProgress, renderLanes) {\n  var providerType = workInProgress.type;\n  var context = providerType._context;\n  var newProps = workInProgress.pendingProps;\n  var oldProps = workInProgress.memoizedProps;\n  var newValue = newProps.value;\n\n  {\n    if (!('value' in newProps)) {\n      if (!hasWarnedAboutUsingNoValuePropOnContextProvider) {\n        hasWarnedAboutUsingNoValuePropOnContextProvider = true;\n\n        error('The `value` prop is required for the `<Context.Provider>`. Did you misspell it or forget to pass it?');\n      }\n    }\n\n    var providerPropTypes = workInProgress.type.propTypes;\n\n    if (providerPropTypes) {\n      checkPropTypes(providerPropTypes, newProps, 'prop', 'Context.Provider');\n    }\n  }\n\n  pushProvider(workInProgress, newValue);\n\n  if (oldProps !== null) {\n    var oldValue = oldProps.value;\n    var changedBits = calculateChangedBits(context, newValue, oldValue);\n\n    if (changedBits === 0) {\n      // No change. Bailout early if children are the same.\n      if (oldProps.children === newProps.children && !hasContextChanged()) {\n        return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n      }\n    } else {\n      // The context value changed. Search for matching consumers and schedule\n      // them to update.\n      propagateContextChange(workInProgress, context, changedBits, renderLanes);\n    }\n  }\n\n  var newChildren = newProps.children;\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  return workInProgress.child;\n}\n\nvar hasWarnedAboutUsingContextAsConsumer = false;\n\nfunction updateContextConsumer(current, workInProgress, renderLanes) {\n  var context = workInProgress.type; // The logic below for Context differs depending on PROD or DEV mode. In\n  // DEV mode, we create a separate object for Context.Consumer that acts\n  // like a proxy to Context. This proxy object adds unnecessary code in PROD\n  // so we use the old behaviour (Context.Consumer references Context) to\n  // reduce size and overhead. The separate object references context via\n  // a property called \"_context\", which also gives us the ability to check\n  // in DEV mode if this property exists or not and warn if it does not.\n\n  {\n    if (context._context === undefined) {\n      // This may be because it's a Context (rather than a Consumer).\n      // Or it may be because it's older React where they're the same thing.\n      // We only want to warn if we're sure it's a new React.\n      if (context !== context.Consumer) {\n        if (!hasWarnedAboutUsingContextAsConsumer) {\n          hasWarnedAboutUsingContextAsConsumer = true;\n\n          error('Rendering <Context> directly is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Consumer> instead?');\n        }\n      }\n    } else {\n      context = context._context;\n    }\n  }\n\n  var newProps = workInProgress.pendingProps;\n  var render = newProps.children;\n\n  {\n    if (typeof render !== 'function') {\n      error('A context consumer was rendered with multiple children, or a child ' + \"that isn't a function. A context consumer expects a single child \" + 'that is a function. If you did pass a function, make sure there ' + 'is no trailing or leading whitespace around it.');\n    }\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var newValue = readContext(context, newProps.unstable_observedBits);\n  var newChildren;\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    newChildren = render(newValue);\n    setIsRendering(false);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction markWorkInProgressReceivedUpdate() {\n  didReceiveUpdate = true;\n}\n\nfunction bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes) {\n  if (current !== null) {\n    // Reuse previous dependencies\n    workInProgress.dependencies = current.dependencies;\n  }\n\n  {\n    // Don't update \"base\" render times for bailouts.\n    stopProfilerTimerIfRunning();\n  }\n\n  markSkippedUpdateLanes(workInProgress.lanes); // Check if the children have any pending work.\n\n  if (!includesSomeLane(renderLanes, workInProgress.childLanes)) {\n    // The children don't have any work either. We can skip them.\n    // TODO: Once we add back resuming, we should check if the children are\n    // a work-in-progress set. If so, we need to transfer their effects.\n    return null;\n  } else {\n    // This fiber doesn't have work, but its subtree does. Clone the child\n    // fibers and continue.\n    cloneChildFibers(current, workInProgress);\n    return workInProgress.child;\n  }\n}\n\nfunction remountFiber(current, oldWorkInProgress, newWorkInProgress) {\n  {\n    var returnFiber = oldWorkInProgress.return;\n\n    if (returnFiber === null) {\n      throw new Error('Cannot swap the root fiber.');\n    } // Disconnect from the old current.\n    // It will get deleted.\n\n\n    current.alternate = null;\n    oldWorkInProgress.alternate = null; // Connect to the new tree.\n\n    newWorkInProgress.index = oldWorkInProgress.index;\n    newWorkInProgress.sibling = oldWorkInProgress.sibling;\n    newWorkInProgress.return = oldWorkInProgress.return;\n    newWorkInProgress.ref = oldWorkInProgress.ref; // Replace the child/sibling pointers above it.\n\n    if (oldWorkInProgress === returnFiber.child) {\n      returnFiber.child = newWorkInProgress;\n    } else {\n      var prevSibling = returnFiber.child;\n\n      if (prevSibling === null) {\n        throw new Error('Expected parent to have a child.');\n      }\n\n      while (prevSibling.sibling !== oldWorkInProgress) {\n        prevSibling = prevSibling.sibling;\n\n        if (prevSibling === null) {\n          throw new Error('Expected to find the previous sibling.');\n        }\n      }\n\n      prevSibling.sibling = newWorkInProgress;\n    } // Delete the old fiber and place the new one.\n    // Since the old fiber is disconnected, we have to schedule it manually.\n\n\n    var last = returnFiber.lastEffect;\n\n    if (last !== null) {\n      last.nextEffect = current;\n      returnFiber.lastEffect = current;\n    } else {\n      returnFiber.firstEffect = returnFiber.lastEffect = current;\n    }\n\n    current.nextEffect = null;\n    current.flags = Deletion;\n    newWorkInProgress.flags |= Placement; // Restart work from the new fiber.\n\n    return newWorkInProgress;\n  }\n}\n\nfunction beginWork(current, workInProgress, renderLanes) {\n  var updateLanes = workInProgress.lanes;\n\n  {\n    if (workInProgress._debugNeedsRemount && current !== null) {\n      // This will restart the begin phase with a new fiber.\n      return remountFiber(current, workInProgress, createFiberFromTypeAndProps(workInProgress.type, workInProgress.key, workInProgress.pendingProps, workInProgress._debugOwner || null, workInProgress.mode, workInProgress.lanes));\n    }\n  }\n\n  if (current !== null) {\n    var oldProps = current.memoizedProps;\n    var newProps = workInProgress.pendingProps;\n\n    if (oldProps !== newProps || hasContextChanged() || ( // Force a re-render if the implementation changed due to hot reload:\n     workInProgress.type !== current.type )) {\n      // If props or context changed, mark the fiber as having performed work.\n      // This may be unset if the props are determined to be equal later (memo).\n      didReceiveUpdate = true;\n    } else if (!includesSomeLane(renderLanes, updateLanes)) {\n      didReceiveUpdate = false; // This fiber does not have any pending work. Bailout without entering\n      // the begin phase. There's still some bookkeeping we that needs to be done\n      // in this optimized path, mostly pushing stuff onto the stack.\n\n      switch (workInProgress.tag) {\n        case HostRoot:\n          pushHostRootContext(workInProgress);\n          resetHydrationState();\n          break;\n\n        case HostComponent:\n          pushHostContext(workInProgress);\n          break;\n\n        case ClassComponent:\n          {\n            var Component = workInProgress.type;\n\n            if (isContextProvider(Component)) {\n              pushContextProvider(workInProgress);\n            }\n\n            break;\n          }\n\n        case HostPortal:\n          pushHostContainer(workInProgress, workInProgress.stateNode.containerInfo);\n          break;\n\n        case ContextProvider:\n          {\n            var newValue = workInProgress.memoizedProps.value;\n            pushProvider(workInProgress, newValue);\n            break;\n          }\n\n        case Profiler:\n          {\n            // Profiler should only call onRender when one of its descendants actually rendered.\n            var hasChildWork = includesSomeLane(renderLanes, workInProgress.childLanes);\n\n            if (hasChildWork) {\n              workInProgress.flags |= Update;\n            } // Reset effect durations for the next eventual effect phase.\n            // These are reset during render to allow the DevTools commit hook a chance to read them,\n\n\n            var stateNode = workInProgress.stateNode;\n            stateNode.effectDuration = 0;\n            stateNode.passiveEffectDuration = 0;\n          }\n\n          break;\n\n        case SuspenseComponent:\n          {\n            var state = workInProgress.memoizedState;\n\n            if (state !== null) {\n              // whether to retry the primary children, or to skip over it and\n              // go straight to the fallback. Check the priority of the primary\n              // child fragment.\n\n\n              var primaryChildFragment = workInProgress.child;\n              var primaryChildLanes = primaryChildFragment.childLanes;\n\n              if (includesSomeLane(renderLanes, primaryChildLanes)) {\n                // The primary children have pending work. Use the normal path\n                // to attempt to render the primary children again.\n                return updateSuspenseComponent(current, workInProgress, renderLanes);\n              } else {\n                // The primary child fragment does not have pending work marked\n                // on it\n                pushSuspenseContext(workInProgress, setDefaultShallowSuspenseContext(suspenseStackCursor.current)); // The primary children do not have pending work with sufficient\n                // priority. Bailout.\n\n                var child = bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n\n                if (child !== null) {\n                  // The fallback children have pending work. Skip over the\n                  // primary children and work on the fallback.\n                  return child.sibling;\n                } else {\n                  return null;\n                }\n              }\n            } else {\n              pushSuspenseContext(workInProgress, setDefaultShallowSuspenseContext(suspenseStackCursor.current));\n            }\n\n            break;\n          }\n\n        case SuspenseListComponent:\n          {\n            var didSuspendBefore = (current.flags & DidCapture) !== NoFlags;\n\n            var _hasChildWork = includesSomeLane(renderLanes, workInProgress.childLanes);\n\n            if (didSuspendBefore) {\n              if (_hasChildWork) {\n                // If something was in fallback state last time, and we have all the\n                // same children then we're still in progressive loading state.\n                // Something might get unblocked by state updates or retries in the\n                // tree which will affect the tail. So we need to use the normal\n                // path to compute the correct tail.\n                return updateSuspenseListComponent(current, workInProgress, renderLanes);\n              } // If none of the children had any work, that means that none of\n              // them got retried so they'll still be blocked in the same way\n              // as before. We can fast bail out.\n\n\n              workInProgress.flags |= DidCapture;\n            } // If nothing suspended before and we're rendering the same children,\n            // then the tail doesn't matter. Anything new that suspends will work\n            // in the \"together\" mode, so we can continue from the state we had.\n\n\n            var renderState = workInProgress.memoizedState;\n\n            if (renderState !== null) {\n              // Reset to the \"together\" mode in case we've started a different\n              // update in the past but didn't complete it.\n              renderState.rendering = null;\n              renderState.tail = null;\n              renderState.lastEffect = null;\n            }\n\n            pushSuspenseContext(workInProgress, suspenseStackCursor.current);\n\n            if (_hasChildWork) {\n              break;\n            } else {\n              // If none of the children had any work, that means that none of\n              // them got retried so they'll still be blocked in the same way\n              // as before. We can fast bail out.\n              return null;\n            }\n          }\n\n        case OffscreenComponent:\n        case LegacyHiddenComponent:\n          {\n            // Need to check if the tree still needs to be deferred. This is\n            // almost identical to the logic used in the normal update path,\n            // so we'll just enter that. The only difference is we'll bail out\n            // at the next level instead of this one, because the child props\n            // have not changed. Which is fine.\n            // TODO: Probably should refactor `beginWork` to split the bailout\n            // path from the normal path. I'm tempted to do a labeled break here\n            // but I won't :)\n            workInProgress.lanes = NoLanes;\n            return updateOffscreenComponent(current, workInProgress, renderLanes);\n          }\n      }\n\n      return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n    } else {\n      if ((current.flags & ForceUpdateForLegacySuspense) !== NoFlags) {\n        // This is a special case that only exists for legacy mode.\n        // See https://github.com/facebook/react/pull/19216.\n        didReceiveUpdate = true;\n      } else {\n        // An update was scheduled on this fiber, but there are no new props\n        // nor legacy context. Set this to false. If an update queue or context\n        // consumer produces a changed value, it will set this to true. Otherwise,\n        // the component will assume the children have not changed and bail out.\n        didReceiveUpdate = false;\n      }\n    }\n  } else {\n    didReceiveUpdate = false;\n  } // Before entering the begin phase, clear pending update priority.\n  // TODO: This assumes that we're about to evaluate the component and process\n  // the update queue. However, there's an exception: SimpleMemoComponent\n  // sometimes bails out later in the begin phase. This indicates that we should\n  // move this assignment out of the common path and into each branch.\n\n\n  workInProgress.lanes = NoLanes;\n\n  switch (workInProgress.tag) {\n    case IndeterminateComponent:\n      {\n        return mountIndeterminateComponent(current, workInProgress, workInProgress.type, renderLanes);\n      }\n\n    case LazyComponent:\n      {\n        var elementType = workInProgress.elementType;\n        return mountLazyComponent(current, workInProgress, elementType, updateLanes, renderLanes);\n      }\n\n    case FunctionComponent:\n      {\n        var _Component = workInProgress.type;\n        var unresolvedProps = workInProgress.pendingProps;\n        var resolvedProps = workInProgress.elementType === _Component ? unresolvedProps : resolveDefaultProps(_Component, unresolvedProps);\n        return updateFunctionComponent(current, workInProgress, _Component, resolvedProps, renderLanes);\n      }\n\n    case ClassComponent:\n      {\n        var _Component2 = workInProgress.type;\n        var _unresolvedProps = workInProgress.pendingProps;\n\n        var _resolvedProps = workInProgress.elementType === _Component2 ? _unresolvedProps : resolveDefaultProps(_Component2, _unresolvedProps);\n\n        return updateClassComponent(current, workInProgress, _Component2, _resolvedProps, renderLanes);\n      }\n\n    case HostRoot:\n      return updateHostRoot(current, workInProgress, renderLanes);\n\n    case HostComponent:\n      return updateHostComponent(current, workInProgress, renderLanes);\n\n    case HostText:\n      return updateHostText(current, workInProgress);\n\n    case SuspenseComponent:\n      return updateSuspenseComponent(current, workInProgress, renderLanes);\n\n    case HostPortal:\n      return updatePortalComponent(current, workInProgress, renderLanes);\n\n    case ForwardRef:\n      {\n        var type = workInProgress.type;\n        var _unresolvedProps2 = workInProgress.pendingProps;\n\n        var _resolvedProps2 = workInProgress.elementType === type ? _unresolvedProps2 : resolveDefaultProps(type, _unresolvedProps2);\n\n        return updateForwardRef(current, workInProgress, type, _resolvedProps2, renderLanes);\n      }\n\n    case Fragment:\n      return updateFragment(current, workInProgress, renderLanes);\n\n    case Mode:\n      return updateMode(current, workInProgress, renderLanes);\n\n    case Profiler:\n      return updateProfiler(current, workInProgress, renderLanes);\n\n    case ContextProvider:\n      return updateContextProvider(current, workInProgress, renderLanes);\n\n    case ContextConsumer:\n      return updateContextConsumer(current, workInProgress, renderLanes);\n\n    case MemoComponent:\n      {\n        var _type2 = workInProgress.type;\n        var _unresolvedProps3 = workInProgress.pendingProps; // Resolve outer props first, then resolve inner props.\n\n        var _resolvedProps3 = resolveDefaultProps(_type2, _unresolvedProps3);\n\n        {\n          if (workInProgress.type !== workInProgress.elementType) {\n            var outerPropTypes = _type2.propTypes;\n\n            if (outerPropTypes) {\n              checkPropTypes(outerPropTypes, _resolvedProps3, // Resolved for outer only\n              'prop', getComponentName(_type2));\n            }\n          }\n        }\n\n        _resolvedProps3 = resolveDefaultProps(_type2.type, _resolvedProps3);\n        return updateMemoComponent(current, workInProgress, _type2, _resolvedProps3, updateLanes, renderLanes);\n      }\n\n    case SimpleMemoComponent:\n      {\n        return updateSimpleMemoComponent(current, workInProgress, workInProgress.type, workInProgress.pendingProps, updateLanes, renderLanes);\n      }\n\n    case IncompleteClassComponent:\n      {\n        var _Component3 = workInProgress.type;\n        var _unresolvedProps4 = workInProgress.pendingProps;\n\n        var _resolvedProps4 = workInProgress.elementType === _Component3 ? _unresolvedProps4 : resolveDefaultProps(_Component3, _unresolvedProps4);\n\n        return mountIncompleteClassComponent(current, workInProgress, _Component3, _resolvedProps4, renderLanes);\n      }\n\n    case SuspenseListComponent:\n      {\n        return updateSuspenseListComponent(current, workInProgress, renderLanes);\n      }\n\n    case FundamentalComponent:\n      {\n\n        break;\n      }\n\n    case ScopeComponent:\n      {\n\n        break;\n      }\n\n    case Block:\n      {\n\n        break;\n      }\n\n    case OffscreenComponent:\n      {\n        return updateOffscreenComponent(current, workInProgress, renderLanes);\n      }\n\n    case LegacyHiddenComponent:\n      {\n        return updateLegacyHiddenComponent(current, workInProgress, renderLanes);\n      }\n  }\n\n  {\n    {\n      throw Error( \"Unknown unit of work tag (\" + workInProgress.tag + \"). This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction markUpdate(workInProgress) {\n  // Tag the fiber with an update effect. This turns a Placement into\n  // a PlacementAndUpdate.\n  workInProgress.flags |= Update;\n}\n\nfunction markRef$1(workInProgress) {\n  workInProgress.flags |= Ref;\n}\n\nvar appendAllChildren;\nvar updateHostContainer;\nvar updateHostComponent$1;\nvar updateHostText$1;\n\n{\n  // Mutation mode\n  appendAllChildren = function (parent, workInProgress, needsVisibilityToggle, isHidden) {\n    // We only have the top Fiber that was created but we need recurse down its\n    // children to find all the terminal nodes.\n    var node = workInProgress.child;\n\n    while (node !== null) {\n      if (node.tag === HostComponent || node.tag === HostText) {\n        appendInitialChild(parent, node.stateNode);\n      } else if (node.tag === HostPortal) ; else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === workInProgress) {\n        return;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === workInProgress) {\n          return;\n        }\n\n        node = node.return;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  };\n\n  updateHostContainer = function (workInProgress) {// Noop\n  };\n\n  updateHostComponent$1 = function (current, workInProgress, type, newProps, rootContainerInstance) {\n    // If we have an alternate, that means this is an update and we need to\n    // schedule a side-effect to do the updates.\n    var oldProps = current.memoizedProps;\n\n    if (oldProps === newProps) {\n      // In mutation mode, this is sufficient for a bailout because\n      // we won't touch this node even if children changed.\n      return;\n    } // If we get updated because one of our children updated, we don't\n    // have newProps so we'll have to reuse them.\n    // TODO: Split the update API as separate for the props vs. children.\n    // Even better would be if children weren't special cased at all tho.\n\n\n    var instance = workInProgress.stateNode;\n    var currentHostContext = getHostContext(); // TODO: Experiencing an error where oldProps is null. Suggests a host\n    // component is hitting the resume path. Figure out why. Possibly\n    // related to `hidden`.\n\n    var updatePayload = prepareUpdate(instance, type, oldProps, newProps, rootContainerInstance, currentHostContext); // TODO: Type this specific to this type of component.\n\n    workInProgress.updateQueue = updatePayload; // If the update payload indicates that there is a change or if there\n    // is a new ref we mark this as an update. All the work is done in commitWork.\n\n    if (updatePayload) {\n      markUpdate(workInProgress);\n    }\n  };\n\n  updateHostText$1 = function (current, workInProgress, oldText, newText) {\n    // If the text differs, mark it as an update. All the work in done in commitWork.\n    if (oldText !== newText) {\n      markUpdate(workInProgress);\n    }\n  };\n}\n\nfunction cutOffTailIfNeeded(renderState, hasRenderedATailFallback) {\n  if (getIsHydrating()) {\n    // If we're hydrating, we should consume as many items as we can\n    // so we don't leave any behind.\n    return;\n  }\n\n  switch (renderState.tailMode) {\n    case 'hidden':\n      {\n        // Any insertions at the end of the tail list after this point\n        // should be invisible. If there are already mounted boundaries\n        // anything before them are not considered for collapsing.\n        // Therefore we need to go through the whole tail to find if\n        // there are any.\n        var tailNode = renderState.tail;\n        var lastTailNode = null;\n\n        while (tailNode !== null) {\n          if (tailNode.alternate !== null) {\n            lastTailNode = tailNode;\n          }\n\n          tailNode = tailNode.sibling;\n        } // Next we're simply going to delete all insertions after the\n        // last rendered item.\n\n\n        if (lastTailNode === null) {\n          // All remaining items in the tail are insertions.\n          renderState.tail = null;\n        } else {\n          // Detach the insertion after the last node that was already\n          // inserted.\n          lastTailNode.sibling = null;\n        }\n\n        break;\n      }\n\n    case 'collapsed':\n      {\n        // Any insertions at the end of the tail list after this point\n        // should be invisible. If there are already mounted boundaries\n        // anything before them are not considered for collapsing.\n        // Therefore we need to go through the whole tail to find if\n        // there are any.\n        var _tailNode = renderState.tail;\n        var _lastTailNode = null;\n\n        while (_tailNode !== null) {\n          if (_tailNode.alternate !== null) {\n            _lastTailNode = _tailNode;\n          }\n\n          _tailNode = _tailNode.sibling;\n        } // Next we're simply going to delete all insertions after the\n        // last rendered item.\n\n\n        if (_lastTailNode === null) {\n          // All remaining items in the tail are insertions.\n          if (!hasRenderedATailFallback && renderState.tail !== null) {\n            // We suspended during the head. We want to show at least one\n            // row at the tail. So we'll keep on and cut off the rest.\n            renderState.tail.sibling = null;\n          } else {\n            renderState.tail = null;\n          }\n        } else {\n          // Detach the insertion after the last node that was already\n          // inserted.\n          _lastTailNode.sibling = null;\n        }\n\n        break;\n      }\n  }\n}\n\nfunction completeWork(current, workInProgress, renderLanes) {\n  var newProps = workInProgress.pendingProps;\n\n  switch (workInProgress.tag) {\n    case IndeterminateComponent:\n    case LazyComponent:\n    case SimpleMemoComponent:\n    case FunctionComponent:\n    case ForwardRef:\n    case Fragment:\n    case Mode:\n    case Profiler:\n    case ContextConsumer:\n    case MemoComponent:\n      return null;\n\n    case ClassComponent:\n      {\n        var Component = workInProgress.type;\n\n        if (isContextProvider(Component)) {\n          popContext(workInProgress);\n        }\n\n        return null;\n      }\n\n    case HostRoot:\n      {\n        popHostContainer(workInProgress);\n        popTopLevelContextObject(workInProgress);\n        resetWorkInProgressVersions();\n        var fiberRoot = workInProgress.stateNode;\n\n        if (fiberRoot.pendingContext) {\n          fiberRoot.context = fiberRoot.pendingContext;\n          fiberRoot.pendingContext = null;\n        }\n\n        if (current === null || current.child === null) {\n          // If we hydrated, pop so that we can delete any remaining children\n          // that weren't hydrated.\n          var wasHydrated = popHydrationState(workInProgress);\n\n          if (wasHydrated) {\n            // If we hydrated, then we'll need to schedule an update for\n            // the commit side-effects on the root.\n            markUpdate(workInProgress);\n          } else if (!fiberRoot.hydrate) {\n            // Schedule an effect to clear this container at the start of the next commit.\n            // This handles the case of React rendering into a container with previous children.\n            // It's also safe to do for updates too, because current.child would only be null\n            // if the previous render was null (so the the container would already be empty).\n            workInProgress.flags |= Snapshot;\n          }\n        }\n\n        updateHostContainer(workInProgress);\n        return null;\n      }\n\n    case HostComponent:\n      {\n        popHostContext(workInProgress);\n        var rootContainerInstance = getRootHostContainer();\n        var type = workInProgress.type;\n\n        if (current !== null && workInProgress.stateNode != null) {\n          updateHostComponent$1(current, workInProgress, type, newProps, rootContainerInstance);\n\n          if (current.ref !== workInProgress.ref) {\n            markRef$1(workInProgress);\n          }\n        } else {\n          if (!newProps) {\n            if (!(workInProgress.stateNode !== null)) {\n              {\n                throw Error( \"We must have new props for new mounts. This error is likely caused by a bug in React. Please file an issue.\" );\n              }\n            } // This can happen when we abort work.\n\n\n            return null;\n          }\n\n          var currentHostContext = getHostContext(); // TODO: Move createInstance to beginWork and keep it on a context\n          // \"stack\" as the parent. Then append children as we go in beginWork\n          // or completeWork depending on whether we want to add them top->down or\n          // bottom->up. Top->down is faster in IE11.\n\n          var _wasHydrated = popHydrationState(workInProgress);\n\n          if (_wasHydrated) {\n            // TODO: Move this and createInstance step into the beginPhase\n            // to consolidate.\n            if (prepareToHydrateHostInstance(workInProgress, rootContainerInstance, currentHostContext)) {\n              // If changes to the hydrated node need to be applied at the\n              // commit-phase we mark this as such.\n              markUpdate(workInProgress);\n            }\n          } else {\n            var instance = createInstance(type, newProps, rootContainerInstance, currentHostContext, workInProgress);\n            appendAllChildren(instance, workInProgress, false, false);\n            workInProgress.stateNode = instance; // Certain renderers require commit-time effects for initial mount.\n            // (eg DOM renderer supports auto-focus for certain elements).\n            // Make sure such renderers get scheduled for later work.\n\n            if (finalizeInitialChildren(instance, type, newProps, rootContainerInstance)) {\n              markUpdate(workInProgress);\n            }\n          }\n\n          if (workInProgress.ref !== null) {\n            // If there is a ref on a host node we need to schedule a callback\n            markRef$1(workInProgress);\n          }\n        }\n\n        return null;\n      }\n\n    case HostText:\n      {\n        var newText = newProps;\n\n        if (current && workInProgress.stateNode != null) {\n          var oldText = current.memoizedProps; // If we have an alternate, that means this is an update and we need\n          // to schedule a side-effect to do the updates.\n\n          updateHostText$1(current, workInProgress, oldText, newText);\n        } else {\n          if (typeof newText !== 'string') {\n            if (!(workInProgress.stateNode !== null)) {\n              {\n                throw Error( \"We must have new props for new mounts. This error is likely caused by a bug in React. Please file an issue.\" );\n              }\n            } // This can happen when we abort work.\n\n          }\n\n          var _rootContainerInstance = getRootHostContainer();\n\n          var _currentHostContext = getHostContext();\n\n          var _wasHydrated2 = popHydrationState(workInProgress);\n\n          if (_wasHydrated2) {\n            if (prepareToHydrateHostTextInstance(workInProgress)) {\n              markUpdate(workInProgress);\n            }\n          } else {\n            workInProgress.stateNode = createTextInstance(newText, _rootContainerInstance, _currentHostContext, workInProgress);\n          }\n        }\n\n        return null;\n      }\n\n    case SuspenseComponent:\n      {\n        popSuspenseContext(workInProgress);\n        var nextState = workInProgress.memoizedState;\n\n        if ((workInProgress.flags & DidCapture) !== NoFlags) {\n          // Something suspended. Re-render with the fallback children.\n          workInProgress.lanes = renderLanes; // Do not reset the effect list.\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          }\n\n          return workInProgress;\n        }\n\n        var nextDidTimeout = nextState !== null;\n        var prevDidTimeout = false;\n\n        if (current === null) {\n          if (workInProgress.memoizedProps.fallback !== undefined) {\n            popHydrationState(workInProgress);\n          }\n        } else {\n          var prevState = current.memoizedState;\n          prevDidTimeout = prevState !== null;\n        }\n\n        if (nextDidTimeout && !prevDidTimeout) {\n          // If this subtreee is running in blocking mode we can suspend,\n          // otherwise we won't suspend.\n          // TODO: This will still suspend a synchronous tree if anything\n          // in the concurrent tree already suspended during this render.\n          // This is a known bug.\n          if ((workInProgress.mode & BlockingMode) !== NoMode) {\n            // TODO: Move this back to throwException because this is too late\n            // if this is a large tree which is common for initial loads. We\n            // don't know if we should restart a render or not until we get\n            // this marker, and this is too late.\n            // If this render already had a ping or lower pri updates,\n            // and this is the first time we know we're going to suspend we\n            // should be able to immediately restart from within throwException.\n            var hasInvisibleChildContext = current === null && workInProgress.memoizedProps.unstable_avoidThisFallback !== true;\n\n            if (hasInvisibleChildContext || hasSuspenseContext(suspenseStackCursor.current, InvisibleParentSuspenseContext)) {\n              // If this was in an invisible tree or a new render, then showing\n              // this boundary is ok.\n              renderDidSuspend();\n            } else {\n              // Otherwise, we're going to have to hide content so we should\n              // suspend for longer if possible.\n              renderDidSuspendDelayIfPossible();\n            }\n          }\n        }\n\n        {\n          // TODO: Only schedule updates if these values are non equal, i.e. it changed.\n          if (nextDidTimeout || prevDidTimeout) {\n            // If this boundary just timed out, schedule an effect to attach a\n            // retry listener to the promise. This flag is also used to hide the\n            // primary children. In mutation mode, we also need the flag to\n            // *unhide* children that were previously hidden, so check if this\n            // is currently timed out, too.\n            workInProgress.flags |= Update;\n          }\n        }\n\n        return null;\n      }\n\n    case HostPortal:\n      popHostContainer(workInProgress);\n      updateHostContainer(workInProgress);\n\n      if (current === null) {\n        preparePortalMount(workInProgress.stateNode.containerInfo);\n      }\n\n      return null;\n\n    case ContextProvider:\n      // Pop provider fiber\n      popProvider(workInProgress);\n      return null;\n\n    case IncompleteClassComponent:\n      {\n        // Same as class component case. I put it down here so that the tags are\n        // sequential to ensure this switch is compiled to a jump table.\n        var _Component = workInProgress.type;\n\n        if (isContextProvider(_Component)) {\n          popContext(workInProgress);\n        }\n\n        return null;\n      }\n\n    case SuspenseListComponent:\n      {\n        popSuspenseContext(workInProgress);\n        var renderState = workInProgress.memoizedState;\n\n        if (renderState === null) {\n          // We're running in the default, \"independent\" mode.\n          // We don't do anything in this mode.\n          return null;\n        }\n\n        var didSuspendAlready = (workInProgress.flags & DidCapture) !== NoFlags;\n        var renderedTail = renderState.rendering;\n\n        if (renderedTail === null) {\n          // We just rendered the head.\n          if (!didSuspendAlready) {\n            // This is the first pass. We need to figure out if anything is still\n            // suspended in the rendered set.\n            // If new content unsuspended, but there's still some content that\n            // didn't. Then we need to do a second pass that forces everything\n            // to keep showing their fallbacks.\n            // We might be suspended if something in this render pass suspended, or\n            // something in the previous committed pass suspended. Otherwise,\n            // there's no chance so we can skip the expensive call to\n            // findFirstSuspended.\n            var cannotBeSuspended = renderHasNotSuspendedYet() && (current === null || (current.flags & DidCapture) === NoFlags);\n\n            if (!cannotBeSuspended) {\n              var row = workInProgress.child;\n\n              while (row !== null) {\n                var suspended = findFirstSuspended(row);\n\n                if (suspended !== null) {\n                  didSuspendAlready = true;\n                  workInProgress.flags |= DidCapture;\n                  cutOffTailIfNeeded(renderState, false); // If this is a newly suspended tree, it might not get committed as\n                  // part of the second pass. In that case nothing will subscribe to\n                  // its thennables. Instead, we'll transfer its thennables to the\n                  // SuspenseList so that it can retry if they resolve.\n                  // There might be multiple of these in the list but since we're\n                  // going to wait for all of them anyway, it doesn't really matter\n                  // which ones gets to ping. In theory we could get clever and keep\n                  // track of how many dependencies remain but it gets tricky because\n                  // in the meantime, we can add/remove/change items and dependencies.\n                  // We might bail out of the loop before finding any but that\n                  // doesn't matter since that means that the other boundaries that\n                  // we did find already has their listeners attached.\n\n                  var newThennables = suspended.updateQueue;\n\n                  if (newThennables !== null) {\n                    workInProgress.updateQueue = newThennables;\n                    workInProgress.flags |= Update;\n                  } // Rerender the whole list, but this time, we'll force fallbacks\n                  // to stay in place.\n                  // Reset the effect list before doing the second pass since that's now invalid.\n\n\n                  if (renderState.lastEffect === null) {\n                    workInProgress.firstEffect = null;\n                  }\n\n                  workInProgress.lastEffect = renderState.lastEffect; // Reset the child fibers to their original state.\n\n                  resetChildFibers(workInProgress, renderLanes); // Set up the Suspense Context to force suspense and immediately\n                  // rerender the children.\n\n                  pushSuspenseContext(workInProgress, setShallowSuspenseContext(suspenseStackCursor.current, ForceSuspenseFallback));\n                  return workInProgress.child;\n                }\n\n                row = row.sibling;\n              }\n            }\n\n            if (renderState.tail !== null && now() > getRenderTargetTime()) {\n              // We have already passed our CPU deadline but we still have rows\n              // left in the tail. We'll just give up further attempts to render\n              // the main content and only render fallbacks.\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true;\n              cutOffTailIfNeeded(renderState, false); // Since nothing actually suspended, there will nothing to ping this\n              // to get it started back up to attempt the next item. While in terms\n              // of priority this work has the same priority as this current render,\n              // it's not part of the same transition once the transition has\n              // committed. If it's sync, we still want to yield so that it can be\n              // painted. Conceptually, this is really the same as pinging.\n              // We can use any RetryLane even if it's the one currently rendering\n              // since we're leaving it behind on this node.\n\n              workInProgress.lanes = SomeRetryLane;\n\n              {\n                markSpawnedWork(SomeRetryLane);\n              }\n            }\n          } else {\n            cutOffTailIfNeeded(renderState, false);\n          } // Next we're going to render the tail.\n\n        } else {\n          // Append the rendered row to the child list.\n          if (!didSuspendAlready) {\n            var _suspended = findFirstSuspended(renderedTail);\n\n            if (_suspended !== null) {\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true; // Ensure we transfer the update queue to the parent so that it doesn't\n              // get lost if this row ends up dropped during a second pass.\n\n              var _newThennables = _suspended.updateQueue;\n\n              if (_newThennables !== null) {\n                workInProgress.updateQueue = _newThennables;\n                workInProgress.flags |= Update;\n              }\n\n              cutOffTailIfNeeded(renderState, true); // This might have been modified.\n\n              if (renderState.tail === null && renderState.tailMode === 'hidden' && !renderedTail.alternate && !getIsHydrating() // We don't cut it if we're hydrating.\n              ) {\n                  // We need to delete the row we just rendered.\n                  // Reset the effect list to what it was before we rendered this\n                  // child. The nested children have already appended themselves.\n                  var lastEffect = workInProgress.lastEffect = renderState.lastEffect; // Remove any effects that were appended after this point.\n\n                  if (lastEffect !== null) {\n                    lastEffect.nextEffect = null;\n                  } // We're done.\n\n\n                  return null;\n                }\n            } else if ( // The time it took to render last row is greater than the remaining\n            // time we have to render. So rendering one more row would likely\n            // exceed it.\n            now() * 2 - renderState.renderingStartTime > getRenderTargetTime() && renderLanes !== OffscreenLane) {\n              // We have now passed our CPU deadline and we'll just give up further\n              // attempts to render the main content and only render fallbacks.\n              // The assumption is that this is usually faster.\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true;\n              cutOffTailIfNeeded(renderState, false); // Since nothing actually suspended, there will nothing to ping this\n              // to get it started back up to attempt the next item. While in terms\n              // of priority this work has the same priority as this current render,\n              // it's not part of the same transition once the transition has\n              // committed. If it's sync, we still want to yield so that it can be\n              // painted. Conceptually, this is really the same as pinging.\n              // We can use any RetryLane even if it's the one currently rendering\n              // since we're leaving it behind on this node.\n\n              workInProgress.lanes = SomeRetryLane;\n\n              {\n                markSpawnedWork(SomeRetryLane);\n              }\n            }\n          }\n\n          if (renderState.isBackwards) {\n            // The effect list of the backwards tail will have been added\n            // to the end. This breaks the guarantee that life-cycles fire in\n            // sibling order but that isn't a strong guarantee promised by React.\n            // Especially since these might also just pop in during future commits.\n            // Append to the beginning of the list.\n            renderedTail.sibling = workInProgress.child;\n            workInProgress.child = renderedTail;\n          } else {\n            var previousSibling = renderState.last;\n\n            if (previousSibling !== null) {\n              previousSibling.sibling = renderedTail;\n            } else {\n              workInProgress.child = renderedTail;\n            }\n\n            renderState.last = renderedTail;\n          }\n        }\n\n        if (renderState.tail !== null) {\n          // We still have tail rows to render.\n          // Pop a row.\n          var next = renderState.tail;\n          renderState.rendering = next;\n          renderState.tail = next.sibling;\n          renderState.lastEffect = workInProgress.lastEffect;\n          renderState.renderingStartTime = now();\n          next.sibling = null; // Restore the context.\n          // TODO: We can probably just avoid popping it instead and only\n          // setting it the first time we go from not suspended to suspended.\n\n          var suspenseContext = suspenseStackCursor.current;\n\n          if (didSuspendAlready) {\n            suspenseContext = setShallowSuspenseContext(suspenseContext, ForceSuspenseFallback);\n          } else {\n            suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n          }\n\n          pushSuspenseContext(workInProgress, suspenseContext); // Do a pass over the next row.\n\n          return next;\n        }\n\n        return null;\n      }\n\n    case FundamentalComponent:\n      {\n\n        break;\n      }\n\n    case ScopeComponent:\n      {\n\n        break;\n      }\n\n    case Block:\n\n      break;\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      {\n        popRenderLanes(workInProgress);\n\n        if (current !== null) {\n          var _nextState = workInProgress.memoizedState;\n          var _prevState = current.memoizedState;\n          var prevIsHidden = _prevState !== null;\n          var nextIsHidden = _nextState !== null;\n\n          if (prevIsHidden !== nextIsHidden && newProps.mode !== 'unstable-defer-without-hiding') {\n            workInProgress.flags |= Update;\n          }\n        }\n\n        return null;\n      }\n  }\n\n  {\n    {\n      throw Error( \"Unknown unit of work tag (\" + workInProgress.tag + \"). This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction unwindWork(workInProgress, renderLanes) {\n  switch (workInProgress.tag) {\n    case ClassComponent:\n      {\n        var Component = workInProgress.type;\n\n        if (isContextProvider(Component)) {\n          popContext(workInProgress);\n        }\n\n        var flags = workInProgress.flags;\n\n        if (flags & ShouldCapture) {\n          workInProgress.flags = flags & ~ShouldCapture | DidCapture;\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          }\n\n          return workInProgress;\n        }\n\n        return null;\n      }\n\n    case HostRoot:\n      {\n        popHostContainer(workInProgress);\n        popTopLevelContextObject(workInProgress);\n        resetWorkInProgressVersions();\n        var _flags = workInProgress.flags;\n\n        if (!((_flags & DidCapture) === NoFlags)) {\n          {\n            throw Error( \"The root failed to unmount after an error. This is likely a bug in React. Please file an issue.\" );\n          }\n        }\n\n        workInProgress.flags = _flags & ~ShouldCapture | DidCapture;\n        return workInProgress;\n      }\n\n    case HostComponent:\n      {\n        // TODO: popHydrationState\n        popHostContext(workInProgress);\n        return null;\n      }\n\n    case SuspenseComponent:\n      {\n        popSuspenseContext(workInProgress);\n\n        var _flags2 = workInProgress.flags;\n\n        if (_flags2 & ShouldCapture) {\n          workInProgress.flags = _flags2 & ~ShouldCapture | DidCapture; // Captured a suspense effect. Re-render the boundary.\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          }\n\n          return workInProgress;\n        }\n\n        return null;\n      }\n\n    case SuspenseListComponent:\n      {\n        popSuspenseContext(workInProgress); // SuspenseList doesn't actually catch anything. It should've been\n        // caught by a nested boundary. If not, it should bubble through.\n\n        return null;\n      }\n\n    case HostPortal:\n      popHostContainer(workInProgress);\n      return null;\n\n    case ContextProvider:\n      popProvider(workInProgress);\n      return null;\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      popRenderLanes(workInProgress);\n      return null;\n\n    default:\n      return null;\n  }\n}\n\nfunction unwindInterruptedWork(interruptedWork) {\n  switch (interruptedWork.tag) {\n    case ClassComponent:\n      {\n        var childContextTypes = interruptedWork.type.childContextTypes;\n\n        if (childContextTypes !== null && childContextTypes !== undefined) {\n          popContext(interruptedWork);\n        }\n\n        break;\n      }\n\n    case HostRoot:\n      {\n        popHostContainer(interruptedWork);\n        popTopLevelContextObject(interruptedWork);\n        resetWorkInProgressVersions();\n        break;\n      }\n\n    case HostComponent:\n      {\n        popHostContext(interruptedWork);\n        break;\n      }\n\n    case HostPortal:\n      popHostContainer(interruptedWork);\n      break;\n\n    case SuspenseComponent:\n      popSuspenseContext(interruptedWork);\n      break;\n\n    case SuspenseListComponent:\n      popSuspenseContext(interruptedWork);\n      break;\n\n    case ContextProvider:\n      popProvider(interruptedWork);\n      break;\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      popRenderLanes(interruptedWork);\n      break;\n  }\n}\n\nfunction createCapturedValue(value, source) {\n  // If the value is an error, call this function immediately after it is thrown\n  // so the stack is accurate.\n  return {\n    value: value,\n    source: source,\n    stack: getStackByFiberInDevAndProd(source)\n  };\n}\n\n// This module is forked in different environments.\n// By default, return `true` to log errors to the console.\n// Forks can return `false` if this isn't desirable.\nfunction showErrorDialog(boundary, errorInfo) {\n  return true;\n}\n\nfunction logCapturedError(boundary, errorInfo) {\n  try {\n    var logError = showErrorDialog(boundary, errorInfo); // Allow injected showErrorDialog() to prevent default console.error logging.\n    // This enables renderers like ReactNative to better manage redbox behavior.\n\n    if (logError === false) {\n      return;\n    }\n\n    var error = errorInfo.value;\n\n    if (true) {\n      var source = errorInfo.source;\n      var stack = errorInfo.stack;\n      var componentStack = stack !== null ? stack : ''; // Browsers support silencing uncaught errors by calling\n      // `preventDefault()` in window `error` handler.\n      // We record this information as an expando on the error.\n\n      if (error != null && error._suppressLogging) {\n        if (boundary.tag === ClassComponent) {\n          // The error is recoverable and was silenced.\n          // Ignore it and don't print the stack addendum.\n          // This is handy for testing error boundaries without noise.\n          return;\n        } // The error is fatal. Since the silencing might have\n        // been accidental, we'll surface it anyway.\n        // However, the browser would have silenced the original error\n        // so we'll print it first, and then print the stack addendum.\n\n\n        console['error'](error); // Don't transform to our wrapper\n        // For a more detailed description of this block, see:\n        // https://github.com/facebook/react/pull/13384\n      }\n\n      var componentName = source ? getComponentName(source.type) : null;\n      var componentNameMessage = componentName ? \"The above error occurred in the <\" + componentName + \"> component:\" : 'The above error occurred in one of your React components:';\n      var errorBoundaryMessage;\n      var errorBoundaryName = getComponentName(boundary.type);\n\n      if (errorBoundaryName) {\n        errorBoundaryMessage = \"React will try to recreate this component tree from scratch \" + (\"using the error boundary you provided, \" + errorBoundaryName + \".\");\n      } else {\n        errorBoundaryMessage = 'Consider adding an error boundary to your tree to customize error handling behavior.\\n' + 'Visit https://reactjs.org/link/error-boundaries to learn more about error boundaries.';\n      }\n\n      var combinedMessage = componentNameMessage + \"\\n\" + componentStack + \"\\n\\n\" + (\"\" + errorBoundaryMessage); // In development, we provide our own message with just the component stack.\n      // We don't include the original error message and JS stack because the browser\n      // has already printed it. Even if the application swallows the error, it is still\n      // displayed by the browser thanks to the DEV-only fake event trick in ReactErrorUtils.\n\n      console['error'](combinedMessage); // Don't transform to our wrapper\n    } else {}\n  } catch (e) {\n    // This method must not throw, or React internal state will get messed up.\n    // If console.error is overridden, or logCapturedError() shows a dialog that throws,\n    // we want to report this error outside of the normal stack as a last resort.\n    // https://github.com/facebook/react/issues/13188\n    setTimeout(function () {\n      throw e;\n    });\n  }\n}\n\nvar PossiblyWeakMap$1 = typeof WeakMap === 'function' ? WeakMap : Map;\n\nfunction createRootErrorUpdate(fiber, errorInfo, lane) {\n  var update = createUpdate(NoTimestamp, lane); // Unmount the root by rendering null.\n\n  update.tag = CaptureUpdate; // Caution: React DevTools currently depends on this property\n  // being called \"element\".\n\n  update.payload = {\n    element: null\n  };\n  var error = errorInfo.value;\n\n  update.callback = function () {\n    onUncaughtError(error);\n    logCapturedError(fiber, errorInfo);\n  };\n\n  return update;\n}\n\nfunction createClassErrorUpdate(fiber, errorInfo, lane) {\n  var update = createUpdate(NoTimestamp, lane);\n  update.tag = CaptureUpdate;\n  var getDerivedStateFromError = fiber.type.getDerivedStateFromError;\n\n  if (typeof getDerivedStateFromError === 'function') {\n    var error$1 = errorInfo.value;\n\n    update.payload = function () {\n      logCapturedError(fiber, errorInfo);\n      return getDerivedStateFromError(error$1);\n    };\n  }\n\n  var inst = fiber.stateNode;\n\n  if (inst !== null && typeof inst.componentDidCatch === 'function') {\n    update.callback = function callback() {\n      {\n        markFailedErrorBoundaryForHotReloading(fiber);\n      }\n\n      if (typeof getDerivedStateFromError !== 'function') {\n        // To preserve the preexisting retry behavior of error boundaries,\n        // we keep track of which ones already failed during this batch.\n        // This gets reset before we yield back to the browser.\n        // TODO: Warn in strict mode if getDerivedStateFromError is\n        // not defined.\n        markLegacyErrorBoundaryAsFailed(this); // Only log here if componentDidCatch is the only error boundary method defined\n\n        logCapturedError(fiber, errorInfo);\n      }\n\n      var error$1 = errorInfo.value;\n      var stack = errorInfo.stack;\n      this.componentDidCatch(error$1, {\n        componentStack: stack !== null ? stack : ''\n      });\n\n      {\n        if (typeof getDerivedStateFromError !== 'function') {\n          // If componentDidCatch is the only error boundary method defined,\n          // then it needs to call setState to recover from errors.\n          // If no state update is scheduled then the boundary will swallow the error.\n          if (!includesSomeLane(fiber.lanes, SyncLane)) {\n            error('%s: Error boundaries should implement getDerivedStateFromError(). ' + 'In that method, return a state update to display an error message or fallback UI.', getComponentName(fiber.type) || 'Unknown');\n          }\n        }\n      }\n    };\n  } else {\n    update.callback = function () {\n      markFailedErrorBoundaryForHotReloading(fiber);\n    };\n  }\n\n  return update;\n}\n\nfunction attachPingListener(root, wakeable, lanes) {\n  // Attach a listener to the promise to \"ping\" the root and retry. But only if\n  // one does not already exist for the lanes we're currently rendering (which\n  // acts like a \"thread ID\" here).\n  var pingCache = root.pingCache;\n  var threadIDs;\n\n  if (pingCache === null) {\n    pingCache = root.pingCache = new PossiblyWeakMap$1();\n    threadIDs = new Set();\n    pingCache.set(wakeable, threadIDs);\n  } else {\n    threadIDs = pingCache.get(wakeable);\n\n    if (threadIDs === undefined) {\n      threadIDs = new Set();\n      pingCache.set(wakeable, threadIDs);\n    }\n  }\n\n  if (!threadIDs.has(lanes)) {\n    // Memoize using the thread ID to prevent redundant listeners.\n    threadIDs.add(lanes);\n    var ping = pingSuspendedRoot.bind(null, root, wakeable, lanes);\n    wakeable.then(ping, ping);\n  }\n}\n\nfunction throwException(root, returnFiber, sourceFiber, value, rootRenderLanes) {\n  // The source fiber did not complete.\n  sourceFiber.flags |= Incomplete; // Its effect list is no longer valid.\n\n  sourceFiber.firstEffect = sourceFiber.lastEffect = null;\n\n  if (value !== null && typeof value === 'object' && typeof value.then === 'function') {\n    // This is a wakeable.\n    var wakeable = value;\n\n    if ((sourceFiber.mode & BlockingMode) === NoMode) {\n      // Reset the memoizedState to what it was before we attempted\n      // to render it.\n      var currentSource = sourceFiber.alternate;\n\n      if (currentSource) {\n        sourceFiber.updateQueue = currentSource.updateQueue;\n        sourceFiber.memoizedState = currentSource.memoizedState;\n        sourceFiber.lanes = currentSource.lanes;\n      } else {\n        sourceFiber.updateQueue = null;\n        sourceFiber.memoizedState = null;\n      }\n    }\n\n    var hasInvisibleParentBoundary = hasSuspenseContext(suspenseStackCursor.current, InvisibleParentSuspenseContext); // Schedule the nearest Suspense to re-render the timed out view.\n\n    var _workInProgress = returnFiber;\n\n    do {\n      if (_workInProgress.tag === SuspenseComponent && shouldCaptureSuspense(_workInProgress, hasInvisibleParentBoundary)) {\n        // Found the nearest boundary.\n        // Stash the promise on the boundary fiber. If the boundary times out, we'll\n        // attach another listener to flip the boundary back to its normal state.\n        var wakeables = _workInProgress.updateQueue;\n\n        if (wakeables === null) {\n          var updateQueue = new Set();\n          updateQueue.add(wakeable);\n          _workInProgress.updateQueue = updateQueue;\n        } else {\n          wakeables.add(wakeable);\n        } // If the boundary is outside of blocking mode, we should *not*\n        // suspend the commit. Pretend as if the suspended component rendered\n        // null and keep rendering. In the commit phase, we'll schedule a\n        // subsequent synchronous update to re-render the Suspense.\n        //\n        // Note: It doesn't matter whether the component that suspended was\n        // inside a blocking mode tree. If the Suspense is outside of it, we\n        // should *not* suspend the commit.\n\n\n        if ((_workInProgress.mode & BlockingMode) === NoMode) {\n          _workInProgress.flags |= DidCapture;\n          sourceFiber.flags |= ForceUpdateForLegacySuspense; // We're going to commit this fiber even though it didn't complete.\n          // But we shouldn't call any lifecycle methods or callbacks. Remove\n          // all lifecycle effect tags.\n\n          sourceFiber.flags &= ~(LifecycleEffectMask | Incomplete);\n\n          if (sourceFiber.tag === ClassComponent) {\n            var currentSourceFiber = sourceFiber.alternate;\n\n            if (currentSourceFiber === null) {\n              // This is a new mount. Change the tag so it's not mistaken for a\n              // completed class component. For example, we should not call\n              // componentWillUnmount if it is deleted.\n              sourceFiber.tag = IncompleteClassComponent;\n            } else {\n              // When we try rendering again, we should not reuse the current fiber,\n              // since it's known to be in an inconsistent state. Use a force update to\n              // prevent a bail out.\n              var update = createUpdate(NoTimestamp, SyncLane);\n              update.tag = ForceUpdate;\n              enqueueUpdate(sourceFiber, update);\n            }\n          } // The source fiber did not complete. Mark it with Sync priority to\n          // indicate that it still has pending work.\n\n\n          sourceFiber.lanes = mergeLanes(sourceFiber.lanes, SyncLane); // Exit without suspending.\n\n          return;\n        } // Confirmed that the boundary is in a concurrent mode tree. Continue\n        // with the normal suspend path.\n        //\n        // After this we'll use a set of heuristics to determine whether this\n        // render pass will run to completion or restart or \"suspend\" the commit.\n        // The actual logic for this is spread out in different places.\n        //\n        // This first principle is that if we're going to suspend when we complete\n        // a root, then we should also restart if we get an update or ping that\n        // might unsuspend it, and vice versa. The only reason to suspend is\n        // because you think you might want to restart before committing. However,\n        // it doesn't make sense to restart only while in the period we're suspended.\n        //\n        // Restarting too aggressively is also not good because it starves out any\n        // intermediate loading state. So we use heuristics to determine when.\n        // Suspense Heuristics\n        //\n        // If nothing threw a Promise or all the same fallbacks are already showing,\n        // then don't suspend/restart.\n        //\n        // If this is an initial render of a new tree of Suspense boundaries and\n        // those trigger a fallback, then don't suspend/restart. We want to ensure\n        // that we can show the initial loading state as quickly as possible.\n        //\n        // If we hit a \"Delayed\" case, such as when we'd switch from content back into\n        // a fallback, then we should always suspend/restart. Transitions apply\n        // to this case. If none is defined, JND is used instead.\n        //\n        // If we're already showing a fallback and it gets \"retried\", allowing us to show\n        // another level, but there's still an inner boundary that would show a fallback,\n        // then we suspend/restart for 500ms since the last time we showed a fallback\n        // anywhere in the tree. This effectively throttles progressive loading into a\n        // consistent train of commits. This also gives us an opportunity to restart to\n        // get to the completed state slightly earlier.\n        //\n        // If there's ambiguity due to batching it's resolved in preference of:\n        // 1) \"delayed\", 2) \"initial render\", 3) \"retry\".\n        //\n        // We want to ensure that a \"busy\" state doesn't get force committed. We want to\n        // ensure that new initial loading states can commit as soon as possible.\n\n\n        attachPingListener(root, wakeable, rootRenderLanes);\n        _workInProgress.flags |= ShouldCapture;\n        _workInProgress.lanes = rootRenderLanes;\n        return;\n      } // This boundary already captured during this render. Continue to the next\n      // boundary.\n\n\n      _workInProgress = _workInProgress.return;\n    } while (_workInProgress !== null); // No boundary was found. Fallthrough to error mode.\n    // TODO: Use invariant so the message is stripped in prod?\n\n\n    value = new Error((getComponentName(sourceFiber.type) || 'A React component') + ' suspended while rendering, but no fallback UI was specified.\\n' + '\\n' + 'Add a <Suspense fallback=...> component higher in the tree to ' + 'provide a loading indicator or placeholder to display.');\n  } // We didn't find a boundary that could handle this type of exception. Start\n  // over and traverse parent path again, this time treating the exception\n  // as an error.\n\n\n  renderDidError();\n  value = createCapturedValue(value, sourceFiber);\n  var workInProgress = returnFiber;\n\n  do {\n    switch (workInProgress.tag) {\n      case HostRoot:\n        {\n          var _errorInfo = value;\n          workInProgress.flags |= ShouldCapture;\n          var lane = pickArbitraryLane(rootRenderLanes);\n          workInProgress.lanes = mergeLanes(workInProgress.lanes, lane);\n\n          var _update = createRootErrorUpdate(workInProgress, _errorInfo, lane);\n\n          enqueueCapturedUpdate(workInProgress, _update);\n          return;\n        }\n\n      case ClassComponent:\n        // Capture and retry\n        var errorInfo = value;\n        var ctor = workInProgress.type;\n        var instance = workInProgress.stateNode;\n\n        if ((workInProgress.flags & DidCapture) === NoFlags && (typeof ctor.getDerivedStateFromError === 'function' || instance !== null && typeof instance.componentDidCatch === 'function' && !isAlreadyFailedLegacyErrorBoundary(instance))) {\n          workInProgress.flags |= ShouldCapture;\n\n          var _lane = pickArbitraryLane(rootRenderLanes);\n\n          workInProgress.lanes = mergeLanes(workInProgress.lanes, _lane); // Schedule the error boundary to re-render using updated state\n\n          var _update2 = createClassErrorUpdate(workInProgress, errorInfo, _lane);\n\n          enqueueCapturedUpdate(workInProgress, _update2);\n          return;\n        }\n\n        break;\n    }\n\n    workInProgress = workInProgress.return;\n  } while (workInProgress !== null);\n}\n\nvar didWarnAboutUndefinedSnapshotBeforeUpdate = null;\n\n{\n  didWarnAboutUndefinedSnapshotBeforeUpdate = new Set();\n}\n\nvar PossiblyWeakSet = typeof WeakSet === 'function' ? WeakSet : Set;\n\nvar callComponentWillUnmountWithTimer = function (current, instance) {\n  instance.props = current.memoizedProps;\n  instance.state = current.memoizedState;\n\n  {\n    instance.componentWillUnmount();\n  }\n}; // Capture errors so they don't interrupt unmounting.\n\n\nfunction safelyCallComponentWillUnmount(current, instance) {\n  {\n    invokeGuardedCallback(null, callComponentWillUnmountWithTimer, null, current, instance);\n\n    if (hasCaughtError()) {\n      var unmountError = clearCaughtError();\n      captureCommitPhaseError(current, unmountError);\n    }\n  }\n}\n\nfunction safelyDetachRef(current) {\n  var ref = current.ref;\n\n  if (ref !== null) {\n    if (typeof ref === 'function') {\n      {\n        invokeGuardedCallback(null, ref, null, null);\n\n        if (hasCaughtError()) {\n          var refError = clearCaughtError();\n          captureCommitPhaseError(current, refError);\n        }\n      }\n    } else {\n      ref.current = null;\n    }\n  }\n}\n\nfunction safelyCallDestroy(current, destroy) {\n  {\n    invokeGuardedCallback(null, destroy, null);\n\n    if (hasCaughtError()) {\n      var error = clearCaughtError();\n      captureCommitPhaseError(current, error);\n    }\n  }\n}\n\nfunction commitBeforeMutationLifeCycles(current, finishedWork) {\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n    case Block:\n      {\n        return;\n      }\n\n    case ClassComponent:\n      {\n        if (finishedWork.flags & Snapshot) {\n          if (current !== null) {\n            var prevProps = current.memoizedProps;\n            var prevState = current.memoizedState;\n            var instance = finishedWork.stateNode; // We could update instance props and state here,\n            // but instead we rely on them being set during last render.\n            // TODO: revisit this when we implement resuming.\n\n            {\n              if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                if (instance.props !== finishedWork.memoizedProps) {\n                  error('Expected %s props to match memoized props before ' + 'getSnapshotBeforeUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n\n                if (instance.state !== finishedWork.memoizedState) {\n                  error('Expected %s state to match memoized state before ' + 'getSnapshotBeforeUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n              }\n            }\n\n            var snapshot = instance.getSnapshotBeforeUpdate(finishedWork.elementType === finishedWork.type ? prevProps : resolveDefaultProps(finishedWork.type, prevProps), prevState);\n\n            {\n              var didWarnSet = didWarnAboutUndefinedSnapshotBeforeUpdate;\n\n              if (snapshot === undefined && !didWarnSet.has(finishedWork.type)) {\n                didWarnSet.add(finishedWork.type);\n\n                error('%s.getSnapshotBeforeUpdate(): A snapshot value (or null) ' + 'must be returned. You have returned undefined.', getComponentName(finishedWork.type));\n              }\n            }\n\n            instance.__reactInternalSnapshotBeforeUpdate = snapshot;\n          }\n        }\n\n        return;\n      }\n\n    case HostRoot:\n      {\n        {\n          if (finishedWork.flags & Snapshot) {\n            var root = finishedWork.stateNode;\n            clearContainer(root.containerInfo);\n          }\n        }\n\n        return;\n      }\n\n    case HostComponent:\n    case HostText:\n    case HostPortal:\n    case IncompleteClassComponent:\n      // Nothing to do for these component types\n      return;\n  }\n\n  {\n    {\n      throw Error( \"This unit of work tag should not have side-effects. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction commitHookEffectListUnmount(tag, finishedWork) {\n  var updateQueue = finishedWork.updateQueue;\n  var lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n\n  if (lastEffect !== null) {\n    var firstEffect = lastEffect.next;\n    var effect = firstEffect;\n\n    do {\n      if ((effect.tag & tag) === tag) {\n        // Unmount\n        var destroy = effect.destroy;\n        effect.destroy = undefined;\n\n        if (destroy !== undefined) {\n          destroy();\n        }\n      }\n\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n\nfunction commitHookEffectListMount(tag, finishedWork) {\n  var updateQueue = finishedWork.updateQueue;\n  var lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n\n  if (lastEffect !== null) {\n    var firstEffect = lastEffect.next;\n    var effect = firstEffect;\n\n    do {\n      if ((effect.tag & tag) === tag) {\n        // Mount\n        var create = effect.create;\n        effect.destroy = create();\n\n        {\n          var destroy = effect.destroy;\n\n          if (destroy !== undefined && typeof destroy !== 'function') {\n            var addendum = void 0;\n\n            if (destroy === null) {\n              addendum = ' You returned null. If your effect does not require clean ' + 'up, return undefined (or nothing).';\n            } else if (typeof destroy.then === 'function') {\n              addendum = '\\n\\nIt looks like you wrote useEffect(async () => ...) or returned a Promise. ' + 'Instead, write the async function inside your effect ' + 'and call it immediately:\\n\\n' + 'useEffect(() => {\\n' + '  async function fetchData() {\\n' + '    // You can await here\\n' + '    const response = await MyAPI.getData(someId);\\n' + '    // ...\\n' + '  }\\n' + '  fetchData();\\n' + \"}, [someId]); // Or [] if effect doesn't need props or state\\n\\n\" + 'Learn more about data fetching with Hooks: https://reactjs.org/link/hooks-data-fetching';\n            } else {\n              addendum = ' You returned: ' + destroy;\n            }\n\n            error('An effect function must not return anything besides a function, ' + 'which is used for clean-up.%s', addendum);\n          }\n        }\n      }\n\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n\nfunction schedulePassiveEffects(finishedWork) {\n  var updateQueue = finishedWork.updateQueue;\n  var lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n\n  if (lastEffect !== null) {\n    var firstEffect = lastEffect.next;\n    var effect = firstEffect;\n\n    do {\n      var _effect = effect,\n          next = _effect.next,\n          tag = _effect.tag;\n\n      if ((tag & Passive$1) !== NoFlags$1 && (tag & HasEffect) !== NoFlags$1) {\n        enqueuePendingPassiveHookEffectUnmount(finishedWork, effect);\n        enqueuePendingPassiveHookEffectMount(finishedWork, effect);\n      }\n\n      effect = next;\n    } while (effect !== firstEffect);\n  }\n}\n\nfunction commitLifeCycles(finishedRoot, current, finishedWork, committedLanes) {\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n    case Block:\n      {\n        // At this point layout effects have already been destroyed (during mutation phase).\n        // This is done to prevent sibling component effects from interfering with each other,\n        // e.g. a destroy function in one component should never override a ref set\n        // by a create function in another component during the same commit.\n        {\n          commitHookEffectListMount(Layout | HasEffect, finishedWork);\n        }\n\n        schedulePassiveEffects(finishedWork);\n        return;\n      }\n\n    case ClassComponent:\n      {\n        var instance = finishedWork.stateNode;\n\n        if (finishedWork.flags & Update) {\n          if (current === null) {\n            // We could update instance props and state here,\n            // but instead we rely on them being set during last render.\n            // TODO: revisit this when we implement resuming.\n            {\n              if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                if (instance.props !== finishedWork.memoizedProps) {\n                  error('Expected %s props to match memoized props before ' + 'componentDidMount. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n\n                if (instance.state !== finishedWork.memoizedState) {\n                  error('Expected %s state to match memoized state before ' + 'componentDidMount. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n              }\n            }\n\n            {\n              instance.componentDidMount();\n            }\n          } else {\n            var prevProps = finishedWork.elementType === finishedWork.type ? current.memoizedProps : resolveDefaultProps(finishedWork.type, current.memoizedProps);\n            var prevState = current.memoizedState; // We could update instance props and state here,\n            // but instead we rely on them being set during last render.\n            // TODO: revisit this when we implement resuming.\n\n            {\n              if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                if (instance.props !== finishedWork.memoizedProps) {\n                  error('Expected %s props to match memoized props before ' + 'componentDidUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n\n                if (instance.state !== finishedWork.memoizedState) {\n                  error('Expected %s state to match memoized state before ' + 'componentDidUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n                }\n              }\n            }\n\n            {\n              instance.componentDidUpdate(prevProps, prevState, instance.__reactInternalSnapshotBeforeUpdate);\n            }\n          }\n        } // TODO: I think this is now always non-null by the time it reaches the\n        // commit phase. Consider removing the type check.\n\n\n        var updateQueue = finishedWork.updateQueue;\n\n        if (updateQueue !== null) {\n          {\n            if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n              if (instance.props !== finishedWork.memoizedProps) {\n                error('Expected %s props to match memoized props before ' + 'processing the update queue. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n              }\n\n              if (instance.state !== finishedWork.memoizedState) {\n                error('Expected %s state to match memoized state before ' + 'processing the update queue. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentName(finishedWork.type) || 'instance');\n              }\n            }\n          } // We could update instance props and state here,\n          // but instead we rely on them being set during last render.\n          // TODO: revisit this when we implement resuming.\n\n\n          commitUpdateQueue(finishedWork, updateQueue, instance);\n        }\n\n        return;\n      }\n\n    case HostRoot:\n      {\n        // TODO: I think this is now always non-null by the time it reaches the\n        // commit phase. Consider removing the type check.\n        var _updateQueue = finishedWork.updateQueue;\n\n        if (_updateQueue !== null) {\n          var _instance = null;\n\n          if (finishedWork.child !== null) {\n            switch (finishedWork.child.tag) {\n              case HostComponent:\n                _instance = getPublicInstance(finishedWork.child.stateNode);\n                break;\n\n              case ClassComponent:\n                _instance = finishedWork.child.stateNode;\n                break;\n            }\n          }\n\n          commitUpdateQueue(finishedWork, _updateQueue, _instance);\n        }\n\n        return;\n      }\n\n    case HostComponent:\n      {\n        var _instance2 = finishedWork.stateNode; // Renderers may schedule work to be done after host components are mounted\n        // (eg DOM renderer may schedule auto-focus for inputs and form controls).\n        // These effects should only be committed when components are first mounted,\n        // aka when there is no current/alternate.\n\n        if (current === null && finishedWork.flags & Update) {\n          var type = finishedWork.type;\n          var props = finishedWork.memoizedProps;\n          commitMount(_instance2, type, props);\n        }\n\n        return;\n      }\n\n    case HostText:\n      {\n        // We have no life-cycles associated with text.\n        return;\n      }\n\n    case HostPortal:\n      {\n        // We have no life-cycles associated with portals.\n        return;\n      }\n\n    case Profiler:\n      {\n        {\n          var _finishedWork$memoize2 = finishedWork.memoizedProps,\n              onCommit = _finishedWork$memoize2.onCommit,\n              onRender = _finishedWork$memoize2.onRender;\n          var effectDuration = finishedWork.stateNode.effectDuration;\n          var commitTime = getCommitTime();\n\n          if (typeof onRender === 'function') {\n            {\n              onRender(finishedWork.memoizedProps.id, current === null ? 'mount' : 'update', finishedWork.actualDuration, finishedWork.treeBaseDuration, finishedWork.actualStartTime, commitTime, finishedRoot.memoizedInteractions);\n            }\n          }\n        }\n\n        return;\n      }\n\n    case SuspenseComponent:\n      {\n        commitSuspenseHydrationCallbacks(finishedRoot, finishedWork);\n        return;\n      }\n\n    case SuspenseListComponent:\n    case IncompleteClassComponent:\n    case FundamentalComponent:\n    case ScopeComponent:\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      return;\n  }\n\n  {\n    {\n      throw Error( \"This unit of work tag should not have side-effects. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction hideOrUnhideAllChildren(finishedWork, isHidden) {\n  {\n    // We only have the top Fiber that was inserted but we need to recurse down its\n    // children to find all the terminal nodes.\n    var node = finishedWork;\n\n    while (true) {\n      if (node.tag === HostComponent) {\n        var instance = node.stateNode;\n\n        if (isHidden) {\n          hideInstance(instance);\n        } else {\n          unhideInstance(node.stateNode, node.memoizedProps);\n        }\n      } else if (node.tag === HostText) {\n        var _instance3 = node.stateNode;\n\n        if (isHidden) {\n          hideTextInstance(_instance3);\n        } else {\n          unhideTextInstance(_instance3, node.memoizedProps);\n        }\n      } else if ((node.tag === OffscreenComponent || node.tag === LegacyHiddenComponent) && node.memoizedState !== null && node !== finishedWork) ; else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === finishedWork) {\n        return;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === finishedWork) {\n          return;\n        }\n\n        node = node.return;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  }\n}\n\nfunction commitAttachRef(finishedWork) {\n  var ref = finishedWork.ref;\n\n  if (ref !== null) {\n    var instance = finishedWork.stateNode;\n    var instanceToUse;\n\n    switch (finishedWork.tag) {\n      case HostComponent:\n        instanceToUse = getPublicInstance(instance);\n        break;\n\n      default:\n        instanceToUse = instance;\n    } // Moved outside to ensure DCE works with this flag\n\n    if (typeof ref === 'function') {\n      ref(instanceToUse);\n    } else {\n      {\n        if (!ref.hasOwnProperty('current')) {\n          error('Unexpected ref object provided for %s. ' + 'Use either a ref-setter function or React.createRef().', getComponentName(finishedWork.type));\n        }\n      }\n\n      ref.current = instanceToUse;\n    }\n  }\n}\n\nfunction commitDetachRef(current) {\n  var currentRef = current.ref;\n\n  if (currentRef !== null) {\n    if (typeof currentRef === 'function') {\n      currentRef(null);\n    } else {\n      currentRef.current = null;\n    }\n  }\n} // User-originating errors (lifecycles and refs) should not interrupt\n// deletion, so don't let them throw. Host-originating errors should\n// interrupt deletion, so it's okay\n\n\nfunction commitUnmount(finishedRoot, current, renderPriorityLevel) {\n  onCommitUnmount(current);\n\n  switch (current.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case MemoComponent:\n    case SimpleMemoComponent:\n    case Block:\n      {\n        var updateQueue = current.updateQueue;\n\n        if (updateQueue !== null) {\n          var lastEffect = updateQueue.lastEffect;\n\n          if (lastEffect !== null) {\n            var firstEffect = lastEffect.next;\n            var effect = firstEffect;\n\n            do {\n              var _effect2 = effect,\n                  destroy = _effect2.destroy,\n                  tag = _effect2.tag;\n\n              if (destroy !== undefined) {\n                if ((tag & Passive$1) !== NoFlags$1) {\n                  enqueuePendingPassiveHookEffectUnmount(current, effect);\n                } else {\n                  {\n                    safelyCallDestroy(current, destroy);\n                  }\n                }\n              }\n\n              effect = effect.next;\n            } while (effect !== firstEffect);\n          }\n        }\n\n        return;\n      }\n\n    case ClassComponent:\n      {\n        safelyDetachRef(current);\n        var instance = current.stateNode;\n\n        if (typeof instance.componentWillUnmount === 'function') {\n          safelyCallComponentWillUnmount(current, instance);\n        }\n\n        return;\n      }\n\n    case HostComponent:\n      {\n        safelyDetachRef(current);\n        return;\n      }\n\n    case HostPortal:\n      {\n        // TODO: this is recursive.\n        // We are also not using this parent because\n        // the portal will get pushed immediately.\n        {\n          unmountHostComponents(finishedRoot, current);\n        }\n\n        return;\n      }\n\n    case FundamentalComponent:\n      {\n\n        return;\n      }\n\n    case DehydratedFragment:\n      {\n\n        return;\n      }\n\n    case ScopeComponent:\n      {\n\n        return;\n      }\n  }\n}\n\nfunction commitNestedUnmounts(finishedRoot, root, renderPriorityLevel) {\n  // While we're inside a removed host node we don't want to call\n  // removeChild on the inner nodes because they're removed by the top\n  // call anyway. We also want to call componentWillUnmount on all\n  // composites before this host node is removed from the tree. Therefore\n  // we do an inner loop while we're still inside the host node.\n  var node = root;\n\n  while (true) {\n    commitUnmount(finishedRoot, node); // Visit children because they may contain more composite or host nodes.\n    // Skip portals because commitUnmount() currently visits them recursively.\n\n    if (node.child !== null && ( // If we use mutation we drill down into portals using commitUnmount above.\n    // If we don't use mutation we drill down into portals here instead.\n     node.tag !== HostPortal)) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === root) {\n      return;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === root) {\n        return;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n}\n\nfunction detachFiberMutation(fiber) {\n  // Cut off the return pointers to disconnect it from the tree. Ideally, we\n  // should clear the child pointer of the parent alternate to let this\n  // get GC:ed but we don't know which for sure which parent is the current\n  // one so we'll settle for GC:ing the subtree of this child. This child\n  // itself will be GC:ed when the parent updates the next time.\n  // Note: we cannot null out sibling here, otherwise it can cause issues\n  // with findDOMNode and how it requires the sibling field to carry out\n  // traversal in a later effect. See PR #16820. We now clear the sibling\n  // field after effects, see: detachFiberAfterEffects.\n  //\n  // Don't disconnect stateNode now; it will be detached in detachFiberAfterEffects.\n  // It may be required if the current component is an error boundary,\n  // and one of its descendants throws while unmounting a passive effect.\n  fiber.alternate = null;\n  fiber.child = null;\n  fiber.dependencies = null;\n  fiber.firstEffect = null;\n  fiber.lastEffect = null;\n  fiber.memoizedProps = null;\n  fiber.memoizedState = null;\n  fiber.pendingProps = null;\n  fiber.return = null;\n  fiber.updateQueue = null;\n\n  {\n    fiber._debugOwner = null;\n  }\n}\n\nfunction getHostParentFiber(fiber) {\n  var parent = fiber.return;\n\n  while (parent !== null) {\n    if (isHostParent(parent)) {\n      return parent;\n    }\n\n    parent = parent.return;\n  }\n\n  {\n    {\n      throw Error( \"Expected to find a host parent. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction isHostParent(fiber) {\n  return fiber.tag === HostComponent || fiber.tag === HostRoot || fiber.tag === HostPortal;\n}\n\nfunction getHostSibling(fiber) {\n  // We're going to search forward into the tree until we find a sibling host\n  // node. Unfortunately, if multiple insertions are done in a row we have to\n  // search past them. This leads to exponential search for the next sibling.\n  // TODO: Find a more efficient way to do this.\n  var node = fiber;\n\n  siblings: while (true) {\n    // If we didn't find anything, let's try the next sibling.\n    while (node.sibling === null) {\n      if (node.return === null || isHostParent(node.return)) {\n        // If we pop out of the root or hit the parent the fiber we are the\n        // last sibling.\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n\n    while (node.tag !== HostComponent && node.tag !== HostText && node.tag !== DehydratedFragment) {\n      // If it is not host node and, we might have a host node inside it.\n      // Try to search down until we find one.\n      if (node.flags & Placement) {\n        // If we don't have a child, try the siblings instead.\n        continue siblings;\n      } // If we don't have a child, try the siblings instead.\n      // We also skip portals because they are not part of this host tree.\n\n\n      if (node.child === null || node.tag === HostPortal) {\n        continue siblings;\n      } else {\n        node.child.return = node;\n        node = node.child;\n      }\n    } // Check if this host node is stable or about to be placed.\n\n\n    if (!(node.flags & Placement)) {\n      // Found it!\n      return node.stateNode;\n    }\n  }\n}\n\nfunction commitPlacement(finishedWork) {\n\n\n  var parentFiber = getHostParentFiber(finishedWork); // Note: these two variables *must* always be updated together.\n\n  var parent;\n  var isContainer;\n  var parentStateNode = parentFiber.stateNode;\n\n  switch (parentFiber.tag) {\n    case HostComponent:\n      parent = parentStateNode;\n      isContainer = false;\n      break;\n\n    case HostRoot:\n      parent = parentStateNode.containerInfo;\n      isContainer = true;\n      break;\n\n    case HostPortal:\n      parent = parentStateNode.containerInfo;\n      isContainer = true;\n      break;\n\n    case FundamentalComponent:\n\n    // eslint-disable-next-line-no-fallthrough\n\n    default:\n      {\n        {\n          throw Error( \"Invalid host parent fiber. This error is likely caused by a bug in React. Please file an issue.\" );\n        }\n      }\n\n  }\n\n  if (parentFiber.flags & ContentReset) {\n    // Reset the text content of the parent before doing any insertions\n    resetTextContent(parent); // Clear ContentReset from the effect tag\n\n    parentFiber.flags &= ~ContentReset;\n  }\n\n  var before = getHostSibling(finishedWork); // We only have the top Fiber that was inserted but we need to recurse down its\n  // children to find all the terminal nodes.\n\n  if (isContainer) {\n    insertOrAppendPlacementNodeIntoContainer(finishedWork, before, parent);\n  } else {\n    insertOrAppendPlacementNode(finishedWork, before, parent);\n  }\n}\n\nfunction insertOrAppendPlacementNodeIntoContainer(node, before, parent) {\n  var tag = node.tag;\n  var isHost = tag === HostComponent || tag === HostText;\n\n  if (isHost || enableFundamentalAPI ) {\n    var stateNode = isHost ? node.stateNode : node.stateNode.instance;\n\n    if (before) {\n      insertInContainerBefore(parent, stateNode, before);\n    } else {\n      appendChildToContainer(parent, stateNode);\n    }\n  } else if (tag === HostPortal) ; else {\n    var child = node.child;\n\n    if (child !== null) {\n      insertOrAppendPlacementNodeIntoContainer(child, before, parent);\n      var sibling = child.sibling;\n\n      while (sibling !== null) {\n        insertOrAppendPlacementNodeIntoContainer(sibling, before, parent);\n        sibling = sibling.sibling;\n      }\n    }\n  }\n}\n\nfunction insertOrAppendPlacementNode(node, before, parent) {\n  var tag = node.tag;\n  var isHost = tag === HostComponent || tag === HostText;\n\n  if (isHost || enableFundamentalAPI ) {\n    var stateNode = isHost ? node.stateNode : node.stateNode.instance;\n\n    if (before) {\n      insertBefore(parent, stateNode, before);\n    } else {\n      appendChild(parent, stateNode);\n    }\n  } else if (tag === HostPortal) ; else {\n    var child = node.child;\n\n    if (child !== null) {\n      insertOrAppendPlacementNode(child, before, parent);\n      var sibling = child.sibling;\n\n      while (sibling !== null) {\n        insertOrAppendPlacementNode(sibling, before, parent);\n        sibling = sibling.sibling;\n      }\n    }\n  }\n}\n\nfunction unmountHostComponents(finishedRoot, current, renderPriorityLevel) {\n  // We only have the top Fiber that was deleted but we need to recurse down its\n  // children to find all the terminal nodes.\n  var node = current; // Each iteration, currentParent is populated with node's host parent if not\n  // currentParentIsValid.\n\n  var currentParentIsValid = false; // Note: these two variables *must* always be updated together.\n\n  var currentParent;\n  var currentParentIsContainer;\n\n  while (true) {\n    if (!currentParentIsValid) {\n      var parent = node.return;\n\n      findParent: while (true) {\n        if (!(parent !== null)) {\n          {\n            throw Error( \"Expected to find a host parent. This error is likely caused by a bug in React. Please file an issue.\" );\n          }\n        }\n\n        var parentStateNode = parent.stateNode;\n\n        switch (parent.tag) {\n          case HostComponent:\n            currentParent = parentStateNode;\n            currentParentIsContainer = false;\n            break findParent;\n\n          case HostRoot:\n            currentParent = parentStateNode.containerInfo;\n            currentParentIsContainer = true;\n            break findParent;\n\n          case HostPortal:\n            currentParent = parentStateNode.containerInfo;\n            currentParentIsContainer = true;\n            break findParent;\n\n        }\n\n        parent = parent.return;\n      }\n\n      currentParentIsValid = true;\n    }\n\n    if (node.tag === HostComponent || node.tag === HostText) {\n      commitNestedUnmounts(finishedRoot, node); // After all the children have unmounted, it is now safe to remove the\n      // node from the tree.\n\n      if (currentParentIsContainer) {\n        removeChildFromContainer(currentParent, node.stateNode);\n      } else {\n        removeChild(currentParent, node.stateNode);\n      } // Don't visit children because we already visited them.\n\n    } else if (node.tag === HostPortal) {\n      if (node.child !== null) {\n        // When we go into a portal, it becomes the parent to remove from.\n        // We will reassign it back when we pop the portal on the way up.\n        currentParent = node.stateNode.containerInfo;\n        currentParentIsContainer = true; // Visit children because portals might contain host components.\n\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n    } else {\n      commitUnmount(finishedRoot, node); // Visit children because we may find more host components below.\n\n      if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n    }\n\n    if (node === current) {\n      return;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === current) {\n        return;\n      }\n\n      node = node.return;\n\n      if (node.tag === HostPortal) {\n        // When we go out of the portal, we need to restore the parent.\n        // Since we don't keep a stack of them, we will search for it.\n        currentParentIsValid = false;\n      }\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n}\n\nfunction commitDeletion(finishedRoot, current, renderPriorityLevel) {\n  {\n    // Recursively delete all host nodes from the parent.\n    // Detach refs and call componentWillUnmount() on the whole subtree.\n    unmountHostComponents(finishedRoot, current);\n  }\n\n  var alternate = current.alternate;\n  detachFiberMutation(current);\n\n  if (alternate !== null) {\n    detachFiberMutation(alternate);\n  }\n}\n\nfunction commitWork(current, finishedWork) {\n\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case MemoComponent:\n    case SimpleMemoComponent:\n    case Block:\n      {\n        // Layout effects are destroyed during the mutation phase so that all\n        // destroy functions for all fibers are called before any create functions.\n        // This prevents sibling component effects from interfering with each other,\n        // e.g. a destroy function in one component should never override a ref set\n        // by a create function in another component during the same commit.\n        {\n          commitHookEffectListUnmount(Layout | HasEffect, finishedWork);\n        }\n\n        return;\n      }\n\n    case ClassComponent:\n      {\n        return;\n      }\n\n    case HostComponent:\n      {\n        var instance = finishedWork.stateNode;\n\n        if (instance != null) {\n          // Commit the work prepared earlier.\n          var newProps = finishedWork.memoizedProps; // For hydration we reuse the update path but we treat the oldProps\n          // as the newProps. The updatePayload will contain the real change in\n          // this case.\n\n          var oldProps = current !== null ? current.memoizedProps : newProps;\n          var type = finishedWork.type; // TODO: Type the updateQueue to be specific to host components.\n\n          var updatePayload = finishedWork.updateQueue;\n          finishedWork.updateQueue = null;\n\n          if (updatePayload !== null) {\n            commitUpdate(instance, updatePayload, type, oldProps, newProps);\n          }\n        }\n\n        return;\n      }\n\n    case HostText:\n      {\n        if (!(finishedWork.stateNode !== null)) {\n          {\n            throw Error( \"This should have a text node initialized. This error is likely caused by a bug in React. Please file an issue.\" );\n          }\n        }\n\n        var textInstance = finishedWork.stateNode;\n        var newText = finishedWork.memoizedProps; // For hydration we reuse the update path but we treat the oldProps\n        // as the newProps. The updatePayload will contain the real change in\n        // this case.\n\n        var oldText = current !== null ? current.memoizedProps : newText;\n        commitTextUpdate(textInstance, oldText, newText);\n        return;\n      }\n\n    case HostRoot:\n      {\n        {\n          var _root = finishedWork.stateNode;\n\n          if (_root.hydrate) {\n            // We've just hydrated. No need to hydrate again.\n            _root.hydrate = false;\n            commitHydratedContainer(_root.containerInfo);\n          }\n        }\n\n        return;\n      }\n\n    case Profiler:\n      {\n        return;\n      }\n\n    case SuspenseComponent:\n      {\n        commitSuspenseComponent(finishedWork);\n        attachSuspenseRetryListeners(finishedWork);\n        return;\n      }\n\n    case SuspenseListComponent:\n      {\n        attachSuspenseRetryListeners(finishedWork);\n        return;\n      }\n\n    case IncompleteClassComponent:\n      {\n        return;\n      }\n\n    case FundamentalComponent:\n      {\n\n        break;\n      }\n\n    case ScopeComponent:\n      {\n\n        break;\n      }\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      {\n        var newState = finishedWork.memoizedState;\n        var isHidden = newState !== null;\n        hideOrUnhideAllChildren(finishedWork, isHidden);\n        return;\n      }\n  }\n\n  {\n    {\n      throw Error( \"This unit of work tag should not have side-effects. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  }\n}\n\nfunction commitSuspenseComponent(finishedWork) {\n  var newState = finishedWork.memoizedState;\n\n  if (newState !== null) {\n    markCommitTimeOfFallback();\n\n    {\n      // Hide the Offscreen component that contains the primary children. TODO:\n      // Ideally, this effect would have been scheduled on the Offscreen fiber\n      // itself. That's how unhiding works: the Offscreen component schedules an\n      // effect on itself. However, in this case, the component didn't complete,\n      // so the fiber was never added to the effect list in the normal path. We\n      // could have appended it to the effect list in the Suspense component's\n      // second pass, but doing it this way is less complicated. This would be\n      // simpler if we got rid of the effect list and traversed the tree, like\n      // we're planning to do.\n      var primaryChildParent = finishedWork.child;\n      hideOrUnhideAllChildren(primaryChildParent, true);\n    }\n  }\n}\n\nfunction commitSuspenseHydrationCallbacks(finishedRoot, finishedWork) {\n\n  var newState = finishedWork.memoizedState;\n\n  if (newState === null) {\n    var current = finishedWork.alternate;\n\n    if (current !== null) {\n      var prevState = current.memoizedState;\n\n      if (prevState !== null) {\n        var suspenseInstance = prevState.dehydrated;\n\n        if (suspenseInstance !== null) {\n          commitHydratedSuspenseInstance(suspenseInstance);\n        }\n      }\n    }\n  }\n}\n\nfunction attachSuspenseRetryListeners(finishedWork) {\n  // If this boundary just timed out, then it will have a set of wakeables.\n  // For each wakeable, attach a listener so that when it resolves, React\n  // attempts to re-render the boundary in the primary (pre-timeout) state.\n  var wakeables = finishedWork.updateQueue;\n\n  if (wakeables !== null) {\n    finishedWork.updateQueue = null;\n    var retryCache = finishedWork.stateNode;\n\n    if (retryCache === null) {\n      retryCache = finishedWork.stateNode = new PossiblyWeakSet();\n    }\n\n    wakeables.forEach(function (wakeable) {\n      // Memoize using the boundary fiber to prevent redundant listeners.\n      var retry = resolveRetryWakeable.bind(null, finishedWork, wakeable);\n\n      if (!retryCache.has(wakeable)) {\n        {\n          if (wakeable.__reactDoNotTraceInteractions !== true) {\n            retry = tracing.unstable_wrap(retry);\n          }\n        }\n\n        retryCache.add(wakeable);\n        wakeable.then(retry, retry);\n      }\n    });\n  }\n} // This function detects when a Suspense boundary goes from visible to hidden.\n// It returns false if the boundary is already hidden.\n// TODO: Use an effect tag.\n\n\nfunction isSuspenseBoundaryBeingHidden(current, finishedWork) {\n  if (current !== null) {\n    var oldState = current.memoizedState;\n\n    if (oldState === null || oldState.dehydrated !== null) {\n      var newState = finishedWork.memoizedState;\n      return newState !== null && newState.dehydrated === null;\n    }\n  }\n\n  return false;\n}\n\nfunction commitResetTextContent(current) {\n\n  resetTextContent(current.stateNode);\n}\n\nvar COMPONENT_TYPE = 0;\nvar HAS_PSEUDO_CLASS_TYPE = 1;\nvar ROLE_TYPE = 2;\nvar TEST_NAME_TYPE = 3;\nvar TEXT_TYPE = 4;\n\nif (typeof Symbol === 'function' && Symbol.for) {\n  var symbolFor$1 = Symbol.for;\n  COMPONENT_TYPE = symbolFor$1('selector.component');\n  HAS_PSEUDO_CLASS_TYPE = symbolFor$1('selector.has_pseudo_class');\n  ROLE_TYPE = symbolFor$1('selector.role');\n  TEST_NAME_TYPE = symbolFor$1('selector.test_id');\n  TEXT_TYPE = symbolFor$1('selector.text');\n}\nvar commitHooks = [];\nfunction onCommitRoot$1() {\n  {\n    commitHooks.forEach(function (commitHook) {\n      return commitHook();\n    });\n  }\n}\n\nvar ceil = Math.ceil;\nvar ReactCurrentDispatcher$2 = ReactSharedInternals.ReactCurrentDispatcher,\n    ReactCurrentOwner$2 = ReactSharedInternals.ReactCurrentOwner,\n    IsSomeRendererActing = ReactSharedInternals.IsSomeRendererActing;\nvar NoContext =\n/*             */\n0;\nvar BatchedContext =\n/*               */\n1;\nvar EventContext =\n/*                 */\n2;\nvar DiscreteEventContext =\n/*         */\n4;\nvar LegacyUnbatchedContext =\n/*       */\n8;\nvar RenderContext =\n/*                */\n16;\nvar CommitContext =\n/*                */\n32;\nvar RetryAfterError =\n/*       */\n64;\nvar RootIncomplete = 0;\nvar RootFatalErrored = 1;\nvar RootErrored = 2;\nvar RootSuspended = 3;\nvar RootSuspendedWithDelay = 4;\nvar RootCompleted = 5; // Describes where we are in the React execution stack\n\nvar executionContext = NoContext; // The root we're working on\n\nvar workInProgressRoot = null; // The fiber we're working on\n\nvar workInProgress = null; // The lanes we're rendering\n\nvar workInProgressRootRenderLanes = NoLanes; // Stack that allows components to change the render lanes for its subtree\n// This is a superset of the lanes we started working on at the root. The only\n// case where it's different from `workInProgressRootRenderLanes` is when we\n// enter a subtree that is hidden and needs to be unhidden: Suspense and\n// Offscreen component.\n//\n// Most things in the work loop should deal with workInProgressRootRenderLanes.\n// Most things in begin/complete phases should deal with subtreeRenderLanes.\n\nvar subtreeRenderLanes = NoLanes;\nvar subtreeRenderLanesCursor = createCursor(NoLanes); // Whether to root completed, errored, suspended, etc.\n\nvar workInProgressRootExitStatus = RootIncomplete; // A fatal error, if one is thrown\n\nvar workInProgressRootFatalError = null; // \"Included\" lanes refer to lanes that were worked on during this render. It's\n// slightly different than `renderLanes` because `renderLanes` can change as you\n// enter and exit an Offscreen tree. This value is the combination of all render\n// lanes for the entire render phase.\n\nvar workInProgressRootIncludedLanes = NoLanes; // The work left over by components that were visited during this render. Only\n// includes unprocessed updates, not work in bailed out children.\n\nvar workInProgressRootSkippedLanes = NoLanes; // Lanes that were updated (in an interleaved event) during this render.\n\nvar workInProgressRootUpdatedLanes = NoLanes; // Lanes that were pinged (in an interleaved event) during this render.\n\nvar workInProgressRootPingedLanes = NoLanes;\nvar mostRecentlyUpdatedRoot = null; // The most recent time we committed a fallback. This lets us ensure a train\n// model where we don't commit new loading states in too quick succession.\n\nvar globalMostRecentFallbackTime = 0;\nvar FALLBACK_THROTTLE_MS = 500; // The absolute time for when we should start giving up on rendering\n// more and prefer CPU suspense heuristics instead.\n\nvar workInProgressRootRenderTargetTime = Infinity; // How long a render is supposed to take before we start following CPU\n// suspense heuristics and opt out of rendering more content.\n\nvar RENDER_TIMEOUT_MS = 500;\n\nfunction resetRenderTimer() {\n  workInProgressRootRenderTargetTime = now() + RENDER_TIMEOUT_MS;\n}\n\nfunction getRenderTargetTime() {\n  return workInProgressRootRenderTargetTime;\n}\nvar nextEffect = null;\nvar hasUncaughtError = false;\nvar firstUncaughtError = null;\nvar legacyErrorBoundariesThatAlreadyFailed = null;\nvar rootDoesHavePassiveEffects = false;\nvar rootWithPendingPassiveEffects = null;\nvar pendingPassiveEffectsRenderPriority = NoPriority$1;\nvar pendingPassiveEffectsLanes = NoLanes;\nvar pendingPassiveHookEffectsMount = [];\nvar pendingPassiveHookEffectsUnmount = [];\nvar rootsWithPendingDiscreteUpdates = null; // Use these to prevent an infinite loop of nested updates\n\nvar NESTED_UPDATE_LIMIT = 50;\nvar nestedUpdateCount = 0;\nvar rootWithNestedUpdates = null;\nvar NESTED_PASSIVE_UPDATE_LIMIT = 50;\nvar nestedPassiveUpdateCount = 0; // Marks the need to reschedule pending interactions at these lanes\n// during the commit phase. This enables them to be traced across components\n// that spawn new work during render. E.g. hidden boundaries, suspended SSR\n// hydration or SuspenseList.\n// TODO: Can use a bitmask instead of an array\n\nvar spawnedWorkDuringRender = null; // If two updates are scheduled within the same event, we should treat their\n// event times as simultaneous, even if the actual clock time has advanced\n// between the first and second call.\n\nvar currentEventTime = NoTimestamp;\nvar currentEventWipLanes = NoLanes;\nvar currentEventPendingLanes = NoLanes; // Dev only flag that tracks if passive effects are currently being flushed.\n// We warn about state updates for unmounted components differently in this case.\n\nvar isFlushingPassiveEffects = false;\nvar focusedInstanceHandle = null;\nvar shouldFireAfterActiveInstanceBlur = false;\nfunction getWorkInProgressRoot() {\n  return workInProgressRoot;\n}\nfunction requestEventTime() {\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    // We're inside React, so it's fine to read the actual time.\n    return now();\n  } // We're not inside React, so we may be in the middle of a browser event.\n\n\n  if (currentEventTime !== NoTimestamp) {\n    // Use the same start time for all updates until we enter React again.\n    return currentEventTime;\n  } // This is the first update since React yielded. Compute a new start time.\n\n\n  currentEventTime = now();\n  return currentEventTime;\n}\nfunction requestUpdateLane(fiber) {\n  // Special cases\n  var mode = fiber.mode;\n\n  if ((mode & BlockingMode) === NoMode) {\n    return SyncLane;\n  } else if ((mode & ConcurrentMode) === NoMode) {\n    return getCurrentPriorityLevel() === ImmediatePriority$1 ? SyncLane : SyncBatchedLane;\n  } // The algorithm for assigning an update to a lane should be stable for all\n  // updates at the same priority within the same event. To do this, the inputs\n  // to the algorithm must be the same. For example, we use the `renderLanes`\n  // to avoid choosing a lane that is already in the middle of rendering.\n  //\n  // However, the \"included\" lanes could be mutated in between updates in the\n  // same event, like if you perform an update inside `flushSync`. Or any other\n  // code path that might call `prepareFreshStack`.\n  //\n  // The trick we use is to cache the first of each of these inputs within an\n  // event. Then reset the cached values once we can be sure the event is over.\n  // Our heuristic for that is whenever we enter a concurrent work loop.\n  //\n  // We'll do the same for `currentEventPendingLanes` below.\n\n\n  if (currentEventWipLanes === NoLanes) {\n    currentEventWipLanes = workInProgressRootIncludedLanes;\n  }\n\n  var isTransition = requestCurrentTransition() !== NoTransition;\n\n  if (isTransition) {\n    if (currentEventPendingLanes !== NoLanes) {\n      currentEventPendingLanes = mostRecentlyUpdatedRoot !== null ? mostRecentlyUpdatedRoot.pendingLanes : NoLanes;\n    }\n\n    return findTransitionLane(currentEventWipLanes, currentEventPendingLanes);\n  } // TODO: Remove this dependency on the Scheduler priority.\n  // To do that, we're replacing it with an update lane priority.\n\n\n  var schedulerPriority = getCurrentPriorityLevel(); // The old behavior was using the priority level of the Scheduler.\n  // This couples React to the Scheduler internals, so we're replacing it\n  // with the currentUpdateLanePriority above. As an example of how this\n  // could be problematic, if we're not inside `Scheduler.runWithPriority`,\n  // then we'll get the priority of the current running Scheduler task,\n  // which is probably not what we want.\n\n  var lane;\n\n  if ( // TODO: Temporary. We're removing the concept of discrete updates.\n  (executionContext & DiscreteEventContext) !== NoContext && schedulerPriority === UserBlockingPriority$2) {\n    lane = findUpdateLane(InputDiscreteLanePriority, currentEventWipLanes);\n  } else {\n    var schedulerLanePriority = schedulerPriorityToLanePriority(schedulerPriority);\n\n    lane = findUpdateLane(schedulerLanePriority, currentEventWipLanes);\n  }\n\n  return lane;\n}\n\nfunction requestRetryLane(fiber) {\n  // This is a fork of `requestUpdateLane` designed specifically for Suspense\n  // \"retries\" — a special update that attempts to flip a Suspense boundary\n  // from its placeholder state to its primary/resolved state.\n  // Special cases\n  var mode = fiber.mode;\n\n  if ((mode & BlockingMode) === NoMode) {\n    return SyncLane;\n  } else if ((mode & ConcurrentMode) === NoMode) {\n    return getCurrentPriorityLevel() === ImmediatePriority$1 ? SyncLane : SyncBatchedLane;\n  } // See `requestUpdateLane` for explanation of `currentEventWipLanes`\n\n\n  if (currentEventWipLanes === NoLanes) {\n    currentEventWipLanes = workInProgressRootIncludedLanes;\n  }\n\n  return findRetryLane(currentEventWipLanes);\n}\n\nfunction scheduleUpdateOnFiber(fiber, lane, eventTime) {\n  checkForNestedUpdates();\n  warnAboutRenderPhaseUpdatesInDEV(fiber);\n  var root = markUpdateLaneFromFiberToRoot(fiber, lane);\n\n  if (root === null) {\n    warnAboutUpdateOnUnmountedFiberInDEV(fiber);\n    return null;\n  } // Mark that the root has a pending update.\n\n\n  markRootUpdated(root, lane, eventTime);\n\n  if (root === workInProgressRoot) {\n    // Received an update to a tree that's in the middle of rendering. Mark\n    // that there was an interleaved update work on this root. Unless the\n    // `deferRenderPhaseUpdateToNextBatch` flag is off and this is a render\n    // phase update. In that case, we don't treat render phase updates as if\n    // they were interleaved, for backwards compat reasons.\n    {\n      workInProgressRootUpdatedLanes = mergeLanes(workInProgressRootUpdatedLanes, lane);\n    }\n\n    if (workInProgressRootExitStatus === RootSuspendedWithDelay) {\n      // The root already suspended with a delay, which means this render\n      // definitely won't finish. Since we have a new update, let's mark it as\n      // suspended now, right before marking the incoming update. This has the\n      // effect of interrupting the current render and switching to the update.\n      // TODO: Make sure this doesn't override pings that happen while we've\n      // already started rendering.\n      markRootSuspended$1(root, workInProgressRootRenderLanes);\n    }\n  } // TODO: requestUpdateLanePriority also reads the priority. Pass the\n  // priority as an argument to that function and this one.\n\n\n  var priorityLevel = getCurrentPriorityLevel();\n\n  if (lane === SyncLane) {\n    if ( // Check if we're inside unbatchedUpdates\n    (executionContext & LegacyUnbatchedContext) !== NoContext && // Check if we're not already rendering\n    (executionContext & (RenderContext | CommitContext)) === NoContext) {\n      // Register pending interactions on the root to avoid losing traced interaction data.\n      schedulePendingInteractions(root, lane); // This is a legacy edge case. The initial mount of a ReactDOM.render-ed\n      // root inside of batchedUpdates should be synchronous, but layout updates\n      // should be deferred until the end of the batch.\n\n      performSyncWorkOnRoot(root);\n    } else {\n      ensureRootIsScheduled(root, eventTime);\n      schedulePendingInteractions(root, lane);\n\n      if (executionContext === NoContext) {\n        // Flush the synchronous work now, unless we're already working or inside\n        // a batch. This is intentionally inside scheduleUpdateOnFiber instead of\n        // scheduleCallbackForFiber to preserve the ability to schedule a callback\n        // without immediately flushing it. We only do this for user-initiated\n        // updates, to preserve historical behavior of legacy mode.\n        resetRenderTimer();\n        flushSyncCallbackQueue();\n      }\n    }\n  } else {\n    // Schedule a discrete update but only if it's not Sync.\n    if ((executionContext & DiscreteEventContext) !== NoContext && ( // Only updates at user-blocking priority or greater are considered\n    // discrete, even inside a discrete event.\n    priorityLevel === UserBlockingPriority$2 || priorityLevel === ImmediatePriority$1)) {\n      // This is the result of a discrete event. Track the lowest priority\n      // discrete update per root so we can flush them early, if needed.\n      if (rootsWithPendingDiscreteUpdates === null) {\n        rootsWithPendingDiscreteUpdates = new Set([root]);\n      } else {\n        rootsWithPendingDiscreteUpdates.add(root);\n      }\n    } // Schedule other updates after in case the callback is sync.\n\n\n    ensureRootIsScheduled(root, eventTime);\n    schedulePendingInteractions(root, lane);\n  } // We use this when assigning a lane for a transition inside\n  // `requestUpdateLane`. We assume it's the same as the root being updated,\n  // since in the common case of a single root app it probably is. If it's not\n  // the same root, then it's not a huge deal, we just might batch more stuff\n  // together more than necessary.\n\n\n  mostRecentlyUpdatedRoot = root;\n} // This is split into a separate function so we can mark a fiber with pending\n// work without treating it as a typical update that originates from an event;\n// e.g. retrying a Suspense boundary isn't an update, but it does schedule work\n// on a fiber.\n\nfunction markUpdateLaneFromFiberToRoot(sourceFiber, lane) {\n  // Update the source fiber's lanes\n  sourceFiber.lanes = mergeLanes(sourceFiber.lanes, lane);\n  var alternate = sourceFiber.alternate;\n\n  if (alternate !== null) {\n    alternate.lanes = mergeLanes(alternate.lanes, lane);\n  }\n\n  {\n    if (alternate === null && (sourceFiber.flags & (Placement | Hydrating)) !== NoFlags) {\n      warnAboutUpdateOnNotYetMountedFiberInDEV(sourceFiber);\n    }\n  } // Walk the parent path to the root and update the child expiration time.\n\n\n  var node = sourceFiber;\n  var parent = sourceFiber.return;\n\n  while (parent !== null) {\n    parent.childLanes = mergeLanes(parent.childLanes, lane);\n    alternate = parent.alternate;\n\n    if (alternate !== null) {\n      alternate.childLanes = mergeLanes(alternate.childLanes, lane);\n    } else {\n      {\n        if ((parent.flags & (Placement | Hydrating)) !== NoFlags) {\n          warnAboutUpdateOnNotYetMountedFiberInDEV(sourceFiber);\n        }\n      }\n    }\n\n    node = parent;\n    parent = parent.return;\n  }\n\n  if (node.tag === HostRoot) {\n    var root = node.stateNode;\n    return root;\n  } else {\n    return null;\n  }\n} // Use this function to schedule a task for a root. There's only one task per\n// root; if a task was already scheduled, we'll check to make sure the priority\n// of the existing task is the same as the priority of the next level that the\n// root has work on. This function is called on every update, and right before\n// exiting a task.\n\n\nfunction ensureRootIsScheduled(root, currentTime) {\n  var existingCallbackNode = root.callbackNode; // Check if any lanes are being starved by other work. If so, mark them as\n  // expired so we know to work on those next.\n\n  markStarvedLanesAsExpired(root, currentTime); // Determine the next lanes to work on, and their priority.\n\n  var nextLanes = getNextLanes(root, root === workInProgressRoot ? workInProgressRootRenderLanes : NoLanes); // This returns the priority level computed during the `getNextLanes` call.\n\n  var newCallbackPriority = returnNextLanesPriority();\n\n  if (nextLanes === NoLanes) {\n    // Special case: There's nothing to work on.\n    if (existingCallbackNode !== null) {\n      cancelCallback(existingCallbackNode);\n      root.callbackNode = null;\n      root.callbackPriority = NoLanePriority;\n    }\n\n    return;\n  } // Check if there's an existing task. We may be able to reuse it.\n\n\n  if (existingCallbackNode !== null) {\n    var existingCallbackPriority = root.callbackPriority;\n\n    if (existingCallbackPriority === newCallbackPriority) {\n      // The priority hasn't changed. We can reuse the existing task. Exit.\n      return;\n    } // The priority changed. Cancel the existing callback. We'll schedule a new\n    // one below.\n\n\n    cancelCallback(existingCallbackNode);\n  } // Schedule a new callback.\n\n\n  var newCallbackNode;\n\n  if (newCallbackPriority === SyncLanePriority) {\n    // Special case: Sync React callbacks are scheduled on a special\n    // internal queue\n    newCallbackNode = scheduleSyncCallback(performSyncWorkOnRoot.bind(null, root));\n  } else if (newCallbackPriority === SyncBatchedLanePriority) {\n    newCallbackNode = scheduleCallback(ImmediatePriority$1, performSyncWorkOnRoot.bind(null, root));\n  } else {\n    var schedulerPriorityLevel = lanePriorityToSchedulerPriority(newCallbackPriority);\n    newCallbackNode = scheduleCallback(schedulerPriorityLevel, performConcurrentWorkOnRoot.bind(null, root));\n  }\n\n  root.callbackPriority = newCallbackPriority;\n  root.callbackNode = newCallbackNode;\n} // This is the entry point for every concurrent task, i.e. anything that\n// goes through Scheduler.\n\n\nfunction performConcurrentWorkOnRoot(root) {\n  // Since we know we're in a React event, we can clear the current\n  // event time. The next update will compute a new event time.\n  currentEventTime = NoTimestamp;\n  currentEventWipLanes = NoLanes;\n  currentEventPendingLanes = NoLanes;\n\n  if (!((executionContext & (RenderContext | CommitContext)) === NoContext)) {\n    {\n      throw Error( \"Should not already be working.\" );\n    }\n  } // Flush any pending passive effects before deciding which lanes to work on,\n  // in case they schedule additional work.\n\n\n  var originalCallbackNode = root.callbackNode;\n  var didFlushPassiveEffects = flushPassiveEffects();\n\n  if (didFlushPassiveEffects) {\n    // Something in the passive effect phase may have canceled the current task.\n    // Check if the task node for this root was changed.\n    if (root.callbackNode !== originalCallbackNode) {\n      // The current task was canceled. Exit. We don't need to call\n      // `ensureRootIsScheduled` because the check above implies either that\n      // there's a new task, or that there's no remaining work on this root.\n      return null;\n    }\n  } // Determine the next expiration time to work on, using the fields stored\n  // on the root.\n\n\n  var lanes = getNextLanes(root, root === workInProgressRoot ? workInProgressRootRenderLanes : NoLanes);\n\n  if (lanes === NoLanes) {\n    // Defensive coding. This is never expected to happen.\n    return null;\n  }\n\n  var exitStatus = renderRootConcurrent(root, lanes);\n\n  if (includesSomeLane(workInProgressRootIncludedLanes, workInProgressRootUpdatedLanes)) {\n    // The render included lanes that were updated during the render phase.\n    // For example, when unhiding a hidden tree, we include all the lanes\n    // that were previously skipped when the tree was hidden. That set of\n    // lanes is a superset of the lanes we started rendering with.\n    //\n    // So we'll throw out the current work and restart.\n    prepareFreshStack(root, NoLanes);\n  } else if (exitStatus !== RootIncomplete) {\n    if (exitStatus === RootErrored) {\n      executionContext |= RetryAfterError; // If an error occurred during hydration,\n      // discard server response and fall back to client side render.\n\n      if (root.hydrate) {\n        root.hydrate = false;\n        clearContainer(root.containerInfo);\n      } // If something threw an error, try rendering one more time. We'll render\n      // synchronously to block concurrent data mutations, and we'll includes\n      // all pending updates are included. If it still fails after the second\n      // attempt, we'll give up and commit the resulting tree.\n\n\n      lanes = getLanesToRetrySynchronouslyOnError(root);\n\n      if (lanes !== NoLanes) {\n        exitStatus = renderRootSync(root, lanes);\n      }\n    }\n\n    if (exitStatus === RootFatalErrored) {\n      var fatalError = workInProgressRootFatalError;\n      prepareFreshStack(root, NoLanes);\n      markRootSuspended$1(root, lanes);\n      ensureRootIsScheduled(root, now());\n      throw fatalError;\n    } // We now have a consistent tree. The next step is either to commit it,\n    // or, if something suspended, wait to commit it after a timeout.\n\n\n    var finishedWork = root.current.alternate;\n    root.finishedWork = finishedWork;\n    root.finishedLanes = lanes;\n    finishConcurrentRender(root, exitStatus, lanes);\n  }\n\n  ensureRootIsScheduled(root, now());\n\n  if (root.callbackNode === originalCallbackNode) {\n    // The task node scheduled for this root is the same one that's\n    // currently executed. Need to return a continuation.\n    return performConcurrentWorkOnRoot.bind(null, root);\n  }\n\n  return null;\n}\n\nfunction finishConcurrentRender(root, exitStatus, lanes) {\n  switch (exitStatus) {\n    case RootIncomplete:\n    case RootFatalErrored:\n      {\n        {\n          {\n            throw Error( \"Root did not complete. This is a bug in React.\" );\n          }\n        }\n      }\n    // Flow knows about invariant, so it complains if I add a break\n    // statement, but eslint doesn't know about invariant, so it complains\n    // if I do. eslint-disable-next-line no-fallthrough\n\n    case RootErrored:\n      {\n        // We should have already attempted to retry this tree. If we reached\n        // this point, it errored again. Commit it.\n        commitRoot(root);\n        break;\n      }\n\n    case RootSuspended:\n      {\n        markRootSuspended$1(root, lanes); // We have an acceptable loading state. We need to figure out if we\n        // should immediately commit it or wait a bit.\n\n        if (includesOnlyRetries(lanes) && // do not delay if we're inside an act() scope\n        !shouldForceFlushFallbacksInDEV()) {\n          // This render only included retries, no updates. Throttle committing\n          // retries so that we don't show too many loading states too quickly.\n          var msUntilTimeout = globalMostRecentFallbackTime + FALLBACK_THROTTLE_MS - now(); // Don't bother with a very short suspense time.\n\n          if (msUntilTimeout > 10) {\n            var nextLanes = getNextLanes(root, NoLanes);\n\n            if (nextLanes !== NoLanes) {\n              // There's additional work on this root.\n              break;\n            }\n\n            var suspendedLanes = root.suspendedLanes;\n\n            if (!isSubsetOfLanes(suspendedLanes, lanes)) {\n              // We should prefer to render the fallback of at the last\n              // suspended level. Ping the last suspended level to try\n              // rendering it again.\n              // FIXME: What if the suspended lanes are Idle? Should not restart.\n              var eventTime = requestEventTime();\n              markRootPinged(root, suspendedLanes);\n              break;\n            } // The render is suspended, it hasn't timed out, and there's no\n            // lower priority work to do. Instead of committing the fallback\n            // immediately, wait for more data to arrive.\n\n\n            root.timeoutHandle = scheduleTimeout(commitRoot.bind(null, root), msUntilTimeout);\n            break;\n          }\n        } // The work expired. Commit immediately.\n\n\n        commitRoot(root);\n        break;\n      }\n\n    case RootSuspendedWithDelay:\n      {\n        markRootSuspended$1(root, lanes);\n\n        if (includesOnlyTransitions(lanes)) {\n          // This is a transition, so we should exit without committing a\n          // placeholder and without scheduling a timeout. Delay indefinitely\n          // until we receive more data.\n          break;\n        }\n\n        if (!shouldForceFlushFallbacksInDEV()) {\n          // This is not a transition, but we did trigger an avoided state.\n          // Schedule a placeholder to display after a short delay, using the Just\n          // Noticeable Difference.\n          // TODO: Is the JND optimization worth the added complexity? If this is\n          // the only reason we track the event time, then probably not.\n          // Consider removing.\n          var mostRecentEventTime = getMostRecentEventTime(root, lanes);\n          var eventTimeMs = mostRecentEventTime;\n          var timeElapsedMs = now() - eventTimeMs;\n\n          var _msUntilTimeout = jnd(timeElapsedMs) - timeElapsedMs; // Don't bother with a very short suspense time.\n\n\n          if (_msUntilTimeout > 10) {\n            // Instead of committing the fallback immediately, wait for more data\n            // to arrive.\n            root.timeoutHandle = scheduleTimeout(commitRoot.bind(null, root), _msUntilTimeout);\n            break;\n          }\n        } // Commit the placeholder.\n\n\n        commitRoot(root);\n        break;\n      }\n\n    case RootCompleted:\n      {\n        // The work completed. Ready to commit.\n        commitRoot(root);\n        break;\n      }\n\n    default:\n      {\n        {\n          {\n            throw Error( \"Unknown root exit status.\" );\n          }\n        }\n      }\n  }\n}\n\nfunction markRootSuspended$1(root, suspendedLanes) {\n  // When suspending, we should always exclude lanes that were pinged or (more\n  // rarely, since we try to avoid it) updated during the render phase.\n  // TODO: Lol maybe there's a better way to factor this besides this\n  // obnoxiously named function :)\n  suspendedLanes = removeLanes(suspendedLanes, workInProgressRootPingedLanes);\n  suspendedLanes = removeLanes(suspendedLanes, workInProgressRootUpdatedLanes);\n  markRootSuspended(root, suspendedLanes);\n} // This is the entry point for synchronous tasks that don't go\n// through Scheduler\n\n\nfunction performSyncWorkOnRoot(root) {\n  if (!((executionContext & (RenderContext | CommitContext)) === NoContext)) {\n    {\n      throw Error( \"Should not already be working.\" );\n    }\n  }\n\n  flushPassiveEffects();\n  var lanes;\n  var exitStatus;\n\n  if (root === workInProgressRoot && includesSomeLane(root.expiredLanes, workInProgressRootRenderLanes)) {\n    // There's a partial tree, and at least one of its lanes has expired. Finish\n    // rendering it before rendering the rest of the expired work.\n    lanes = workInProgressRootRenderLanes;\n    exitStatus = renderRootSync(root, lanes);\n\n    if (includesSomeLane(workInProgressRootIncludedLanes, workInProgressRootUpdatedLanes)) {\n      // The render included lanes that were updated during the render phase.\n      // For example, when unhiding a hidden tree, we include all the lanes\n      // that were previously skipped when the tree was hidden. That set of\n      // lanes is a superset of the lanes we started rendering with.\n      //\n      // Note that this only happens when part of the tree is rendered\n      // concurrently. If the whole tree is rendered synchronously, then there\n      // are no interleaved events.\n      lanes = getNextLanes(root, lanes);\n      exitStatus = renderRootSync(root, lanes);\n    }\n  } else {\n    lanes = getNextLanes(root, NoLanes);\n    exitStatus = renderRootSync(root, lanes);\n  }\n\n  if (root.tag !== LegacyRoot && exitStatus === RootErrored) {\n    executionContext |= RetryAfterError; // If an error occurred during hydration,\n    // discard server response and fall back to client side render.\n\n    if (root.hydrate) {\n      root.hydrate = false;\n      clearContainer(root.containerInfo);\n    } // If something threw an error, try rendering one more time. We'll render\n    // synchronously to block concurrent data mutations, and we'll includes\n    // all pending updates are included. If it still fails after the second\n    // attempt, we'll give up and commit the resulting tree.\n\n\n    lanes = getLanesToRetrySynchronouslyOnError(root);\n\n    if (lanes !== NoLanes) {\n      exitStatus = renderRootSync(root, lanes);\n    }\n  }\n\n  if (exitStatus === RootFatalErrored) {\n    var fatalError = workInProgressRootFatalError;\n    prepareFreshStack(root, NoLanes);\n    markRootSuspended$1(root, lanes);\n    ensureRootIsScheduled(root, now());\n    throw fatalError;\n  } // We now have a consistent tree. Because this is a sync render, we\n  // will commit it even if something suspended.\n\n\n  var finishedWork = root.current.alternate;\n  root.finishedWork = finishedWork;\n  root.finishedLanes = lanes;\n  commitRoot(root); // Before exiting, make sure there's a callback scheduled for the next\n  // pending level.\n\n  ensureRootIsScheduled(root, now());\n  return null;\n}\nfunction flushDiscreteUpdates() {\n  // TODO: Should be able to flush inside batchedUpdates, but not inside `act`.\n  // However, `act` uses `batchedUpdates`, so there's no way to distinguish\n  // those two cases. Need to fix this before exposing flushDiscreteUpdates\n  // as a public API.\n  if ((executionContext & (BatchedContext | RenderContext | CommitContext)) !== NoContext) {\n    {\n      if ((executionContext & RenderContext) !== NoContext) {\n        error('unstable_flushDiscreteUpdates: Cannot flush updates when React is ' + 'already rendering.');\n      }\n    } // We're already rendering, so we can't synchronously flush pending work.\n    // This is probably a nested event dispatch triggered by a lifecycle/effect,\n    // like `el.focus()`. Exit.\n\n\n    return;\n  }\n\n  flushPendingDiscreteUpdates(); // If the discrete updates scheduled passive effects, flush them now so that\n  // they fire before the next serial event.\n\n  flushPassiveEffects();\n}\n\nfunction flushPendingDiscreteUpdates() {\n  if (rootsWithPendingDiscreteUpdates !== null) {\n    // For each root with pending discrete updates, schedule a callback to\n    // immediately flush them.\n    var roots = rootsWithPendingDiscreteUpdates;\n    rootsWithPendingDiscreteUpdates = null;\n    roots.forEach(function (root) {\n      markDiscreteUpdatesExpired(root);\n      ensureRootIsScheduled(root, now());\n    });\n  } // Now flush the immediate queue.\n\n\n  flushSyncCallbackQueue();\n}\n\nfunction batchedUpdates$1(fn, a) {\n  var prevExecutionContext = executionContext;\n  executionContext |= BatchedContext;\n\n  try {\n    return fn(a);\n  } finally {\n    executionContext = prevExecutionContext;\n\n    if (executionContext === NoContext) {\n      // Flush the immediate callbacks that were scheduled during this batch\n      resetRenderTimer();\n      flushSyncCallbackQueue();\n    }\n  }\n}\nfunction batchedEventUpdates$1(fn, a) {\n  var prevExecutionContext = executionContext;\n  executionContext |= EventContext;\n\n  try {\n    return fn(a);\n  } finally {\n    executionContext = prevExecutionContext;\n\n    if (executionContext === NoContext) {\n      // Flush the immediate callbacks that were scheduled during this batch\n      resetRenderTimer();\n      flushSyncCallbackQueue();\n    }\n  }\n}\nfunction discreteUpdates$1(fn, a, b, c, d) {\n  var prevExecutionContext = executionContext;\n  executionContext |= DiscreteEventContext;\n\n  {\n    try {\n      return runWithPriority$1(UserBlockingPriority$2, fn.bind(null, a, b, c, d));\n    } finally {\n      executionContext = prevExecutionContext;\n\n      if (executionContext === NoContext) {\n        // Flush the immediate callbacks that were scheduled during this batch\n        resetRenderTimer();\n        flushSyncCallbackQueue();\n      }\n    }\n  }\n}\nfunction unbatchedUpdates(fn, a) {\n  var prevExecutionContext = executionContext;\n  executionContext &= ~BatchedContext;\n  executionContext |= LegacyUnbatchedContext;\n\n  try {\n    return fn(a);\n  } finally {\n    executionContext = prevExecutionContext;\n\n    if (executionContext === NoContext) {\n      // Flush the immediate callbacks that were scheduled during this batch\n      resetRenderTimer();\n      flushSyncCallbackQueue();\n    }\n  }\n}\nfunction flushSync(fn, a) {\n  var prevExecutionContext = executionContext;\n\n  if ((prevExecutionContext & (RenderContext | CommitContext)) !== NoContext) {\n    {\n      error('flushSync was called from inside a lifecycle method. React cannot ' + 'flush when React is already rendering. Consider moving this call to ' + 'a scheduler task or micro task.');\n    }\n\n    return fn(a);\n  }\n\n  executionContext |= BatchedContext;\n\n  {\n    try {\n      if (fn) {\n        return runWithPriority$1(ImmediatePriority$1, fn.bind(null, a));\n      } else {\n        return undefined;\n      }\n    } finally {\n      executionContext = prevExecutionContext; // Flush the immediate callbacks that were scheduled during this batch.\n      // Note that this will happen even if batchedUpdates is higher up\n      // the stack.\n\n      flushSyncCallbackQueue();\n    }\n  }\n}\nfunction pushRenderLanes(fiber, lanes) {\n  push(subtreeRenderLanesCursor, subtreeRenderLanes, fiber);\n  subtreeRenderLanes = mergeLanes(subtreeRenderLanes, lanes);\n  workInProgressRootIncludedLanes = mergeLanes(workInProgressRootIncludedLanes, lanes);\n}\nfunction popRenderLanes(fiber) {\n  subtreeRenderLanes = subtreeRenderLanesCursor.current;\n  pop(subtreeRenderLanesCursor, fiber);\n}\n\nfunction prepareFreshStack(root, lanes) {\n  root.finishedWork = null;\n  root.finishedLanes = NoLanes;\n  var timeoutHandle = root.timeoutHandle;\n\n  if (timeoutHandle !== noTimeout) {\n    // The root previous suspended and scheduled a timeout to commit a fallback\n    // state. Now that we have additional work, cancel the timeout.\n    root.timeoutHandle = noTimeout; // $FlowFixMe Complains noTimeout is not a TimeoutID, despite the check above\n\n    cancelTimeout(timeoutHandle);\n  }\n\n  if (workInProgress !== null) {\n    var interruptedWork = workInProgress.return;\n\n    while (interruptedWork !== null) {\n      unwindInterruptedWork(interruptedWork);\n      interruptedWork = interruptedWork.return;\n    }\n  }\n\n  workInProgressRoot = root;\n  workInProgress = createWorkInProgress(root.current, null);\n  workInProgressRootRenderLanes = subtreeRenderLanes = workInProgressRootIncludedLanes = lanes;\n  workInProgressRootExitStatus = RootIncomplete;\n  workInProgressRootFatalError = null;\n  workInProgressRootSkippedLanes = NoLanes;\n  workInProgressRootUpdatedLanes = NoLanes;\n  workInProgressRootPingedLanes = NoLanes;\n\n  {\n    spawnedWorkDuringRender = null;\n  }\n\n  {\n    ReactStrictModeWarnings.discardPendingWarnings();\n  }\n}\n\nfunction handleError(root, thrownValue) {\n  do {\n    var erroredWork = workInProgress;\n\n    try {\n      // Reset module-level state that was set during the render phase.\n      resetContextDependencies();\n      resetHooksAfterThrow();\n      resetCurrentFiber(); // TODO: I found and added this missing line while investigating a\n      // separate issue. Write a regression test using string refs.\n\n      ReactCurrentOwner$2.current = null;\n\n      if (erroredWork === null || erroredWork.return === null) {\n        // Expected to be working on a non-root fiber. This is a fatal error\n        // because there's no ancestor that can handle it; the root is\n        // supposed to capture all errors that weren't caught by an error\n        // boundary.\n        workInProgressRootExitStatus = RootFatalErrored;\n        workInProgressRootFatalError = thrownValue; // Set `workInProgress` to null. This represents advancing to the next\n        // sibling, or the parent if there are no siblings. But since the root\n        // has no siblings nor a parent, we set it to null. Usually this is\n        // handled by `completeUnitOfWork` or `unwindWork`, but since we're\n        // intentionally not calling those, we need set it here.\n        // TODO: Consider calling `unwindWork` to pop the contexts.\n\n        workInProgress = null;\n        return;\n      }\n\n      if (enableProfilerTimer && erroredWork.mode & ProfileMode) {\n        // Record the time spent rendering before an error was thrown. This\n        // avoids inaccurate Profiler durations in the case of a\n        // suspended render.\n        stopProfilerTimerIfRunningAndRecordDelta(erroredWork, true);\n      }\n\n      throwException(root, erroredWork.return, erroredWork, thrownValue, workInProgressRootRenderLanes);\n      completeUnitOfWork(erroredWork);\n    } catch (yetAnotherThrownValue) {\n      // Something in the return path also threw.\n      thrownValue = yetAnotherThrownValue;\n\n      if (workInProgress === erroredWork && erroredWork !== null) {\n        // If this boundary has already errored, then we had trouble processing\n        // the error. Bubble it to the next boundary.\n        erroredWork = erroredWork.return;\n        workInProgress = erroredWork;\n      } else {\n        erroredWork = workInProgress;\n      }\n\n      continue;\n    } // Return to the normal work loop.\n\n\n    return;\n  } while (true);\n}\n\nfunction pushDispatcher() {\n  var prevDispatcher = ReactCurrentDispatcher$2.current;\n  ReactCurrentDispatcher$2.current = ContextOnlyDispatcher;\n\n  if (prevDispatcher === null) {\n    // The React isomorphic package does not include a default dispatcher.\n    // Instead the first renderer will lazily attach one, in order to give\n    // nicer error messages.\n    return ContextOnlyDispatcher;\n  } else {\n    return prevDispatcher;\n  }\n}\n\nfunction popDispatcher(prevDispatcher) {\n  ReactCurrentDispatcher$2.current = prevDispatcher;\n}\n\nfunction pushInteractions(root) {\n  {\n    var prevInteractions = tracing.__interactionsRef.current;\n    tracing.__interactionsRef.current = root.memoizedInteractions;\n    return prevInteractions;\n  }\n}\n\nfunction popInteractions(prevInteractions) {\n  {\n    tracing.__interactionsRef.current = prevInteractions;\n  }\n}\n\nfunction markCommitTimeOfFallback() {\n  globalMostRecentFallbackTime = now();\n}\nfunction markSkippedUpdateLanes(lane) {\n  workInProgressRootSkippedLanes = mergeLanes(lane, workInProgressRootSkippedLanes);\n}\nfunction renderDidSuspend() {\n  if (workInProgressRootExitStatus === RootIncomplete) {\n    workInProgressRootExitStatus = RootSuspended;\n  }\n}\nfunction renderDidSuspendDelayIfPossible() {\n  if (workInProgressRootExitStatus === RootIncomplete || workInProgressRootExitStatus === RootSuspended) {\n    workInProgressRootExitStatus = RootSuspendedWithDelay;\n  } // Check if there are updates that we skipped tree that might have unblocked\n  // this render.\n\n\n  if (workInProgressRoot !== null && (includesNonIdleWork(workInProgressRootSkippedLanes) || includesNonIdleWork(workInProgressRootUpdatedLanes))) {\n    // Mark the current render as suspended so that we switch to working on\n    // the updates that were skipped. Usually we only suspend at the end of\n    // the render phase.\n    // TODO: We should probably always mark the root as suspended immediately\n    // (inside this function), since by suspending at the end of the render\n    // phase introduces a potential mistake where we suspend lanes that were\n    // pinged or updated while we were rendering.\n    markRootSuspended$1(workInProgressRoot, workInProgressRootRenderLanes);\n  }\n}\nfunction renderDidError() {\n  if (workInProgressRootExitStatus !== RootCompleted) {\n    workInProgressRootExitStatus = RootErrored;\n  }\n} // Called during render to determine if anything has suspended.\n// Returns false if we're not sure.\n\nfunction renderHasNotSuspendedYet() {\n  // If something errored or completed, we can't really be sure,\n  // so those are false.\n  return workInProgressRootExitStatus === RootIncomplete;\n}\n\nfunction renderRootSync(root, lanes) {\n  var prevExecutionContext = executionContext;\n  executionContext |= RenderContext;\n  var prevDispatcher = pushDispatcher(); // If the root or lanes have changed, throw out the existing stack\n  // and prepare a fresh one. Otherwise we'll continue where we left off.\n\n  if (workInProgressRoot !== root || workInProgressRootRenderLanes !== lanes) {\n    prepareFreshStack(root, lanes);\n    startWorkOnPendingInteractions(root, lanes);\n  }\n\n  var prevInteractions = pushInteractions(root);\n\n  do {\n    try {\n      workLoopSync();\n      break;\n    } catch (thrownValue) {\n      handleError(root, thrownValue);\n    }\n  } while (true);\n\n  resetContextDependencies();\n\n  {\n    popInteractions(prevInteractions);\n  }\n\n  executionContext = prevExecutionContext;\n  popDispatcher(prevDispatcher);\n\n  if (workInProgress !== null) {\n    // This is a sync render, so we should have finished the whole tree.\n    {\n      {\n        throw Error( \"Cannot commit an incomplete root. This error is likely caused by a bug in React. Please file an issue.\" );\n      }\n    }\n  }\n\n\n  workInProgressRoot = null;\n  workInProgressRootRenderLanes = NoLanes;\n  return workInProgressRootExitStatus;\n} // The work loop is an extremely hot path. Tell Closure not to inline it.\n\n/** @noinline */\n\n\nfunction workLoopSync() {\n  // Already timed out, so perform work without checking if we need to yield.\n  while (workInProgress !== null) {\n    performUnitOfWork(workInProgress);\n  }\n}\n\nfunction renderRootConcurrent(root, lanes) {\n  var prevExecutionContext = executionContext;\n  executionContext |= RenderContext;\n  var prevDispatcher = pushDispatcher(); // If the root or lanes have changed, throw out the existing stack\n  // and prepare a fresh one. Otherwise we'll continue where we left off.\n\n  if (workInProgressRoot !== root || workInProgressRootRenderLanes !== lanes) {\n    resetRenderTimer();\n    prepareFreshStack(root, lanes);\n    startWorkOnPendingInteractions(root, lanes);\n  }\n\n  var prevInteractions = pushInteractions(root);\n\n  do {\n    try {\n      workLoopConcurrent();\n      break;\n    } catch (thrownValue) {\n      handleError(root, thrownValue);\n    }\n  } while (true);\n\n  resetContextDependencies();\n\n  {\n    popInteractions(prevInteractions);\n  }\n\n  popDispatcher(prevDispatcher);\n  executionContext = prevExecutionContext;\n\n\n  if (workInProgress !== null) {\n\n    return RootIncomplete;\n  } else {\n\n\n    workInProgressRoot = null;\n    workInProgressRootRenderLanes = NoLanes; // Return the final exit status.\n\n    return workInProgressRootExitStatus;\n  }\n}\n/** @noinline */\n\n\nfunction workLoopConcurrent() {\n  // Perform work until Scheduler asks us to yield\n  while (workInProgress !== null && !shouldYield()) {\n    performUnitOfWork(workInProgress);\n  }\n}\n\nfunction performUnitOfWork(unitOfWork) {\n  // The current, flushed, state of this fiber is the alternate. Ideally\n  // nothing should rely on this, but relying on it here means that we don't\n  // need an additional field on the work in progress.\n  var current = unitOfWork.alternate;\n  setCurrentFiber(unitOfWork);\n  var next;\n\n  if ( (unitOfWork.mode & ProfileMode) !== NoMode) {\n    startProfilerTimer(unitOfWork);\n    next = beginWork$1(current, unitOfWork, subtreeRenderLanes);\n    stopProfilerTimerIfRunningAndRecordDelta(unitOfWork, true);\n  } else {\n    next = beginWork$1(current, unitOfWork, subtreeRenderLanes);\n  }\n\n  resetCurrentFiber();\n  unitOfWork.memoizedProps = unitOfWork.pendingProps;\n\n  if (next === null) {\n    // If this doesn't spawn new work, complete the current work.\n    completeUnitOfWork(unitOfWork);\n  } else {\n    workInProgress = next;\n  }\n\n  ReactCurrentOwner$2.current = null;\n}\n\nfunction completeUnitOfWork(unitOfWork) {\n  // Attempt to complete the current unit of work, then move to the next\n  // sibling. If there are no more siblings, return to the parent fiber.\n  var completedWork = unitOfWork;\n\n  do {\n    // The current, flushed, state of this fiber is the alternate. Ideally\n    // nothing should rely on this, but relying on it here means that we don't\n    // need an additional field on the work in progress.\n    var current = completedWork.alternate;\n    var returnFiber = completedWork.return; // Check if the work completed or if something threw.\n\n    if ((completedWork.flags & Incomplete) === NoFlags) {\n      setCurrentFiber(completedWork);\n      var next = void 0;\n\n      if ( (completedWork.mode & ProfileMode) === NoMode) {\n        next = completeWork(current, completedWork, subtreeRenderLanes);\n      } else {\n        startProfilerTimer(completedWork);\n        next = completeWork(current, completedWork, subtreeRenderLanes); // Update render duration assuming we didn't error.\n\n        stopProfilerTimerIfRunningAndRecordDelta(completedWork, false);\n      }\n\n      resetCurrentFiber();\n\n      if (next !== null) {\n        // Completing this fiber spawned new work. Work on that next.\n        workInProgress = next;\n        return;\n      }\n\n      resetChildLanes(completedWork);\n\n      if (returnFiber !== null && // Do not append effects to parents if a sibling failed to complete\n      (returnFiber.flags & Incomplete) === NoFlags) {\n        // Append all the effects of the subtree and this fiber onto the effect\n        // list of the parent. The completion order of the children affects the\n        // side-effect order.\n        if (returnFiber.firstEffect === null) {\n          returnFiber.firstEffect = completedWork.firstEffect;\n        }\n\n        if (completedWork.lastEffect !== null) {\n          if (returnFiber.lastEffect !== null) {\n            returnFiber.lastEffect.nextEffect = completedWork.firstEffect;\n          }\n\n          returnFiber.lastEffect = completedWork.lastEffect;\n        } // If this fiber had side-effects, we append it AFTER the children's\n        // side-effects. We can perform certain side-effects earlier if needed,\n        // by doing multiple passes over the effect list. We don't want to\n        // schedule our own side-effect on our own list because if end up\n        // reusing children we'll schedule this effect onto itself since we're\n        // at the end.\n\n\n        var flags = completedWork.flags; // Skip both NoWork and PerformedWork tags when creating the effect\n        // list. PerformedWork effect is read by React DevTools but shouldn't be\n        // committed.\n\n        if (flags > PerformedWork) {\n          if (returnFiber.lastEffect !== null) {\n            returnFiber.lastEffect.nextEffect = completedWork;\n          } else {\n            returnFiber.firstEffect = completedWork;\n          }\n\n          returnFiber.lastEffect = completedWork;\n        }\n      }\n    } else {\n      // This fiber did not complete because something threw. Pop values off\n      // the stack without entering the complete phase. If this is a boundary,\n      // capture values if possible.\n      var _next = unwindWork(completedWork); // Because this fiber did not complete, don't reset its expiration time.\n\n\n      if (_next !== null) {\n        // If completing this work spawned new work, do that next. We'll come\n        // back here again.\n        // Since we're restarting, remove anything that is not a host effect\n        // from the effect tag.\n        _next.flags &= HostEffectMask;\n        workInProgress = _next;\n        return;\n      }\n\n      if ( (completedWork.mode & ProfileMode) !== NoMode) {\n        // Record the render duration for the fiber that errored.\n        stopProfilerTimerIfRunningAndRecordDelta(completedWork, false); // Include the time spent working on failed children before continuing.\n\n        var actualDuration = completedWork.actualDuration;\n        var child = completedWork.child;\n\n        while (child !== null) {\n          actualDuration += child.actualDuration;\n          child = child.sibling;\n        }\n\n        completedWork.actualDuration = actualDuration;\n      }\n\n      if (returnFiber !== null) {\n        // Mark the parent fiber as incomplete and clear its effect list.\n        returnFiber.firstEffect = returnFiber.lastEffect = null;\n        returnFiber.flags |= Incomplete;\n      }\n    }\n\n    var siblingFiber = completedWork.sibling;\n\n    if (siblingFiber !== null) {\n      // If there is more work to do in this returnFiber, do that next.\n      workInProgress = siblingFiber;\n      return;\n    } // Otherwise, return to the parent\n\n\n    completedWork = returnFiber; // Update the next thing we're working on in case something throws.\n\n    workInProgress = completedWork;\n  } while (completedWork !== null); // We've reached the root.\n\n\n  if (workInProgressRootExitStatus === RootIncomplete) {\n    workInProgressRootExitStatus = RootCompleted;\n  }\n}\n\nfunction resetChildLanes(completedWork) {\n  if ( // TODO: Move this check out of the hot path by moving `resetChildLanes`\n  // to switch statement in `completeWork`.\n  (completedWork.tag === LegacyHiddenComponent || completedWork.tag === OffscreenComponent) && completedWork.memoizedState !== null && !includesSomeLane(subtreeRenderLanes, OffscreenLane) && (completedWork.mode & ConcurrentMode) !== NoLanes) {\n    // The children of this component are hidden. Don't bubble their\n    // expiration times.\n    return;\n  }\n\n  var newChildLanes = NoLanes; // Bubble up the earliest expiration time.\n\n  if ( (completedWork.mode & ProfileMode) !== NoMode) {\n    // In profiling mode, resetChildExpirationTime is also used to reset\n    // profiler durations.\n    var actualDuration = completedWork.actualDuration;\n    var treeBaseDuration = completedWork.selfBaseDuration; // When a fiber is cloned, its actualDuration is reset to 0. This value will\n    // only be updated if work is done on the fiber (i.e. it doesn't bailout).\n    // When work is done, it should bubble to the parent's actualDuration. If\n    // the fiber has not been cloned though, (meaning no work was done), then\n    // this value will reflect the amount of time spent working on a previous\n    // render. In that case it should not bubble. We determine whether it was\n    // cloned by comparing the child pointer.\n\n    var shouldBubbleActualDurations = completedWork.alternate === null || completedWork.child !== completedWork.alternate.child;\n    var child = completedWork.child;\n\n    while (child !== null) {\n      newChildLanes = mergeLanes(newChildLanes, mergeLanes(child.lanes, child.childLanes));\n\n      if (shouldBubbleActualDurations) {\n        actualDuration += child.actualDuration;\n      }\n\n      treeBaseDuration += child.treeBaseDuration;\n      child = child.sibling;\n    }\n\n    var isTimedOutSuspense = completedWork.tag === SuspenseComponent && completedWork.memoizedState !== null;\n\n    if (isTimedOutSuspense) {\n      // Don't count time spent in a timed out Suspense subtree as part of the base duration.\n      var primaryChildFragment = completedWork.child;\n\n      if (primaryChildFragment !== null) {\n        treeBaseDuration -= primaryChildFragment.treeBaseDuration;\n      }\n    }\n\n    completedWork.actualDuration = actualDuration;\n    completedWork.treeBaseDuration = treeBaseDuration;\n  } else {\n    var _child = completedWork.child;\n\n    while (_child !== null) {\n      newChildLanes = mergeLanes(newChildLanes, mergeLanes(_child.lanes, _child.childLanes));\n      _child = _child.sibling;\n    }\n  }\n\n  completedWork.childLanes = newChildLanes;\n}\n\nfunction commitRoot(root) {\n  var renderPriorityLevel = getCurrentPriorityLevel();\n  runWithPriority$1(ImmediatePriority$1, commitRootImpl.bind(null, root, renderPriorityLevel));\n  return null;\n}\n\nfunction commitRootImpl(root, renderPriorityLevel) {\n  do {\n    // `flushPassiveEffects` will call `flushSyncUpdateQueue` at the end, which\n    // means `flushPassiveEffects` will sometimes result in additional\n    // passive effects. So we need to keep flushing in a loop until there are\n    // no more pending effects.\n    // TODO: Might be better if `flushPassiveEffects` did not automatically\n    // flush synchronous work at the end, to avoid factoring hazards like this.\n    flushPassiveEffects();\n  } while (rootWithPendingPassiveEffects !== null);\n\n  flushRenderPhaseStrictModeWarningsInDEV();\n\n  if (!((executionContext & (RenderContext | CommitContext)) === NoContext)) {\n    {\n      throw Error( \"Should not already be working.\" );\n    }\n  }\n\n  var finishedWork = root.finishedWork;\n  var lanes = root.finishedLanes;\n\n  if (finishedWork === null) {\n\n    return null;\n  }\n\n  root.finishedWork = null;\n  root.finishedLanes = NoLanes;\n\n  if (!(finishedWork !== root.current)) {\n    {\n      throw Error( \"Cannot commit the same tree as before. This error is likely caused by a bug in React. Please file an issue.\" );\n    }\n  } // commitRoot never returns a continuation; it always finishes synchronously.\n  // So we can clear these now to allow a new callback to be scheduled.\n\n\n  root.callbackNode = null; // Update the first and last pending times on this root. The new first\n  // pending time is whatever is left on the root fiber.\n\n  var remainingLanes = mergeLanes(finishedWork.lanes, finishedWork.childLanes);\n  markRootFinished(root, remainingLanes); // Clear already finished discrete updates in case that a later call of\n  // `flushDiscreteUpdates` starts a useless render pass which may cancels\n  // a scheduled timeout.\n\n  if (rootsWithPendingDiscreteUpdates !== null) {\n    if (!hasDiscreteLanes(remainingLanes) && rootsWithPendingDiscreteUpdates.has(root)) {\n      rootsWithPendingDiscreteUpdates.delete(root);\n    }\n  }\n\n  if (root === workInProgressRoot) {\n    // We can reset these now that they are finished.\n    workInProgressRoot = null;\n    workInProgress = null;\n    workInProgressRootRenderLanes = NoLanes;\n  } // Get the list of effects.\n\n\n  var firstEffect;\n\n  if (finishedWork.flags > PerformedWork) {\n    // A fiber's effect list consists only of its children, not itself. So if\n    // the root has an effect, we need to add it to the end of the list. The\n    // resulting list is the set that would belong to the root's parent, if it\n    // had one; that is, all the effects in the tree including the root.\n    if (finishedWork.lastEffect !== null) {\n      finishedWork.lastEffect.nextEffect = finishedWork;\n      firstEffect = finishedWork.firstEffect;\n    } else {\n      firstEffect = finishedWork;\n    }\n  } else {\n    // There is no effect on the root.\n    firstEffect = finishedWork.firstEffect;\n  }\n\n  if (firstEffect !== null) {\n\n    var prevExecutionContext = executionContext;\n    executionContext |= CommitContext;\n    var prevInteractions = pushInteractions(root); // Reset this to null before calling lifecycles\n\n    ReactCurrentOwner$2.current = null; // The commit phase is broken into several sub-phases. We do a separate pass\n    // of the effect list for each phase: all mutation effects come before all\n    // layout effects, and so on.\n    // The first phase a \"before mutation\" phase. We use this phase to read the\n    // state of the host tree right before we mutate it. This is where\n    // getSnapshotBeforeUpdate is called.\n\n    focusedInstanceHandle = prepareForCommit(root.containerInfo);\n    shouldFireAfterActiveInstanceBlur = false;\n    nextEffect = firstEffect;\n\n    do {\n      {\n        invokeGuardedCallback(null, commitBeforeMutationEffects, null);\n\n        if (hasCaughtError()) {\n          if (!(nextEffect !== null)) {\n            {\n              throw Error( \"Should be working on an effect.\" );\n            }\n          }\n\n          var error = clearCaughtError();\n          captureCommitPhaseError(nextEffect, error);\n          nextEffect = nextEffect.nextEffect;\n        }\n      }\n    } while (nextEffect !== null); // We no longer need to track the active instance fiber\n\n\n    focusedInstanceHandle = null;\n\n    {\n      // Mark the current commit time to be shared by all Profilers in this\n      // batch. This enables them to be grouped later.\n      recordCommitTime();\n    } // The next phase is the mutation phase, where we mutate the host tree.\n\n\n    nextEffect = firstEffect;\n\n    do {\n      {\n        invokeGuardedCallback(null, commitMutationEffects, null, root, renderPriorityLevel);\n\n        if (hasCaughtError()) {\n          if (!(nextEffect !== null)) {\n            {\n              throw Error( \"Should be working on an effect.\" );\n            }\n          }\n\n          var _error = clearCaughtError();\n\n          captureCommitPhaseError(nextEffect, _error);\n          nextEffect = nextEffect.nextEffect;\n        }\n      }\n    } while (nextEffect !== null);\n\n    resetAfterCommit(root.containerInfo); // The work-in-progress tree is now the current tree. This must come after\n    // the mutation phase, so that the previous tree is still current during\n    // componentWillUnmount, but before the layout phase, so that the finished\n    // work is current during componentDidMount/Update.\n\n    root.current = finishedWork; // The next phase is the layout phase, where we call effects that read\n    // the host tree after it's been mutated. The idiomatic use case for this is\n    // layout, but class component lifecycles also fire here for legacy reasons.\n\n    nextEffect = firstEffect;\n\n    do {\n      {\n        invokeGuardedCallback(null, commitLayoutEffects, null, root, lanes);\n\n        if (hasCaughtError()) {\n          if (!(nextEffect !== null)) {\n            {\n              throw Error( \"Should be working on an effect.\" );\n            }\n          }\n\n          var _error2 = clearCaughtError();\n\n          captureCommitPhaseError(nextEffect, _error2);\n          nextEffect = nextEffect.nextEffect;\n        }\n      }\n    } while (nextEffect !== null);\n\n    nextEffect = null; // Tell Scheduler to yield at the end of the frame, so the browser has an\n    // opportunity to paint.\n\n    requestPaint();\n\n    {\n      popInteractions(prevInteractions);\n    }\n\n    executionContext = prevExecutionContext;\n  } else {\n    // No effects.\n    root.current = finishedWork; // Measure these anyway so the flamegraph explicitly shows that there were\n    // no effects.\n    // TODO: Maybe there's a better way to report this.\n\n    {\n      recordCommitTime();\n    }\n  }\n\n  var rootDidHavePassiveEffects = rootDoesHavePassiveEffects;\n\n  if (rootDoesHavePassiveEffects) {\n    // This commit has passive effects. Stash a reference to them. But don't\n    // schedule a callback until after flushing layout work.\n    rootDoesHavePassiveEffects = false;\n    rootWithPendingPassiveEffects = root;\n    pendingPassiveEffectsLanes = lanes;\n    pendingPassiveEffectsRenderPriority = renderPriorityLevel;\n  } else {\n    // We are done with the effect chain at this point so let's clear the\n    // nextEffect pointers to assist with GC. If we have passive effects, we'll\n    // clear this in flushPassiveEffects.\n    nextEffect = firstEffect;\n\n    while (nextEffect !== null) {\n      var nextNextEffect = nextEffect.nextEffect;\n      nextEffect.nextEffect = null;\n\n      if (nextEffect.flags & Deletion) {\n        detachFiberAfterEffects(nextEffect);\n      }\n\n      nextEffect = nextNextEffect;\n    }\n  } // Read this again, since an effect might have updated it\n\n\n  remainingLanes = root.pendingLanes; // Check if there's remaining work on this root\n\n  if (remainingLanes !== NoLanes) {\n    {\n      if (spawnedWorkDuringRender !== null) {\n        var expirationTimes = spawnedWorkDuringRender;\n        spawnedWorkDuringRender = null;\n\n        for (var i = 0; i < expirationTimes.length; i++) {\n          scheduleInteractions(root, expirationTimes[i], root.memoizedInteractions);\n        }\n      }\n\n      schedulePendingInteractions(root, remainingLanes);\n    }\n  } else {\n    // If there's no remaining work, we can clear the set of already failed\n    // error boundaries.\n    legacyErrorBoundariesThatAlreadyFailed = null;\n  }\n\n  {\n    if (!rootDidHavePassiveEffects) {\n      // If there are no passive effects, then we can complete the pending interactions.\n      // Otherwise, we'll wait until after the passive effects are flushed.\n      // Wait to do this until after remaining work has been scheduled,\n      // so that we don't prematurely signal complete for interactions when there's e.g. hidden work.\n      finishPendingInteractions(root, lanes);\n    }\n  }\n\n  if (remainingLanes === SyncLane) {\n    // Count the number of times the root synchronously re-renders without\n    // finishing. If there are too many, it indicates an infinite update loop.\n    if (root === rootWithNestedUpdates) {\n      nestedUpdateCount++;\n    } else {\n      nestedUpdateCount = 0;\n      rootWithNestedUpdates = root;\n    }\n  } else {\n    nestedUpdateCount = 0;\n  }\n\n  onCommitRoot(finishedWork.stateNode, renderPriorityLevel);\n\n  {\n    onCommitRoot$1();\n  } // Always call this before exiting `commitRoot`, to ensure that any\n  // additional work on this root is scheduled.\n\n\n  ensureRootIsScheduled(root, now());\n\n  if (hasUncaughtError) {\n    hasUncaughtError = false;\n    var _error3 = firstUncaughtError;\n    firstUncaughtError = null;\n    throw _error3;\n  }\n\n  if ((executionContext & LegacyUnbatchedContext) !== NoContext) {\n    // a ReactDOM.render-ed root inside of batchedUpdates. The commit fired\n    // synchronously, but layout updates should be deferred until the end\n    // of the batch.\n\n\n    return null;\n  } // If layout work was scheduled, flush it now.\n\n\n  flushSyncCallbackQueue();\n\n  return null;\n}\n\nfunction commitBeforeMutationEffects() {\n  while (nextEffect !== null) {\n    var current = nextEffect.alternate;\n\n    if (!shouldFireAfterActiveInstanceBlur && focusedInstanceHandle !== null) {\n      if ((nextEffect.flags & Deletion) !== NoFlags) {\n        if (doesFiberContain(nextEffect, focusedInstanceHandle)) {\n          shouldFireAfterActiveInstanceBlur = true;\n        }\n      } else {\n        // TODO: Move this out of the hot path using a dedicated effect tag.\n        if (nextEffect.tag === SuspenseComponent && isSuspenseBoundaryBeingHidden(current, nextEffect) && doesFiberContain(nextEffect, focusedInstanceHandle)) {\n          shouldFireAfterActiveInstanceBlur = true;\n        }\n      }\n    }\n\n    var flags = nextEffect.flags;\n\n    if ((flags & Snapshot) !== NoFlags) {\n      setCurrentFiber(nextEffect);\n      commitBeforeMutationLifeCycles(current, nextEffect);\n      resetCurrentFiber();\n    }\n\n    if ((flags & Passive) !== NoFlags) {\n      // If there are passive effects, schedule a callback to flush at\n      // the earliest opportunity.\n      if (!rootDoesHavePassiveEffects) {\n        rootDoesHavePassiveEffects = true;\n        scheduleCallback(NormalPriority$1, function () {\n          flushPassiveEffects();\n          return null;\n        });\n      }\n    }\n\n    nextEffect = nextEffect.nextEffect;\n  }\n}\n\nfunction commitMutationEffects(root, renderPriorityLevel) {\n  // TODO: Should probably move the bulk of this function to commitWork.\n  while (nextEffect !== null) {\n    setCurrentFiber(nextEffect);\n    var flags = nextEffect.flags;\n\n    if (flags & ContentReset) {\n      commitResetTextContent(nextEffect);\n    }\n\n    if (flags & Ref) {\n      var current = nextEffect.alternate;\n\n      if (current !== null) {\n        commitDetachRef(current);\n      }\n    } // The following switch statement is only concerned about placement,\n    // updates, and deletions. To avoid needing to add a case for every possible\n    // bitmap value, we remove the secondary effects from the effect tag and\n    // switch on that value.\n\n\n    var primaryFlags = flags & (Placement | Update | Deletion | Hydrating);\n\n    switch (primaryFlags) {\n      case Placement:\n        {\n          commitPlacement(nextEffect); // Clear the \"placement\" from effect tag so that we know that this is\n          // inserted, before any life-cycles like componentDidMount gets called.\n          // TODO: findDOMNode doesn't rely on this any more but isMounted does\n          // and isMounted is deprecated anyway so we should be able to kill this.\n\n          nextEffect.flags &= ~Placement;\n          break;\n        }\n\n      case PlacementAndUpdate:\n        {\n          // Placement\n          commitPlacement(nextEffect); // Clear the \"placement\" from effect tag so that we know that this is\n          // inserted, before any life-cycles like componentDidMount gets called.\n\n          nextEffect.flags &= ~Placement; // Update\n\n          var _current = nextEffect.alternate;\n          commitWork(_current, nextEffect);\n          break;\n        }\n\n      case Hydrating:\n        {\n          nextEffect.flags &= ~Hydrating;\n          break;\n        }\n\n      case HydratingAndUpdate:\n        {\n          nextEffect.flags &= ~Hydrating; // Update\n\n          var _current2 = nextEffect.alternate;\n          commitWork(_current2, nextEffect);\n          break;\n        }\n\n      case Update:\n        {\n          var _current3 = nextEffect.alternate;\n          commitWork(_current3, nextEffect);\n          break;\n        }\n\n      case Deletion:\n        {\n          commitDeletion(root, nextEffect);\n          break;\n        }\n    }\n\n    resetCurrentFiber();\n    nextEffect = nextEffect.nextEffect;\n  }\n}\n\nfunction commitLayoutEffects(root, committedLanes) {\n\n\n  while (nextEffect !== null) {\n    setCurrentFiber(nextEffect);\n    var flags = nextEffect.flags;\n\n    if (flags & (Update | Callback)) {\n      var current = nextEffect.alternate;\n      commitLifeCycles(root, current, nextEffect);\n    }\n\n    {\n      if (flags & Ref) {\n        commitAttachRef(nextEffect);\n      }\n    }\n\n    resetCurrentFiber();\n    nextEffect = nextEffect.nextEffect;\n  }\n}\n\nfunction flushPassiveEffects() {\n  // Returns whether passive effects were flushed.\n  if (pendingPassiveEffectsRenderPriority !== NoPriority$1) {\n    var priorityLevel = pendingPassiveEffectsRenderPriority > NormalPriority$1 ? NormalPriority$1 : pendingPassiveEffectsRenderPriority;\n    pendingPassiveEffectsRenderPriority = NoPriority$1;\n\n    {\n      return runWithPriority$1(priorityLevel, flushPassiveEffectsImpl);\n    }\n  }\n\n  return false;\n}\nfunction enqueuePendingPassiveHookEffectMount(fiber, effect) {\n  pendingPassiveHookEffectsMount.push(effect, fiber);\n\n  if (!rootDoesHavePassiveEffects) {\n    rootDoesHavePassiveEffects = true;\n    scheduleCallback(NormalPriority$1, function () {\n      flushPassiveEffects();\n      return null;\n    });\n  }\n}\nfunction enqueuePendingPassiveHookEffectUnmount(fiber, effect) {\n  pendingPassiveHookEffectsUnmount.push(effect, fiber);\n\n  {\n    fiber.flags |= PassiveUnmountPendingDev;\n    var alternate = fiber.alternate;\n\n    if (alternate !== null) {\n      alternate.flags |= PassiveUnmountPendingDev;\n    }\n  }\n\n  if (!rootDoesHavePassiveEffects) {\n    rootDoesHavePassiveEffects = true;\n    scheduleCallback(NormalPriority$1, function () {\n      flushPassiveEffects();\n      return null;\n    });\n  }\n}\n\nfunction invokePassiveEffectCreate(effect) {\n  var create = effect.create;\n  effect.destroy = create();\n}\n\nfunction flushPassiveEffectsImpl() {\n  if (rootWithPendingPassiveEffects === null) {\n    return false;\n  }\n\n  var root = rootWithPendingPassiveEffects;\n  var lanes = pendingPassiveEffectsLanes;\n  rootWithPendingPassiveEffects = null;\n  pendingPassiveEffectsLanes = NoLanes;\n\n  if (!((executionContext & (RenderContext | CommitContext)) === NoContext)) {\n    {\n      throw Error( \"Cannot flush passive effects while already rendering.\" );\n    }\n  }\n\n  {\n    isFlushingPassiveEffects = true;\n  }\n\n  var prevExecutionContext = executionContext;\n  executionContext |= CommitContext;\n  var prevInteractions = pushInteractions(root); // It's important that ALL pending passive effect destroy functions are called\n  // before ANY passive effect create functions are called.\n  // Otherwise effects in sibling components might interfere with each other.\n  // e.g. a destroy function in one component may unintentionally override a ref\n  // value set by a create function in another component.\n  // Layout effects have the same constraint.\n  // First pass: Destroy stale passive effects.\n\n  var unmountEffects = pendingPassiveHookEffectsUnmount;\n  pendingPassiveHookEffectsUnmount = [];\n\n  for (var i = 0; i < unmountEffects.length; i += 2) {\n    var _effect = unmountEffects[i];\n    var fiber = unmountEffects[i + 1];\n    var destroy = _effect.destroy;\n    _effect.destroy = undefined;\n\n    {\n      fiber.flags &= ~PassiveUnmountPendingDev;\n      var alternate = fiber.alternate;\n\n      if (alternate !== null) {\n        alternate.flags &= ~PassiveUnmountPendingDev;\n      }\n    }\n\n    if (typeof destroy === 'function') {\n      {\n        setCurrentFiber(fiber);\n\n        {\n          invokeGuardedCallback(null, destroy, null);\n        }\n\n        if (hasCaughtError()) {\n          if (!(fiber !== null)) {\n            {\n              throw Error( \"Should be working on an effect.\" );\n            }\n          }\n\n          var error = clearCaughtError();\n          captureCommitPhaseError(fiber, error);\n        }\n\n        resetCurrentFiber();\n      }\n    }\n  } // Second pass: Create new passive effects.\n\n\n  var mountEffects = pendingPassiveHookEffectsMount;\n  pendingPassiveHookEffectsMount = [];\n\n  for (var _i = 0; _i < mountEffects.length; _i += 2) {\n    var _effect2 = mountEffects[_i];\n    var _fiber = mountEffects[_i + 1];\n\n    {\n      setCurrentFiber(_fiber);\n\n      {\n        invokeGuardedCallback(null, invokePassiveEffectCreate, null, _effect2);\n      }\n\n      if (hasCaughtError()) {\n        if (!(_fiber !== null)) {\n          {\n            throw Error( \"Should be working on an effect.\" );\n          }\n        }\n\n        var _error4 = clearCaughtError();\n\n        captureCommitPhaseError(_fiber, _error4);\n      }\n\n      resetCurrentFiber();\n    }\n  } // Note: This currently assumes there are no passive effects on the root fiber\n  // because the root is not part of its own effect list.\n  // This could change in the future.\n\n\n  var effect = root.current.firstEffect;\n\n  while (effect !== null) {\n    var nextNextEffect = effect.nextEffect; // Remove nextEffect pointer to assist GC\n\n    effect.nextEffect = null;\n\n    if (effect.flags & Deletion) {\n      detachFiberAfterEffects(effect);\n    }\n\n    effect = nextNextEffect;\n  }\n\n  {\n    popInteractions(prevInteractions);\n    finishPendingInteractions(root, lanes);\n  }\n\n  {\n    isFlushingPassiveEffects = false;\n  }\n\n  executionContext = prevExecutionContext;\n  flushSyncCallbackQueue(); // If additional passive effects were scheduled, increment a counter. If this\n  // exceeds the limit, we'll fire a warning.\n\n  nestedPassiveUpdateCount = rootWithPendingPassiveEffects === null ? 0 : nestedPassiveUpdateCount + 1;\n  return true;\n}\n\nfunction isAlreadyFailedLegacyErrorBoundary(instance) {\n  return legacyErrorBoundariesThatAlreadyFailed !== null && legacyErrorBoundariesThatAlreadyFailed.has(instance);\n}\nfunction markLegacyErrorBoundaryAsFailed(instance) {\n  if (legacyErrorBoundariesThatAlreadyFailed === null) {\n    legacyErrorBoundariesThatAlreadyFailed = new Set([instance]);\n  } else {\n    legacyErrorBoundariesThatAlreadyFailed.add(instance);\n  }\n}\n\nfunction prepareToThrowUncaughtError(error) {\n  if (!hasUncaughtError) {\n    hasUncaughtError = true;\n    firstUncaughtError = error;\n  }\n}\n\nvar onUncaughtError = prepareToThrowUncaughtError;\n\nfunction captureCommitPhaseErrorOnRoot(rootFiber, sourceFiber, error) {\n  var errorInfo = createCapturedValue(error, sourceFiber);\n  var update = createRootErrorUpdate(rootFiber, errorInfo, SyncLane);\n  enqueueUpdate(rootFiber, update);\n  var eventTime = requestEventTime();\n  var root = markUpdateLaneFromFiberToRoot(rootFiber, SyncLane);\n\n  if (root !== null) {\n    markRootUpdated(root, SyncLane, eventTime);\n    ensureRootIsScheduled(root, eventTime);\n    schedulePendingInteractions(root, SyncLane);\n  }\n}\n\nfunction captureCommitPhaseError(sourceFiber, error) {\n  if (sourceFiber.tag === HostRoot) {\n    // Error was thrown at the root. There is no parent, so the root\n    // itself should capture it.\n    captureCommitPhaseErrorOnRoot(sourceFiber, sourceFiber, error);\n    return;\n  }\n\n  var fiber = sourceFiber.return;\n\n  while (fiber !== null) {\n    if (fiber.tag === HostRoot) {\n      captureCommitPhaseErrorOnRoot(fiber, sourceFiber, error);\n      return;\n    } else if (fiber.tag === ClassComponent) {\n      var ctor = fiber.type;\n      var instance = fiber.stateNode;\n\n      if (typeof ctor.getDerivedStateFromError === 'function' || typeof instance.componentDidCatch === 'function' && !isAlreadyFailedLegacyErrorBoundary(instance)) {\n        var errorInfo = createCapturedValue(error, sourceFiber);\n        var update = createClassErrorUpdate(fiber, errorInfo, SyncLane);\n        enqueueUpdate(fiber, update);\n        var eventTime = requestEventTime();\n        var root = markUpdateLaneFromFiberToRoot(fiber, SyncLane);\n\n        if (root !== null) {\n          markRootUpdated(root, SyncLane, eventTime);\n          ensureRootIsScheduled(root, eventTime);\n          schedulePendingInteractions(root, SyncLane);\n        } else {\n          // This component has already been unmounted.\n          // We can't schedule any follow up work for the root because the fiber is already unmounted,\n          // but we can still call the log-only boundary so the error isn't swallowed.\n          //\n          // TODO This is only a temporary bandaid for the old reconciler fork.\n          // We can delete this special case once the new fork is merged.\n          if (typeof instance.componentDidCatch === 'function' && !isAlreadyFailedLegacyErrorBoundary(instance)) {\n            try {\n              instance.componentDidCatch(error, errorInfo);\n            } catch (errorToIgnore) {// TODO Ignore this error? Rethrow it?\n              // This is kind of an edge case.\n            }\n          }\n        }\n\n        return;\n      }\n    }\n\n    fiber = fiber.return;\n  }\n}\nfunction pingSuspendedRoot(root, wakeable, pingedLanes) {\n  var pingCache = root.pingCache;\n\n  if (pingCache !== null) {\n    // The wakeable resolved, so we no longer need to memoize, because it will\n    // never be thrown again.\n    pingCache.delete(wakeable);\n  }\n\n  var eventTime = requestEventTime();\n  markRootPinged(root, pingedLanes);\n\n  if (workInProgressRoot === root && isSubsetOfLanes(workInProgressRootRenderLanes, pingedLanes)) {\n    // Received a ping at the same priority level at which we're currently\n    // rendering. We might want to restart this render. This should mirror\n    // the logic of whether or not a root suspends once it completes.\n    // TODO: If we're rendering sync either due to Sync, Batched or expired,\n    // we should probably never restart.\n    // If we're suspended with delay, or if it's a retry, we'll always suspend\n    // so we can always restart.\n    if (workInProgressRootExitStatus === RootSuspendedWithDelay || workInProgressRootExitStatus === RootSuspended && includesOnlyRetries(workInProgressRootRenderLanes) && now() - globalMostRecentFallbackTime < FALLBACK_THROTTLE_MS) {\n      // Restart from the root.\n      prepareFreshStack(root, NoLanes);\n    } else {\n      // Even though we can't restart right now, we might get an\n      // opportunity later. So we mark this render as having a ping.\n      workInProgressRootPingedLanes = mergeLanes(workInProgressRootPingedLanes, pingedLanes);\n    }\n  }\n\n  ensureRootIsScheduled(root, eventTime);\n  schedulePendingInteractions(root, pingedLanes);\n}\n\nfunction retryTimedOutBoundary(boundaryFiber, retryLane) {\n  // The boundary fiber (a Suspense component or SuspenseList component)\n  // previously was rendered in its fallback state. One of the promises that\n  // suspended it has resolved, which means at least part of the tree was\n  // likely unblocked. Try rendering again, at a new expiration time.\n  if (retryLane === NoLane) {\n    retryLane = requestRetryLane(boundaryFiber);\n  } // TODO: Special case idle priority?\n\n\n  var eventTime = requestEventTime();\n  var root = markUpdateLaneFromFiberToRoot(boundaryFiber, retryLane);\n\n  if (root !== null) {\n    markRootUpdated(root, retryLane, eventTime);\n    ensureRootIsScheduled(root, eventTime);\n    schedulePendingInteractions(root, retryLane);\n  }\n}\nfunction resolveRetryWakeable(boundaryFiber, wakeable) {\n  var retryLane = NoLane; // Default\n\n  var retryCache;\n\n  {\n    retryCache = boundaryFiber.stateNode;\n  }\n\n  if (retryCache !== null) {\n    // The wakeable resolved, so we no longer need to memoize, because it will\n    // never be thrown again.\n    retryCache.delete(wakeable);\n  }\n\n  retryTimedOutBoundary(boundaryFiber, retryLane);\n} // Computes the next Just Noticeable Difference (JND) boundary.\n// The theory is that a person can't tell the difference between small differences in time.\n// Therefore, if we wait a bit longer than necessary that won't translate to a noticeable\n// difference in the experience. However, waiting for longer might mean that we can avoid\n// showing an intermediate loading state. The longer we have already waited, the harder it\n// is to tell small differences in time. Therefore, the longer we've already waited,\n// the longer we can wait additionally. At some point we have to give up though.\n// We pick a train model where the next boundary commits at a consistent schedule.\n// These particular numbers are vague estimates. We expect to adjust them based on research.\n\nfunction jnd(timeElapsed) {\n  return timeElapsed < 120 ? 120 : timeElapsed < 480 ? 480 : timeElapsed < 1080 ? 1080 : timeElapsed < 1920 ? 1920 : timeElapsed < 3000 ? 3000 : timeElapsed < 4320 ? 4320 : ceil(timeElapsed / 1960) * 1960;\n}\n\nfunction checkForNestedUpdates() {\n  if (nestedUpdateCount > NESTED_UPDATE_LIMIT) {\n    nestedUpdateCount = 0;\n    rootWithNestedUpdates = null;\n\n    {\n      {\n        throw Error( \"Maximum update depth exceeded. This can happen when a component repeatedly calls setState inside componentWillUpdate or componentDidUpdate. React limits the number of nested updates to prevent infinite loops.\" );\n      }\n    }\n  }\n\n  {\n    if (nestedPassiveUpdateCount > NESTED_PASSIVE_UPDATE_LIMIT) {\n      nestedPassiveUpdateCount = 0;\n\n      error('Maximum update depth exceeded. This can happen when a component ' + \"calls setState inside useEffect, but useEffect either doesn't \" + 'have a dependency array, or one of the dependencies changes on ' + 'every render.');\n    }\n  }\n}\n\nfunction flushRenderPhaseStrictModeWarningsInDEV() {\n  {\n    ReactStrictModeWarnings.flushLegacyContextWarning();\n\n    {\n      ReactStrictModeWarnings.flushPendingUnsafeLifecycleWarnings();\n    }\n  }\n}\n\nvar didWarnStateUpdateForNotYetMountedComponent = null;\n\nfunction warnAboutUpdateOnNotYetMountedFiberInDEV(fiber) {\n  {\n    if ((executionContext & RenderContext) !== NoContext) {\n      // We let the other warning about render phase updates deal with this one.\n      return;\n    }\n\n    if (!(fiber.mode & (BlockingMode | ConcurrentMode))) {\n      return;\n    }\n\n    var tag = fiber.tag;\n\n    if (tag !== IndeterminateComponent && tag !== HostRoot && tag !== ClassComponent && tag !== FunctionComponent && tag !== ForwardRef && tag !== MemoComponent && tag !== SimpleMemoComponent && tag !== Block) {\n      // Only warn for user-defined components, not internal ones like Suspense.\n      return;\n    } // We show the whole stack but dedupe on the top component's name because\n    // the problematic code almost always lies inside that component.\n\n\n    var componentName = getComponentName(fiber.type) || 'ReactComponent';\n\n    if (didWarnStateUpdateForNotYetMountedComponent !== null) {\n      if (didWarnStateUpdateForNotYetMountedComponent.has(componentName)) {\n        return;\n      }\n\n      didWarnStateUpdateForNotYetMountedComponent.add(componentName);\n    } else {\n      didWarnStateUpdateForNotYetMountedComponent = new Set([componentName]);\n    }\n\n    var previousFiber = current;\n\n    try {\n      setCurrentFiber(fiber);\n\n      error(\"Can't perform a React state update on a component that hasn't mounted yet. \" + 'This indicates that you have a side-effect in your render function that ' + 'asynchronously later calls tries to update the component. Move this work to ' + 'useEffect instead.');\n    } finally {\n      if (previousFiber) {\n        setCurrentFiber(fiber);\n      } else {\n        resetCurrentFiber();\n      }\n    }\n  }\n}\n\nvar didWarnStateUpdateForUnmountedComponent = null;\n\nfunction warnAboutUpdateOnUnmountedFiberInDEV(fiber) {\n  {\n    var tag = fiber.tag;\n\n    if (tag !== HostRoot && tag !== ClassComponent && tag !== FunctionComponent && tag !== ForwardRef && tag !== MemoComponent && tag !== SimpleMemoComponent && tag !== Block) {\n      // Only warn for user-defined components, not internal ones like Suspense.\n      return;\n    } // If there are pending passive effects unmounts for this Fiber,\n    // we can assume that they would have prevented this update.\n\n\n    if ((fiber.flags & PassiveUnmountPendingDev) !== NoFlags) {\n      return;\n    } // We show the whole stack but dedupe on the top component's name because\n    // the problematic code almost always lies inside that component.\n\n\n    var componentName = getComponentName(fiber.type) || 'ReactComponent';\n\n    if (didWarnStateUpdateForUnmountedComponent !== null) {\n      if (didWarnStateUpdateForUnmountedComponent.has(componentName)) {\n        return;\n      }\n\n      didWarnStateUpdateForUnmountedComponent.add(componentName);\n    } else {\n      didWarnStateUpdateForUnmountedComponent = new Set([componentName]);\n    }\n\n    if (isFlushingPassiveEffects) ; else {\n      var previousFiber = current;\n\n      try {\n        setCurrentFiber(fiber);\n\n        error(\"Can't perform a React state update on an unmounted component. This \" + 'is a no-op, but it indicates a memory leak in your application. To ' + 'fix, cancel all subscriptions and asynchronous tasks in %s.', tag === ClassComponent ? 'the componentWillUnmount method' : 'a useEffect cleanup function');\n      } finally {\n        if (previousFiber) {\n          setCurrentFiber(fiber);\n        } else {\n          resetCurrentFiber();\n        }\n      }\n    }\n  }\n}\n\nvar beginWork$1;\n\n{\n  var dummyFiber = null;\n\n  beginWork$1 = function (current, unitOfWork, lanes) {\n    // If a component throws an error, we replay it again in a synchronously\n    // dispatched event, so that the debugger will treat it as an uncaught\n    // error See ReactErrorUtils for more information.\n    // Before entering the begin phase, copy the work-in-progress onto a dummy\n    // fiber. If beginWork throws, we'll use this to reset the state.\n    var originalWorkInProgressCopy = assignFiberPropertiesInDEV(dummyFiber, unitOfWork);\n\n    try {\n      return beginWork(current, unitOfWork, lanes);\n    } catch (originalError) {\n      if (originalError !== null && typeof originalError === 'object' && typeof originalError.then === 'function') {\n        // Don't replay promises. Treat everything else like an error.\n        throw originalError;\n      } // Keep this code in sync with handleError; any changes here must have\n      // corresponding changes there.\n\n\n      resetContextDependencies();\n      resetHooksAfterThrow(); // Don't reset current debug fiber, since we're about to work on the\n      // same fiber again.\n      // Unwind the failed stack frame\n\n      unwindInterruptedWork(unitOfWork); // Restore the original properties of the fiber.\n\n      assignFiberPropertiesInDEV(unitOfWork, originalWorkInProgressCopy);\n\n      if ( unitOfWork.mode & ProfileMode) {\n        // Reset the profiler timer.\n        startProfilerTimer(unitOfWork);\n      } // Run beginWork again.\n\n\n      invokeGuardedCallback(null, beginWork, null, current, unitOfWork, lanes);\n\n      if (hasCaughtError()) {\n        var replayError = clearCaughtError(); // `invokeGuardedCallback` sometimes sets an expando `_suppressLogging`.\n        // Rethrow this error instead of the original one.\n\n        throw replayError;\n      } else {\n        // This branch is reachable if the render phase is impure.\n        throw originalError;\n      }\n    }\n  };\n}\n\nvar didWarnAboutUpdateInRender = false;\nvar didWarnAboutUpdateInRenderForAnotherComponent;\n\n{\n  didWarnAboutUpdateInRenderForAnotherComponent = new Set();\n}\n\nfunction warnAboutRenderPhaseUpdatesInDEV(fiber) {\n  {\n    if (isRendering && (executionContext & RenderContext) !== NoContext && !getIsUpdatingOpaqueValueInRenderPhaseInDEV()) {\n      switch (fiber.tag) {\n        case FunctionComponent:\n        case ForwardRef:\n        case SimpleMemoComponent:\n          {\n            var renderingComponentName = workInProgress && getComponentName(workInProgress.type) || 'Unknown'; // Dedupe by the rendering component because it's the one that needs to be fixed.\n\n            var dedupeKey = renderingComponentName;\n\n            if (!didWarnAboutUpdateInRenderForAnotherComponent.has(dedupeKey)) {\n              didWarnAboutUpdateInRenderForAnotherComponent.add(dedupeKey);\n              var setStateComponentName = getComponentName(fiber.type) || 'Unknown';\n\n              error('Cannot update a component (`%s`) while rendering a ' + 'different component (`%s`). To locate the bad setState() call inside `%s`, ' + 'follow the stack trace as described in https://reactjs.org/link/setstate-in-render', setStateComponentName, renderingComponentName, renderingComponentName);\n            }\n\n            break;\n          }\n\n        case ClassComponent:\n          {\n            if (!didWarnAboutUpdateInRender) {\n              error('Cannot update during an existing state transition (such as ' + 'within `render`). Render methods should be a pure ' + 'function of props and state.');\n\n              didWarnAboutUpdateInRender = true;\n            }\n\n            break;\n          }\n      }\n    }\n  }\n} // a 'shared' variable that changes when act() opens/closes in tests.\n\n\nvar IsThisRendererActing = {\n  current: false\n};\nfunction warnIfNotScopedWithMatchingAct(fiber) {\n  {\n    if ( IsSomeRendererActing.current === true && IsThisRendererActing.current !== true) {\n      var previousFiber = current;\n\n      try {\n        setCurrentFiber(fiber);\n\n        error(\"It looks like you're using the wrong act() around your test interactions.\\n\" + 'Be sure to use the matching version of act() corresponding to your renderer:\\n\\n' + '// for react-dom:\\n' + // Break up imports to avoid accidentally parsing them as dependencies.\n        'import {act} fr' + \"om 'react-dom/test-utils';\\n\" + '// ...\\n' + 'act(() => ...);\\n\\n' + '// for react-test-renderer:\\n' + // Break up imports to avoid accidentally parsing them as dependencies.\n        'import TestRenderer fr' + \"om react-test-renderer';\\n\" + 'const {act} = TestRenderer;\\n' + '// ...\\n' + 'act(() => ...);');\n      } finally {\n        if (previousFiber) {\n          setCurrentFiber(fiber);\n        } else {\n          resetCurrentFiber();\n        }\n      }\n    }\n  }\n}\nfunction warnIfNotCurrentlyActingEffectsInDEV(fiber) {\n  {\n    if ( (fiber.mode & StrictMode) !== NoMode && IsSomeRendererActing.current === false && IsThisRendererActing.current === false) {\n      error('An update to %s ran an effect, but was not wrapped in act(...).\\n\\n' + 'When testing, code that causes React state updates should be ' + 'wrapped into act(...):\\n\\n' + 'act(() => {\\n' + '  /* fire events that update state */\\n' + '});\\n' + '/* assert on the output */\\n\\n' + \"This ensures that you're testing the behavior the user would see \" + 'in the browser.' + ' Learn more at https://reactjs.org/link/wrap-tests-with-act', getComponentName(fiber.type));\n    }\n  }\n}\n\nfunction warnIfNotCurrentlyActingUpdatesInDEV(fiber) {\n  {\n    if ( executionContext === NoContext && IsSomeRendererActing.current === false && IsThisRendererActing.current === false) {\n      var previousFiber = current;\n\n      try {\n        setCurrentFiber(fiber);\n\n        error('An update to %s inside a test was not wrapped in act(...).\\n\\n' + 'When testing, code that causes React state updates should be ' + 'wrapped into act(...):\\n\\n' + 'act(() => {\\n' + '  /* fire events that update state */\\n' + '});\\n' + '/* assert on the output */\\n\\n' + \"This ensures that you're testing the behavior the user would see \" + 'in the browser.' + ' Learn more at https://reactjs.org/link/wrap-tests-with-act', getComponentName(fiber.type));\n      } finally {\n        if (previousFiber) {\n          setCurrentFiber(fiber);\n        } else {\n          resetCurrentFiber();\n        }\n      }\n    }\n  }\n}\n\nvar warnIfNotCurrentlyActingUpdatesInDev = warnIfNotCurrentlyActingUpdatesInDEV; // In tests, we want to enforce a mocked scheduler.\n\nvar didWarnAboutUnmockedScheduler = false; // TODO Before we release concurrent mode, revisit this and decide whether a mocked\n// scheduler is the actual recommendation. The alternative could be a testing build,\n// a new lib, or whatever; we dunno just yet. This message is for early adopters\n// to get their tests right.\n\nfunction warnIfUnmockedScheduler(fiber) {\n  {\n    if (didWarnAboutUnmockedScheduler === false && Scheduler.unstable_flushAllWithoutAsserting === undefined) {\n      if (fiber.mode & BlockingMode || fiber.mode & ConcurrentMode) {\n        didWarnAboutUnmockedScheduler = true;\n\n        error('In Concurrent or Sync modes, the \"scheduler\" module needs to be mocked ' + 'to guarantee consistent behaviour across tests and browsers. ' + 'For example, with jest: \\n' + // Break up requires to avoid accidentally parsing them as dependencies.\n        \"jest.mock('scheduler', () => require\" + \"('scheduler/unstable_mock'));\\n\\n\" + 'For more info, visit https://reactjs.org/link/mock-scheduler');\n      }\n    }\n  }\n}\n\nfunction computeThreadID(root, lane) {\n  // Interaction threads are unique per root and expiration time.\n  // NOTE: Intentionally unsound cast. All that matters is that it's a number\n  // and it represents a batch of work. Could make a helper function instead,\n  // but meh this is fine for now.\n  return lane * 1000 + root.interactionThreadID;\n}\n\nfunction markSpawnedWork(lane) {\n\n  if (spawnedWorkDuringRender === null) {\n    spawnedWorkDuringRender = [lane];\n  } else {\n    spawnedWorkDuringRender.push(lane);\n  }\n}\n\nfunction scheduleInteractions(root, lane, interactions) {\n\n  if (interactions.size > 0) {\n    var pendingInteractionMap = root.pendingInteractionMap;\n    var pendingInteractions = pendingInteractionMap.get(lane);\n\n    if (pendingInteractions != null) {\n      interactions.forEach(function (interaction) {\n        if (!pendingInteractions.has(interaction)) {\n          // Update the pending async work count for previously unscheduled interaction.\n          interaction.__count++;\n        }\n\n        pendingInteractions.add(interaction);\n      });\n    } else {\n      pendingInteractionMap.set(lane, new Set(interactions)); // Update the pending async work count for the current interactions.\n\n      interactions.forEach(function (interaction) {\n        interaction.__count++;\n      });\n    }\n\n    var subscriber = tracing.__subscriberRef.current;\n\n    if (subscriber !== null) {\n      var threadID = computeThreadID(root, lane);\n      subscriber.onWorkScheduled(interactions, threadID);\n    }\n  }\n}\n\nfunction schedulePendingInteractions(root, lane) {\n\n  scheduleInteractions(root, lane, tracing.__interactionsRef.current);\n}\n\nfunction startWorkOnPendingInteractions(root, lanes) {\n  // we can accurately attribute time spent working on it, And so that cascading\n  // work triggered during the render phase will be associated with it.\n\n\n  var interactions = new Set();\n  root.pendingInteractionMap.forEach(function (scheduledInteractions, scheduledLane) {\n    if (includesSomeLane(lanes, scheduledLane)) {\n      scheduledInteractions.forEach(function (interaction) {\n        return interactions.add(interaction);\n      });\n    }\n  }); // Store the current set of interactions on the FiberRoot for a few reasons:\n  // We can re-use it in hot functions like performConcurrentWorkOnRoot()\n  // without having to recalculate it. We will also use it in commitWork() to\n  // pass to any Profiler onRender() hooks. This also provides DevTools with a\n  // way to access it when the onCommitRoot() hook is called.\n\n  root.memoizedInteractions = interactions;\n\n  if (interactions.size > 0) {\n    var subscriber = tracing.__subscriberRef.current;\n\n    if (subscriber !== null) {\n      var threadID = computeThreadID(root, lanes);\n\n      try {\n        subscriber.onWorkStarted(interactions, threadID);\n      } catch (error) {\n        // If the subscriber throws, rethrow it in a separate task\n        scheduleCallback(ImmediatePriority$1, function () {\n          throw error;\n        });\n      }\n    }\n  }\n}\n\nfunction finishPendingInteractions(root, committedLanes) {\n\n  var remainingLanesAfterCommit = root.pendingLanes;\n  var subscriber;\n\n  try {\n    subscriber = tracing.__subscriberRef.current;\n\n    if (subscriber !== null && root.memoizedInteractions.size > 0) {\n      // FIXME: More than one lane can finish in a single commit.\n      var threadID = computeThreadID(root, committedLanes);\n      subscriber.onWorkStopped(root.memoizedInteractions, threadID);\n    }\n  } catch (error) {\n    // If the subscriber throws, rethrow it in a separate task\n    scheduleCallback(ImmediatePriority$1, function () {\n      throw error;\n    });\n  } finally {\n    // Clear completed interactions from the pending Map.\n    // Unless the render was suspended or cascading work was scheduled,\n    // In which case– leave pending interactions until the subsequent render.\n    var pendingInteractionMap = root.pendingInteractionMap;\n    pendingInteractionMap.forEach(function (scheduledInteractions, lane) {\n      // Only decrement the pending interaction count if we're done.\n      // If there's still work at the current priority,\n      // That indicates that we are waiting for suspense data.\n      if (!includesSomeLane(remainingLanesAfterCommit, lane)) {\n        pendingInteractionMap.delete(lane);\n        scheduledInteractions.forEach(function (interaction) {\n          interaction.__count--;\n\n          if (subscriber !== null && interaction.__count === 0) {\n            try {\n              subscriber.onInteractionScheduledWorkCompleted(interaction);\n            } catch (error) {\n              // If the subscriber throws, rethrow it in a separate task\n              scheduleCallback(ImmediatePriority$1, function () {\n                throw error;\n              });\n            }\n          }\n        });\n      }\n    });\n  }\n} // `act` testing API\n\nfunction shouldForceFlushFallbacksInDEV() {\n  // Never force flush in production. This function should get stripped out.\n  return  actingUpdatesScopeDepth > 0;\n}\n// so we can tell if any async act() calls try to run in parallel.\n\n\nvar actingUpdatesScopeDepth = 0;\n\nfunction detachFiberAfterEffects(fiber) {\n  fiber.sibling = null;\n  fiber.stateNode = null;\n}\n\nvar resolveFamily = null; // $FlowFixMe Flow gets confused by a WeakSet feature check below.\n\nvar failedBoundaries = null;\nvar setRefreshHandler = function (handler) {\n  {\n    resolveFamily = handler;\n  }\n};\nfunction resolveFunctionForHotReloading(type) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return type;\n    }\n\n    var family = resolveFamily(type);\n\n    if (family === undefined) {\n      return type;\n    } // Use the latest known implementation.\n\n\n    return family.current;\n  }\n}\nfunction resolveClassForHotReloading(type) {\n  // No implementation differences.\n  return resolveFunctionForHotReloading(type);\n}\nfunction resolveForwardRefForHotReloading(type) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return type;\n    }\n\n    var family = resolveFamily(type);\n\n    if (family === undefined) {\n      // Check if we're dealing with a real forwardRef. Don't want to crash early.\n      if (type !== null && type !== undefined && typeof type.render === 'function') {\n        // ForwardRef is special because its resolved .type is an object,\n        // but it's possible that we only have its inner render function in the map.\n        // If that inner render function is different, we'll build a new forwardRef type.\n        var currentRender = resolveFunctionForHotReloading(type.render);\n\n        if (type.render !== currentRender) {\n          var syntheticType = {\n            $$typeof: REACT_FORWARD_REF_TYPE,\n            render: currentRender\n          };\n\n          if (type.displayName !== undefined) {\n            syntheticType.displayName = type.displayName;\n          }\n\n          return syntheticType;\n        }\n      }\n\n      return type;\n    } // Use the latest known implementation.\n\n\n    return family.current;\n  }\n}\nfunction isCompatibleFamilyForHotReloading(fiber, element) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return false;\n    }\n\n    var prevType = fiber.elementType;\n    var nextType = element.type; // If we got here, we know types aren't === equal.\n\n    var needsCompareFamilies = false;\n    var $$typeofNextType = typeof nextType === 'object' && nextType !== null ? nextType.$$typeof : null;\n\n    switch (fiber.tag) {\n      case ClassComponent:\n        {\n          if (typeof nextType === 'function') {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case FunctionComponent:\n        {\n          if (typeof nextType === 'function') {\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            // We don't know the inner type yet.\n            // We're going to assume that the lazy inner type is stable,\n            // and so it is sufficient to avoid reconciling it away.\n            // We're not going to unwrap or actually use the new lazy type.\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case ForwardRef:\n        {\n          if ($$typeofNextType === REACT_FORWARD_REF_TYPE) {\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case MemoComponent:\n      case SimpleMemoComponent:\n        {\n          if ($$typeofNextType === REACT_MEMO_TYPE) {\n            // TODO: if it was but can no longer be simple,\n            // we shouldn't set this.\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      default:\n        return false;\n    } // Check if both types have a family and it's the same one.\n\n\n    if (needsCompareFamilies) {\n      // Note: memo() and forwardRef() we'll compare outer rather than inner type.\n      // This means both of them need to be registered to preserve state.\n      // If we unwrapped and compared the inner types for wrappers instead,\n      // then we would risk falsely saying two separate memo(Foo)\n      // calls are equivalent because they wrap the same Foo function.\n      var prevFamily = resolveFamily(prevType);\n\n      if (prevFamily !== undefined && prevFamily === resolveFamily(nextType)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n}\nfunction markFailedErrorBoundaryForHotReloading(fiber) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return;\n    }\n\n    if (typeof WeakSet !== 'function') {\n      return;\n    }\n\n    if (failedBoundaries === null) {\n      failedBoundaries = new WeakSet();\n    }\n\n    failedBoundaries.add(fiber);\n  }\n}\nvar scheduleRefresh = function (root, update) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return;\n    }\n\n    var staleFamilies = update.staleFamilies,\n        updatedFamilies = update.updatedFamilies;\n    flushPassiveEffects();\n    flushSync(function () {\n      scheduleFibersWithFamiliesRecursively(root.current, updatedFamilies, staleFamilies);\n    });\n  }\n};\nvar scheduleRoot = function (root, element) {\n  {\n    if (root.context !== emptyContextObject) {\n      // Super edge case: root has a legacy _renderSubtree context\n      // but we don't know the parentComponent so we can't pass it.\n      // Just ignore. We'll delete this with _renderSubtree code path later.\n      return;\n    }\n\n    flushPassiveEffects();\n    flushSync(function () {\n      updateContainer(element, root, null, null);\n    });\n  }\n};\n\nfunction scheduleFibersWithFamiliesRecursively(fiber, updatedFamilies, staleFamilies) {\n  {\n    var alternate = fiber.alternate,\n        child = fiber.child,\n        sibling = fiber.sibling,\n        tag = fiber.tag,\n        type = fiber.type;\n    var candidateType = null;\n\n    switch (tag) {\n      case FunctionComponent:\n      case SimpleMemoComponent:\n      case ClassComponent:\n        candidateType = type;\n        break;\n\n      case ForwardRef:\n        candidateType = type.render;\n        break;\n    }\n\n    if (resolveFamily === null) {\n      throw new Error('Expected resolveFamily to be set during hot reload.');\n    }\n\n    var needsRender = false;\n    var needsRemount = false;\n\n    if (candidateType !== null) {\n      var family = resolveFamily(candidateType);\n\n      if (family !== undefined) {\n        if (staleFamilies.has(family)) {\n          needsRemount = true;\n        } else if (updatedFamilies.has(family)) {\n          if (tag === ClassComponent) {\n            needsRemount = true;\n          } else {\n            needsRender = true;\n          }\n        }\n      }\n    }\n\n    if (failedBoundaries !== null) {\n      if (failedBoundaries.has(fiber) || alternate !== null && failedBoundaries.has(alternate)) {\n        needsRemount = true;\n      }\n    }\n\n    if (needsRemount) {\n      fiber._debugNeedsRemount = true;\n    }\n\n    if (needsRemount || needsRender) {\n      scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n    }\n\n    if (child !== null && !needsRemount) {\n      scheduleFibersWithFamiliesRecursively(child, updatedFamilies, staleFamilies);\n    }\n\n    if (sibling !== null) {\n      scheduleFibersWithFamiliesRecursively(sibling, updatedFamilies, staleFamilies);\n    }\n  }\n}\n\nvar findHostInstancesForRefresh = function (root, families) {\n  {\n    var hostInstances = new Set();\n    var types = new Set(families.map(function (family) {\n      return family.current;\n    }));\n    findHostInstancesForMatchingFibersRecursively(root.current, types, hostInstances);\n    return hostInstances;\n  }\n};\n\nfunction findHostInstancesForMatchingFibersRecursively(fiber, types, hostInstances) {\n  {\n    var child = fiber.child,\n        sibling = fiber.sibling,\n        tag = fiber.tag,\n        type = fiber.type;\n    var candidateType = null;\n\n    switch (tag) {\n      case FunctionComponent:\n      case SimpleMemoComponent:\n      case ClassComponent:\n        candidateType = type;\n        break;\n\n      case ForwardRef:\n        candidateType = type.render;\n        break;\n    }\n\n    var didMatch = false;\n\n    if (candidateType !== null) {\n      if (types.has(candidateType)) {\n        didMatch = true;\n      }\n    }\n\n    if (didMatch) {\n      // We have a match. This only drills down to the closest host components.\n      // There's no need to search deeper because for the purpose of giving\n      // visual feedback, \"flashing\" outermost parent rectangles is sufficient.\n      findHostInstancesForFiberShallowly(fiber, hostInstances);\n    } else {\n      // If there's no match, maybe there will be one further down in the child tree.\n      if (child !== null) {\n        findHostInstancesForMatchingFibersRecursively(child, types, hostInstances);\n      }\n    }\n\n    if (sibling !== null) {\n      findHostInstancesForMatchingFibersRecursively(sibling, types, hostInstances);\n    }\n  }\n}\n\nfunction findHostInstancesForFiberShallowly(fiber, hostInstances) {\n  {\n    var foundHostInstances = findChildHostInstancesForFiberShallowly(fiber, hostInstances);\n\n    if (foundHostInstances) {\n      return;\n    } // If we didn't find any host children, fallback to closest host parent.\n\n\n    var node = fiber;\n\n    while (true) {\n      switch (node.tag) {\n        case HostComponent:\n          hostInstances.add(node.stateNode);\n          return;\n\n        case HostPortal:\n          hostInstances.add(node.stateNode.containerInfo);\n          return;\n\n        case HostRoot:\n          hostInstances.add(node.stateNode.containerInfo);\n          return;\n      }\n\n      if (node.return === null) {\n        throw new Error('Expected to reach root first.');\n      }\n\n      node = node.return;\n    }\n  }\n}\n\nfunction findChildHostInstancesForFiberShallowly(fiber, hostInstances) {\n  {\n    var node = fiber;\n    var foundHostInstances = false;\n\n    while (true) {\n      if (node.tag === HostComponent) {\n        // We got a match.\n        foundHostInstances = true;\n        hostInstances.add(node.stateNode); // There may still be more, so keep searching.\n      } else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === fiber) {\n        return foundHostInstances;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === fiber) {\n          return foundHostInstances;\n        }\n\n        node = node.return;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  }\n\n  return false;\n}\n\nvar hasBadMapPolyfill;\n\n{\n  hasBadMapPolyfill = false;\n\n  try {\n    var nonExtensibleObject = Object.preventExtensions({});\n    /* eslint-disable no-new */\n\n    new Map([[nonExtensibleObject, null]]);\n    new Set([nonExtensibleObject]);\n    /* eslint-enable no-new */\n  } catch (e) {\n    // TODO: Consider warning about bad polyfills\n    hasBadMapPolyfill = true;\n  }\n}\n\nvar debugCounter = 1;\n\nfunction FiberNode(tag, pendingProps, key, mode) {\n  // Instance\n  this.tag = tag;\n  this.key = key;\n  this.elementType = null;\n  this.type = null;\n  this.stateNode = null; // Fiber\n\n  this.return = null;\n  this.child = null;\n  this.sibling = null;\n  this.index = 0;\n  this.ref = null;\n  this.pendingProps = pendingProps;\n  this.memoizedProps = null;\n  this.updateQueue = null;\n  this.memoizedState = null;\n  this.dependencies = null;\n  this.mode = mode; // Effects\n\n  this.flags = NoFlags;\n  this.nextEffect = null;\n  this.firstEffect = null;\n  this.lastEffect = null;\n  this.lanes = NoLanes;\n  this.childLanes = NoLanes;\n  this.alternate = null;\n\n  {\n    // Note: The following is done to avoid a v8 performance cliff.\n    //\n    // Initializing the fields below to smis and later updating them with\n    // double values will cause Fibers to end up having separate shapes.\n    // This behavior/bug has something to do with Object.preventExtension().\n    // Fortunately this only impacts DEV builds.\n    // Unfortunately it makes React unusably slow for some applications.\n    // To work around this, initialize the fields below with doubles.\n    //\n    // Learn more about this here:\n    // https://github.com/facebook/react/issues/14365\n    // https://bugs.chromium.org/p/v8/issues/detail?id=8538\n    this.actualDuration = Number.NaN;\n    this.actualStartTime = Number.NaN;\n    this.selfBaseDuration = Number.NaN;\n    this.treeBaseDuration = Number.NaN; // It's okay to replace the initial doubles with smis after initialization.\n    // This won't trigger the performance cliff mentioned above,\n    // and it simplifies other profiler code (including DevTools).\n\n    this.actualDuration = 0;\n    this.actualStartTime = -1;\n    this.selfBaseDuration = 0;\n    this.treeBaseDuration = 0;\n  }\n\n  {\n    // This isn't directly used but is handy for debugging internals:\n    this._debugID = debugCounter++;\n    this._debugSource = null;\n    this._debugOwner = null;\n    this._debugNeedsRemount = false;\n    this._debugHookTypes = null;\n\n    if (!hasBadMapPolyfill && typeof Object.preventExtensions === 'function') {\n      Object.preventExtensions(this);\n    }\n  }\n} // This is a constructor function, rather than a POJO constructor, still\n// please ensure we do the following:\n// 1) Nobody should add any instance methods on this. Instance methods can be\n//    more difficult to predict when they get optimized and they are almost\n//    never inlined properly in static compilers.\n// 2) Nobody should rely on `instanceof Fiber` for type testing. We should\n//    always know when it is a fiber.\n// 3) We might want to experiment with using numeric keys since they are easier\n//    to optimize in a non-JIT environment.\n// 4) We can easily go from a constructor to a createFiber object literal if that\n//    is faster.\n// 5) It should be easy to port this to a C struct and keep a C implementation\n//    compatible.\n\n\nvar createFiber = function (tag, pendingProps, key, mode) {\n  // $FlowFixMe: the shapes are exact here but Flow doesn't like constructors\n  return new FiberNode(tag, pendingProps, key, mode);\n};\n\nfunction shouldConstruct$1(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction isSimpleFunctionComponent(type) {\n  return typeof type === 'function' && !shouldConstruct$1(type) && type.defaultProps === undefined;\n}\nfunction resolveLazyComponentTag(Component) {\n  if (typeof Component === 'function') {\n    return shouldConstruct$1(Component) ? ClassComponent : FunctionComponent;\n  } else if (Component !== undefined && Component !== null) {\n    var $$typeof = Component.$$typeof;\n\n    if ($$typeof === REACT_FORWARD_REF_TYPE) {\n      return ForwardRef;\n    }\n\n    if ($$typeof === REACT_MEMO_TYPE) {\n      return MemoComponent;\n    }\n  }\n\n  return IndeterminateComponent;\n} // This is used to create an alternate fiber to do work on.\n\nfunction createWorkInProgress(current, pendingProps) {\n  var workInProgress = current.alternate;\n\n  if (workInProgress === null) {\n    // We use a double buffering pooling technique because we know that we'll\n    // only ever need at most two versions of a tree. We pool the \"other\" unused\n    // node that we're free to reuse. This is lazily created to avoid allocating\n    // extra objects for things that are never updated. It also allow us to\n    // reclaim the extra memory if needed.\n    workInProgress = createFiber(current.tag, pendingProps, current.key, current.mode);\n    workInProgress.elementType = current.elementType;\n    workInProgress.type = current.type;\n    workInProgress.stateNode = current.stateNode;\n\n    {\n      // DEV-only fields\n      workInProgress._debugID = current._debugID;\n      workInProgress._debugSource = current._debugSource;\n      workInProgress._debugOwner = current._debugOwner;\n      workInProgress._debugHookTypes = current._debugHookTypes;\n    }\n\n    workInProgress.alternate = current;\n    current.alternate = workInProgress;\n  } else {\n    workInProgress.pendingProps = pendingProps; // Needed because Blocks store data on type.\n\n    workInProgress.type = current.type; // We already have an alternate.\n    // Reset the effect tag.\n\n    workInProgress.flags = NoFlags; // The effect list is no longer valid.\n\n    workInProgress.nextEffect = null;\n    workInProgress.firstEffect = null;\n    workInProgress.lastEffect = null;\n\n    {\n      // We intentionally reset, rather than copy, actualDuration & actualStartTime.\n      // This prevents time from endlessly accumulating in new commits.\n      // This has the downside of resetting values for different priority renders,\n      // But works for yielding (the common case) and should support resuming.\n      workInProgress.actualDuration = 0;\n      workInProgress.actualStartTime = -1;\n    }\n  }\n\n  workInProgress.childLanes = current.childLanes;\n  workInProgress.lanes = current.lanes;\n  workInProgress.child = current.child;\n  workInProgress.memoizedProps = current.memoizedProps;\n  workInProgress.memoizedState = current.memoizedState;\n  workInProgress.updateQueue = current.updateQueue; // Clone the dependencies object. This is mutated during the render phase, so\n  // it cannot be shared with the current fiber.\n\n  var currentDependencies = current.dependencies;\n  workInProgress.dependencies = currentDependencies === null ? null : {\n    lanes: currentDependencies.lanes,\n    firstContext: currentDependencies.firstContext\n  }; // These will be overridden during the parent's reconciliation\n\n  workInProgress.sibling = current.sibling;\n  workInProgress.index = current.index;\n  workInProgress.ref = current.ref;\n\n  {\n    workInProgress.selfBaseDuration = current.selfBaseDuration;\n    workInProgress.treeBaseDuration = current.treeBaseDuration;\n  }\n\n  {\n    workInProgress._debugNeedsRemount = current._debugNeedsRemount;\n\n    switch (workInProgress.tag) {\n      case IndeterminateComponent:\n      case FunctionComponent:\n      case SimpleMemoComponent:\n        workInProgress.type = resolveFunctionForHotReloading(current.type);\n        break;\n\n      case ClassComponent:\n        workInProgress.type = resolveClassForHotReloading(current.type);\n        break;\n\n      case ForwardRef:\n        workInProgress.type = resolveForwardRefForHotReloading(current.type);\n        break;\n    }\n  }\n\n  return workInProgress;\n} // Used to reuse a Fiber for a second pass.\n\nfunction resetWorkInProgress(workInProgress, renderLanes) {\n  // This resets the Fiber to what createFiber or createWorkInProgress would\n  // have set the values to before during the first pass. Ideally this wouldn't\n  // be necessary but unfortunately many code paths reads from the workInProgress\n  // when they should be reading from current and writing to workInProgress.\n  // We assume pendingProps, index, key, ref, return are still untouched to\n  // avoid doing another reconciliation.\n  // Reset the effect tag but keep any Placement tags, since that's something\n  // that child fiber is setting, not the reconciliation.\n  workInProgress.flags &= Placement; // The effect list is no longer valid.\n\n  workInProgress.nextEffect = null;\n  workInProgress.firstEffect = null;\n  workInProgress.lastEffect = null;\n  var current = workInProgress.alternate;\n\n  if (current === null) {\n    // Reset to createFiber's initial values.\n    workInProgress.childLanes = NoLanes;\n    workInProgress.lanes = renderLanes;\n    workInProgress.child = null;\n    workInProgress.memoizedProps = null;\n    workInProgress.memoizedState = null;\n    workInProgress.updateQueue = null;\n    workInProgress.dependencies = null;\n    workInProgress.stateNode = null;\n\n    {\n      // Note: We don't reset the actualTime counts. It's useful to accumulate\n      // actual time across multiple render passes.\n      workInProgress.selfBaseDuration = 0;\n      workInProgress.treeBaseDuration = 0;\n    }\n  } else {\n    // Reset to the cloned values that createWorkInProgress would've.\n    workInProgress.childLanes = current.childLanes;\n    workInProgress.lanes = current.lanes;\n    workInProgress.child = current.child;\n    workInProgress.memoizedProps = current.memoizedProps;\n    workInProgress.memoizedState = current.memoizedState;\n    workInProgress.updateQueue = current.updateQueue; // Needed because Blocks store data on type.\n\n    workInProgress.type = current.type; // Clone the dependencies object. This is mutated during the render phase, so\n    // it cannot be shared with the current fiber.\n\n    var currentDependencies = current.dependencies;\n    workInProgress.dependencies = currentDependencies === null ? null : {\n      lanes: currentDependencies.lanes,\n      firstContext: currentDependencies.firstContext\n    };\n\n    {\n      // Note: We don't reset the actualTime counts. It's useful to accumulate\n      // actual time across multiple render passes.\n      workInProgress.selfBaseDuration = current.selfBaseDuration;\n      workInProgress.treeBaseDuration = current.treeBaseDuration;\n    }\n  }\n\n  return workInProgress;\n}\nfunction createHostRootFiber(tag) {\n  var mode;\n\n  if (tag === ConcurrentRoot) {\n    mode = ConcurrentMode | BlockingMode | StrictMode;\n  } else if (tag === BlockingRoot) {\n    mode = BlockingMode | StrictMode;\n  } else {\n    mode = NoMode;\n  }\n\n  if ( isDevToolsPresent) {\n    // Always collect profile timings when DevTools are present.\n    // This enables DevTools to start capturing timing at any point–\n    // Without some nodes in the tree having empty base times.\n    mode |= ProfileMode;\n  }\n\n  return createFiber(HostRoot, null, null, mode);\n}\nfunction createFiberFromTypeAndProps(type, // React$ElementType\nkey, pendingProps, owner, mode, lanes) {\n  var fiberTag = IndeterminateComponent; // The resolved type is set if we know what the final type will be. I.e. it's not lazy.\n\n  var resolvedType = type;\n\n  if (typeof type === 'function') {\n    if (shouldConstruct$1(type)) {\n      fiberTag = ClassComponent;\n\n      {\n        resolvedType = resolveClassForHotReloading(resolvedType);\n      }\n    } else {\n      {\n        resolvedType = resolveFunctionForHotReloading(resolvedType);\n      }\n    }\n  } else if (typeof type === 'string') {\n    fiberTag = HostComponent;\n  } else {\n    getTag: switch (type) {\n      case REACT_FRAGMENT_TYPE:\n        return createFiberFromFragment(pendingProps.children, mode, lanes, key);\n\n      case REACT_DEBUG_TRACING_MODE_TYPE:\n        fiberTag = Mode;\n        mode |= DebugTracingMode;\n        break;\n\n      case REACT_STRICT_MODE_TYPE:\n        fiberTag = Mode;\n        mode |= StrictMode;\n        break;\n\n      case REACT_PROFILER_TYPE:\n        return createFiberFromProfiler(pendingProps, mode, lanes, key);\n\n      case REACT_SUSPENSE_TYPE:\n        return createFiberFromSuspense(pendingProps, mode, lanes, key);\n\n      case REACT_SUSPENSE_LIST_TYPE:\n        return createFiberFromSuspenseList(pendingProps, mode, lanes, key);\n\n      case REACT_OFFSCREEN_TYPE:\n        return createFiberFromOffscreen(pendingProps, mode, lanes, key);\n\n      case REACT_LEGACY_HIDDEN_TYPE:\n        return createFiberFromLegacyHidden(pendingProps, mode, lanes, key);\n\n      case REACT_SCOPE_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      default:\n        {\n          if (typeof type === 'object' && type !== null) {\n            switch (type.$$typeof) {\n              case REACT_PROVIDER_TYPE:\n                fiberTag = ContextProvider;\n                break getTag;\n\n              case REACT_CONTEXT_TYPE:\n                // This is a consumer\n                fiberTag = ContextConsumer;\n                break getTag;\n\n              case REACT_FORWARD_REF_TYPE:\n                fiberTag = ForwardRef;\n\n                {\n                  resolvedType = resolveForwardRefForHotReloading(resolvedType);\n                }\n\n                break getTag;\n\n              case REACT_MEMO_TYPE:\n                fiberTag = MemoComponent;\n                break getTag;\n\n              case REACT_LAZY_TYPE:\n                fiberTag = LazyComponent;\n                resolvedType = null;\n                break getTag;\n\n              case REACT_BLOCK_TYPE:\n                fiberTag = Block;\n                break getTag;\n            }\n          }\n\n          var info = '';\n\n          {\n            if (type === undefined || typeof type === 'object' && type !== null && Object.keys(type).length === 0) {\n              info += ' You likely forgot to export your component from the file ' + \"it's defined in, or you might have mixed up default and \" + 'named imports.';\n            }\n\n            var ownerName = owner ? getComponentName(owner.type) : null;\n\n            if (ownerName) {\n              info += '\\n\\nCheck the render method of `' + ownerName + '`.';\n            }\n          }\n\n          {\n            {\n              throw Error( \"Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: \" + (type == null ? type : typeof type) + \".\" + info );\n            }\n          }\n        }\n    }\n  }\n\n  var fiber = createFiber(fiberTag, pendingProps, key, mode);\n  fiber.elementType = type;\n  fiber.type = resolvedType;\n  fiber.lanes = lanes;\n\n  {\n    fiber._debugOwner = owner;\n  }\n\n  return fiber;\n}\nfunction createFiberFromElement(element, mode, lanes) {\n  var owner = null;\n\n  {\n    owner = element._owner;\n  }\n\n  var type = element.type;\n  var key = element.key;\n  var pendingProps = element.props;\n  var fiber = createFiberFromTypeAndProps(type, key, pendingProps, owner, mode, lanes);\n\n  {\n    fiber._debugSource = element._source;\n    fiber._debugOwner = element._owner;\n  }\n\n  return fiber;\n}\nfunction createFiberFromFragment(elements, mode, lanes, key) {\n  var fiber = createFiber(Fragment, elements, key, mode);\n  fiber.lanes = lanes;\n  return fiber;\n}\n\nfunction createFiberFromProfiler(pendingProps, mode, lanes, key) {\n  {\n    if (typeof pendingProps.id !== 'string') {\n      error('Profiler must specify an \"id\" as a prop');\n    }\n  }\n\n  var fiber = createFiber(Profiler, pendingProps, key, mode | ProfileMode); // TODO: The Profiler fiber shouldn't have a type. It has a tag.\n\n  fiber.elementType = REACT_PROFILER_TYPE;\n  fiber.type = REACT_PROFILER_TYPE;\n  fiber.lanes = lanes;\n\n  {\n    fiber.stateNode = {\n      effectDuration: 0,\n      passiveEffectDuration: 0\n    };\n  }\n\n  return fiber;\n}\n\nfunction createFiberFromSuspense(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(SuspenseComponent, pendingProps, key, mode); // TODO: The SuspenseComponent fiber shouldn't have a type. It has a tag.\n  // This needs to be fixed in getComponentName so that it relies on the tag\n  // instead.\n\n  fiber.type = REACT_SUSPENSE_TYPE;\n  fiber.elementType = REACT_SUSPENSE_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromSuspenseList(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(SuspenseListComponent, pendingProps, key, mode);\n\n  {\n    // TODO: The SuspenseListComponent fiber shouldn't have a type. It has a tag.\n    // This needs to be fixed in getComponentName so that it relies on the tag\n    // instead.\n    fiber.type = REACT_SUSPENSE_LIST_TYPE;\n  }\n\n  fiber.elementType = REACT_SUSPENSE_LIST_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromOffscreen(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(OffscreenComponent, pendingProps, key, mode); // TODO: The OffscreenComponent fiber shouldn't have a type. It has a tag.\n  // This needs to be fixed in getComponentName so that it relies on the tag\n  // instead.\n\n  {\n    fiber.type = REACT_OFFSCREEN_TYPE;\n  }\n\n  fiber.elementType = REACT_OFFSCREEN_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromLegacyHidden(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(LegacyHiddenComponent, pendingProps, key, mode); // TODO: The LegacyHidden fiber shouldn't have a type. It has a tag.\n  // This needs to be fixed in getComponentName so that it relies on the tag\n  // instead.\n\n  {\n    fiber.type = REACT_LEGACY_HIDDEN_TYPE;\n  }\n\n  fiber.elementType = REACT_LEGACY_HIDDEN_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromText(content, mode, lanes) {\n  var fiber = createFiber(HostText, content, null, mode);\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromHostInstanceForDeletion() {\n  var fiber = createFiber(HostComponent, null, null, NoMode); // TODO: These should not need a type.\n\n  fiber.elementType = 'DELETED';\n  fiber.type = 'DELETED';\n  return fiber;\n}\nfunction createFiberFromPortal(portal, mode, lanes) {\n  var pendingProps = portal.children !== null ? portal.children : [];\n  var fiber = createFiber(HostPortal, pendingProps, portal.key, mode);\n  fiber.lanes = lanes;\n  fiber.stateNode = {\n    containerInfo: portal.containerInfo,\n    pendingChildren: null,\n    // Used by persistent updates\n    implementation: portal.implementation\n  };\n  return fiber;\n} // Used for stashing WIP properties to replay failed work in DEV.\n\nfunction assignFiberPropertiesInDEV(target, source) {\n  if (target === null) {\n    // This Fiber's initial properties will always be overwritten.\n    // We only use a Fiber to ensure the same hidden class so DEV isn't slow.\n    target = createFiber(IndeterminateComponent, null, null, NoMode);\n  } // This is intentionally written as a list of all properties.\n  // We tried to use Object.assign() instead but this is called in\n  // the hottest path, and Object.assign() was too slow:\n  // https://github.com/facebook/react/issues/12502\n  // This code is DEV-only so size is not a concern.\n\n\n  target.tag = source.tag;\n  target.key = source.key;\n  target.elementType = source.elementType;\n  target.type = source.type;\n  target.stateNode = source.stateNode;\n  target.return = source.return;\n  target.child = source.child;\n  target.sibling = source.sibling;\n  target.index = source.index;\n  target.ref = source.ref;\n  target.pendingProps = source.pendingProps;\n  target.memoizedProps = source.memoizedProps;\n  target.updateQueue = source.updateQueue;\n  target.memoizedState = source.memoizedState;\n  target.dependencies = source.dependencies;\n  target.mode = source.mode;\n  target.flags = source.flags;\n  target.nextEffect = source.nextEffect;\n  target.firstEffect = source.firstEffect;\n  target.lastEffect = source.lastEffect;\n  target.lanes = source.lanes;\n  target.childLanes = source.childLanes;\n  target.alternate = source.alternate;\n\n  {\n    target.actualDuration = source.actualDuration;\n    target.actualStartTime = source.actualStartTime;\n    target.selfBaseDuration = source.selfBaseDuration;\n    target.treeBaseDuration = source.treeBaseDuration;\n  }\n\n  target._debugID = source._debugID;\n  target._debugSource = source._debugSource;\n  target._debugOwner = source._debugOwner;\n  target._debugNeedsRemount = source._debugNeedsRemount;\n  target._debugHookTypes = source._debugHookTypes;\n  return target;\n}\n\nfunction FiberRootNode(containerInfo, tag, hydrate) {\n  this.tag = tag;\n  this.containerInfo = containerInfo;\n  this.pendingChildren = null;\n  this.current = null;\n  this.pingCache = null;\n  this.finishedWork = null;\n  this.timeoutHandle = noTimeout;\n  this.context = null;\n  this.pendingContext = null;\n  this.hydrate = hydrate;\n  this.callbackNode = null;\n  this.callbackPriority = NoLanePriority;\n  this.eventTimes = createLaneMap(NoLanes);\n  this.expirationTimes = createLaneMap(NoTimestamp);\n  this.pendingLanes = NoLanes;\n  this.suspendedLanes = NoLanes;\n  this.pingedLanes = NoLanes;\n  this.expiredLanes = NoLanes;\n  this.mutableReadLanes = NoLanes;\n  this.finishedLanes = NoLanes;\n  this.entangledLanes = NoLanes;\n  this.entanglements = createLaneMap(NoLanes);\n\n  {\n    this.mutableSourceEagerHydrationData = null;\n  }\n\n  {\n    this.interactionThreadID = tracing.unstable_getThreadID();\n    this.memoizedInteractions = new Set();\n    this.pendingInteractionMap = new Map();\n  }\n\n  {\n    switch (tag) {\n      case BlockingRoot:\n        this._debugRootType = 'createBlockingRoot()';\n        break;\n\n      case ConcurrentRoot:\n        this._debugRootType = 'createRoot()';\n        break;\n\n      case LegacyRoot:\n        this._debugRootType = 'createLegacyRoot()';\n        break;\n    }\n  }\n}\n\nfunction createFiberRoot(containerInfo, tag, hydrate, hydrationCallbacks) {\n  var root = new FiberRootNode(containerInfo, tag, hydrate);\n  // stateNode is any.\n\n\n  var uninitializedFiber = createHostRootFiber(tag);\n  root.current = uninitializedFiber;\n  uninitializedFiber.stateNode = root;\n  initializeUpdateQueue(uninitializedFiber);\n  return root;\n}\n\n// This ensures that the version used for server rendering matches the one\n// that is eventually read during hydration.\n// If they don't match there's a potential tear and a full deopt render is required.\n\nfunction registerMutableSourceForHydration(root, mutableSource) {\n  var getVersion = mutableSource._getVersion;\n  var version = getVersion(mutableSource._source); // TODO Clear this data once all pending hydration work is finished.\n  // Retaining it forever may interfere with GC.\n\n  if (root.mutableSourceEagerHydrationData == null) {\n    root.mutableSourceEagerHydrationData = [mutableSource, version];\n  } else {\n    root.mutableSourceEagerHydrationData.push(mutableSource, version);\n  }\n}\n\nfunction createPortal(children, containerInfo, // TODO: figure out the API for cross-renderer implementation.\nimplementation) {\n  var key = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n  return {\n    // This tag allow us to uniquely identify this as a React Portal\n    $$typeof: REACT_PORTAL_TYPE,\n    key: key == null ? null : '' + key,\n    children: children,\n    containerInfo: containerInfo,\n    implementation: implementation\n  };\n}\n\nvar didWarnAboutNestedUpdates;\nvar didWarnAboutFindNodeInStrictMode;\n\n{\n  didWarnAboutNestedUpdates = false;\n  didWarnAboutFindNodeInStrictMode = {};\n}\n\nfunction getContextForSubtree(parentComponent) {\n  if (!parentComponent) {\n    return emptyContextObject;\n  }\n\n  var fiber = get(parentComponent);\n  var parentContext = findCurrentUnmaskedContext(fiber);\n\n  if (fiber.tag === ClassComponent) {\n    var Component = fiber.type;\n\n    if (isContextProvider(Component)) {\n      return processChildContext(fiber, Component, parentContext);\n    }\n  }\n\n  return parentContext;\n}\n\nfunction findHostInstanceWithWarning(component, methodName) {\n  {\n    var fiber = get(component);\n\n    if (fiber === undefined) {\n      if (typeof component.render === 'function') {\n        {\n          {\n            throw Error( \"Unable to find node on an unmounted component.\" );\n          }\n        }\n      } else {\n        {\n          {\n            throw Error( \"Argument appears to not be a ReactComponent. Keys: \" + Object.keys(component) );\n          }\n        }\n      }\n    }\n\n    var hostFiber = findCurrentHostFiber(fiber);\n\n    if (hostFiber === null) {\n      return null;\n    }\n\n    if (hostFiber.mode & StrictMode) {\n      var componentName = getComponentName(fiber.type) || 'Component';\n\n      if (!didWarnAboutFindNodeInStrictMode[componentName]) {\n        didWarnAboutFindNodeInStrictMode[componentName] = true;\n        var previousFiber = current;\n\n        try {\n          setCurrentFiber(hostFiber);\n\n          if (fiber.mode & StrictMode) {\n            error('%s is deprecated in StrictMode. ' + '%s was passed an instance of %s which is inside StrictMode. ' + 'Instead, add a ref directly to the element you want to reference. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-find-node', methodName, methodName, componentName);\n          } else {\n            error('%s is deprecated in StrictMode. ' + '%s was passed an instance of %s which renders StrictMode children. ' + 'Instead, add a ref directly to the element you want to reference. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-find-node', methodName, methodName, componentName);\n          }\n        } finally {\n          // Ideally this should reset to previous but this shouldn't be called in\n          // render and there's another warning for that anyway.\n          if (previousFiber) {\n            setCurrentFiber(previousFiber);\n          } else {\n            resetCurrentFiber();\n          }\n        }\n      }\n    }\n\n    return hostFiber.stateNode;\n  }\n}\n\nfunction createContainer(containerInfo, tag, hydrate, hydrationCallbacks) {\n  return createFiberRoot(containerInfo, tag, hydrate);\n}\nfunction updateContainer(element, container, parentComponent, callback) {\n  {\n    onScheduleRoot(container, element);\n  }\n\n  var current$1 = container.current;\n  var eventTime = requestEventTime();\n\n  {\n    // $FlowExpectedError - jest isn't a global, and isn't recognized outside of tests\n    if ('undefined' !== typeof jest) {\n      warnIfUnmockedScheduler(current$1);\n      warnIfNotScopedWithMatchingAct(current$1);\n    }\n  }\n\n  var lane = requestUpdateLane(current$1);\n\n  var context = getContextForSubtree(parentComponent);\n\n  if (container.context === null) {\n    container.context = context;\n  } else {\n    container.pendingContext = context;\n  }\n\n  {\n    if (isRendering && current !== null && !didWarnAboutNestedUpdates) {\n      didWarnAboutNestedUpdates = true;\n\n      error('Render methods should be a pure function of props and state; ' + 'triggering nested component updates from render is not allowed. ' + 'If necessary, trigger nested updates in componentDidUpdate.\\n\\n' + 'Check the render method of %s.', getComponentName(current.type) || 'Unknown');\n    }\n  }\n\n  var update = createUpdate(eventTime, lane); // Caution: React DevTools currently depends on this property\n  // being called \"element\".\n\n  update.payload = {\n    element: element\n  };\n  callback = callback === undefined ? null : callback;\n\n  if (callback !== null) {\n    {\n      if (typeof callback !== 'function') {\n        error('render(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callback);\n      }\n    }\n\n    update.callback = callback;\n  }\n\n  enqueueUpdate(current$1, update);\n  scheduleUpdateOnFiber(current$1, lane, eventTime);\n  return lane;\n}\nfunction getPublicRootInstance(container) {\n  var containerFiber = container.current;\n\n  if (!containerFiber.child) {\n    return null;\n  }\n\n  switch (containerFiber.child.tag) {\n    case HostComponent:\n      return getPublicInstance(containerFiber.child.stateNode);\n\n    default:\n      return containerFiber.child.stateNode;\n  }\n}\n\nfunction markRetryLaneImpl(fiber, retryLane) {\n  var suspenseState = fiber.memoizedState;\n\n  if (suspenseState !== null && suspenseState.dehydrated !== null) {\n    suspenseState.retryLane = higherPriorityLane(suspenseState.retryLane, retryLane);\n  }\n} // Increases the priority of thennables when they resolve within this boundary.\n\n\nfunction markRetryLaneIfNotHydrated(fiber, retryLane) {\n  markRetryLaneImpl(fiber, retryLane);\n  var alternate = fiber.alternate;\n\n  if (alternate) {\n    markRetryLaneImpl(alternate, retryLane);\n  }\n}\n\nfunction attemptUserBlockingHydration$1(fiber) {\n  if (fiber.tag !== SuspenseComponent) {\n    // We ignore HostRoots here because we can't increase\n    // their priority and they should not suspend on I/O,\n    // since you have to wrap anything that might suspend in\n    // Suspense.\n    return;\n  }\n\n  var eventTime = requestEventTime();\n  var lane = InputDiscreteHydrationLane;\n  scheduleUpdateOnFiber(fiber, lane, eventTime);\n  markRetryLaneIfNotHydrated(fiber, lane);\n}\nfunction attemptContinuousHydration$1(fiber) {\n  if (fiber.tag !== SuspenseComponent) {\n    // We ignore HostRoots here because we can't increase\n    // their priority and they should not suspend on I/O,\n    // since you have to wrap anything that might suspend in\n    // Suspense.\n    return;\n  }\n\n  var eventTime = requestEventTime();\n  var lane = SelectiveHydrationLane;\n  scheduleUpdateOnFiber(fiber, lane, eventTime);\n  markRetryLaneIfNotHydrated(fiber, lane);\n}\nfunction attemptHydrationAtCurrentPriority$1(fiber) {\n  if (fiber.tag !== SuspenseComponent) {\n    // We ignore HostRoots here because we can't increase\n    // their priority other than synchronously flush it.\n    return;\n  }\n\n  var eventTime = requestEventTime();\n  var lane = requestUpdateLane(fiber);\n  scheduleUpdateOnFiber(fiber, lane, eventTime);\n  markRetryLaneIfNotHydrated(fiber, lane);\n}\nfunction runWithPriority$2(priority, fn) {\n\n  try {\n    setCurrentUpdateLanePriority(priority);\n    return fn();\n  } finally {\n  }\n}\nfunction findHostInstanceWithNoPortals(fiber) {\n  var hostFiber = findCurrentHostFiberWithNoPortals(fiber);\n\n  if (hostFiber === null) {\n    return null;\n  }\n\n  if (hostFiber.tag === FundamentalComponent) {\n    return hostFiber.stateNode.instance;\n  }\n\n  return hostFiber.stateNode;\n}\n\nvar shouldSuspendImpl = function (fiber) {\n  return false;\n};\n\nfunction shouldSuspend(fiber) {\n  return shouldSuspendImpl(fiber);\n}\nvar overrideHookState = null;\nvar overrideHookStateDeletePath = null;\nvar overrideHookStateRenamePath = null;\nvar overrideProps = null;\nvar overridePropsDeletePath = null;\nvar overridePropsRenamePath = null;\nvar scheduleUpdate = null;\nvar setSuspenseHandler = null;\n\n{\n  var copyWithDeleteImpl = function (obj, path, index) {\n    var key = path[index];\n    var updated = Array.isArray(obj) ? obj.slice() : _assign({}, obj);\n\n    if (index + 1 === path.length) {\n      if (Array.isArray(updated)) {\n        updated.splice(key, 1);\n      } else {\n        delete updated[key];\n      }\n\n      return updated;\n    } // $FlowFixMe number or string is fine here\n\n\n    updated[key] = copyWithDeleteImpl(obj[key], path, index + 1);\n    return updated;\n  };\n\n  var copyWithDelete = function (obj, path) {\n    return copyWithDeleteImpl(obj, path, 0);\n  };\n\n  var copyWithRenameImpl = function (obj, oldPath, newPath, index) {\n    var oldKey = oldPath[index];\n    var updated = Array.isArray(obj) ? obj.slice() : _assign({}, obj);\n\n    if (index + 1 === oldPath.length) {\n      var newKey = newPath[index]; // $FlowFixMe number or string is fine here\n\n      updated[newKey] = updated[oldKey];\n\n      if (Array.isArray(updated)) {\n        updated.splice(oldKey, 1);\n      } else {\n        delete updated[oldKey];\n      }\n    } else {\n      // $FlowFixMe number or string is fine here\n      updated[oldKey] = copyWithRenameImpl( // $FlowFixMe number or string is fine here\n      obj[oldKey], oldPath, newPath, index + 1);\n    }\n\n    return updated;\n  };\n\n  var copyWithRename = function (obj, oldPath, newPath) {\n    if (oldPath.length !== newPath.length) {\n      warn('copyWithRename() expects paths of the same length');\n\n      return;\n    } else {\n      for (var i = 0; i < newPath.length - 1; i++) {\n        if (oldPath[i] !== newPath[i]) {\n          warn('copyWithRename() expects paths to be the same except for the deepest key');\n\n          return;\n        }\n      }\n    }\n\n    return copyWithRenameImpl(obj, oldPath, newPath, 0);\n  };\n\n  var copyWithSetImpl = function (obj, path, index, value) {\n    if (index >= path.length) {\n      return value;\n    }\n\n    var key = path[index];\n    var updated = Array.isArray(obj) ? obj.slice() : _assign({}, obj); // $FlowFixMe number or string is fine here\n\n    updated[key] = copyWithSetImpl(obj[key], path, index + 1, value);\n    return updated;\n  };\n\n  var copyWithSet = function (obj, path, value) {\n    return copyWithSetImpl(obj, path, 0, value);\n  };\n\n  var findHook = function (fiber, id) {\n    // For now, the \"id\" of stateful hooks is just the stateful hook index.\n    // This may change in the future with e.g. nested hooks.\n    var currentHook = fiber.memoizedState;\n\n    while (currentHook !== null && id > 0) {\n      currentHook = currentHook.next;\n      id--;\n    }\n\n    return currentHook;\n  }; // Support DevTools editable values for useState and useReducer.\n\n\n  overrideHookState = function (fiber, id, path, value) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithSet(hook.memoizedState, path, value);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = _assign({}, fiber.memoizedProps);\n      scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  overrideHookStateDeletePath = function (fiber, id, path) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithDelete(hook.memoizedState, path);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = _assign({}, fiber.memoizedProps);\n      scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  overrideHookStateRenamePath = function (fiber, id, oldPath, newPath) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithRename(hook.memoizedState, oldPath, newPath);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = _assign({}, fiber.memoizedProps);\n      scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n    }\n  }; // Support DevTools props for function components, forwardRef, memo, host components, etc.\n\n\n  overrideProps = function (fiber, path, value) {\n    fiber.pendingProps = copyWithSet(fiber.memoizedProps, path, value);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n  };\n\n  overridePropsDeletePath = function (fiber, path) {\n    fiber.pendingProps = copyWithDelete(fiber.memoizedProps, path);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n  };\n\n  overridePropsRenamePath = function (fiber, oldPath, newPath) {\n    fiber.pendingProps = copyWithRename(fiber.memoizedProps, oldPath, newPath);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n  };\n\n  scheduleUpdate = function (fiber) {\n    scheduleUpdateOnFiber(fiber, SyncLane, NoTimestamp);\n  };\n\n  setSuspenseHandler = function (newShouldSuspendImpl) {\n    shouldSuspendImpl = newShouldSuspendImpl;\n  };\n}\n\nfunction findHostInstanceByFiber(fiber) {\n  var hostFiber = findCurrentHostFiber(fiber);\n\n  if (hostFiber === null) {\n    return null;\n  }\n\n  return hostFiber.stateNode;\n}\n\nfunction emptyFindFiberByHostInstance(instance) {\n  return null;\n}\n\nfunction getCurrentFiberForDevTools() {\n  return current;\n}\n\nfunction injectIntoDevTools(devToolsConfig) {\n  var findFiberByHostInstance = devToolsConfig.findFiberByHostInstance;\n  var ReactCurrentDispatcher = ReactSharedInternals.ReactCurrentDispatcher;\n  return injectInternals({\n    bundleType: devToolsConfig.bundleType,\n    version: devToolsConfig.version,\n    rendererPackageName: devToolsConfig.rendererPackageName,\n    rendererConfig: devToolsConfig.rendererConfig,\n    overrideHookState: overrideHookState,\n    overrideHookStateDeletePath: overrideHookStateDeletePath,\n    overrideHookStateRenamePath: overrideHookStateRenamePath,\n    overrideProps: overrideProps,\n    overridePropsDeletePath: overridePropsDeletePath,\n    overridePropsRenamePath: overridePropsRenamePath,\n    setSuspenseHandler: setSuspenseHandler,\n    scheduleUpdate: scheduleUpdate,\n    currentDispatcherRef: ReactCurrentDispatcher,\n    findHostInstanceByFiber: findHostInstanceByFiber,\n    findFiberByHostInstance: findFiberByHostInstance || emptyFindFiberByHostInstance,\n    // React Refresh\n    findHostInstancesForRefresh:  findHostInstancesForRefresh ,\n    scheduleRefresh:  scheduleRefresh ,\n    scheduleRoot:  scheduleRoot ,\n    setRefreshHandler:  setRefreshHandler ,\n    // Enables DevTools to append owner stacks to error messages in DEV mode.\n    getCurrentFiber:  getCurrentFiberForDevTools \n  });\n}\n\nfunction ReactDOMRoot(container, options) {\n  this._internalRoot = createRootImpl(container, ConcurrentRoot, options);\n}\n\nfunction ReactDOMBlockingRoot(container, tag, options) {\n  this._internalRoot = createRootImpl(container, tag, options);\n}\n\nReactDOMRoot.prototype.render = ReactDOMBlockingRoot.prototype.render = function (children) {\n  var root = this._internalRoot;\n\n  {\n    if (typeof arguments[1] === 'function') {\n      error('render(...): does not support the second callback argument. ' + 'To execute a side effect after rendering, declare it in a component body with useEffect().');\n    }\n\n    var container = root.containerInfo;\n\n    if (container.nodeType !== COMMENT_NODE) {\n      var hostInstance = findHostInstanceWithNoPortals(root.current);\n\n      if (hostInstance) {\n        if (hostInstance.parentNode !== container) {\n          error('render(...): It looks like the React-rendered content of the ' + 'root container was removed without using React. This is not ' + 'supported and will cause errors. Instead, call ' + \"root.unmount() to empty a root's container.\");\n        }\n      }\n    }\n  }\n\n  updateContainer(children, root, null, null);\n};\n\nReactDOMRoot.prototype.unmount = ReactDOMBlockingRoot.prototype.unmount = function () {\n  {\n    if (typeof arguments[0] === 'function') {\n      error('unmount(...): does not support a callback argument. ' + 'To execute a side effect after rendering, declare it in a component body with useEffect().');\n    }\n  }\n\n  var root = this._internalRoot;\n  var container = root.containerInfo;\n  updateContainer(null, root, null, function () {\n    unmarkContainerAsRoot(container);\n  });\n};\n\nfunction createRootImpl(container, tag, options) {\n  // Tag is either LegacyRoot or Concurrent Root\n  var hydrate = options != null && options.hydrate === true;\n  var hydrationCallbacks = options != null && options.hydrationOptions || null;\n  var mutableSources = options != null && options.hydrationOptions != null && options.hydrationOptions.mutableSources || null;\n  var root = createContainer(container, tag, hydrate);\n  markContainerAsRoot(root.current, container);\n  var containerNodeType = container.nodeType;\n\n  {\n    var rootContainerElement = container.nodeType === COMMENT_NODE ? container.parentNode : container;\n    listenToAllSupportedEvents(rootContainerElement);\n  }\n\n  if (mutableSources) {\n    for (var i = 0; i < mutableSources.length; i++) {\n      var mutableSource = mutableSources[i];\n      registerMutableSourceForHydration(root, mutableSource);\n    }\n  }\n\n  return root;\n}\nfunction createLegacyRoot(container, options) {\n  return new ReactDOMBlockingRoot(container, LegacyRoot, options);\n}\nfunction isValidContainer(node) {\n  return !!(node && (node.nodeType === ELEMENT_NODE || node.nodeType === DOCUMENT_NODE || node.nodeType === DOCUMENT_FRAGMENT_NODE || node.nodeType === COMMENT_NODE && node.nodeValue === ' react-mount-point-unstable '));\n}\n\nvar ReactCurrentOwner$3 = ReactSharedInternals.ReactCurrentOwner;\nvar topLevelUpdateWarnings;\nvar warnedAboutHydrateAPI = false;\n\n{\n  topLevelUpdateWarnings = function (container) {\n    if (container._reactRootContainer && container.nodeType !== COMMENT_NODE) {\n      var hostInstance = findHostInstanceWithNoPortals(container._reactRootContainer._internalRoot.current);\n\n      if (hostInstance) {\n        if (hostInstance.parentNode !== container) {\n          error('render(...): It looks like the React-rendered content of this ' + 'container was removed without using React. This is not ' + 'supported and will cause errors. Instead, call ' + 'ReactDOM.unmountComponentAtNode to empty a container.');\n        }\n      }\n    }\n\n    var isRootRenderedBySomeReact = !!container._reactRootContainer;\n    var rootEl = getReactRootElementInContainer(container);\n    var hasNonRootReactChild = !!(rootEl && getInstanceFromNode(rootEl));\n\n    if (hasNonRootReactChild && !isRootRenderedBySomeReact) {\n      error('render(...): Replacing React-rendered children with a new root ' + 'component. If you intended to update the children of this node, ' + 'you should instead have the existing children update their state ' + 'and render the new components instead of calling ReactDOM.render.');\n    }\n\n    if (container.nodeType === ELEMENT_NODE && container.tagName && container.tagName.toUpperCase() === 'BODY') {\n      error('render(): Rendering components directly into document.body is ' + 'discouraged, since its children are often manipulated by third-party ' + 'scripts and browser extensions. This may lead to subtle ' + 'reconciliation issues. Try rendering into a container element created ' + 'for your app.');\n    }\n  };\n}\n\nfunction getReactRootElementInContainer(container) {\n  if (!container) {\n    return null;\n  }\n\n  if (container.nodeType === DOCUMENT_NODE) {\n    return container.documentElement;\n  } else {\n    return container.firstChild;\n  }\n}\n\nfunction shouldHydrateDueToLegacyHeuristic(container) {\n  var rootElement = getReactRootElementInContainer(container);\n  return !!(rootElement && rootElement.nodeType === ELEMENT_NODE && rootElement.hasAttribute(ROOT_ATTRIBUTE_NAME));\n}\n\nfunction legacyCreateRootFromDOMContainer(container, forceHydrate) {\n  var shouldHydrate = forceHydrate || shouldHydrateDueToLegacyHeuristic(container); // First clear any existing content.\n\n  if (!shouldHydrate) {\n    var warned = false;\n    var rootSibling;\n\n    while (rootSibling = container.lastChild) {\n      {\n        if (!warned && rootSibling.nodeType === ELEMENT_NODE && rootSibling.hasAttribute(ROOT_ATTRIBUTE_NAME)) {\n          warned = true;\n\n          error('render(): Target node has markup rendered by React, but there ' + 'are unrelated nodes as well. This is most commonly caused by ' + 'white-space inserted around server-rendered markup.');\n        }\n      }\n\n      container.removeChild(rootSibling);\n    }\n  }\n\n  {\n    if (shouldHydrate && !forceHydrate && !warnedAboutHydrateAPI) {\n      warnedAboutHydrateAPI = true;\n\n      warn('render(): Calling ReactDOM.render() to hydrate server-rendered markup ' + 'will stop working in React v18. Replace the ReactDOM.render() call ' + 'with ReactDOM.hydrate() if you want React to attach to the server HTML.');\n    }\n  }\n\n  return createLegacyRoot(container, shouldHydrate ? {\n    hydrate: true\n  } : undefined);\n}\n\nfunction warnOnInvalidCallback$1(callback, callerName) {\n  {\n    if (callback !== null && typeof callback !== 'function') {\n      error('%s(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callerName, callback);\n    }\n  }\n}\n\nfunction legacyRenderSubtreeIntoContainer(parentComponent, children, container, forceHydrate, callback) {\n  {\n    topLevelUpdateWarnings(container);\n    warnOnInvalidCallback$1(callback === undefined ? null : callback, 'render');\n  } // TODO: Without `any` type, Flow says \"Property cannot be accessed on any\n  // member of intersection type.\" Whyyyyyy.\n\n\n  var root = container._reactRootContainer;\n  var fiberRoot;\n\n  if (!root) {\n    // Initial mount\n    root = container._reactRootContainer = legacyCreateRootFromDOMContainer(container, forceHydrate);\n    fiberRoot = root._internalRoot;\n\n    if (typeof callback === 'function') {\n      var originalCallback = callback;\n\n      callback = function () {\n        var instance = getPublicRootInstance(fiberRoot);\n        originalCallback.call(instance);\n      };\n    } // Initial mount should not be batched.\n\n\n    unbatchedUpdates(function () {\n      updateContainer(children, fiberRoot, parentComponent, callback);\n    });\n  } else {\n    fiberRoot = root._internalRoot;\n\n    if (typeof callback === 'function') {\n      var _originalCallback = callback;\n\n      callback = function () {\n        var instance = getPublicRootInstance(fiberRoot);\n\n        _originalCallback.call(instance);\n      };\n    } // Update\n\n\n    updateContainer(children, fiberRoot, parentComponent, callback);\n  }\n\n  return getPublicRootInstance(fiberRoot);\n}\n\nfunction findDOMNode(componentOrElement) {\n  {\n    var owner = ReactCurrentOwner$3.current;\n\n    if (owner !== null && owner.stateNode !== null) {\n      var warnedAboutRefsInRender = owner.stateNode._warnedAboutRefsInRender;\n\n      if (!warnedAboutRefsInRender) {\n        error('%s is accessing findDOMNode inside its render(). ' + 'render() should be a pure function of props and state. It should ' + 'never access something that requires stale data from the previous ' + 'render, such as refs. Move this logic to componentDidMount and ' + 'componentDidUpdate instead.', getComponentName(owner.type) || 'A component');\n      }\n\n      owner.stateNode._warnedAboutRefsInRender = true;\n    }\n  }\n\n  if (componentOrElement == null) {\n    return null;\n  }\n\n  if (componentOrElement.nodeType === ELEMENT_NODE) {\n    return componentOrElement;\n  }\n\n  {\n    return findHostInstanceWithWarning(componentOrElement, 'findDOMNode');\n  }\n}\nfunction hydrate(element, container, callback) {\n  if (!isValidContainer(container)) {\n    {\n      throw Error( \"Target container is not a DOM element.\" );\n    }\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.hydrate() on a container that was previously ' + 'passed to ReactDOM.createRoot(). This is not supported. ' + 'Did you mean to call createRoot(container, {hydrate: true}).render(element)?');\n    }\n  } // TODO: throw or warn if we couldn't hydrate?\n\n\n  return legacyRenderSubtreeIntoContainer(null, element, container, true, callback);\n}\nfunction render(element, container, callback) {\n  if (!isValidContainer(container)) {\n    {\n      throw Error( \"Target container is not a DOM element.\" );\n    }\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.render() on a container that was previously ' + 'passed to ReactDOM.createRoot(). This is not supported. ' + 'Did you mean to call root.render(element)?');\n    }\n  }\n\n  return legacyRenderSubtreeIntoContainer(null, element, container, false, callback);\n}\nfunction unstable_renderSubtreeIntoContainer(parentComponent, element, containerNode, callback) {\n  if (!isValidContainer(containerNode)) {\n    {\n      throw Error( \"Target container is not a DOM element.\" );\n    }\n  }\n\n  if (!(parentComponent != null && has(parentComponent))) {\n    {\n      throw Error( \"parentComponent must be a valid React Component\" );\n    }\n  }\n\n  return legacyRenderSubtreeIntoContainer(parentComponent, element, containerNode, false, callback);\n}\nfunction unmountComponentAtNode(container) {\n  if (!isValidContainer(container)) {\n    {\n      throw Error( \"unmountComponentAtNode(...): Target container is not a DOM element.\" );\n    }\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.unmountComponentAtNode() on a container that was previously ' + 'passed to ReactDOM.createRoot(). This is not supported. Did you mean to call root.unmount()?');\n    }\n  }\n\n  if (container._reactRootContainer) {\n    {\n      var rootEl = getReactRootElementInContainer(container);\n      var renderedByDifferentReact = rootEl && !getInstanceFromNode(rootEl);\n\n      if (renderedByDifferentReact) {\n        error(\"unmountComponentAtNode(): The node you're attempting to unmount \" + 'was rendered by another copy of React.');\n      }\n    } // Unmount should not be batched.\n\n\n    unbatchedUpdates(function () {\n      legacyRenderSubtreeIntoContainer(null, null, container, false, function () {\n        // $FlowFixMe This should probably use `delete container._reactRootContainer`\n        container._reactRootContainer = null;\n        unmarkContainerAsRoot(container);\n      });\n    }); // If you call unmountComponentAtNode twice in quick succession, you'll\n    // get `true` twice. That's probably fine?\n\n    return true;\n  } else {\n    {\n      var _rootEl = getReactRootElementInContainer(container);\n\n      var hasNonRootReactChild = !!(_rootEl && getInstanceFromNode(_rootEl)); // Check if the container itself is a React root node.\n\n      var isContainerReactRoot = container.nodeType === ELEMENT_NODE && isValidContainer(container.parentNode) && !!container.parentNode._reactRootContainer;\n\n      if (hasNonRootReactChild) {\n        error(\"unmountComponentAtNode(): The node you're attempting to unmount \" + 'was rendered by React and is not a top-level container. %s', isContainerReactRoot ? 'You may have accidentally passed in a React root node instead ' + 'of its container.' : 'Instead, have the parent component update its state and ' + 'rerender in order to remove this component.');\n      }\n    }\n\n    return false;\n  }\n}\n\nsetAttemptUserBlockingHydration(attemptUserBlockingHydration$1);\nsetAttemptContinuousHydration(attemptContinuousHydration$1);\nsetAttemptHydrationAtCurrentPriority(attemptHydrationAtCurrentPriority$1);\nsetAttemptHydrationAtPriority(runWithPriority$2);\nvar didWarnAboutUnstableCreatePortal = false;\n\n{\n  if (typeof Map !== 'function' || // $FlowIssue Flow incorrectly thinks Map has no prototype\n  Map.prototype == null || typeof Map.prototype.forEach !== 'function' || typeof Set !== 'function' || // $FlowIssue Flow incorrectly thinks Set has no prototype\n  Set.prototype == null || typeof Set.prototype.clear !== 'function' || typeof Set.prototype.forEach !== 'function') {\n    error('React depends on Map and Set built-in types. Make sure that you load a ' + 'polyfill in older browsers. https://reactjs.org/link/react-polyfills');\n  }\n}\n\nsetRestoreImplementation(restoreControlledState$3);\nsetBatchingImplementation(batchedUpdates$1, discreteUpdates$1, flushDiscreteUpdates, batchedEventUpdates$1);\n\nfunction createPortal$1(children, container) {\n  var key = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n  if (!isValidContainer(container)) {\n    {\n      throw Error( \"Target container is not a DOM element.\" );\n    }\n  } // TODO: pass ReactDOM portal implementation as third argument\n  // $FlowFixMe The Flow type is opaque but there's no way to actually create it.\n\n\n  return createPortal(children, container, null, key);\n}\n\nfunction renderSubtreeIntoContainer(parentComponent, element, containerNode, callback) {\n\n  return unstable_renderSubtreeIntoContainer(parentComponent, element, containerNode, callback);\n}\n\nfunction unstable_createPortal(children, container) {\n  var key = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n  {\n    if (!didWarnAboutUnstableCreatePortal) {\n      didWarnAboutUnstableCreatePortal = true;\n\n      warn('The ReactDOM.unstable_createPortal() alias has been deprecated, ' + 'and will be removed in React 18+. Update your code to use ' + 'ReactDOM.createPortal() instead. It has the exact same API, ' + 'but without the \"unstable_\" prefix.');\n    }\n  }\n\n  return createPortal$1(children, container, key);\n}\n\nvar Internals = {\n  // Keep in sync with ReactTestUtils.js, and ReactTestUtilsAct.js.\n  // This is an array for better minification.\n  Events: [getInstanceFromNode, getNodeFromInstance, getFiberCurrentPropsFromNode, enqueueStateRestore, restoreStateIfNeeded, flushPassiveEffects, // TODO: This is related to `act`, not events. Move to separate key?\n  IsThisRendererActing]\n};\nvar foundDevTools = injectIntoDevTools({\n  findFiberByHostInstance: getClosestInstanceFromNode,\n  bundleType:  1 ,\n  version: ReactVersion,\n  rendererPackageName: 'react-dom'\n});\n\n{\n  if (!foundDevTools && canUseDOM && window.top === window.self) {\n    // If we're in Chrome or Firefox, provide a download link if not installed.\n    if (navigator.userAgent.indexOf('Chrome') > -1 && navigator.userAgent.indexOf('Edge') === -1 || navigator.userAgent.indexOf('Firefox') > -1) {\n      var protocol = window.location.protocol; // Don't warn in exotic cases like chrome-extension://.\n\n      if (/^(https?|file):$/.test(protocol)) {\n        // eslint-disable-next-line react-internal/no-production-logging\n        console.info('%cDownload the React DevTools ' + 'for a better development experience: ' + 'https://reactjs.org/link/react-devtools' + (protocol === 'file:' ? '\\nYou might need to use a local HTTP server (instead of file://): ' + 'https://reactjs.org/link/react-devtools-faq' : ''), 'font-weight:bold');\n      }\n    }\n  }\n}\n\nexports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED = Internals;\nexports.createPortal = createPortal$1;\nexports.findDOMNode = findDOMNode;\nexports.flushSync = flushSync;\nexports.hydrate = hydrate;\nexports.render = render;\nexports.unmountComponentAtNode = unmountComponentAtNode;\nexports.unstable_batchedUpdates = batchedUpdates$1;\nexports.unstable_createPortal = unstable_createPortal;\nexports.unstable_renderSubtreeIntoContainer = renderSubtreeIntoContainer;\nexports.version = ReactVersion;\n  })();\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/react-dom/cjs/react-dom.development.js?");

/***/ }),

/***/ "./node_modules/react-dom/index.js":
/*!*****************************************!*\
  !*** ./node_modules/react-dom/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction checkDCE() {\n  /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\n  if (\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ === 'undefined' ||\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE !== 'function'\n  ) {\n    return;\n  }\n  if (true) {\n    // This branch is unreachable because this function is only called\n    // in production, but the condition is true only in development.\n    // Therefore if the branch is still here, dead code elimination wasn't\n    // properly applied.\n    // Don't change the message. React DevTools relies on it. Also make sure\n    // this message doesn't occur elsewhere in this function, or it will cause\n    // a false positive.\n    throw new Error('^_^');\n  }\n  try {\n    // Verify that the code above has been dead code eliminated (DCE'd).\n    __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(checkDCE);\n  } catch (err) {\n    // DevTools shouldn't crash React, no matter what.\n    // We should still report in case we break this code.\n    console.error(err);\n  }\n}\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/react-dom.development.js */ \"./node_modules/react-dom/cjs/react-dom.development.js\");\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/react-dom/index.js?");

/***/ }),

/***/ "./node_modules/react/cjs/react.development.js":
/*!*****************************************************!*\
  !*** ./node_modules/react/cjs/react.development.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/** @license React v17.0.2\n * react.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nvar _assign = __webpack_require__(/*! object-assign */ \"./node_modules/object-assign/index.js\");\n\n// TODO: this is special because it gets imported during build.\nvar ReactVersion = '17.0.2';\n\n// ATTENTION\n// When adding new symbols to this file,\n// Please consider also adding to 'react-devtools-shared/src/backend/ReactSymbols'\n// The Symbol used to tag the ReactElement-like types. If there is no native Symbol\n// nor polyfill, then a plain number is used for performance.\nvar REACT_ELEMENT_TYPE = 0xeac7;\nvar REACT_PORTAL_TYPE = 0xeaca;\nexports.Fragment = 0xeacb;\nexports.StrictMode = 0xeacc;\nexports.Profiler = 0xead2;\nvar REACT_PROVIDER_TYPE = 0xeacd;\nvar REACT_CONTEXT_TYPE = 0xeace;\nvar REACT_FORWARD_REF_TYPE = 0xead0;\nexports.Suspense = 0xead1;\nvar REACT_SUSPENSE_LIST_TYPE = 0xead8;\nvar REACT_MEMO_TYPE = 0xead3;\nvar REACT_LAZY_TYPE = 0xead4;\nvar REACT_BLOCK_TYPE = 0xead9;\nvar REACT_SERVER_BLOCK_TYPE = 0xeada;\nvar REACT_FUNDAMENTAL_TYPE = 0xead5;\nvar REACT_SCOPE_TYPE = 0xead7;\nvar REACT_OPAQUE_ID_TYPE = 0xeae0;\nvar REACT_DEBUG_TRACING_MODE_TYPE = 0xeae1;\nvar REACT_OFFSCREEN_TYPE = 0xeae2;\nvar REACT_LEGACY_HIDDEN_TYPE = 0xeae3;\n\nif (typeof Symbol === 'function' && Symbol.for) {\n  var symbolFor = Symbol.for;\n  REACT_ELEMENT_TYPE = symbolFor('react.element');\n  REACT_PORTAL_TYPE = symbolFor('react.portal');\n  exports.Fragment = symbolFor('react.fragment');\n  exports.StrictMode = symbolFor('react.strict_mode');\n  exports.Profiler = symbolFor('react.profiler');\n  REACT_PROVIDER_TYPE = symbolFor('react.provider');\n  REACT_CONTEXT_TYPE = symbolFor('react.context');\n  REACT_FORWARD_REF_TYPE = symbolFor('react.forward_ref');\n  exports.Suspense = symbolFor('react.suspense');\n  REACT_SUSPENSE_LIST_TYPE = symbolFor('react.suspense_list');\n  REACT_MEMO_TYPE = symbolFor('react.memo');\n  REACT_LAZY_TYPE = symbolFor('react.lazy');\n  REACT_BLOCK_TYPE = symbolFor('react.block');\n  REACT_SERVER_BLOCK_TYPE = symbolFor('react.server.block');\n  REACT_FUNDAMENTAL_TYPE = symbolFor('react.fundamental');\n  REACT_SCOPE_TYPE = symbolFor('react.scope');\n  REACT_OPAQUE_ID_TYPE = symbolFor('react.opaque.id');\n  REACT_DEBUG_TRACING_MODE_TYPE = symbolFor('react.debug_trace_mode');\n  REACT_OFFSCREEN_TYPE = symbolFor('react.offscreen');\n  REACT_LEGACY_HIDDEN_TYPE = symbolFor('react.legacy_hidden');\n}\n\nvar MAYBE_ITERATOR_SYMBOL = typeof Symbol === 'function' && Symbol.iterator;\nvar FAUX_ITERATOR_SYMBOL = '@@iterator';\nfunction getIteratorFn(maybeIterable) {\n  if (maybeIterable === null || typeof maybeIterable !== 'object') {\n    return null;\n  }\n\n  var maybeIterator = MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL] || maybeIterable[FAUX_ITERATOR_SYMBOL];\n\n  if (typeof maybeIterator === 'function') {\n    return maybeIterator;\n  }\n\n  return null;\n}\n\n/**\n * Keeps track of the current dispatcher.\n */\nvar ReactCurrentDispatcher = {\n  /**\n   * @internal\n   * @type {ReactComponent}\n   */\n  current: null\n};\n\n/**\n * Keeps track of the current batch's configuration such as how long an update\n * should suspend for if it needs to.\n */\nvar ReactCurrentBatchConfig = {\n  transition: 0\n};\n\n/**\n * Keeps track of the current owner.\n *\n * The current owner is the component who should own any components that are\n * currently being constructed.\n */\nvar ReactCurrentOwner = {\n  /**\n   * @internal\n   * @type {ReactComponent}\n   */\n  current: null\n};\n\nvar ReactDebugCurrentFrame = {};\nvar currentExtraStackFrame = null;\nfunction setExtraStackFrame(stack) {\n  {\n    currentExtraStackFrame = stack;\n  }\n}\n\n{\n  ReactDebugCurrentFrame.setExtraStackFrame = function (stack) {\n    {\n      currentExtraStackFrame = stack;\n    }\n  }; // Stack implementation injected by the current renderer.\n\n\n  ReactDebugCurrentFrame.getCurrentStack = null;\n\n  ReactDebugCurrentFrame.getStackAddendum = function () {\n    var stack = ''; // Add an extra top frame while an element is being validated\n\n    if (currentExtraStackFrame) {\n      stack += currentExtraStackFrame;\n    } // Delegate to the injected renderer-specific implementation\n\n\n    var impl = ReactDebugCurrentFrame.getCurrentStack;\n\n    if (impl) {\n      stack += impl() || '';\n    }\n\n    return stack;\n  };\n}\n\n/**\n * Used by act() to track whether you're inside an act() scope.\n */\nvar IsSomeRendererActing = {\n  current: false\n};\n\nvar ReactSharedInternals = {\n  ReactCurrentDispatcher: ReactCurrentDispatcher,\n  ReactCurrentBatchConfig: ReactCurrentBatchConfig,\n  ReactCurrentOwner: ReactCurrentOwner,\n  IsSomeRendererActing: IsSomeRendererActing,\n  // Used by renderers to avoid bundling object-assign twice in UMD bundles:\n  assign: _assign\n};\n\n{\n  ReactSharedInternals.ReactDebugCurrentFrame = ReactDebugCurrentFrame;\n}\n\n// by calls to these methods by a Babel plugin.\n//\n// In PROD (or in packages without access to React internals),\n// they are left as they are instead.\n\nfunction warn(format) {\n  {\n    for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      args[_key - 1] = arguments[_key];\n    }\n\n    printWarning('warn', format, args);\n  }\n}\nfunction error(format) {\n  {\n    for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n      args[_key2 - 1] = arguments[_key2];\n    }\n\n    printWarning('error', format, args);\n  }\n}\n\nfunction printWarning(level, format, args) {\n  // When changing this logic, you might want to also\n  // update consoleWithStackDev.www.js as well.\n  {\n    var ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\n    var stack = ReactDebugCurrentFrame.getStackAddendum();\n\n    if (stack !== '') {\n      format += '%s';\n      args = args.concat([stack]);\n    }\n\n    var argsWithFormat = args.map(function (item) {\n      return '' + item;\n    }); // Careful: RN currently depends on this prefix\n\n    argsWithFormat.unshift('Warning: ' + format); // We intentionally don't use spread (or .apply) directly because it\n    // breaks IE9: https://github.com/facebook/react/issues/13610\n    // eslint-disable-next-line react-internal/no-production-logging\n\n    Function.prototype.apply.call(console[level], console, argsWithFormat);\n  }\n}\n\nvar didWarnStateUpdateForUnmountedComponent = {};\n\nfunction warnNoop(publicInstance, callerName) {\n  {\n    var _constructor = publicInstance.constructor;\n    var componentName = _constructor && (_constructor.displayName || _constructor.name) || 'ReactClass';\n    var warningKey = componentName + \".\" + callerName;\n\n    if (didWarnStateUpdateForUnmountedComponent[warningKey]) {\n      return;\n    }\n\n    error(\"Can't call %s on a component that is not yet mounted. \" + 'This is a no-op, but it might indicate a bug in your application. ' + 'Instead, assign to `this.state` directly or define a `state = {};` ' + 'class property with the desired state in the %s component.', callerName, componentName);\n\n    didWarnStateUpdateForUnmountedComponent[warningKey] = true;\n  }\n}\n/**\n * This is the abstract API for an update queue.\n */\n\n\nvar ReactNoopUpdateQueue = {\n  /**\n   * Checks whether or not this composite component is mounted.\n   * @param {ReactClass} publicInstance The instance we want to test.\n   * @return {boolean} True if mounted, false otherwise.\n   * @protected\n   * @final\n   */\n  isMounted: function (publicInstance) {\n    return false;\n  },\n\n  /**\n   * Forces an update. This should only be invoked when it is known with\n   * certainty that we are **not** in a DOM transaction.\n   *\n   * You may want to call this when you know that some deeper aspect of the\n   * component's state has changed but `setState` was not called.\n   *\n   * This will not invoke `shouldComponentUpdate`, but it will invoke\n   * `componentWillUpdate` and `componentDidUpdate`.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} callerName name of the calling function in the public API.\n   * @internal\n   */\n  enqueueForceUpdate: function (publicInstance, callback, callerName) {\n    warnNoop(publicInstance, 'forceUpdate');\n  },\n\n  /**\n   * Replaces all of the state. Always use this or `setState` to mutate state.\n   * You should treat `this.state` as immutable.\n   *\n   * There is no guarantee that `this.state` will be immediately updated, so\n   * accessing `this.state` after calling this method may return the old value.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {object} completeState Next state.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} callerName name of the calling function in the public API.\n   * @internal\n   */\n  enqueueReplaceState: function (publicInstance, completeState, callback, callerName) {\n    warnNoop(publicInstance, 'replaceState');\n  },\n\n  /**\n   * Sets a subset of the state. This only exists because _pendingState is\n   * internal. This provides a merging strategy that is not available to deep\n   * properties which is confusing. TODO: Expose pendingState or don't use it\n   * during the merge.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {object} partialState Next partial state to be merged with state.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} Name of the calling function in the public API.\n   * @internal\n   */\n  enqueueSetState: function (publicInstance, partialState, callback, callerName) {\n    warnNoop(publicInstance, 'setState');\n  }\n};\n\nvar emptyObject = {};\n\n{\n  Object.freeze(emptyObject);\n}\n/**\n * Base class helpers for the updating state of a component.\n */\n\n\nfunction Component(props, context, updater) {\n  this.props = props;\n  this.context = context; // If a component has string refs, we will assign a different object later.\n\n  this.refs = emptyObject; // We initialize the default updater but the real one gets injected by the\n  // renderer.\n\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n\nComponent.prototype.isReactComponent = {};\n/**\n * Sets a subset of the state. Always use this to mutate\n * state. You should treat `this.state` as immutable.\n *\n * There is no guarantee that `this.state` will be immediately updated, so\n * accessing `this.state` after calling this method may return the old value.\n *\n * There is no guarantee that calls to `setState` will run synchronously,\n * as they may eventually be batched together.  You can provide an optional\n * callback that will be executed when the call to setState is actually\n * completed.\n *\n * When a function is provided to setState, it will be called at some point in\n * the future (not synchronously). It will be called with the up to date\n * component arguments (state, props, context). These values can be different\n * from this.* because your function may be called after receiveProps but before\n * shouldComponentUpdate, and this new state, props, and context will not yet be\n * assigned to this.\n *\n * @param {object|function} partialState Next partial state or function to\n *        produce next partial state to be merged with current state.\n * @param {?function} callback Called after state is updated.\n * @final\n * @protected\n */\n\nComponent.prototype.setState = function (partialState, callback) {\n  if (!(typeof partialState === 'object' || typeof partialState === 'function' || partialState == null)) {\n    {\n      throw Error( \"setState(...): takes an object of state variables to update or a function which returns an object of state variables.\" );\n    }\n  }\n\n  this.updater.enqueueSetState(this, partialState, callback, 'setState');\n};\n/**\n * Forces an update. This should only be invoked when it is known with\n * certainty that we are **not** in a DOM transaction.\n *\n * You may want to call this when you know that some deeper aspect of the\n * component's state has changed but `setState` was not called.\n *\n * This will not invoke `shouldComponentUpdate`, but it will invoke\n * `componentWillUpdate` and `componentDidUpdate`.\n *\n * @param {?function} callback Called after update is complete.\n * @final\n * @protected\n */\n\n\nComponent.prototype.forceUpdate = function (callback) {\n  this.updater.enqueueForceUpdate(this, callback, 'forceUpdate');\n};\n/**\n * Deprecated APIs. These APIs used to exist on classic React classes but since\n * we would like to deprecate them, we're not going to move them over to this\n * modern base class. Instead, we define a getter that warns if it's accessed.\n */\n\n\n{\n  var deprecatedAPIs = {\n    isMounted: ['isMounted', 'Instead, make sure to clean up subscriptions and pending requests in ' + 'componentWillUnmount to prevent memory leaks.'],\n    replaceState: ['replaceState', 'Refactor your code to use setState instead (see ' + 'https://github.com/facebook/react/issues/3236).']\n  };\n\n  var defineDeprecationWarning = function (methodName, info) {\n    Object.defineProperty(Component.prototype, methodName, {\n      get: function () {\n        warn('%s(...) is deprecated in plain JavaScript React classes. %s', info[0], info[1]);\n\n        return undefined;\n      }\n    });\n  };\n\n  for (var fnName in deprecatedAPIs) {\n    if (deprecatedAPIs.hasOwnProperty(fnName)) {\n      defineDeprecationWarning(fnName, deprecatedAPIs[fnName]);\n    }\n  }\n}\n\nfunction ComponentDummy() {}\n\nComponentDummy.prototype = Component.prototype;\n/**\n * Convenience component with default shallow equality check for sCU.\n */\n\nfunction PureComponent(props, context, updater) {\n  this.props = props;\n  this.context = context; // If a component has string refs, we will assign a different object later.\n\n  this.refs = emptyObject;\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n\nvar pureComponentPrototype = PureComponent.prototype = new ComponentDummy();\npureComponentPrototype.constructor = PureComponent; // Avoid an extra prototype jump for these methods.\n\n_assign(pureComponentPrototype, Component.prototype);\n\npureComponentPrototype.isPureReactComponent = true;\n\n// an immutable object with a single mutable value\nfunction createRef() {\n  var refObject = {\n    current: null\n  };\n\n  {\n    Object.seal(refObject);\n  }\n\n  return refObject;\n}\n\nfunction getWrappedName(outerType, innerType, wrapperName) {\n  var functionName = innerType.displayName || innerType.name || '';\n  return outerType.displayName || (functionName !== '' ? wrapperName + \"(\" + functionName + \")\" : wrapperName);\n}\n\nfunction getContextName(type) {\n  return type.displayName || 'Context';\n}\n\nfunction getComponentName(type) {\n  if (type == null) {\n    // Host root, text node or just invalid type.\n    return null;\n  }\n\n  {\n    if (typeof type.tag === 'number') {\n      error('Received an unexpected object in getComponentName(). ' + 'This is likely a bug in React. Please file an issue.');\n    }\n  }\n\n  if (typeof type === 'function') {\n    return type.displayName || type.name || null;\n  }\n\n  if (typeof type === 'string') {\n    return type;\n  }\n\n  switch (type) {\n    case exports.Fragment:\n      return 'Fragment';\n\n    case REACT_PORTAL_TYPE:\n      return 'Portal';\n\n    case exports.Profiler:\n      return 'Profiler';\n\n    case exports.StrictMode:\n      return 'StrictMode';\n\n    case exports.Suspense:\n      return 'Suspense';\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return 'SuspenseList';\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_CONTEXT_TYPE:\n        var context = type;\n        return getContextName(context) + '.Consumer';\n\n      case REACT_PROVIDER_TYPE:\n        var provider = type;\n        return getContextName(provider._context) + '.Provider';\n\n      case REACT_FORWARD_REF_TYPE:\n        return getWrappedName(type, type.render, 'ForwardRef');\n\n      case REACT_MEMO_TYPE:\n        return getComponentName(type.type);\n\n      case REACT_BLOCK_TYPE:\n        return getComponentName(type._render);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            return getComponentName(init(payload));\n          } catch (x) {\n            return null;\n          }\n        }\n    }\n  }\n\n  return null;\n}\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar RESERVED_PROPS = {\n  key: true,\n  ref: true,\n  __self: true,\n  __source: true\n};\nvar specialPropKeyWarningShown, specialPropRefWarningShown, didWarnAboutStringRefs;\n\n{\n  didWarnAboutStringRefs = {};\n}\n\nfunction hasValidRef(config) {\n  {\n    if (hasOwnProperty.call(config, 'ref')) {\n      var getter = Object.getOwnPropertyDescriptor(config, 'ref').get;\n\n      if (getter && getter.isReactWarning) {\n        return false;\n      }\n    }\n  }\n\n  return config.ref !== undefined;\n}\n\nfunction hasValidKey(config) {\n  {\n    if (hasOwnProperty.call(config, 'key')) {\n      var getter = Object.getOwnPropertyDescriptor(config, 'key').get;\n\n      if (getter && getter.isReactWarning) {\n        return false;\n      }\n    }\n  }\n\n  return config.key !== undefined;\n}\n\nfunction defineKeyPropWarningGetter(props, displayName) {\n  var warnAboutAccessingKey = function () {\n    {\n      if (!specialPropKeyWarningShown) {\n        specialPropKeyWarningShown = true;\n\n        error('%s: `key` is not a prop. Trying to access it will result ' + 'in `undefined` being returned. If you need to access the same ' + 'value within the child component, you should pass it as a different ' + 'prop. (https://reactjs.org/link/special-props)', displayName);\n      }\n    }\n  };\n\n  warnAboutAccessingKey.isReactWarning = true;\n  Object.defineProperty(props, 'key', {\n    get: warnAboutAccessingKey,\n    configurable: true\n  });\n}\n\nfunction defineRefPropWarningGetter(props, displayName) {\n  var warnAboutAccessingRef = function () {\n    {\n      if (!specialPropRefWarningShown) {\n        specialPropRefWarningShown = true;\n\n        error('%s: `ref` is not a prop. Trying to access it will result ' + 'in `undefined` being returned. If you need to access the same ' + 'value within the child component, you should pass it as a different ' + 'prop. (https://reactjs.org/link/special-props)', displayName);\n      }\n    }\n  };\n\n  warnAboutAccessingRef.isReactWarning = true;\n  Object.defineProperty(props, 'ref', {\n    get: warnAboutAccessingRef,\n    configurable: true\n  });\n}\n\nfunction warnIfStringRefCannotBeAutoConverted(config) {\n  {\n    if (typeof config.ref === 'string' && ReactCurrentOwner.current && config.__self && ReactCurrentOwner.current.stateNode !== config.__self) {\n      var componentName = getComponentName(ReactCurrentOwner.current.type);\n\n      if (!didWarnAboutStringRefs[componentName]) {\n        error('Component \"%s\" contains the string ref \"%s\". ' + 'Support for string refs will be removed in a future major release. ' + 'This case cannot be automatically converted to an arrow function. ' + 'We ask you to manually fix this case by using useRef() or createRef() instead. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-string-ref', componentName, config.ref);\n\n        didWarnAboutStringRefs[componentName] = true;\n      }\n    }\n  }\n}\n/**\n * Factory method to create a new React element. This no longer adheres to\n * the class pattern, so do not use new to call it. Also, instanceof check\n * will not work. Instead test $$typeof field against Symbol.for('react.element') to check\n * if something is a React Element.\n *\n * @param {*} type\n * @param {*} props\n * @param {*} key\n * @param {string|object} ref\n * @param {*} owner\n * @param {*} self A *temporary* helper to detect places where `this` is\n * different from the `owner` when React.createElement is called, so that we\n * can warn. We want to get rid of owner and replace string `ref`s with arrow\n * functions, and as long as `this` and owner are the same, there will be no\n * change in behavior.\n * @param {*} source An annotation object (added by a transpiler or otherwise)\n * indicating filename, line number, and/or other information.\n * @internal\n */\n\n\nvar ReactElement = function (type, key, ref, self, source, owner, props) {\n  var element = {\n    // This tag allows us to uniquely identify this as a React Element\n    $$typeof: REACT_ELEMENT_TYPE,\n    // Built-in properties that belong on the element\n    type: type,\n    key: key,\n    ref: ref,\n    props: props,\n    // Record the component responsible for creating this element.\n    _owner: owner\n  };\n\n  {\n    // The validation flag is currently mutative. We put it on\n    // an external backing store so that we can freeze the whole object.\n    // This can be replaced with a WeakMap once they are implemented in\n    // commonly used development environments.\n    element._store = {}; // To make comparing ReactElements easier for testing purposes, we make\n    // the validation flag non-enumerable (where possible, which should\n    // include every environment we run tests in), so the test framework\n    // ignores it.\n\n    Object.defineProperty(element._store, 'validated', {\n      configurable: false,\n      enumerable: false,\n      writable: true,\n      value: false\n    }); // self and source are DEV only properties.\n\n    Object.defineProperty(element, '_self', {\n      configurable: false,\n      enumerable: false,\n      writable: false,\n      value: self\n    }); // Two elements created in two different places should be considered\n    // equal for testing purposes and therefore we hide it from enumeration.\n\n    Object.defineProperty(element, '_source', {\n      configurable: false,\n      enumerable: false,\n      writable: false,\n      value: source\n    });\n\n    if (Object.freeze) {\n      Object.freeze(element.props);\n      Object.freeze(element);\n    }\n  }\n\n  return element;\n};\n/**\n * Create and return a new ReactElement of the given type.\n * See https://reactjs.org/docs/react-api.html#createelement\n */\n\nfunction createElement(type, config, children) {\n  var propName; // Reserved names are extracted\n\n  var props = {};\n  var key = null;\n  var ref = null;\n  var self = null;\n  var source = null;\n\n  if (config != null) {\n    if (hasValidRef(config)) {\n      ref = config.ref;\n\n      {\n        warnIfStringRefCannotBeAutoConverted(config);\n      }\n    }\n\n    if (hasValidKey(config)) {\n      key = '' + config.key;\n    }\n\n    self = config.__self === undefined ? null : config.__self;\n    source = config.__source === undefined ? null : config.__source; // Remaining properties are added to a new props object\n\n    for (propName in config) {\n      if (hasOwnProperty.call(config, propName) && !RESERVED_PROPS.hasOwnProperty(propName)) {\n        props[propName] = config[propName];\n      }\n    }\n  } // Children can be more than one argument, and those are transferred onto\n  // the newly allocated props object.\n\n\n  var childrenLength = arguments.length - 2;\n\n  if (childrenLength === 1) {\n    props.children = children;\n  } else if (childrenLength > 1) {\n    var childArray = Array(childrenLength);\n\n    for (var i = 0; i < childrenLength; i++) {\n      childArray[i] = arguments[i + 2];\n    }\n\n    {\n      if (Object.freeze) {\n        Object.freeze(childArray);\n      }\n    }\n\n    props.children = childArray;\n  } // Resolve default props\n\n\n  if (type && type.defaultProps) {\n    var defaultProps = type.defaultProps;\n\n    for (propName in defaultProps) {\n      if (props[propName] === undefined) {\n        props[propName] = defaultProps[propName];\n      }\n    }\n  }\n\n  {\n    if (key || ref) {\n      var displayName = typeof type === 'function' ? type.displayName || type.name || 'Unknown' : type;\n\n      if (key) {\n        defineKeyPropWarningGetter(props, displayName);\n      }\n\n      if (ref) {\n        defineRefPropWarningGetter(props, displayName);\n      }\n    }\n  }\n\n  return ReactElement(type, key, ref, self, source, ReactCurrentOwner.current, props);\n}\nfunction cloneAndReplaceKey(oldElement, newKey) {\n  var newElement = ReactElement(oldElement.type, newKey, oldElement.ref, oldElement._self, oldElement._source, oldElement._owner, oldElement.props);\n  return newElement;\n}\n/**\n * Clone and return a new ReactElement using element as the starting point.\n * See https://reactjs.org/docs/react-api.html#cloneelement\n */\n\nfunction cloneElement(element, config, children) {\n  if (!!(element === null || element === undefined)) {\n    {\n      throw Error( \"React.cloneElement(...): The argument must be a React element, but you passed \" + element + \".\" );\n    }\n  }\n\n  var propName; // Original props are copied\n\n  var props = _assign({}, element.props); // Reserved names are extracted\n\n\n  var key = element.key;\n  var ref = element.ref; // Self is preserved since the owner is preserved.\n\n  var self = element._self; // Source is preserved since cloneElement is unlikely to be targeted by a\n  // transpiler, and the original source is probably a better indicator of the\n  // true owner.\n\n  var source = element._source; // Owner will be preserved, unless ref is overridden\n\n  var owner = element._owner;\n\n  if (config != null) {\n    if (hasValidRef(config)) {\n      // Silently steal the ref from the parent.\n      ref = config.ref;\n      owner = ReactCurrentOwner.current;\n    }\n\n    if (hasValidKey(config)) {\n      key = '' + config.key;\n    } // Remaining properties override existing props\n\n\n    var defaultProps;\n\n    if (element.type && element.type.defaultProps) {\n      defaultProps = element.type.defaultProps;\n    }\n\n    for (propName in config) {\n      if (hasOwnProperty.call(config, propName) && !RESERVED_PROPS.hasOwnProperty(propName)) {\n        if (config[propName] === undefined && defaultProps !== undefined) {\n          // Resolve default props\n          props[propName] = defaultProps[propName];\n        } else {\n          props[propName] = config[propName];\n        }\n      }\n    }\n  } // Children can be more than one argument, and those are transferred onto\n  // the newly allocated props object.\n\n\n  var childrenLength = arguments.length - 2;\n\n  if (childrenLength === 1) {\n    props.children = children;\n  } else if (childrenLength > 1) {\n    var childArray = Array(childrenLength);\n\n    for (var i = 0; i < childrenLength; i++) {\n      childArray[i] = arguments[i + 2];\n    }\n\n    props.children = childArray;\n  }\n\n  return ReactElement(element.type, key, ref, self, source, owner, props);\n}\n/**\n * Verifies the object is a ReactElement.\n * See https://reactjs.org/docs/react-api.html#isvalidelement\n * @param {?object} object\n * @return {boolean} True if `object` is a ReactElement.\n * @final\n */\n\nfunction isValidElement(object) {\n  return typeof object === 'object' && object !== null && object.$$typeof === REACT_ELEMENT_TYPE;\n}\n\nvar SEPARATOR = '.';\nvar SUBSEPARATOR = ':';\n/**\n * Escape and wrap key so it is safe to use as a reactid\n *\n * @param {string} key to be escaped.\n * @return {string} the escaped key.\n */\n\nfunction escape(key) {\n  var escapeRegex = /[=:]/g;\n  var escaperLookup = {\n    '=': '=0',\n    ':': '=2'\n  };\n  var escapedString = key.replace(escapeRegex, function (match) {\n    return escaperLookup[match];\n  });\n  return '$' + escapedString;\n}\n/**\n * TODO: Test that a single child and an array with one item have the same key\n * pattern.\n */\n\n\nvar didWarnAboutMaps = false;\nvar userProvidedKeyEscapeRegex = /\\/+/g;\n\nfunction escapeUserProvidedKey(text) {\n  return text.replace(userProvidedKeyEscapeRegex, '$&/');\n}\n/**\n * Generate a key string that identifies a element within a set.\n *\n * @param {*} element A element that could contain a manual key.\n * @param {number} index Index that is used if a manual key is not provided.\n * @return {string}\n */\n\n\nfunction getElementKey(element, index) {\n  // Do some typechecking here since we call this blindly. We want to ensure\n  // that we don't block potential future ES APIs.\n  if (typeof element === 'object' && element !== null && element.key != null) {\n    // Explicit key\n    return escape('' + element.key);\n  } // Implicit key determined by the index in the set\n\n\n  return index.toString(36);\n}\n\nfunction mapIntoArray(children, array, escapedPrefix, nameSoFar, callback) {\n  var type = typeof children;\n\n  if (type === 'undefined' || type === 'boolean') {\n    // All of the above are perceived as null.\n    children = null;\n  }\n\n  var invokeCallback = false;\n\n  if (children === null) {\n    invokeCallback = true;\n  } else {\n    switch (type) {\n      case 'string':\n      case 'number':\n        invokeCallback = true;\n        break;\n\n      case 'object':\n        switch (children.$$typeof) {\n          case REACT_ELEMENT_TYPE:\n          case REACT_PORTAL_TYPE:\n            invokeCallback = true;\n        }\n\n    }\n  }\n\n  if (invokeCallback) {\n    var _child = children;\n    var mappedChild = callback(_child); // If it's the only child, treat the name as if it was wrapped in an array\n    // so that it's consistent if the number of children grows:\n\n    var childKey = nameSoFar === '' ? SEPARATOR + getElementKey(_child, 0) : nameSoFar;\n\n    if (Array.isArray(mappedChild)) {\n      var escapedChildKey = '';\n\n      if (childKey != null) {\n        escapedChildKey = escapeUserProvidedKey(childKey) + '/';\n      }\n\n      mapIntoArray(mappedChild, array, escapedChildKey, '', function (c) {\n        return c;\n      });\n    } else if (mappedChild != null) {\n      if (isValidElement(mappedChild)) {\n        mappedChild = cloneAndReplaceKey(mappedChild, // Keep both the (mapped) and old keys if they differ, just as\n        // traverseAllChildren used to do for objects as children\n        escapedPrefix + ( // $FlowFixMe Flow incorrectly thinks React.Portal doesn't have a key\n        mappedChild.key && (!_child || _child.key !== mappedChild.key) ? // $FlowFixMe Flow incorrectly thinks existing element's key can be a number\n        escapeUserProvidedKey('' + mappedChild.key) + '/' : '') + childKey);\n      }\n\n      array.push(mappedChild);\n    }\n\n    return 1;\n  }\n\n  var child;\n  var nextName;\n  var subtreeCount = 0; // Count of children found in the current subtree.\n\n  var nextNamePrefix = nameSoFar === '' ? SEPARATOR : nameSoFar + SUBSEPARATOR;\n\n  if (Array.isArray(children)) {\n    for (var i = 0; i < children.length; i++) {\n      child = children[i];\n      nextName = nextNamePrefix + getElementKey(child, i);\n      subtreeCount += mapIntoArray(child, array, escapedPrefix, nextName, callback);\n    }\n  } else {\n    var iteratorFn = getIteratorFn(children);\n\n    if (typeof iteratorFn === 'function') {\n      var iterableChildren = children;\n\n      {\n        // Warn about using Maps as children\n        if (iteratorFn === iterableChildren.entries) {\n          if (!didWarnAboutMaps) {\n            warn('Using Maps as children is not supported. ' + 'Use an array of keyed ReactElements instead.');\n          }\n\n          didWarnAboutMaps = true;\n        }\n      }\n\n      var iterator = iteratorFn.call(iterableChildren);\n      var step;\n      var ii = 0;\n\n      while (!(step = iterator.next()).done) {\n        child = step.value;\n        nextName = nextNamePrefix + getElementKey(child, ii++);\n        subtreeCount += mapIntoArray(child, array, escapedPrefix, nextName, callback);\n      }\n    } else if (type === 'object') {\n      var childrenString = '' + children;\n\n      {\n        {\n          throw Error( \"Objects are not valid as a React child (found: \" + (childrenString === '[object Object]' ? 'object with keys {' + Object.keys(children).join(', ') + '}' : childrenString) + \"). If you meant to render a collection of children, use an array instead.\" );\n        }\n      }\n    }\n  }\n\n  return subtreeCount;\n}\n\n/**\n * Maps children that are typically specified as `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenmap\n *\n * The provided mapFunction(child, index) will be called for each\n * leaf child.\n *\n * @param {?*} children Children tree container.\n * @param {function(*, int)} func The map function.\n * @param {*} context Context for mapFunction.\n * @return {object} Object containing the ordered map of results.\n */\nfunction mapChildren(children, func, context) {\n  if (children == null) {\n    return children;\n  }\n\n  var result = [];\n  var count = 0;\n  mapIntoArray(children, result, '', '', function (child) {\n    return func.call(context, child, count++);\n  });\n  return result;\n}\n/**\n * Count the number of children that are typically specified as\n * `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrencount\n *\n * @param {?*} children Children tree container.\n * @return {number} The number of children.\n */\n\n\nfunction countChildren(children) {\n  var n = 0;\n  mapChildren(children, function () {\n    n++; // Don't return anything\n  });\n  return n;\n}\n\n/**\n * Iterates through children that are typically specified as `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenforeach\n *\n * The provided forEachFunc(child, index) will be called for each\n * leaf child.\n *\n * @param {?*} children Children tree container.\n * @param {function(*, int)} forEachFunc\n * @param {*} forEachContext Context for forEachContext.\n */\nfunction forEachChildren(children, forEachFunc, forEachContext) {\n  mapChildren(children, function () {\n    forEachFunc.apply(this, arguments); // Don't return anything.\n  }, forEachContext);\n}\n/**\n * Flatten a children object (typically specified as `props.children`) and\n * return an array with appropriately re-keyed children.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrentoarray\n */\n\n\nfunction toArray(children) {\n  return mapChildren(children, function (child) {\n    return child;\n  }) || [];\n}\n/**\n * Returns the first child in a collection of children and verifies that there\n * is only one child in the collection.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenonly\n *\n * The current implementation of this function assumes that a single child gets\n * passed without a wrapper, but the purpose of this helper function is to\n * abstract away the particular structure of children.\n *\n * @param {?object} children Child collection structure.\n * @return {ReactElement} The first and only `ReactElement` contained in the\n * structure.\n */\n\n\nfunction onlyChild(children) {\n  if (!isValidElement(children)) {\n    {\n      throw Error( \"React.Children.only expected to receive a single React element child.\" );\n    }\n  }\n\n  return children;\n}\n\nfunction createContext(defaultValue, calculateChangedBits) {\n  if (calculateChangedBits === undefined) {\n    calculateChangedBits = null;\n  } else {\n    {\n      if (calculateChangedBits !== null && typeof calculateChangedBits !== 'function') {\n        error('createContext: Expected the optional second argument to be a ' + 'function. Instead received: %s', calculateChangedBits);\n      }\n    }\n  }\n\n  var context = {\n    $$typeof: REACT_CONTEXT_TYPE,\n    _calculateChangedBits: calculateChangedBits,\n    // As a workaround to support multiple concurrent renderers, we categorize\n    // some renderers as primary and others as secondary. We only expect\n    // there to be two concurrent renderers at most: React Native (primary) and\n    // Fabric (secondary); React DOM (primary) and React ART (secondary).\n    // Secondary renderers store their context values on separate fields.\n    _currentValue: defaultValue,\n    _currentValue2: defaultValue,\n    // Used to track how many concurrent renderers this context currently\n    // supports within in a single renderer. Such as parallel server rendering.\n    _threadCount: 0,\n    // These are circular\n    Provider: null,\n    Consumer: null\n  };\n  context.Provider = {\n    $$typeof: REACT_PROVIDER_TYPE,\n    _context: context\n  };\n  var hasWarnedAboutUsingNestedContextConsumers = false;\n  var hasWarnedAboutUsingConsumerProvider = false;\n  var hasWarnedAboutDisplayNameOnConsumer = false;\n\n  {\n    // A separate object, but proxies back to the original context object for\n    // backwards compatibility. It has a different $$typeof, so we can properly\n    // warn for the incorrect usage of Context as a Consumer.\n    var Consumer = {\n      $$typeof: REACT_CONTEXT_TYPE,\n      _context: context,\n      _calculateChangedBits: context._calculateChangedBits\n    }; // $FlowFixMe: Flow complains about not setting a value, which is intentional here\n\n    Object.defineProperties(Consumer, {\n      Provider: {\n        get: function () {\n          if (!hasWarnedAboutUsingConsumerProvider) {\n            hasWarnedAboutUsingConsumerProvider = true;\n\n            error('Rendering <Context.Consumer.Provider> is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Provider> instead?');\n          }\n\n          return context.Provider;\n        },\n        set: function (_Provider) {\n          context.Provider = _Provider;\n        }\n      },\n      _currentValue: {\n        get: function () {\n          return context._currentValue;\n        },\n        set: function (_currentValue) {\n          context._currentValue = _currentValue;\n        }\n      },\n      _currentValue2: {\n        get: function () {\n          return context._currentValue2;\n        },\n        set: function (_currentValue2) {\n          context._currentValue2 = _currentValue2;\n        }\n      },\n      _threadCount: {\n        get: function () {\n          return context._threadCount;\n        },\n        set: function (_threadCount) {\n          context._threadCount = _threadCount;\n        }\n      },\n      Consumer: {\n        get: function () {\n          if (!hasWarnedAboutUsingNestedContextConsumers) {\n            hasWarnedAboutUsingNestedContextConsumers = true;\n\n            error('Rendering <Context.Consumer.Consumer> is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Consumer> instead?');\n          }\n\n          return context.Consumer;\n        }\n      },\n      displayName: {\n        get: function () {\n          return context.displayName;\n        },\n        set: function (displayName) {\n          if (!hasWarnedAboutDisplayNameOnConsumer) {\n            warn('Setting `displayName` on Context.Consumer has no effect. ' + \"You should set it directly on the context with Context.displayName = '%s'.\", displayName);\n\n            hasWarnedAboutDisplayNameOnConsumer = true;\n          }\n        }\n      }\n    }); // $FlowFixMe: Flow complains about missing properties because it doesn't understand defineProperty\n\n    context.Consumer = Consumer;\n  }\n\n  {\n    context._currentRenderer = null;\n    context._currentRenderer2 = null;\n  }\n\n  return context;\n}\n\nvar Uninitialized = -1;\nvar Pending = 0;\nvar Resolved = 1;\nvar Rejected = 2;\n\nfunction lazyInitializer(payload) {\n  if (payload._status === Uninitialized) {\n    var ctor = payload._result;\n    var thenable = ctor(); // Transition to the next state.\n\n    var pending = payload;\n    pending._status = Pending;\n    pending._result = thenable;\n    thenable.then(function (moduleObject) {\n      if (payload._status === Pending) {\n        var defaultExport = moduleObject.default;\n\n        {\n          if (defaultExport === undefined) {\n            error('lazy: Expected the result of a dynamic import() call. ' + 'Instead received: %s\\n\\nYour code should look like: \\n  ' + // Break up imports to avoid accidentally parsing them as dependencies.\n            'const MyComponent = lazy(() => imp' + \"ort('./MyComponent'))\", moduleObject);\n          }\n        } // Transition to the next state.\n\n\n        var resolved = payload;\n        resolved._status = Resolved;\n        resolved._result = defaultExport;\n      }\n    }, function (error) {\n      if (payload._status === Pending) {\n        // Transition to the next state.\n        var rejected = payload;\n        rejected._status = Rejected;\n        rejected._result = error;\n      }\n    });\n  }\n\n  if (payload._status === Resolved) {\n    return payload._result;\n  } else {\n    throw payload._result;\n  }\n}\n\nfunction lazy(ctor) {\n  var payload = {\n    // We use these fields to store the result.\n    _status: -1,\n    _result: ctor\n  };\n  var lazyType = {\n    $$typeof: REACT_LAZY_TYPE,\n    _payload: payload,\n    _init: lazyInitializer\n  };\n\n  {\n    // In production, this would just set it on the object.\n    var defaultProps;\n    var propTypes; // $FlowFixMe\n\n    Object.defineProperties(lazyType, {\n      defaultProps: {\n        configurable: true,\n        get: function () {\n          return defaultProps;\n        },\n        set: function (newDefaultProps) {\n          error('React.lazy(...): It is not supported to assign `defaultProps` to ' + 'a lazy component import. Either specify them where the component ' + 'is defined, or create a wrapping component around it.');\n\n          defaultProps = newDefaultProps; // Match production behavior more closely:\n          // $FlowFixMe\n\n          Object.defineProperty(lazyType, 'defaultProps', {\n            enumerable: true\n          });\n        }\n      },\n      propTypes: {\n        configurable: true,\n        get: function () {\n          return propTypes;\n        },\n        set: function (newPropTypes) {\n          error('React.lazy(...): It is not supported to assign `propTypes` to ' + 'a lazy component import. Either specify them where the component ' + 'is defined, or create a wrapping component around it.');\n\n          propTypes = newPropTypes; // Match production behavior more closely:\n          // $FlowFixMe\n\n          Object.defineProperty(lazyType, 'propTypes', {\n            enumerable: true\n          });\n        }\n      }\n    });\n  }\n\n  return lazyType;\n}\n\nfunction forwardRef(render) {\n  {\n    if (render != null && render.$$typeof === REACT_MEMO_TYPE) {\n      error('forwardRef requires a render function but received a `memo` ' + 'component. Instead of forwardRef(memo(...)), use ' + 'memo(forwardRef(...)).');\n    } else if (typeof render !== 'function') {\n      error('forwardRef requires a render function but was given %s.', render === null ? 'null' : typeof render);\n    } else {\n      if (render.length !== 0 && render.length !== 2) {\n        error('forwardRef render functions accept exactly two parameters: props and ref. %s', render.length === 1 ? 'Did you forget to use the ref parameter?' : 'Any additional parameter will be undefined.');\n      }\n    }\n\n    if (render != null) {\n      if (render.defaultProps != null || render.propTypes != null) {\n        error('forwardRef render functions do not support propTypes or defaultProps. ' + 'Did you accidentally pass a React component?');\n      }\n    }\n  }\n\n  var elementType = {\n    $$typeof: REACT_FORWARD_REF_TYPE,\n    render: render\n  };\n\n  {\n    var ownName;\n    Object.defineProperty(elementType, 'displayName', {\n      enumerable: false,\n      configurable: true,\n      get: function () {\n        return ownName;\n      },\n      set: function (name) {\n        ownName = name;\n\n        if (render.displayName == null) {\n          render.displayName = name;\n        }\n      }\n    });\n  }\n\n  return elementType;\n}\n\n// Filter certain DOM attributes (e.g. src, href) if their values are empty strings.\n\nvar enableScopeAPI = false; // Experimental Create Event Handle API.\n\nfunction isValidElementType(type) {\n  if (typeof type === 'string' || typeof type === 'function') {\n    return true;\n  } // Note: typeof might be other than 'symbol' or 'number' (e.g. if it's a polyfill).\n\n\n  if (type === exports.Fragment || type === exports.Profiler || type === REACT_DEBUG_TRACING_MODE_TYPE || type === exports.StrictMode || type === exports.Suspense || type === REACT_SUSPENSE_LIST_TYPE || type === REACT_LEGACY_HIDDEN_TYPE || enableScopeAPI ) {\n    return true;\n  }\n\n  if (typeof type === 'object' && type !== null) {\n    if (type.$$typeof === REACT_LAZY_TYPE || type.$$typeof === REACT_MEMO_TYPE || type.$$typeof === REACT_PROVIDER_TYPE || type.$$typeof === REACT_CONTEXT_TYPE || type.$$typeof === REACT_FORWARD_REF_TYPE || type.$$typeof === REACT_FUNDAMENTAL_TYPE || type.$$typeof === REACT_BLOCK_TYPE || type[0] === REACT_SERVER_BLOCK_TYPE) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction memo(type, compare) {\n  {\n    if (!isValidElementType(type)) {\n      error('memo: The first argument must be a component. Instead ' + 'received: %s', type === null ? 'null' : typeof type);\n    }\n  }\n\n  var elementType = {\n    $$typeof: REACT_MEMO_TYPE,\n    type: type,\n    compare: compare === undefined ? null : compare\n  };\n\n  {\n    var ownName;\n    Object.defineProperty(elementType, 'displayName', {\n      enumerable: false,\n      configurable: true,\n      get: function () {\n        return ownName;\n      },\n      set: function (name) {\n        ownName = name;\n\n        if (type.displayName == null) {\n          type.displayName = name;\n        }\n      }\n    });\n  }\n\n  return elementType;\n}\n\nfunction resolveDispatcher() {\n  var dispatcher = ReactCurrentDispatcher.current;\n\n  if (!(dispatcher !== null)) {\n    {\n      throw Error( \"Invalid hook call. Hooks can only be called inside of the body of a function component. This could happen for one of the following reasons:\\n1. You might have mismatching versions of React and the renderer (such as React DOM)\\n2. You might be breaking the Rules of Hooks\\n3. You might have more than one copy of React in the same app\\nSee https://reactjs.org/link/invalid-hook-call for tips about how to debug and fix this problem.\" );\n    }\n  }\n\n  return dispatcher;\n}\n\nfunction useContext(Context, unstable_observedBits) {\n  var dispatcher = resolveDispatcher();\n\n  {\n    if (unstable_observedBits !== undefined) {\n      error('useContext() second argument is reserved for future ' + 'use in React. Passing it is not supported. ' + 'You passed: %s.%s', unstable_observedBits, typeof unstable_observedBits === 'number' && Array.isArray(arguments[2]) ? '\\n\\nDid you call array.map(useContext)? ' + 'Calling Hooks inside a loop is not supported. ' + 'Learn more at https://reactjs.org/link/rules-of-hooks' : '');\n    } // TODO: add a more generic warning for invalid values.\n\n\n    if (Context._context !== undefined) {\n      var realContext = Context._context; // Don't deduplicate because this legitimately causes bugs\n      // and nobody should be using this in existing code.\n\n      if (realContext.Consumer === Context) {\n        error('Calling useContext(Context.Consumer) is not supported, may cause bugs, and will be ' + 'removed in a future major release. Did you mean to call useContext(Context) instead?');\n      } else if (realContext.Provider === Context) {\n        error('Calling useContext(Context.Provider) is not supported. ' + 'Did you mean to call useContext(Context) instead?');\n      }\n    }\n  }\n\n  return dispatcher.useContext(Context, unstable_observedBits);\n}\nfunction useState(initialState) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useState(initialState);\n}\nfunction useReducer(reducer, initialArg, init) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useReducer(reducer, initialArg, init);\n}\nfunction useRef(initialValue) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useRef(initialValue);\n}\nfunction useEffect(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useEffect(create, deps);\n}\nfunction useLayoutEffect(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useLayoutEffect(create, deps);\n}\nfunction useCallback(callback, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useCallback(callback, deps);\n}\nfunction useMemo(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useMemo(create, deps);\n}\nfunction useImperativeHandle(ref, create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useImperativeHandle(ref, create, deps);\n}\nfunction useDebugValue(value, formatterFn) {\n  {\n    var dispatcher = resolveDispatcher();\n    return dispatcher.useDebugValue(value, formatterFn);\n  }\n}\n\n// Helpers to patch console.logs to avoid logging during side-effect free\n// replaying on render function. This currently only patches the object\n// lazily which won't cover if the log function was extracted eagerly.\n// We could also eagerly patch the method.\nvar disabledDepth = 0;\nvar prevLog;\nvar prevInfo;\nvar prevWarn;\nvar prevError;\nvar prevGroup;\nvar prevGroupCollapsed;\nvar prevGroupEnd;\n\nfunction disabledLog() {}\n\ndisabledLog.__reactDisabledLog = true;\nfunction disableLogs() {\n  {\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      prevLog = console.log;\n      prevInfo = console.info;\n      prevWarn = console.warn;\n      prevError = console.error;\n      prevGroup = console.group;\n      prevGroupCollapsed = console.groupCollapsed;\n      prevGroupEnd = console.groupEnd; // https://github.com/facebook/react/issues/19099\n\n      var props = {\n        configurable: true,\n        enumerable: true,\n        value: disabledLog,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        info: props,\n        log: props,\n        warn: props,\n        error: props,\n        group: props,\n        groupCollapsed: props,\n        groupEnd: props\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    disabledDepth++;\n  }\n}\nfunction reenableLogs() {\n  {\n    disabledDepth--;\n\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      var props = {\n        configurable: true,\n        enumerable: true,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        log: _assign({}, props, {\n          value: prevLog\n        }),\n        info: _assign({}, props, {\n          value: prevInfo\n        }),\n        warn: _assign({}, props, {\n          value: prevWarn\n        }),\n        error: _assign({}, props, {\n          value: prevError\n        }),\n        group: _assign({}, props, {\n          value: prevGroup\n        }),\n        groupCollapsed: _assign({}, props, {\n          value: prevGroupCollapsed\n        }),\n        groupEnd: _assign({}, props, {\n          value: prevGroupEnd\n        })\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    if (disabledDepth < 0) {\n      error('disabledDepth fell below zero. ' + 'This is a bug in React. Please file an issue.');\n    }\n  }\n}\n\nvar ReactCurrentDispatcher$1 = ReactSharedInternals.ReactCurrentDispatcher;\nvar prefix;\nfunction describeBuiltInComponentFrame(name, source, ownerFn) {\n  {\n    if (prefix === undefined) {\n      // Extract the VM specific prefix used by each line.\n      try {\n        throw Error();\n      } catch (x) {\n        var match = x.stack.trim().match(/\\n( *(at )?)/);\n        prefix = match && match[1] || '';\n      }\n    } // We use the prefix to ensure our stacks line up with native stack frames.\n\n\n    return '\\n' + prefix + name;\n  }\n}\nvar reentry = false;\nvar componentFrameCache;\n\n{\n  var PossiblyWeakMap = typeof WeakMap === 'function' ? WeakMap : Map;\n  componentFrameCache = new PossiblyWeakMap();\n}\n\nfunction describeNativeComponentFrame(fn, construct) {\n  // If something asked for a stack inside a fake render, it should get ignored.\n  if (!fn || reentry) {\n    return '';\n  }\n\n  {\n    var frame = componentFrameCache.get(fn);\n\n    if (frame !== undefined) {\n      return frame;\n    }\n  }\n\n  var control;\n  reentry = true;\n  var previousPrepareStackTrace = Error.prepareStackTrace; // $FlowFixMe It does accept undefined.\n\n  Error.prepareStackTrace = undefined;\n  var previousDispatcher;\n\n  {\n    previousDispatcher = ReactCurrentDispatcher$1.current; // Set the dispatcher in DEV because this might be call in the render function\n    // for warnings.\n\n    ReactCurrentDispatcher$1.current = null;\n    disableLogs();\n  }\n\n  try {\n    // This should throw.\n    if (construct) {\n      // Something should be setting the props in the constructor.\n      var Fake = function () {\n        throw Error();\n      }; // $FlowFixMe\n\n\n      Object.defineProperty(Fake.prototype, 'props', {\n        set: function () {\n          // We use a throwing setter instead of frozen or non-writable props\n          // because that won't throw in a non-strict mode function.\n          throw Error();\n        }\n      });\n\n      if (typeof Reflect === 'object' && Reflect.construct) {\n        // We construct a different control for this case to include any extra\n        // frames added by the construct call.\n        try {\n          Reflect.construct(Fake, []);\n        } catch (x) {\n          control = x;\n        }\n\n        Reflect.construct(fn, [], Fake);\n      } else {\n        try {\n          Fake.call();\n        } catch (x) {\n          control = x;\n        }\n\n        fn.call(Fake.prototype);\n      }\n    } else {\n      try {\n        throw Error();\n      } catch (x) {\n        control = x;\n      }\n\n      fn();\n    }\n  } catch (sample) {\n    // This is inlined manually because closure doesn't do it for us.\n    if (sample && control && typeof sample.stack === 'string') {\n      // This extracts the first frame from the sample that isn't also in the control.\n      // Skipping one frame that we assume is the frame that calls the two.\n      var sampleLines = sample.stack.split('\\n');\n      var controlLines = control.stack.split('\\n');\n      var s = sampleLines.length - 1;\n      var c = controlLines.length - 1;\n\n      while (s >= 1 && c >= 0 && sampleLines[s] !== controlLines[c]) {\n        // We expect at least one stack frame to be shared.\n        // Typically this will be the root most one. However, stack frames may be\n        // cut off due to maximum stack limits. In this case, one maybe cut off\n        // earlier than the other. We assume that the sample is longer or the same\n        // and there for cut off earlier. So we should find the root most frame in\n        // the sample somewhere in the control.\n        c--;\n      }\n\n      for (; s >= 1 && c >= 0; s--, c--) {\n        // Next we find the first one that isn't the same which should be the\n        // frame that called our sample function and the control.\n        if (sampleLines[s] !== controlLines[c]) {\n          // In V8, the first line is describing the message but other VMs don't.\n          // If we're about to return the first line, and the control is also on the same\n          // line, that's a pretty good indicator that our sample threw at same line as\n          // the control. I.e. before we entered the sample frame. So we ignore this result.\n          // This can happen if you passed a class to function component, or non-function.\n          if (s !== 1 || c !== 1) {\n            do {\n              s--;\n              c--; // We may still have similar intermediate frames from the construct call.\n              // The next one that isn't the same should be our match though.\n\n              if (c < 0 || sampleLines[s] !== controlLines[c]) {\n                // V8 adds a \"new\" prefix for native classes. Let's remove it to make it prettier.\n                var _frame = '\\n' + sampleLines[s].replace(' at new ', ' at ');\n\n                {\n                  if (typeof fn === 'function') {\n                    componentFrameCache.set(fn, _frame);\n                  }\n                } // Return the line we found.\n\n\n                return _frame;\n              }\n            } while (s >= 1 && c >= 0);\n          }\n\n          break;\n        }\n      }\n    }\n  } finally {\n    reentry = false;\n\n    {\n      ReactCurrentDispatcher$1.current = previousDispatcher;\n      reenableLogs();\n    }\n\n    Error.prepareStackTrace = previousPrepareStackTrace;\n  } // Fallback to just using the name if we couldn't make it throw.\n\n\n  var name = fn ? fn.displayName || fn.name : '';\n  var syntheticFrame = name ? describeBuiltInComponentFrame(name) : '';\n\n  {\n    if (typeof fn === 'function') {\n      componentFrameCache.set(fn, syntheticFrame);\n    }\n  }\n\n  return syntheticFrame;\n}\nfunction describeFunctionComponentFrame(fn, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(fn, false);\n  }\n}\n\nfunction shouldConstruct(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction describeUnknownElementTypeFrameInDEV(type, source, ownerFn) {\n\n  if (type == null) {\n    return '';\n  }\n\n  if (typeof type === 'function') {\n    {\n      return describeNativeComponentFrame(type, shouldConstruct(type));\n    }\n  }\n\n  if (typeof type === 'string') {\n    return describeBuiltInComponentFrame(type);\n  }\n\n  switch (type) {\n    case exports.Suspense:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return describeBuiltInComponentFrame('SuspenseList');\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_FORWARD_REF_TYPE:\n        return describeFunctionComponentFrame(type.render);\n\n      case REACT_MEMO_TYPE:\n        // Memo may contain any component type so we recursively resolve it.\n        return describeUnknownElementTypeFrameInDEV(type.type, source, ownerFn);\n\n      case REACT_BLOCK_TYPE:\n        return describeFunctionComponentFrame(type._render);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            // Lazy may contain any component type so we recursively resolve it.\n            return describeUnknownElementTypeFrameInDEV(init(payload), source, ownerFn);\n          } catch (x) {}\n        }\n    }\n  }\n\n  return '';\n}\n\nvar loggedTypeFailures = {};\nvar ReactDebugCurrentFrame$1 = ReactSharedInternals.ReactDebugCurrentFrame;\n\nfunction setCurrentlyValidatingElement(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      ReactDebugCurrentFrame$1.setExtraStackFrame(stack);\n    } else {\n      ReactDebugCurrentFrame$1.setExtraStackFrame(null);\n    }\n  }\n}\n\nfunction checkPropTypes(typeSpecs, values, location, componentName, element) {\n  {\n    // $FlowFixMe This is okay but Flow doesn't know it.\n    var has = Function.call.bind(Object.prototype.hasOwnProperty);\n\n    for (var typeSpecName in typeSpecs) {\n      if (has(typeSpecs, typeSpecName)) {\n        var error$1 = void 0; // Prop type validation may throw. In case they do, we don't want to\n        // fail the render phase where it didn't fail before. So we log it.\n        // After these have been cleaned up, we'll let them throw.\n\n        try {\n          // This is intentionally an invariant that gets caught. It's the same\n          // behavior as without this statement except with a better message.\n          if (typeof typeSpecs[typeSpecName] !== 'function') {\n            var err = Error((componentName || 'React class') + ': ' + location + ' type `' + typeSpecName + '` is invalid; ' + 'it must be a function, usually from the `prop-types` package, but received `' + typeof typeSpecs[typeSpecName] + '`.' + 'This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.');\n            err.name = 'Invariant Violation';\n            throw err;\n          }\n\n          error$1 = typeSpecs[typeSpecName](values, typeSpecName, componentName, location, null, 'SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED');\n        } catch (ex) {\n          error$1 = ex;\n        }\n\n        if (error$1 && !(error$1 instanceof Error)) {\n          setCurrentlyValidatingElement(element);\n\n          error('%s: type specification of %s' + ' `%s` is invalid; the type checker ' + 'function must return `null` or an `Error` but returned a %s. ' + 'You may have forgotten to pass an argument to the type checker ' + 'creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and ' + 'shape all require an argument).', componentName || 'React class', location, typeSpecName, typeof error$1);\n\n          setCurrentlyValidatingElement(null);\n        }\n\n        if (error$1 instanceof Error && !(error$1.message in loggedTypeFailures)) {\n          // Only monitor this failure once because there tends to be a lot of the\n          // same error.\n          loggedTypeFailures[error$1.message] = true;\n          setCurrentlyValidatingElement(element);\n\n          error('Failed %s type: %s', location, error$1.message);\n\n          setCurrentlyValidatingElement(null);\n        }\n      }\n    }\n  }\n}\n\nfunction setCurrentlyValidatingElement$1(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      setExtraStackFrame(stack);\n    } else {\n      setExtraStackFrame(null);\n    }\n  }\n}\n\nvar propTypesMisspellWarningShown;\n\n{\n  propTypesMisspellWarningShown = false;\n}\n\nfunction getDeclarationErrorAddendum() {\n  if (ReactCurrentOwner.current) {\n    var name = getComponentName(ReactCurrentOwner.current.type);\n\n    if (name) {\n      return '\\n\\nCheck the render method of `' + name + '`.';\n    }\n  }\n\n  return '';\n}\n\nfunction getSourceInfoErrorAddendum(source) {\n  if (source !== undefined) {\n    var fileName = source.fileName.replace(/^.*[\\\\\\/]/, '');\n    var lineNumber = source.lineNumber;\n    return '\\n\\nCheck your code at ' + fileName + ':' + lineNumber + '.';\n  }\n\n  return '';\n}\n\nfunction getSourceInfoErrorAddendumForProps(elementProps) {\n  if (elementProps !== null && elementProps !== undefined) {\n    return getSourceInfoErrorAddendum(elementProps.__source);\n  }\n\n  return '';\n}\n/**\n * Warn if there's no key explicitly set on dynamic arrays of children or\n * object keys are not valid. This allows us to keep track of children between\n * updates.\n */\n\n\nvar ownerHasKeyUseWarning = {};\n\nfunction getCurrentComponentErrorInfo(parentType) {\n  var info = getDeclarationErrorAddendum();\n\n  if (!info) {\n    var parentName = typeof parentType === 'string' ? parentType : parentType.displayName || parentType.name;\n\n    if (parentName) {\n      info = \"\\n\\nCheck the top-level render call using <\" + parentName + \">.\";\n    }\n  }\n\n  return info;\n}\n/**\n * Warn if the element doesn't have an explicit key assigned to it.\n * This element is in an array. The array could grow and shrink or be\n * reordered. All children that haven't already been validated are required to\n * have a \"key\" property assigned to it. Error statuses are cached so a warning\n * will only be shown once.\n *\n * @internal\n * @param {ReactElement} element Element that requires a key.\n * @param {*} parentType element's parent's type.\n */\n\n\nfunction validateExplicitKey(element, parentType) {\n  if (!element._store || element._store.validated || element.key != null) {\n    return;\n  }\n\n  element._store.validated = true;\n  var currentComponentErrorInfo = getCurrentComponentErrorInfo(parentType);\n\n  if (ownerHasKeyUseWarning[currentComponentErrorInfo]) {\n    return;\n  }\n\n  ownerHasKeyUseWarning[currentComponentErrorInfo] = true; // Usually the current owner is the offender, but if it accepts children as a\n  // property, it may be the creator of the child that's responsible for\n  // assigning it a key.\n\n  var childOwner = '';\n\n  if (element && element._owner && element._owner !== ReactCurrentOwner.current) {\n    // Give the component that originally created this child.\n    childOwner = \" It was passed a child from \" + getComponentName(element._owner.type) + \".\";\n  }\n\n  {\n    setCurrentlyValidatingElement$1(element);\n\n    error('Each child in a list should have a unique \"key\" prop.' + '%s%s See https://reactjs.org/link/warning-keys for more information.', currentComponentErrorInfo, childOwner);\n\n    setCurrentlyValidatingElement$1(null);\n  }\n}\n/**\n * Ensure that every element either is passed in a static location, in an\n * array with an explicit keys property defined, or in an object literal\n * with valid key property.\n *\n * @internal\n * @param {ReactNode} node Statically passed child of any type.\n * @param {*} parentType node's parent's type.\n */\n\n\nfunction validateChildKeys(node, parentType) {\n  if (typeof node !== 'object') {\n    return;\n  }\n\n  if (Array.isArray(node)) {\n    for (var i = 0; i < node.length; i++) {\n      var child = node[i];\n\n      if (isValidElement(child)) {\n        validateExplicitKey(child, parentType);\n      }\n    }\n  } else if (isValidElement(node)) {\n    // This element was passed in a valid location.\n    if (node._store) {\n      node._store.validated = true;\n    }\n  } else if (node) {\n    var iteratorFn = getIteratorFn(node);\n\n    if (typeof iteratorFn === 'function') {\n      // Entry iterators used to provide implicit keys,\n      // but now we print a separate warning for them later.\n      if (iteratorFn !== node.entries) {\n        var iterator = iteratorFn.call(node);\n        var step;\n\n        while (!(step = iterator.next()).done) {\n          if (isValidElement(step.value)) {\n            validateExplicitKey(step.value, parentType);\n          }\n        }\n      }\n    }\n  }\n}\n/**\n * Given an element, validate that its props follow the propTypes definition,\n * provided by the type.\n *\n * @param {ReactElement} element\n */\n\n\nfunction validatePropTypes(element) {\n  {\n    var type = element.type;\n\n    if (type === null || type === undefined || typeof type === 'string') {\n      return;\n    }\n\n    var propTypes;\n\n    if (typeof type === 'function') {\n      propTypes = type.propTypes;\n    } else if (typeof type === 'object' && (type.$$typeof === REACT_FORWARD_REF_TYPE || // Note: Memo only checks outer props here.\n    // Inner props are checked in the reconciler.\n    type.$$typeof === REACT_MEMO_TYPE)) {\n      propTypes = type.propTypes;\n    } else {\n      return;\n    }\n\n    if (propTypes) {\n      // Intentionally inside to avoid triggering lazy initializers:\n      var name = getComponentName(type);\n      checkPropTypes(propTypes, element.props, 'prop', name, element);\n    } else if (type.PropTypes !== undefined && !propTypesMisspellWarningShown) {\n      propTypesMisspellWarningShown = true; // Intentionally inside to avoid triggering lazy initializers:\n\n      var _name = getComponentName(type);\n\n      error('Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?', _name || 'Unknown');\n    }\n\n    if (typeof type.getDefaultProps === 'function' && !type.getDefaultProps.isReactClassApproved) {\n      error('getDefaultProps is only used on classic React.createClass ' + 'definitions. Use a static property named `defaultProps` instead.');\n    }\n  }\n}\n/**\n * Given a fragment, validate that it can only be provided with fragment props\n * @param {ReactElement} fragment\n */\n\n\nfunction validateFragmentProps(fragment) {\n  {\n    var keys = Object.keys(fragment.props);\n\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i];\n\n      if (key !== 'children' && key !== 'key') {\n        setCurrentlyValidatingElement$1(fragment);\n\n        error('Invalid prop `%s` supplied to `React.Fragment`. ' + 'React.Fragment can only have `key` and `children` props.', key);\n\n        setCurrentlyValidatingElement$1(null);\n        break;\n      }\n    }\n\n    if (fragment.ref !== null) {\n      setCurrentlyValidatingElement$1(fragment);\n\n      error('Invalid attribute `ref` supplied to `React.Fragment`.');\n\n      setCurrentlyValidatingElement$1(null);\n    }\n  }\n}\nfunction createElementWithValidation(type, props, children) {\n  var validType = isValidElementType(type); // We warn in this case but don't throw. We expect the element creation to\n  // succeed and there will likely be errors in render.\n\n  if (!validType) {\n    var info = '';\n\n    if (type === undefined || typeof type === 'object' && type !== null && Object.keys(type).length === 0) {\n      info += ' You likely forgot to export your component from the file ' + \"it's defined in, or you might have mixed up default and named imports.\";\n    }\n\n    var sourceInfo = getSourceInfoErrorAddendumForProps(props);\n\n    if (sourceInfo) {\n      info += sourceInfo;\n    } else {\n      info += getDeclarationErrorAddendum();\n    }\n\n    var typeString;\n\n    if (type === null) {\n      typeString = 'null';\n    } else if (Array.isArray(type)) {\n      typeString = 'array';\n    } else if (type !== undefined && type.$$typeof === REACT_ELEMENT_TYPE) {\n      typeString = \"<\" + (getComponentName(type.type) || 'Unknown') + \" />\";\n      info = ' Did you accidentally export a JSX literal instead of a component?';\n    } else {\n      typeString = typeof type;\n    }\n\n    {\n      error('React.createElement: type is invalid -- expected a string (for ' + 'built-in components) or a class/function (for composite ' + 'components) but got: %s.%s', typeString, info);\n    }\n  }\n\n  var element = createElement.apply(this, arguments); // The result can be nullish if a mock or a custom function is used.\n  // TODO: Drop this when these are no longer allowed as the type argument.\n\n  if (element == null) {\n    return element;\n  } // Skip key warning if the type isn't valid since our key validation logic\n  // doesn't expect a non-string/function type and can throw confusing errors.\n  // We don't want exception behavior to differ between dev and prod.\n  // (Rendering will throw with a helpful message and as soon as the type is\n  // fixed, the key warnings will appear.)\n\n\n  if (validType) {\n    for (var i = 2; i < arguments.length; i++) {\n      validateChildKeys(arguments[i], type);\n    }\n  }\n\n  if (type === exports.Fragment) {\n    validateFragmentProps(element);\n  } else {\n    validatePropTypes(element);\n  }\n\n  return element;\n}\nvar didWarnAboutDeprecatedCreateFactory = false;\nfunction createFactoryWithValidation(type) {\n  var validatedFactory = createElementWithValidation.bind(null, type);\n  validatedFactory.type = type;\n\n  {\n    if (!didWarnAboutDeprecatedCreateFactory) {\n      didWarnAboutDeprecatedCreateFactory = true;\n\n      warn('React.createFactory() is deprecated and will be removed in ' + 'a future major release. Consider using JSX ' + 'or use React.createElement() directly instead.');\n    } // Legacy hook: remove it\n\n\n    Object.defineProperty(validatedFactory, 'type', {\n      enumerable: false,\n      get: function () {\n        warn('Factory.type is deprecated. Access the class directly ' + 'before passing it to createFactory.');\n\n        Object.defineProperty(this, 'type', {\n          value: type\n        });\n        return type;\n      }\n    });\n  }\n\n  return validatedFactory;\n}\nfunction cloneElementWithValidation(element, props, children) {\n  var newElement = cloneElement.apply(this, arguments);\n\n  for (var i = 2; i < arguments.length; i++) {\n    validateChildKeys(arguments[i], newElement.type);\n  }\n\n  validatePropTypes(newElement);\n  return newElement;\n}\n\n{\n\n  try {\n    var frozenObject = Object.freeze({});\n    /* eslint-disable no-new */\n\n    new Map([[frozenObject, null]]);\n    new Set([frozenObject]);\n    /* eslint-enable no-new */\n  } catch (e) {\n  }\n}\n\nvar createElement$1 =  createElementWithValidation ;\nvar cloneElement$1 =  cloneElementWithValidation ;\nvar createFactory =  createFactoryWithValidation ;\nvar Children = {\n  map: mapChildren,\n  forEach: forEachChildren,\n  count: countChildren,\n  toArray: toArray,\n  only: onlyChild\n};\n\nexports.Children = Children;\nexports.Component = Component;\nexports.PureComponent = PureComponent;\nexports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED = ReactSharedInternals;\nexports.cloneElement = cloneElement$1;\nexports.createContext = createContext;\nexports.createElement = createElement$1;\nexports.createFactory = createFactory;\nexports.createRef = createRef;\nexports.forwardRef = forwardRef;\nexports.isValidElement = isValidElement;\nexports.lazy = lazy;\nexports.memo = memo;\nexports.useCallback = useCallback;\nexports.useContext = useContext;\nexports.useDebugValue = useDebugValue;\nexports.useEffect = useEffect;\nexports.useImperativeHandle = useImperativeHandle;\nexports.useLayoutEffect = useLayoutEffect;\nexports.useMemo = useMemo;\nexports.useReducer = useReducer;\nexports.useRef = useRef;\nexports.useState = useState;\nexports.version = ReactVersion;\n  })();\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/react/cjs/react.development.js?");

/***/ }),

/***/ "./node_modules/react/index.js":
/*!*************************************!*\
  !*** ./node_modules/react/index.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/react.development.js */ \"./node_modules/react/cjs/react.development.js\");\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/react/index.js?");

/***/ }),

/***/ "./node_modules/scheduler/cjs/scheduler-tracing.development.js":
/*!*********************************************************************!*\
  !*** ./node_modules/scheduler/cjs/scheduler-tracing.development.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("/** @license React v0.20.2\n * scheduler-tracing.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nvar DEFAULT_THREAD_ID = 0; // Counters used to generate unique IDs.\n\nvar interactionIDCounter = 0;\nvar threadIDCounter = 0; // Set of currently traced interactions.\n// Interactions \"stack\"–\n// Meaning that newly traced interactions are appended to the previously active set.\n// When an interaction goes out of scope, the previous set (if any) is restored.\n\nexports.__interactionsRef = null; // Listener(s) to notify when interactions begin and end.\n\nexports.__subscriberRef = null;\n\n{\n  exports.__interactionsRef = {\n    current: new Set()\n  };\n  exports.__subscriberRef = {\n    current: null\n  };\n}\nfunction unstable_clear(callback) {\n\n  var prevInteractions = exports.__interactionsRef.current;\n  exports.__interactionsRef.current = new Set();\n\n  try {\n    return callback();\n  } finally {\n    exports.__interactionsRef.current = prevInteractions;\n  }\n}\nfunction unstable_getCurrent() {\n  {\n    return exports.__interactionsRef.current;\n  }\n}\nfunction unstable_getThreadID() {\n  return ++threadIDCounter;\n}\nfunction unstable_trace(name, timestamp, callback) {\n  var threadID = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : DEFAULT_THREAD_ID;\n\n  var interaction = {\n    __count: 1,\n    id: interactionIDCounter++,\n    name: name,\n    timestamp: timestamp\n  };\n  var prevInteractions = exports.__interactionsRef.current; // Traced interactions should stack/accumulate.\n  // To do that, clone the current interactions.\n  // The previous set will be restored upon completion.\n\n  var interactions = new Set(prevInteractions);\n  interactions.add(interaction);\n  exports.__interactionsRef.current = interactions;\n  var subscriber = exports.__subscriberRef.current;\n  var returnValue;\n\n  try {\n    if (subscriber !== null) {\n      subscriber.onInteractionTraced(interaction);\n    }\n  } finally {\n    try {\n      if (subscriber !== null) {\n        subscriber.onWorkStarted(interactions, threadID);\n      }\n    } finally {\n      try {\n        returnValue = callback();\n      } finally {\n        exports.__interactionsRef.current = prevInteractions;\n\n        try {\n          if (subscriber !== null) {\n            subscriber.onWorkStopped(interactions, threadID);\n          }\n        } finally {\n          interaction.__count--; // If no async work was scheduled for this interaction,\n          // Notify subscribers that it's completed.\n\n          if (subscriber !== null && interaction.__count === 0) {\n            subscriber.onInteractionScheduledWorkCompleted(interaction);\n          }\n        }\n      }\n    }\n  }\n\n  return returnValue;\n}\nfunction unstable_wrap(callback) {\n  var threadID = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_THREAD_ID;\n\n  var wrappedInteractions = exports.__interactionsRef.current;\n  var subscriber = exports.__subscriberRef.current;\n\n  if (subscriber !== null) {\n    subscriber.onWorkScheduled(wrappedInteractions, threadID);\n  } // Update the pending async work count for the current interactions.\n  // Update after calling subscribers in case of error.\n\n\n  wrappedInteractions.forEach(function (interaction) {\n    interaction.__count++;\n  });\n  var hasRun = false;\n\n  function wrapped() {\n    var prevInteractions = exports.__interactionsRef.current;\n    exports.__interactionsRef.current = wrappedInteractions;\n    subscriber = exports.__subscriberRef.current;\n\n    try {\n      var returnValue;\n\n      try {\n        if (subscriber !== null) {\n          subscriber.onWorkStarted(wrappedInteractions, threadID);\n        }\n      } finally {\n        try {\n          returnValue = callback.apply(undefined, arguments);\n        } finally {\n          exports.__interactionsRef.current = prevInteractions;\n\n          if (subscriber !== null) {\n            subscriber.onWorkStopped(wrappedInteractions, threadID);\n          }\n        }\n      }\n\n      return returnValue;\n    } finally {\n      if (!hasRun) {\n        // We only expect a wrapped function to be executed once,\n        // But in the event that it's executed more than once–\n        // Only decrement the outstanding interaction counts once.\n        hasRun = true; // Update pending async counts for all wrapped interactions.\n        // If this was the last scheduled async work for any of them,\n        // Mark them as completed.\n\n        wrappedInteractions.forEach(function (interaction) {\n          interaction.__count--;\n\n          if (subscriber !== null && interaction.__count === 0) {\n            subscriber.onInteractionScheduledWorkCompleted(interaction);\n          }\n        });\n      }\n    }\n  }\n\n  wrapped.cancel = function cancel() {\n    subscriber = exports.__subscriberRef.current;\n\n    try {\n      if (subscriber !== null) {\n        subscriber.onWorkCanceled(wrappedInteractions, threadID);\n      }\n    } finally {\n      // Update pending async counts for all wrapped interactions.\n      // If this was the last scheduled async work for any of them,\n      // Mark them as completed.\n      wrappedInteractions.forEach(function (interaction) {\n        interaction.__count--;\n\n        if (subscriber && interaction.__count === 0) {\n          subscriber.onInteractionScheduledWorkCompleted(interaction);\n        }\n      });\n    }\n  };\n\n  return wrapped;\n}\n\nvar subscribers = null;\n\n{\n  subscribers = new Set();\n}\n\nfunction unstable_subscribe(subscriber) {\n  {\n    subscribers.add(subscriber);\n\n    if (subscribers.size === 1) {\n      exports.__subscriberRef.current = {\n        onInteractionScheduledWorkCompleted: onInteractionScheduledWorkCompleted,\n        onInteractionTraced: onInteractionTraced,\n        onWorkCanceled: onWorkCanceled,\n        onWorkScheduled: onWorkScheduled,\n        onWorkStarted: onWorkStarted,\n        onWorkStopped: onWorkStopped\n      };\n    }\n  }\n}\nfunction unstable_unsubscribe(subscriber) {\n  {\n    subscribers.delete(subscriber);\n\n    if (subscribers.size === 0) {\n      exports.__subscriberRef.current = null;\n    }\n  }\n}\n\nfunction onInteractionTraced(interaction) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onInteractionTraced(interaction);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onInteractionScheduledWorkCompleted(interaction) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onInteractionScheduledWorkCompleted(interaction);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkScheduled(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkScheduled(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkStarted(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkStarted(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkStopped(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkStopped(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkCanceled(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkCanceled(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nexports.unstable_clear = unstable_clear;\nexports.unstable_getCurrent = unstable_getCurrent;\nexports.unstable_getThreadID = unstable_getThreadID;\nexports.unstable_subscribe = unstable_subscribe;\nexports.unstable_trace = unstable_trace;\nexports.unstable_unsubscribe = unstable_unsubscribe;\nexports.unstable_wrap = unstable_wrap;\n  })();\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/scheduler/cjs/scheduler-tracing.development.js?");

/***/ }),

/***/ "./node_modules/scheduler/cjs/scheduler.development.js":
/*!*************************************************************!*\
  !*** ./node_modules/scheduler/cjs/scheduler.development.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("/** @license React v0.20.2\n * scheduler.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nvar enableSchedulerDebugging = false;\nvar enableProfiling = false;\n\nvar requestHostCallback;\nvar requestHostTimeout;\nvar cancelHostTimeout;\nvar requestPaint;\nvar hasPerformanceNow = typeof performance === 'object' && typeof performance.now === 'function';\n\nif (hasPerformanceNow) {\n  var localPerformance = performance;\n\n  exports.unstable_now = function () {\n    return localPerformance.now();\n  };\n} else {\n  var localDate = Date;\n  var initialTime = localDate.now();\n\n  exports.unstable_now = function () {\n    return localDate.now() - initialTime;\n  };\n}\n\nif ( // If Scheduler runs in a non-DOM environment, it falls back to a naive\n// implementation using setTimeout.\ntypeof window === 'undefined' || // Check if MessageChannel is supported, too.\ntypeof MessageChannel !== 'function') {\n  // If this accidentally gets imported in a non-browser environment, e.g. JavaScriptCore,\n  // fallback to a naive implementation.\n  var _callback = null;\n  var _timeoutID = null;\n\n  var _flushCallback = function () {\n    if (_callback !== null) {\n      try {\n        var currentTime = exports.unstable_now();\n        var hasRemainingTime = true;\n\n        _callback(hasRemainingTime, currentTime);\n\n        _callback = null;\n      } catch (e) {\n        setTimeout(_flushCallback, 0);\n        throw e;\n      }\n    }\n  };\n\n  requestHostCallback = function (cb) {\n    if (_callback !== null) {\n      // Protect against re-entrancy.\n      setTimeout(requestHostCallback, 0, cb);\n    } else {\n      _callback = cb;\n      setTimeout(_flushCallback, 0);\n    }\n  };\n\n  requestHostTimeout = function (cb, ms) {\n    _timeoutID = setTimeout(cb, ms);\n  };\n\n  cancelHostTimeout = function () {\n    clearTimeout(_timeoutID);\n  };\n\n  exports.unstable_shouldYield = function () {\n    return false;\n  };\n\n  requestPaint = exports.unstable_forceFrameRate = function () {};\n} else {\n  // Capture local references to native APIs, in case a polyfill overrides them.\n  var _setTimeout = window.setTimeout;\n  var _clearTimeout = window.clearTimeout;\n\n  if (typeof console !== 'undefined') {\n    // TODO: Scheduler no longer requires these methods to be polyfilled. But\n    // maybe we want to continue warning if they don't exist, to preserve the\n    // option to rely on it in the future?\n    var requestAnimationFrame = window.requestAnimationFrame;\n    var cancelAnimationFrame = window.cancelAnimationFrame;\n\n    if (typeof requestAnimationFrame !== 'function') {\n      // Using console['error'] to evade Babel and ESLint\n      console['error'](\"This browser doesn't support requestAnimationFrame. \" + 'Make sure that you load a ' + 'polyfill in older browsers. https://reactjs.org/link/react-polyfills');\n    }\n\n    if (typeof cancelAnimationFrame !== 'function') {\n      // Using console['error'] to evade Babel and ESLint\n      console['error'](\"This browser doesn't support cancelAnimationFrame. \" + 'Make sure that you load a ' + 'polyfill in older browsers. https://reactjs.org/link/react-polyfills');\n    }\n  }\n\n  var isMessageLoopRunning = false;\n  var scheduledHostCallback = null;\n  var taskTimeoutID = -1; // Scheduler periodically yields in case there is other work on the main\n  // thread, like user events. By default, it yields multiple times per frame.\n  // It does not attempt to align with frame boundaries, since most tasks don't\n  // need to be frame aligned; for those that do, use requestAnimationFrame.\n\n  var yieldInterval = 5;\n  var deadline = 0; // TODO: Make this configurable\n\n  {\n    // `isInputPending` is not available. Since we have no way of knowing if\n    // there's pending input, always yield at the end of the frame.\n    exports.unstable_shouldYield = function () {\n      return exports.unstable_now() >= deadline;\n    }; // Since we yield every frame regardless, `requestPaint` has no effect.\n\n\n    requestPaint = function () {};\n  }\n\n  exports.unstable_forceFrameRate = function (fps) {\n    if (fps < 0 || fps > 125) {\n      // Using console['error'] to evade Babel and ESLint\n      console['error']('forceFrameRate takes a positive int between 0 and 125, ' + 'forcing frame rates higher than 125 fps is not supported');\n      return;\n    }\n\n    if (fps > 0) {\n      yieldInterval = Math.floor(1000 / fps);\n    } else {\n      // reset the framerate\n      yieldInterval = 5;\n    }\n  };\n\n  var performWorkUntilDeadline = function () {\n    if (scheduledHostCallback !== null) {\n      var currentTime = exports.unstable_now(); // Yield after `yieldInterval` ms, regardless of where we are in the vsync\n      // cycle. This means there's always time remaining at the beginning of\n      // the message event.\n\n      deadline = currentTime + yieldInterval;\n      var hasTimeRemaining = true;\n\n      try {\n        var hasMoreWork = scheduledHostCallback(hasTimeRemaining, currentTime);\n\n        if (!hasMoreWork) {\n          isMessageLoopRunning = false;\n          scheduledHostCallback = null;\n        } else {\n          // If there's more work, schedule the next message event at the end\n          // of the preceding one.\n          port.postMessage(null);\n        }\n      } catch (error) {\n        // If a scheduler task throws, exit the current browser task so the\n        // error can be observed.\n        port.postMessage(null);\n        throw error;\n      }\n    } else {\n      isMessageLoopRunning = false;\n    } // Yielding to the browser will give it a chance to paint, so we can\n  };\n\n  var channel = new MessageChannel();\n  var port = channel.port2;\n  channel.port1.onmessage = performWorkUntilDeadline;\n\n  requestHostCallback = function (callback) {\n    scheduledHostCallback = callback;\n\n    if (!isMessageLoopRunning) {\n      isMessageLoopRunning = true;\n      port.postMessage(null);\n    }\n  };\n\n  requestHostTimeout = function (callback, ms) {\n    taskTimeoutID = _setTimeout(function () {\n      callback(exports.unstable_now());\n    }, ms);\n  };\n\n  cancelHostTimeout = function () {\n    _clearTimeout(taskTimeoutID);\n\n    taskTimeoutID = -1;\n  };\n}\n\nfunction push(heap, node) {\n  var index = heap.length;\n  heap.push(node);\n  siftUp(heap, node, index);\n}\nfunction peek(heap) {\n  var first = heap[0];\n  return first === undefined ? null : first;\n}\nfunction pop(heap) {\n  var first = heap[0];\n\n  if (first !== undefined) {\n    var last = heap.pop();\n\n    if (last !== first) {\n      heap[0] = last;\n      siftDown(heap, last, 0);\n    }\n\n    return first;\n  } else {\n    return null;\n  }\n}\n\nfunction siftUp(heap, node, i) {\n  var index = i;\n\n  while (true) {\n    var parentIndex = index - 1 >>> 1;\n    var parent = heap[parentIndex];\n\n    if (parent !== undefined && compare(parent, node) > 0) {\n      // The parent is larger. Swap positions.\n      heap[parentIndex] = node;\n      heap[index] = parent;\n      index = parentIndex;\n    } else {\n      // The parent is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction siftDown(heap, node, i) {\n  var index = i;\n  var length = heap.length;\n\n  while (index < length) {\n    var leftIndex = (index + 1) * 2 - 1;\n    var left = heap[leftIndex];\n    var rightIndex = leftIndex + 1;\n    var right = heap[rightIndex]; // If the left or right node is smaller, swap with the smaller of those.\n\n    if (left !== undefined && compare(left, node) < 0) {\n      if (right !== undefined && compare(right, left) < 0) {\n        heap[index] = right;\n        heap[rightIndex] = node;\n        index = rightIndex;\n      } else {\n        heap[index] = left;\n        heap[leftIndex] = node;\n        index = leftIndex;\n      }\n    } else if (right !== undefined && compare(right, node) < 0) {\n      heap[index] = right;\n      heap[rightIndex] = node;\n      index = rightIndex;\n    } else {\n      // Neither child is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction compare(a, b) {\n  // Compare sort index first, then task id.\n  var diff = a.sortIndex - b.sortIndex;\n  return diff !== 0 ? diff : a.id - b.id;\n}\n\n// TODO: Use symbols?\nvar ImmediatePriority = 1;\nvar UserBlockingPriority = 2;\nvar NormalPriority = 3;\nvar LowPriority = 4;\nvar IdlePriority = 5;\n\nfunction markTaskErrored(task, ms) {\n}\n\n/* eslint-disable no-var */\n// Math.pow(2, 30) - 1\n// 0b111111111111111111111111111111\n\nvar maxSigned31BitInt = 1073741823; // Times out immediately\n\nvar IMMEDIATE_PRIORITY_TIMEOUT = -1; // Eventually times out\n\nvar USER_BLOCKING_PRIORITY_TIMEOUT = 250;\nvar NORMAL_PRIORITY_TIMEOUT = 5000;\nvar LOW_PRIORITY_TIMEOUT = 10000; // Never times out\n\nvar IDLE_PRIORITY_TIMEOUT = maxSigned31BitInt; // Tasks are stored on a min heap\n\nvar taskQueue = [];\nvar timerQueue = []; // Incrementing id counter. Used to maintain insertion order.\n\nvar taskIdCounter = 1; // Pausing the scheduler is useful for debugging.\nvar currentTask = null;\nvar currentPriorityLevel = NormalPriority; // This is set while performing work, to prevent re-entrancy.\n\nvar isPerformingWork = false;\nvar isHostCallbackScheduled = false;\nvar isHostTimeoutScheduled = false;\n\nfunction advanceTimers(currentTime) {\n  // Check for tasks that are no longer delayed and add them to the queue.\n  var timer = peek(timerQueue);\n\n  while (timer !== null) {\n    if (timer.callback === null) {\n      // Timer was cancelled.\n      pop(timerQueue);\n    } else if (timer.startTime <= currentTime) {\n      // Timer fired. Transfer to the task queue.\n      pop(timerQueue);\n      timer.sortIndex = timer.expirationTime;\n      push(taskQueue, timer);\n    } else {\n      // Remaining timers are pending.\n      return;\n    }\n\n    timer = peek(timerQueue);\n  }\n}\n\nfunction handleTimeout(currentTime) {\n  isHostTimeoutScheduled = false;\n  advanceTimers(currentTime);\n\n  if (!isHostCallbackScheduled) {\n    if (peek(taskQueue) !== null) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    } else {\n      var firstTimer = peek(timerQueue);\n\n      if (firstTimer !== null) {\n        requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n      }\n    }\n  }\n}\n\nfunction flushWork(hasTimeRemaining, initialTime) {\n\n\n  isHostCallbackScheduled = false;\n\n  if (isHostTimeoutScheduled) {\n    // We scheduled a timeout but it's no longer needed. Cancel it.\n    isHostTimeoutScheduled = false;\n    cancelHostTimeout();\n  }\n\n  isPerformingWork = true;\n  var previousPriorityLevel = currentPriorityLevel;\n\n  try {\n    if (enableProfiling) {\n      try {\n        return workLoop(hasTimeRemaining, initialTime);\n      } catch (error) {\n        if (currentTask !== null) {\n          var currentTime = exports.unstable_now();\n          markTaskErrored(currentTask, currentTime);\n          currentTask.isQueued = false;\n        }\n\n        throw error;\n      }\n    } else {\n      // No catch in prod code path.\n      return workLoop(hasTimeRemaining, initialTime);\n    }\n  } finally {\n    currentTask = null;\n    currentPriorityLevel = previousPriorityLevel;\n    isPerformingWork = false;\n  }\n}\n\nfunction workLoop(hasTimeRemaining, initialTime) {\n  var currentTime = initialTime;\n  advanceTimers(currentTime);\n  currentTask = peek(taskQueue);\n\n  while (currentTask !== null && !(enableSchedulerDebugging )) {\n    if (currentTask.expirationTime > currentTime && (!hasTimeRemaining || exports.unstable_shouldYield())) {\n      // This currentTask hasn't expired, and we've reached the deadline.\n      break;\n    }\n\n    var callback = currentTask.callback;\n\n    if (typeof callback === 'function') {\n      currentTask.callback = null;\n      currentPriorityLevel = currentTask.priorityLevel;\n      var didUserCallbackTimeout = currentTask.expirationTime <= currentTime;\n\n      var continuationCallback = callback(didUserCallbackTimeout);\n      currentTime = exports.unstable_now();\n\n      if (typeof continuationCallback === 'function') {\n        currentTask.callback = continuationCallback;\n      } else {\n\n        if (currentTask === peek(taskQueue)) {\n          pop(taskQueue);\n        }\n      }\n\n      advanceTimers(currentTime);\n    } else {\n      pop(taskQueue);\n    }\n\n    currentTask = peek(taskQueue);\n  } // Return whether there's additional work\n\n\n  if (currentTask !== null) {\n    return true;\n  } else {\n    var firstTimer = peek(timerQueue);\n\n    if (firstTimer !== null) {\n      requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n    }\n\n    return false;\n  }\n}\n\nfunction unstable_runWithPriority(priorityLevel, eventHandler) {\n  switch (priorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n    case LowPriority:\n    case IdlePriority:\n      break;\n\n    default:\n      priorityLevel = NormalPriority;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_next(eventHandler) {\n  var priorityLevel;\n\n  switch (currentPriorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n      // Shift down to normal priority\n      priorityLevel = NormalPriority;\n      break;\n\n    default:\n      // Anything lower than normal priority should remain at the current level.\n      priorityLevel = currentPriorityLevel;\n      break;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_wrapCallback(callback) {\n  var parentPriorityLevel = currentPriorityLevel;\n  return function () {\n    // This is a fork of runWithPriority, inlined for performance.\n    var previousPriorityLevel = currentPriorityLevel;\n    currentPriorityLevel = parentPriorityLevel;\n\n    try {\n      return callback.apply(this, arguments);\n    } finally {\n      currentPriorityLevel = previousPriorityLevel;\n    }\n  };\n}\n\nfunction unstable_scheduleCallback(priorityLevel, callback, options) {\n  var currentTime = exports.unstable_now();\n  var startTime;\n\n  if (typeof options === 'object' && options !== null) {\n    var delay = options.delay;\n\n    if (typeof delay === 'number' && delay > 0) {\n      startTime = currentTime + delay;\n    } else {\n      startTime = currentTime;\n    }\n  } else {\n    startTime = currentTime;\n  }\n\n  var timeout;\n\n  switch (priorityLevel) {\n    case ImmediatePriority:\n      timeout = IMMEDIATE_PRIORITY_TIMEOUT;\n      break;\n\n    case UserBlockingPriority:\n      timeout = USER_BLOCKING_PRIORITY_TIMEOUT;\n      break;\n\n    case IdlePriority:\n      timeout = IDLE_PRIORITY_TIMEOUT;\n      break;\n\n    case LowPriority:\n      timeout = LOW_PRIORITY_TIMEOUT;\n      break;\n\n    case NormalPriority:\n    default:\n      timeout = NORMAL_PRIORITY_TIMEOUT;\n      break;\n  }\n\n  var expirationTime = startTime + timeout;\n  var newTask = {\n    id: taskIdCounter++,\n    callback: callback,\n    priorityLevel: priorityLevel,\n    startTime: startTime,\n    expirationTime: expirationTime,\n    sortIndex: -1\n  };\n\n  if (startTime > currentTime) {\n    // This is a delayed task.\n    newTask.sortIndex = startTime;\n    push(timerQueue, newTask);\n\n    if (peek(taskQueue) === null && newTask === peek(timerQueue)) {\n      // All tasks are delayed, and this is the task with the earliest delay.\n      if (isHostTimeoutScheduled) {\n        // Cancel an existing timeout.\n        cancelHostTimeout();\n      } else {\n        isHostTimeoutScheduled = true;\n      } // Schedule a timeout.\n\n\n      requestHostTimeout(handleTimeout, startTime - currentTime);\n    }\n  } else {\n    newTask.sortIndex = expirationTime;\n    push(taskQueue, newTask);\n    // wait until the next time we yield.\n\n\n    if (!isHostCallbackScheduled && !isPerformingWork) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    }\n  }\n\n  return newTask;\n}\n\nfunction unstable_pauseExecution() {\n}\n\nfunction unstable_continueExecution() {\n\n  if (!isHostCallbackScheduled && !isPerformingWork) {\n    isHostCallbackScheduled = true;\n    requestHostCallback(flushWork);\n  }\n}\n\nfunction unstable_getFirstCallbackNode() {\n  return peek(taskQueue);\n}\n\nfunction unstable_cancelCallback(task) {\n  // remove from the queue because you can't remove arbitrary nodes from an\n  // array based heap, only the first one.)\n\n\n  task.callback = null;\n}\n\nfunction unstable_getCurrentPriorityLevel() {\n  return currentPriorityLevel;\n}\n\nvar unstable_requestPaint = requestPaint;\nvar unstable_Profiling =  null;\n\nexports.unstable_IdlePriority = IdlePriority;\nexports.unstable_ImmediatePriority = ImmediatePriority;\nexports.unstable_LowPriority = LowPriority;\nexports.unstable_NormalPriority = NormalPriority;\nexports.unstable_Profiling = unstable_Profiling;\nexports.unstable_UserBlockingPriority = UserBlockingPriority;\nexports.unstable_cancelCallback = unstable_cancelCallback;\nexports.unstable_continueExecution = unstable_continueExecution;\nexports.unstable_getCurrentPriorityLevel = unstable_getCurrentPriorityLevel;\nexports.unstable_getFirstCallbackNode = unstable_getFirstCallbackNode;\nexports.unstable_next = unstable_next;\nexports.unstable_pauseExecution = unstable_pauseExecution;\nexports.unstable_requestPaint = unstable_requestPaint;\nexports.unstable_runWithPriority = unstable_runWithPriority;\nexports.unstable_scheduleCallback = unstable_scheduleCallback;\nexports.unstable_wrapCallback = unstable_wrapCallback;\n  })();\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/scheduler/cjs/scheduler.development.js?");

/***/ }),

/***/ "./node_modules/scheduler/index.js":
/*!*****************************************!*\
  !*** ./node_modules/scheduler/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/scheduler.development.js */ \"./node_modules/scheduler/cjs/scheduler.development.js\");\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/scheduler/index.js?");

/***/ }),

/***/ "./node_modules/scheduler/tracing.js":
/*!*******************************************!*\
  !*** ./node_modules/scheduler/tracing.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/scheduler-tracing.development.js */ \"./node_modules/scheduler/cjs/scheduler-tracing.development.js\");\n}\n\n\n//# sourceURL=webpack://react-demo/./node_modules/scheduler/tracing.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/constants.js":
/*!***************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/constants.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MOST_NEGATIVE_SINGLE_FLOAT\": () => (/* binding */ MOST_NEGATIVE_SINGLE_FLOAT),\n/* harmony export */   \"MOST_POSITIVE_SINGLE_FLOAT\": () => (/* binding */ MOST_POSITIVE_SINGLE_FLOAT)\n/* harmony export */ });\nconst MOST_NEGATIVE_SINGLE_FLOAT = -3.4028234663852886e38;\nconst MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/constants.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAbortError\": () => (/* binding */ createAbortError)\n/* harmony export */ });\nconst createAbortError = () => new DOMException('', 'AbortError');\n//# sourceMappingURL=abort-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddActiveInputConnectionToAudioNode\": () => (/* binding */ createAddActiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createAddActiveInputConnectionToAudioNode = (insertElementInSet) => {\n    return (activeInputs, source, [output, input, eventListener], ignoreDuplicates) => {\n        insertElementInSet(activeInputs[input], [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);\n    };\n};\n//# sourceMappingURL=add-active-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioNodeConnections\": () => (/* binding */ createAddAudioNodeConnections)\n/* harmony export */ });\nconst createAddAudioNodeConnections = (audioNodeConnectionsStore) => {\n    return (audioNode, audioNodeRenderer, nativeAudioNode) => {\n        const activeInputs = [];\n        for (let i = 0; i < nativeAudioNode.numberOfInputs; i += 1) {\n            activeInputs.push(new Set());\n        }\n        audioNodeConnectionsStore.set(audioNode, {\n            activeInputs,\n            outputs: new Set(),\n            passiveInputs: new WeakMap(),\n            renderer: audioNodeRenderer\n        });\n    };\n};\n//# sourceMappingURL=add-audio-node-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioParamConnections\": () => (/* binding */ createAddAudioParamConnections)\n/* harmony export */ });\nconst createAddAudioParamConnections = (audioParamConnectionsStore) => {\n    return (audioParam, audioParamRenderer) => {\n        audioParamConnectionsStore.set(audioParam, { activeInputs: new Set(), passiveInputs: new WeakMap(), renderer: audioParamRenderer });\n    };\n};\n//# sourceMappingURL=add-audio-param-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioWorkletModule\": () => (/* binding */ createAddAudioWorkletModule)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _helpers_is_constructible__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-constructible */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js\");\n/* harmony import */ var _helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/split-import-statements */ \"./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js\");\n\n\n\nconst verifyParameterDescriptors = (parameterDescriptors) => {\n    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) {\n        throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');\n    }\n};\nconst verifyProcessorCtor = (processorCtor) => {\n    if (!(0,_helpers_is_constructible__WEBPACK_IMPORTED_MODULE_1__.isConstructible)(processorCtor)) {\n        throw new TypeError('The given value for processorCtor should be a constructor.');\n    }\n    if (processorCtor.prototype === null || typeof processorCtor.prototype !== 'object') {\n        throw new TypeError('The given value for processorCtor should have a prototype.');\n    }\n};\nconst createAddAudioWorkletModule = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window) => {\n    let index = 0;\n    return (context, moduleURL, options = { credentials: 'omit' }) => {\n        const resolvedRequestsOfContext = resolvedRequests.get(context);\n        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) {\n            return Promise.resolve();\n        }\n        const ongoingRequestsOfContext = ongoingRequests.get(context);\n        if (ongoingRequestsOfContext !== undefined) {\n            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);\n            if (promiseOfOngoingRequest !== undefined) {\n                return promiseOfOngoingRequest;\n            }\n        }\n        const nativeContext = getNativeContext(context);\n        // Bug #59: Safari does not implement the audioWorklet property.\n        const promise = nativeContext.audioWorklet === undefined\n            ? fetchSource(moduleURL)\n                .then(([source, absoluteUrl]) => {\n                const [importStatements, sourceWithoutImportStatements] = (0,_helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__.splitImportStatements)(source, absoluteUrl);\n                /*\n                 * This is the unminified version of the code used below:\n                 *\n                 * ```js\n                 * ${ importStatements };\n                 * ((a, b) => {\n                 *     (a[b] = a[b] || [ ]).push(\n                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {\n                 *             ${ sourceWithoutImportStatements }\n                 *         }\n                 *     );\n                 * })(window, '_AWGS');\n                 * ```\n                 */\n                // tslint:disable-next-line:max-line-length\n                const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}\n})})(window,'_AWGS')`;\n                // @todo Evaluating the given source code is a possible security problem.\n                return evaluateSource(wrappedSource);\n            })\n                .then(() => {\n                const evaluateAudioWorkletGlobalScope = window._AWGS.pop();\n                if (evaluateAudioWorkletGlobalScope === undefined) {\n                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n                    throw new SyntaxError();\n                }\n                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {\n                }, undefined, (name, processorCtor) => {\n                    if (name.trim() === '') {\n                        throw createNotSupportedError();\n                    }\n                    const nodeNameToProcessorConstructorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n                    if (nodeNameToProcessorConstructorMap !== undefined) {\n                        if (nodeNameToProcessorConstructorMap.has(name)) {\n                            throw createNotSupportedError();\n                        }\n                        verifyProcessorCtor(processorCtor);\n                        verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                        nodeNameToProcessorConstructorMap.set(name, processorCtor);\n                    }\n                    else {\n                        verifyProcessorCtor(processorCtor);\n                        verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                        _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.set(nativeContext, new Map([[name, processorCtor]]));\n                    }\n                }, nativeContext.sampleRate, undefined, undefined));\n            })\n            : Promise.all([\n                fetchSource(moduleURL),\n                Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))\n            ]).then(([[source, absoluteUrl], isSupportingPostMessage]) => {\n                const currentIndex = index + 1;\n                index = currentIndex;\n                const [importStatements, sourceWithoutImportStatements] = (0,_helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__.splitImportStatements)(source, absoluteUrl);\n                /*\n                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\n                 *\n                 * This is the unminified version of the code used below.\n                 *\n                 * ```js\n                 * class extends AudioWorkletProcessor {\n                 *\n                 *     __buffers = new WeakSet();\n                 *\n                 *     constructor () {\n                 *         super();\n                 *\n                 *         this.port.postMessage = ((postMessage) => {\n                 *             return (message, transferables) => {\n                 *                 const filteredTransferables = (transferables)\n                 *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))\n                 *                     : transferables;\n                 *\n                 *                 return postMessage.call(this.port, message, filteredTransferables);\n                 *              };\n                 *         })(this.port.postMessage);\n                 *     }\n                 * }\n                 * ```\n                 */\n                const patchedAudioWorkletProcessor = isSupportingPostMessage\n                    ? 'AudioWorkletProcessor'\n                    : 'class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}';\n                /*\n                 * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.\n                 *\n                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\n                 *\n                 * Bug #190: Safari doesn't throw an error when loading an unparsable module.\n                 *\n                 * This is the unminified version of the code used below:\n                 *\n                 * ```js\n                 * `${ importStatements };\n                 * ((AudioWorkletProcessor, registerProcessor) => {${ sourceWithoutImportStatements }\n                 * })(\n                 *     ${ patchedAudioWorkletProcessor },\n                 *     (name, processorCtor) => registerProcessor(name, class extends processorCtor {\n                 *\n                 *         __collectBuffers = (array) => {\n                 *             array.forEach((element) => this.__buffers.add(element.buffer));\n                 *         };\n                 *\n                 *         process (inputs, outputs, parameters) {\n                 *             inputs.forEach(this.__collectBuffers);\n                 *             outputs.forEach(this.__collectBuffers);\n                 *             this.__collectBuffers(Object.values(parameters));\n                 *\n                 *             return super.process(\n                 *                 (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),\n                 *                 outputs,\n                 *                 parameters\n                 *             );\n                 *         }\n                 *\n                 *     })\n                 * );\n                 *\n                 * registerProcessor(`__sac${currentIndex}`, class extends AudioWorkletProcessor{\n                 *\n                 *     process () {\n                 *         return false;\n                 *     }\n                 *\n                 * })`\n                 * ```\n                 */\n                const memberDefinition = isSupportingPostMessage ? '' : '__c = (a) => a.forEach(e=>this.__b.add(e.buffer));';\n                const bufferRegistration = isSupportingPostMessage\n                    ? ''\n                    : 'i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));';\n                const wrappedSource = `${importStatements};((AudioWorkletProcessor,registerProcessor)=>{${sourceWithoutImportStatements}\n})(${patchedAudioWorkletProcessor},(n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${currentIndex}',class extends AudioWorkletProcessor{process(){return !1}})`;\n                const blob = new Blob([wrappedSource], { type: 'application/javascript; charset=utf-8' });\n                const url = URL.createObjectURL(blob);\n                return nativeContext.audioWorklet\n                    .addModule(url, options)\n                    .then(() => {\n                    if (isNativeOfflineAudioContext(nativeContext)) {\n                        return nativeContext;\n                    }\n                    // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.\n                    const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);\n                    return backupOfflineAudioContext.audioWorklet.addModule(url, options).then(() => backupOfflineAudioContext);\n                })\n                    .then((nativeContextOrBackupOfflineAudioContext) => {\n                    if (nativeAudioWorkletNodeConstructor === null) {\n                        throw new SyntaxError();\n                    }\n                    try {\n                        // Bug #190: Safari doesn't throw an error when loading an unparsable module.\n                        new nativeAudioWorkletNodeConstructor(nativeContextOrBackupOfflineAudioContext, `__sac${currentIndex}`); // tslint:disable-line:no-unused-expression\n                    }\n                    catch {\n                        throw new SyntaxError();\n                    }\n                })\n                    .finally(() => URL.revokeObjectURL(url));\n            });\n        if (ongoingRequestsOfContext === undefined) {\n            ongoingRequests.set(context, new Map([[moduleURL, promise]]));\n        }\n        else {\n            ongoingRequestsOfContext.set(moduleURL, promise);\n        }\n        promise\n            .then(() => {\n            const updatedResolvedRequestsOfContext = resolvedRequests.get(context);\n            if (updatedResolvedRequestsOfContext === undefined) {\n                resolvedRequests.set(context, new Set([moduleURL]));\n            }\n            else {\n                updatedResolvedRequestsOfContext.add(moduleURL);\n            }\n        })\n            .finally(() => {\n            const updatedOngoingRequestsOfContext = ongoingRequests.get(context);\n            if (updatedOngoingRequestsOfContext !== undefined) {\n                updatedOngoingRequestsOfContext.delete(moduleURL);\n            }\n        });\n        return promise;\n    };\n};\n//# sourceMappingURL=add-audio-worklet-module.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddConnectionToAudioNode\": () => (/* binding */ createAddConnectionToAudioNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive-when-necessary */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js\");\n\n\n\nconst createAddConnectionToAudioNode = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode) => {\n    const tailTimeTimeoutIds = new WeakMap();\n    return (source, destination, output, input, isOffline) => {\n        const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);\n        const { outputs } = getAudioNodeConnections(source);\n        const eventListeners = getEventListenersOfAudioNode(source);\n        const eventListener = (isActive) => {\n            const nativeDestinationAudioNode = getNativeAudioNode(destination);\n            const nativeSourceAudioNode = getNativeAudioNode(source);\n            if (isActive) {\n                const partialConnection = (0,_helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_0__.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);\n                addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);\n                if (!isOffline && !isPartOfACycle(source)) {\n                    connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n                }\n                if (isPassiveAudioNode(destination)) {\n                    (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToActive)(destination);\n                }\n            }\n            else {\n                const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);\n                addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);\n                if (!isOffline && !isPartOfACycle(source)) {\n                    disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n                }\n                const tailTime = getAudioNodeTailTime(destination);\n                if (tailTime === 0) {\n                    if (isActiveAudioNode(destination)) {\n                        (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n                    }\n                }\n                else {\n                    const tailTimeTimeoutId = tailTimeTimeoutIds.get(destination);\n                    if (tailTimeTimeoutId !== undefined) {\n                        clearTimeout(tailTimeTimeoutId);\n                    }\n                    tailTimeTimeoutIds.set(destination, setTimeout(() => {\n                        if (isActiveAudioNode(destination)) {\n                            (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n                        }\n                    }, tailTime * 1000));\n                }\n            }\n        };\n        if (insertElementInSet(outputs, [destination, output, input], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input, true)) {\n            eventListeners.add(eventListener);\n            if (isActiveAudioNode(source)) {\n                addActiveInputConnectionToAudioNode(activeInputs, source, [output, input, eventListener], true);\n            }\n            else {\n                addPassiveInputConnectionToAudioNode(passiveInputs, input, [source, output, eventListener], true);\n            }\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=add-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddPassiveInputConnectionToAudioNode\": () => (/* binding */ createAddPassiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createAddPassiveInputConnectionToAudioNode = (insertElementInSet) => {\n    return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates) => {\n        const passiveInputConnections = passiveInputs.get(source);\n        if (passiveInputConnections === undefined) {\n            passiveInputs.set(source, new Set([[output, input, eventListener]]));\n        }\n        else {\n            insertElementInSet(passiveInputConnections, [output, input, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input, ignoreDuplicates);\n        }\n    };\n};\n//# sourceMappingURL=add-passive-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddSilentConnection\": () => (/* binding */ createAddSilentConnection)\n/* harmony export */ });\nconst createAddSilentConnection = (createNativeGainNode) => {\n    return (nativeContext, nativeAudioScheduledSourceNode) => {\n        const nativeGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);\n        const disconnect = () => {\n            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnect);\n            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        nativeAudioScheduledSourceNode.addEventListener('ended', disconnect);\n    };\n};\n//# sourceMappingURL=add-silent-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddUnrenderedAudioWorkletNode\": () => (/* binding */ createAddUnrenderedAudioWorkletNode)\n/* harmony export */ });\nconst createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=add-unrendered-audio-worklet-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAnalyserNodeConstructor\": () => (/* binding */ createAnalyserNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    fftSize: 2048,\n    maxDecibels: -30,\n    minDecibels: -100,\n    smoothingTimeConstant: 0.8\n};\nconst createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class AnalyserNode extends audionNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);\n            const analyserNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null));\n            super(context, false, nativeAnalyserNode, analyserNodeRenderer);\n            this._nativeAnalyserNode = nativeAnalyserNode;\n        }\n        get fftSize() {\n            return this._nativeAnalyserNode.fftSize;\n        }\n        set fftSize(value) {\n            this._nativeAnalyserNode.fftSize = value;\n        }\n        get frequencyBinCount() {\n            return this._nativeAnalyserNode.frequencyBinCount;\n        }\n        get maxDecibels() {\n            return this._nativeAnalyserNode.maxDecibels;\n        }\n        set maxDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const maxDecibels = this._nativeAnalyserNode.maxDecibels;\n            this._nativeAnalyserNode.maxDecibels = value;\n            if (!(value > this._nativeAnalyserNode.minDecibels)) {\n                this._nativeAnalyserNode.maxDecibels = maxDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get minDecibels() {\n            return this._nativeAnalyserNode.minDecibels;\n        }\n        set minDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const minDecibels = this._nativeAnalyserNode.minDecibels;\n            this._nativeAnalyserNode.minDecibels = value;\n            if (!(this._nativeAnalyserNode.maxDecibels > value)) {\n                this._nativeAnalyserNode.minDecibels = minDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get smoothingTimeConstant() {\n            return this._nativeAnalyserNode.smoothingTimeConstant;\n        }\n        set smoothingTimeConstant(value) {\n            this._nativeAnalyserNode.smoothingTimeConstant = value;\n        }\n        getByteFrequencyData(array) {\n            this._nativeAnalyserNode.getByteFrequencyData(array);\n        }\n        getByteTimeDomainData(array) {\n            this._nativeAnalyserNode.getByteTimeDomainData(array);\n        }\n        getFloatFrequencyData(array) {\n            this._nativeAnalyserNode.getFloatFrequencyData(array);\n        }\n        getFloatTimeDomainData(array) {\n            this._nativeAnalyserNode.getFloatTimeDomainData(array);\n        }\n    };\n};\n//# sourceMappingURL=analyser-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAnalyserNodeRendererFactory\": () => (/* binding */ createAnalyserNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAnalyserNodes = new WeakMap();\n        const createAnalyserNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAnalyserNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAnalyserNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAnalyserNode, nativeOfflineAudioContext);\n            if (!nativeAnalyserNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                };\n                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);\n            return nativeAnalyserNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAnalyserNode !== undefined) {\n                    return Promise.resolve(renderedNativeAnalyserNode);\n                }\n                return createAnalyserNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=analyser-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferConstructor\": () => (/* binding */ createAudioBufferConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    let nativeOfflineAudioContext = null;\n    return class AudioBuffer {\n        constructor(options) {\n            if (nativeOfflineAudioContextConstructor === null) {\n                throw new Error('Missing the native OfflineAudioContext constructor.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            if (nativeOfflineAudioContext === null) {\n                nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n            }\n            /*\n             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the\n             * factory function. But since Firefox also supports the constructor everything should be fine.\n             */\n            const audioBuffer = nativeAudioBufferConstructor !== null &&\n                cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport)\n                ? new nativeAudioBufferConstructor({ length, numberOfChannels, sampleRate })\n                : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);\n            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.\n            if (audioBuffer.numberOfChannels === 0) {\n                throw createNotSupportedError();\n            }\n            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n            if (typeof audioBuffer.copyFromChannel !== 'function') {\n                wrapAudioBufferCopyChannelMethods(audioBuffer);\n                (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n                // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n            }\n            else if (!cacheTestResult(_helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => (0,_helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport)(audioBuffer))) {\n                wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n            }\n            audioBufferStore.add(audioBuffer);\n            /*\n             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native\n             * (Offline)AudioContexts.\n             */\n            return audioBuffer;\n        }\n        static [Symbol.hasInstance](instance) {\n            return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === AudioBuffer.prototype) ||\n                audioBufferStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferSourceNodeConstructor\": () => (/* binding */ createAudioBufferSourceNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\nconst DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    // Bug #149: Safari does not yet support the detune AudioParam.\n    loop: false,\n    loopEnd: 0,\n    loopStart: 0,\n    playbackRate: 1\n};\nconst createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class AudioBufferSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const audioBufferSourceNodeRenderer = ((isOffline ? createAudioBufferSourceNodeRenderer() : null));\n            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);\n            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;\n            this._isBufferNullified = false;\n            this._isBufferSet = mergedOptions.buffer !== null;\n            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;\n            this._onended = null;\n            // Bug #73: Safari does not export the correct values for maxValue and minValue.\n            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeAudioBufferSourceNode.buffer;\n        }\n        set buffer(value) {\n            this._nativeAudioBufferSourceNode.buffer = value;\n            // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.\n            if (value !== null) {\n                if (this._isBufferSet) {\n                    throw createInvalidStateError();\n                }\n                this._isBufferSet = true;\n            }\n        }\n        get loop() {\n            return this._nativeAudioBufferSourceNode.loop;\n        }\n        set loop(value) {\n            this._nativeAudioBufferSourceNode.loop = value;\n        }\n        get loopEnd() {\n            return this._nativeAudioBufferSourceNode.loopEnd;\n        }\n        set loopEnd(value) {\n            this._nativeAudioBufferSourceNode.loopEnd = value;\n        }\n        get loopStart() {\n            return this._nativeAudioBufferSourceNode.loopStart;\n        }\n        set loopStart(value) {\n            this._nativeAudioBufferSourceNode.loopStart = value;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeAudioBufferSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        get playbackRate() {\n            return this._playbackRate;\n        }\n        start(when = 0, offset = 0, duration) {\n            this._nativeAudioBufferSourceNode.start(when, offset, duration);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.start = duration === undefined ? [when, offset] : [when, offset, duration];\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeAudioBufferSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeAudioBufferSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeAudioBufferSourceNode.stop(when);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-buffer-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferSourceNodeRendererFactory\": () => (/* binding */ createAudioBufferSourceNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioBufferSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeAudioBufferSourceNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioBufferSourceNode, nativeOfflineAudioContext);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeAudioBufferSourceNode.buffer,\n                    channelCount: nativeAudioBufferSourceNode.channelCount,\n                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,\n                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,\n                    // Bug #149: Safari does not yet support the detune AudioParam.\n                    loop: nativeAudioBufferSourceNode.loop,\n                    loopEnd: nativeAudioBufferSourceNode.loopEnd,\n                    loopStart: nativeAudioBufferSourceNode.loopStart,\n                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value\n                };\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeAudioBufferSourceNode.start(...start);\n                }\n                if (stop !== null) {\n                    nativeAudioBufferSourceNode.stop(stop);\n                }\n            }\n            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);\n            }\n            else {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode);\n            return nativeAudioBufferSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioBufferSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioBufferSourceNode);\n                }\n                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioContextConstructor\": () => (/* binding */ createAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-valid-latency-hint */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js\");\n\n\nconst createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor) => {\n    return class AudioContext extends baseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            let nativeAudioContext;\n            try {\n                nativeAudioContext = new nativeAudioContextConstructor(options);\n            }\n            catch (err) {\n                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.\n                if (err.code === 12 && err.message === 'sampleRate is not in range') {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome, Edge and Opera throw an error if the given latencyHint is invalid.\n            if (!(0,_helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__.isValidLatencyHint)(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Safari does not support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency =\n                typeof nativeAudioContext.baseLatency === 'number'\n                    ? nativeAudioContext.baseLatency\n                    : latencyHint === 'balanced'\n                        ? 512 / sampleRate\n                        : latencyHint === 'interactive' || latencyHint === undefined\n                            ? 256 / sampleRate\n                            : latencyHint === 'playback'\n                                ? 1024 / sampleRate\n                                : /*\n                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                                   * ScriptProcessorNode.\n                                   */\n                                    (Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate;\n            this._nativeAudioContext = nativeAudioContext;\n            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.\n            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                this._nativeGainNode = nativeAudioContext.createGain();\n                this._nativeOscillatorNode = nativeAudioContext.createOscillator();\n                this._nativeGainNode.gain.value = 1e-37;\n                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);\n                this._nativeOscillatorNode.start();\n            }\n            else {\n                this._nativeGainNode = null;\n                this._nativeOscillatorNode = null;\n            }\n            this._state = null;\n            /*\n             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually\n             * changes to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return this._state !== null ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext.close().then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close().then(() => {\n                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {\n                    this._nativeOscillatorNode.stop();\n                    this._nativeGainNode.disconnect();\n                    this._nativeOscillatorNode.disconnect();\n                }\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        createMediaElementSource(mediaElement) {\n            return new mediaElementAudioSourceNodeConstructor(this, { mediaElement });\n        }\n        createMediaStreamDestination() {\n            return new mediaStreamAudioDestinationNodeConstructor(this);\n        }\n        createMediaStreamSource(mediaStream) {\n            return new mediaStreamAudioSourceNodeConstructor(this, { mediaStream });\n        }\n        createMediaStreamTrackSource(mediaStreamTrack) {\n            return new mediaStreamTrackAudioSourceNodeConstructor(this, { mediaStreamTrack });\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this.resume().then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext.resume().catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext.suspend().catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioDestinationNodeConstructor\": () => (/* binding */ createAudioDestinationNodeConstructor)\n/* harmony export */ });\nconst createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode) => {\n    return class AudioDestinationNode extends audioNodeConstructor {\n        constructor(context, channelCount) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);\n            const audioDestinationNodeRenderer = ((isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null));\n            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);\n            this._isNodeOfNativeOfflineAudioContext = isOffline;\n            this._nativeAudioDestinationNode = nativeAudioDestinationNode;\n        }\n        get channelCount() {\n            return this._nativeAudioDestinationNode.channelCount;\n        }\n        set channelCount(value) {\n            // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.\n            // Bug #54: Firefox does throw an IndexSizeError.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.\n            if (value > this._nativeAudioDestinationNode.maxChannelCount) {\n                throw createIndexSizeError();\n            }\n            this._nativeAudioDestinationNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioDestinationNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            // Bug #53: No browser does throw an exception yet.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            this._nativeAudioDestinationNode.channelCountMode = value;\n        }\n        get maxChannelCount() {\n            return this._nativeAudioDestinationNode.maxChannelCount;\n        }\n    };\n};\n//# sourceMappingURL=audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioDestinationNodeRenderer\": () => (/* binding */ createAudioDestinationNodeRenderer)\n/* harmony export */ });\nconst createAudioDestinationNodeRenderer = (renderInputsOfAudioNode) => {\n    const renderedNativeAudioDestinationNodes = new WeakMap();\n    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext) => {\n        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;\n        renderedNativeAudioDestinationNodes.set(nativeOfflineAudioContext, nativeAudioDestinationNode);\n        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode);\n        return nativeAudioDestinationNode;\n    };\n    return {\n        render(proxy, nativeOfflineAudioContext) {\n            const renderedNativeAudioDestinationNode = renderedNativeAudioDestinationNodes.get(nativeOfflineAudioContext);\n            if (renderedNativeAudioDestinationNode !== undefined) {\n                return Promise.resolve(renderedNativeAudioDestinationNode);\n            }\n            return createAudioDestinationNode(proxy, nativeOfflineAudioContext);\n        }\n    };\n};\n//# sourceMappingURL=audio-destination-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioListenerFactory\": () => (/* binding */ createAudioListenerFactory)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, createNotSupportedError, getFirstSample, isNativeOfflineAudioContext, overwriteAccessors) => {\n    return (context, nativeContext) => {\n        const nativeListener = nativeContext.listener;\n        // Bug #117: Only Chrome, Edge & Opera support the new interface already.\n        const createFakeAudioParams = () => {\n            const buffer = new Float32Array(1);\n            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'speakers',\n                numberOfInputs: 9\n            });\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            let isScriptProcessorNodeCreated = false;\n            let lastOrientation = [0, 0, -1, 0, 1, 0];\n            let lastPosition = [0, 0, 0];\n            const createScriptProcessorNode = () => {\n                if (isScriptProcessorNodeCreated) {\n                    return;\n                }\n                isScriptProcessorNodeCreated = true;\n                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);\n                // tslint:disable-next-line:deprecation\n                scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n                    const orientation = [\n                        getFirstSample(inputBuffer, buffer, 0),\n                        getFirstSample(inputBuffer, buffer, 1),\n                        getFirstSample(inputBuffer, buffer, 2),\n                        getFirstSample(inputBuffer, buffer, 3),\n                        getFirstSample(inputBuffer, buffer, 4),\n                        getFirstSample(inputBuffer, buffer, 5)\n                    ];\n                    if (orientation.some((value, index) => value !== lastOrientation[index])) {\n                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation\n                        lastOrientation = orientation;\n                    }\n                    const positon = [\n                        getFirstSample(inputBuffer, buffer, 6),\n                        getFirstSample(inputBuffer, buffer, 7),\n                        getFirstSample(inputBuffer, buffer, 8)\n                    ];\n                    if (positon.some((value, index) => value !== lastPosition[index])) {\n                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation\n                        lastPosition = positon;\n                    }\n                };\n                channelMergerNode.connect(scriptProcessorNode);\n            };\n            const createSetOrientation = (index) => (value) => {\n                if (value !== lastOrientation[index]) {\n                    lastOrientation[index] = value;\n                    nativeListener.setOrientation(...lastOrientation); // tslint:disable-line:deprecation\n                }\n            };\n            const createSetPosition = (index) => (value) => {\n                if (value !== lastPosition[index]) {\n                    lastPosition[index] = value;\n                    nativeListener.setPosition(...lastPosition); // tslint:disable-line:deprecation\n                }\n            };\n            const createFakeAudioParam = (input, initialValue, setValue) => {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {\n                    channelCount: 1,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    offset: initialValue\n                });\n                constantSourceNode.connect(channelMergerNode, 0, input);\n                // @todo This should be stopped when the context is closed.\n                constantSourceNode.start();\n                Object.defineProperty(constantSourceNode.offset, 'defaultValue', {\n                    get() {\n                        return initialValue;\n                    }\n                });\n                /*\n                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and\n                 * minValue for GainNodes.\n                 */\n                const audioParam = createAudioParam({ context }, isOffline, constantSourceNode.offset, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n                overwriteAccessors(audioParam, 'value', (get) => () => get.call(audioParam), (set) => (value) => {\n                    try {\n                        set.call(audioParam, value);\n                    }\n                    catch (err) {\n                        if (err.code !== 9) {\n                            throw err;\n                        }\n                    }\n                    createScriptProcessorNode();\n                    if (isOffline) {\n                        // Bug #117: Using setOrientation() and setPosition() doesn't work with an OfflineAudioContext.\n                        setValue(value);\n                    }\n                });\n                audioParam.cancelAndHoldAtTime = ((cancelAndHoldAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = cancelAndHoldAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.cancelAndHoldAtTime);\n                audioParam.cancelScheduledValues = ((cancelScheduledValues) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = cancelScheduledValues.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.cancelScheduledValues);\n                audioParam.exponentialRampToValueAtTime = ((exponentialRampToValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = exponentialRampToValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.exponentialRampToValueAtTime);\n                audioParam.linearRampToValueAtTime = ((linearRampToValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = linearRampToValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.linearRampToValueAtTime);\n                audioParam.setTargetAtTime = ((setTargetAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setTargetAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setTargetAtTime);\n                audioParam.setValueAtTime = ((setValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setValueAtTime);\n                audioParam.setValueCurveAtTime = ((setValueCurveAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setValueCurveAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setValueCurveAtTime);\n                return audioParam;\n            };\n            return {\n                forwardX: createFakeAudioParam(0, 0, createSetOrientation(0)),\n                forwardY: createFakeAudioParam(1, 0, createSetOrientation(1)),\n                forwardZ: createFakeAudioParam(2, -1, createSetOrientation(2)),\n                positionX: createFakeAudioParam(6, 0, createSetPosition(0)),\n                positionY: createFakeAudioParam(7, 0, createSetPosition(1)),\n                positionZ: createFakeAudioParam(8, 0, createSetPosition(2)),\n                upX: createFakeAudioParam(3, 0, createSetOrientation(3)),\n                upY: createFakeAudioParam(4, 1, createSetOrientation(4)),\n                upZ: createFakeAudioParam(5, 0, createSetOrientation(5))\n            };\n        };\n        const { forwardX, forwardY, forwardZ, positionX, positionY, positionZ, upX, upY, upZ } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;\n        return {\n            get forwardX() {\n                return forwardX;\n            },\n            get forwardY() {\n                return forwardY;\n            },\n            get forwardZ() {\n                return forwardZ;\n            },\n            get positionX() {\n                return positionX;\n            },\n            get positionY() {\n                return positionY;\n            },\n            get positionZ() {\n                return positionZ;\n            },\n            get upX() {\n                return upX;\n            },\n            get upY() {\n                return upY;\n            },\n            get upZ() {\n                return upZ;\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-listener-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioNodeConstructor\": () => (/* binding */ createAudioNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _guards_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n/* harmony import */ var _helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/add-active-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/add-passive-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/connect-native-audio-node-to-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js\");\n/* harmony import */ var _helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/delete-active-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js\");\n/* harmony import */ var _helpers_delete_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../helpers/delete-active-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../helpers/delete-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../helpers/disconnect-native-audio-node-from-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../helpers/get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../helpers/get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../helpers/get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../helpers/get-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js\");\n/* harmony import */ var _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../helpers/insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../helpers/is-part-of-a-cycle */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js\");\n/* harmony import */ var _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../helpers/is-passive-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive-when-necessary */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js\");\n/* harmony import */ var _helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ../helpers/test-audio-node-disconnect-method-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js\");\n/* harmony import */ var _helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ../helpers/visit-each-audio-node-once */ \"./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js\");\n/* harmony import */ var _helpers_wrap_audio_node_disconnect_method__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../helpers/wrap-audio-node-disconnect-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__.getAudioParamConnections)(destination);\n    const { outputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const eventListeners = (0,_helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_14__.getEventListenersOfAudioNode)(source);\n    const eventListener = (isActive) => {\n        const nativeAudioNode = (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source);\n        const nativeAudioParam = (0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination);\n        if (isActive) {\n            const partialConnection = (0,_helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);\n            (0,_helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__.addActiveInputConnectionToAudioParam)(activeInputs, source, partialConnection, false);\n            if (!isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n                nativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }\n        else {\n            const partialConnection = (0,_helpers_delete_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_7__.deleteActiveInputConnectionToAudioParam)(activeInputs, source, output);\n            (0,_helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__.addPassiveInputConnectionToAudioParam)(passiveInputs, partialConnection, false);\n            if (!isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n                nativeAudioNode.disconnect(nativeAudioParam, output);\n            }\n        }\n    };\n    if ((0,_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_17__.insertElementInSet)(outputs, [destination, output], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output, true)) {\n        eventListeners.add(eventListener);\n        if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__.isActiveAudioNode)(source)) {\n            (0,_helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__.addActiveInputConnectionToAudioParam)(activeInputs, source, [output, eventListener], true);\n        }\n        else {\n            (0,_helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__.addPassiveInputConnectionToAudioParam)(passiveInputs, [source, output, eventListener], true);\n        }\n        return true;\n    }\n    return false;\n};\nconst deleteInputConnectionOfAudioNode = (source, destination, output, input) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(destination);\n    const activeInputConnection = (0,_helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__.deleteActiveInputConnection)(activeInputs[input], source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = (0,_helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_9__.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);\n        return [passiveInputConnection[2], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputConnectionOfAudioParam = (source, destination, output) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__.getAudioParamConnections)(destination);\n    const activeInputConnection = (0,_helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__.deleteActiveInputConnection)(activeInputs, source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = (0,_helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);\n        return [passiveInputConnection[1], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputsOfAudioNode = (source, isOffline, destination, output, input) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);\n    if (listener !== null) {\n        (0,_helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__.deleteEventListenerOfAudioNode)(source, listener);\n        if (isActive && !isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n            (0,_helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_11__.disconnectNativeAudioNodeFromNativeAudioNode)((0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source), (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(destination), output, input);\n        }\n    }\n    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__.isActiveAudioNode)(destination)) {\n        const { activeInputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(destination);\n        (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_22__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n    }\n};\nconst deleteInputsOfAudioParam = (source, isOffline, destination, output) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);\n    if (listener !== null) {\n        (0,_helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__.deleteEventListenerOfAudioNode)(source, listener);\n        if (isActive && !isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n            (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source).disconnect((0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination), output);\n        }\n    }\n};\nconst deleteAnyConnection = (source, isOffline) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n            deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n        }\n        destinations.push(outputConnection[0]);\n    }\n    audioNodeConnectionsOfSource.outputs.clear();\n    return destinations;\n};\nconst deleteConnectionAtOutput = (source, isOffline, output) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if (outputConnection[1] === output) {\n            if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n                deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n            }\n            else {\n                deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n            }\n            destinations.push(outputConnection[0]);\n            audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        }\n    }\n    return destinations;\n};\nconst deleteConnectionToDestination = (source, isOffline, destination, output, input) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    return Array.from(audioNodeConnectionsOfSource.outputs)\n        .filter((outputConnection) => outputConnection[0] === destination &&\n        (output === undefined || outputConnection[1] === output) &&\n        (input === undefined || outputConnection[2] === input))\n        .map((outputConnection) => {\n        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n            deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n        }\n        audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        return outputConnection[0];\n    });\n};\nconst createAudioNodeConstructor = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor) => {\n    return class AudioNode extends eventTargetConstructor {\n        constructor(context, isActive, nativeAudioNode, audioNodeRenderer) {\n            super(nativeAudioNode);\n            this._context = context;\n            this._nativeAudioNode = nativeAudioNode;\n            const nativeContext = getNativeContext(context);\n            // Bug #12: Safari does not support to disconnect a specific destination.\n            if (isNativeAudioContext(nativeContext) &&\n                true !==\n                    cacheTestResult(_helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__.testAudioNodeDisconnectMethodSupport, () => {\n                        return (0,_helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__.testAudioNodeDisconnectMethodSupport)(nativeContext, nativeAudioWorkletNodeConstructor);\n                    })) {\n                (0,_helpers_wrap_audio_node_disconnect_method__WEBPACK_IMPORTED_MODULE_25__.wrapAudioNodeDisconnectMethod)(nativeAudioNode);\n            }\n            _globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_STORE.set(this, nativeAudioNode);\n            _globals__WEBPACK_IMPORTED_MODULE_0__.EVENT_LISTENERS.set(this, new Set());\n            if (context.state !== 'closed' && isActive) {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__.setInternalStateToActive)(this);\n            }\n            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);\n        }\n        get channelCount() {\n            return this._nativeAudioNode.channelCount;\n        }\n        set channelCount(value) {\n            this._nativeAudioNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            this._nativeAudioNode.channelCountMode = value;\n        }\n        get channelInterpretation() {\n            return this._nativeAudioNode.channelInterpretation;\n        }\n        set channelInterpretation(value) {\n            this._nativeAudioNode.channelInterpretation = value;\n        }\n        get context() {\n            return this._context;\n        }\n        get numberOfInputs() {\n            return this._nativeAudioNode.numberOfInputs;\n        }\n        get numberOfOutputs() {\n            return this._nativeAudioNode.numberOfOutputs;\n        }\n        // tslint:disable-next-line:invalid-void\n        connect(destination, output = 0, input = 0) {\n            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.\n            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) {\n                throw createIndexSizeError();\n            }\n            const nativeContext = getNativeContext(this._context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) {\n                throw createInvalidAccessError();\n            }\n            if ((0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_1__.isAudioNode)(destination)) {\n                const nativeDestinationAudioNode = (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(destination);\n                try {\n                    const connection = (0,_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_5__.connectNativeAudioNodeToNativeAudioNode)(this._nativeAudioNode, nativeDestinationAudioNode, output, input);\n                    const isPassive = (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(this);\n                    if (isOffline || isPassive) {\n                        this._nativeAudioNode.disconnect(...connection);\n                    }\n                    if (this.context.state !== 'closed' && !isPassive && (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(destination)) {\n                        (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__.setInternalStateToActive)(destination);\n                    }\n                }\n                catch (err) {\n                    // Bug #41: Safari does not throw the correct exception so far.\n                    if (err.code === 12) {\n                        throw createInvalidAccessError();\n                    }\n                    throw err;\n                }\n                const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);\n                // Bug #164: Only Firefox detects cycles so far.\n                if (isNewConnectionToAudioNode) {\n                    const cycles = detectCycles([this], destination);\n                    (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));\n                }\n                return destination;\n            }\n            const nativeAudioParam = (0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination);\n            /*\n             * Bug #73, #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an\n             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify\n             * Safari. In addition to that the maxValue property is used to only detect the affected versions below v14.0.2.\n             */\n            if (nativeAudioParam.name === 'playbackRate' && nativeAudioParam.maxValue === 1024) {\n                throw createNotSupportedError();\n            }\n            try {\n                this._nativeAudioNode.connect(nativeAudioParam, output);\n                if (isOffline || (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(this)) {\n                    this._nativeAudioNode.disconnect(nativeAudioParam, output);\n                }\n            }\n            catch (err) {\n                // Bug #58: Safari doesn't throw an InvalidAccessError yet.\n                if (err.code === 12) {\n                    throw createInvalidAccessError();\n                }\n                throw err;\n            }\n            const isNewConnectionToAudioParam = addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);\n            // Bug #164: Only Firefox detects cycles so far.\n            if (isNewConnectionToAudioParam) {\n                const cycles = detectCycles([this], destination);\n                (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));\n            }\n        }\n        disconnect(destinationOrOutput, output, input) {\n            let destinations;\n            const nativeContext = getNativeContext(this._context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            if (destinationOrOutput === undefined) {\n                destinations = deleteAnyConnection(this, isOffline);\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionAtOutput(this, isOffline, destinationOrOutput);\n            }\n            else {\n                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) {\n                    throw createIndexSizeError();\n                }\n                if ((0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_1__.isAudioNode)(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);\n                if (destinations.length === 0) {\n                    throw createInvalidAccessError();\n                }\n            }\n            // Bug #164: Only Firefox detects cycles so far.\n            for (const destination of destinations) {\n                const cycles = detectCycles([this], destination);\n                (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, decrementCycleCounter);\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioParamFactory\": () => (/* binding */ createAudioParamFactory)\n/* harmony export */ });\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! automation-events */ \"./node_modules/automation-events/build/es5/bundle.js\");\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(automation_events__WEBPACK_IMPORTED_MODULE_0__);\n\nconst createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor, setValueAtTimeUntilPossible) => {\n    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null) => {\n        const automationEventList = new automation_events__WEBPACK_IMPORTED_MODULE_0__.AutomationEventList(nativeAudioParam.defaultValue);\n        const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;\n        const audioParam = {\n            get defaultValue() {\n                return nativeAudioParam.defaultValue;\n            },\n            get maxValue() {\n                return maxValue === null ? nativeAudioParam.maxValue : maxValue;\n            },\n            get minValue() {\n                return minValue === null ? nativeAudioParam.minValue : minValue;\n            },\n            get value() {\n                return nativeAudioParam.value;\n            },\n            set value(value) {\n                nativeAudioParam.value = value;\n                // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().\n                audioParam.setValueAtTime(value, audioNode.context.currentTime);\n            },\n            cancelAndHoldAtTime(cancelTime) {\n                // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().\n                if (typeof nativeAudioParam.cancelAndHoldAtTime === 'function') {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);\n                }\n                else {\n                    const previousLastEvent = Array.from(automationEventList).pop();\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    const currentLastEvent = Array.from(automationEventList).pop();\n                    nativeAudioParam.cancelScheduledValues(cancelTime);\n                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {\n                        if (currentLastEvent.type === 'exponentialRampToValue') {\n                            nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'linearRampToValue') {\n                            nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'setValue') {\n                            nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);\n                        }\n                        else if (currentLastEvent.type === 'setValueCurve') {\n                            nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);\n                        }\n                    }\n                }\n                return audioParam;\n            },\n            cancelScheduledValues(cancelTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));\n                nativeAudioParam.cancelScheduledValues(cancelTime);\n                return audioParam;\n            },\n            exponentialRampToValueAtTime(value, endTime) {\n                // Bug #45: Safari does not throw an error yet.\n                if (value === 0) {\n                    throw new RangeError();\n                }\n                // Bug #187: Safari does not throw an error yet.\n                if (!Number.isFinite(endTime) || endTime < 0) {\n                    throw new RangeError();\n                }\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.exponentialRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            linearRampToValueAtTime(value, endTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.linearRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            setTargetAtTime(target, startTime, timeConstant) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));\n                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);\n                return audioParam;\n            },\n            setValueAtTime(value, startTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetValueAutomationEvent(value, startTime));\n                nativeAudioParam.setValueAtTime(value, startTime);\n                return audioParam;\n            },\n            setValueCurveAtTime(values, startTime, duration) {\n                // Bug 183: Safari only accepts a Float32Array.\n                const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);\n                /*\n                 * Bug #152: Safari does not correctly interpolate the values of the curve.\n                 * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the\n                 * existence of the webkitAudioContext is used as a workaround here.\n                 */\n                if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                    const endTime = startTime + duration;\n                    const sampleRate = audioNode.context.sampleRate;\n                    const firstSample = Math.ceil(startTime * sampleRate);\n                    const lastSample = Math.floor(endTime * sampleRate);\n                    const numberOfInterpolatedValues = lastSample - firstSample;\n                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);\n                    for (let i = 0; i < numberOfInterpolatedValues; i += 1) {\n                        const theoreticIndex = ((convertedValues.length - 1) / duration) * ((firstSample + i) / sampleRate - startTime);\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        interpolatedValues[i] =\n                            lowerIndex === upperIndex\n                                ? convertedValues[lowerIndex]\n                                : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] +\n                                    (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];\n                    }\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);\n                    const timeOfLastSample = lastSample / sampleRate;\n                    if (timeOfLastSample < endTime) {\n                        setValueAtTimeUntilPossible(audioParam, interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);\n                    }\n                    setValueAtTimeUntilPossible(audioParam, convertedValues[convertedValues.length - 1], endTime);\n                }\n                else {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);\n                }\n                return audioParam;\n            }\n        };\n        audioParamStore.set(audioParam, nativeAudioParam);\n        audioParamAudioNodeStore.set(audioParam, audioNode);\n        addAudioParamConnections(audioParam, audioParamRenderer);\n        return audioParam;\n    };\n};\n//# sourceMappingURL=audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioParamRenderer\": () => (/* binding */ createAudioParamRenderer)\n/* harmony export */ });\nconst createAudioParamRenderer = (automationEventList) => {\n    return {\n        replay(audioParam) {\n            for (const automationEvent of automationEventList) {\n                if (automationEvent.type === 'exponentialRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.exponentialRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'linearRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.linearRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'setTarget') {\n                    const { startTime, target, timeConstant } = automationEvent;\n                    audioParam.setTargetAtTime(target, startTime, timeConstant);\n                }\n                else if (automationEvent.type === 'setValue') {\n                    const { startTime, value } = automationEvent;\n                    audioParam.setValueAtTime(value, startTime);\n                }\n                else if (automationEvent.type === 'setValueCurve') {\n                    const { duration, startTime, values } = automationEvent;\n                    audioParam.setValueCurveAtTime(values, startTime, duration);\n                }\n                else {\n                    throw new Error(\"Can't apply an unknown automation.\");\n                }\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-param-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletNodeConstructor\": () => (/* binding */ createAudioWorkletNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/read-only-map.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 1,\n    numberOfOutputs: 1,\n    parameterData: {},\n    processorOptions: {}\n};\nconst createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, testAudioWorkletNodeOptionsClonability, wrapEventListener) => {\n    return class AudioWorkletNode extends audioNodeConstructor {\n        constructor(context, name, options) {\n            var _a;\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = sanitizeAudioWorkletNodeOptions({ ...DEFAULT_OPTIONS, ...options });\n            // Bug #191: Safari doesn't throw an error if the options aren't clonable.\n            testAudioWorkletNodeOptionsClonability(mergedOptions);\n            const nodeNameToProcessorConstructorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n            const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);\n            // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.\n            const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== 'closed'\n                ? nativeContext\n                : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;\n            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);\n            const audioWorkletNodeRenderer = ((isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null));\n            /*\n             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor\n             * returns false.\n             */\n            super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);\n            const parameters = [];\n            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm) => {\n                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);\n                parameters.push([nm, audioParam]);\n            });\n            this._nativeAudioWorkletNode = nativeAudioWorkletNode;\n            this._onprocessorerror = null;\n            this._parameters = new _read_only_map__WEBPACK_IMPORTED_MODULE_1__.ReadOnlyMap(parameters);\n            /*\n             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to\n             * the destination.\n             */\n            if (isOffline) {\n                addUnrenderedAudioWorkletNode(nativeContext, this);\n            }\n            const { activeInputs } = getAudioNodeConnections(this);\n            setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);\n        }\n        get onprocessorerror() {\n            return this._onprocessorerror;\n        }\n        set onprocessorerror(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;\n            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;\n            this._onprocessorerror =\n                nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener\n                    ? value\n                    : nativeOnProcessorError;\n        }\n        get parameters() {\n            if (this._parameters === null) {\n                // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                return this._nativeAudioWorkletNode.parameters;\n            }\n            return this._parameters;\n        }\n        get port() {\n            return this._nativeAudioWorkletNode.port;\n        }\n    };\n};\n//# sourceMappingURL=audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletNodeRendererFactory\": () => (/* binding */ createAudioWorkletNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/copy-from-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js\");\n/* harmony import */ var _helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/copy-to-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js\");\n/* harmony import */ var _helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/create-nested-arrays */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/get-audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\n\n\n\n\nconst processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime) => {\n    // Ceil the length to the next full render quantum.\n    // Bug #17: Safari does not yet expose the length.\n    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;\n    const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n    const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n    const processedBuffer = numberOfOutputChannels === 0\n        ? null\n        : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);\n    if (processorConstructor === undefined) {\n        throw new Error('Missing the processor constructor.');\n    }\n    const audioNodeConnections = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__.getAudioNodeConnections)(proxy);\n    const audioWorkletProcessor = await (0,_helpers_get_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__.getAudioWorkletProcessor)(nativeOfflineAudioContext, proxy);\n    const inputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__.createNestedArrays)(options.numberOfInputs, options.channelCount);\n    const outputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__.createNestedArrays)(options.numberOfOutputs, outputChannelCount);\n    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n    for (let i = 0; i < length; i += 128) {\n        if (options.numberOfInputs > 0 && renderedBuffer !== null) {\n            for (let j = 0; j < options.numberOfInputs; j += 1) {\n                for (let k = 0; k < options.channelCount; k += 1) {\n                    (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__.copyFromChannel)(renderedBuffer, inputs[j], k, k, i);\n                }\n            }\n        }\n        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {\n            processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__.copyFromChannel)(renderedBuffer, parameters, name, numberOfInputChannels + index, i);\n            });\n        }\n        for (let j = 0; j < options.numberOfInputs; j += 1) {\n            for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                // The byteLength will be 0 when the ArrayBuffer was transferred.\n                if (outputs[j][k].byteLength === 0) {\n                    outputs[j][k] = new Float32Array(128);\n                }\n            }\n        }\n        try {\n            const potentiallyEmptyInputs = inputs.map((input, index) => {\n                if (audioNodeConnections.activeInputs[index].size === 0) {\n                    return [];\n                }\n                return input;\n            });\n            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n            if (processedBuffer !== null) {\n                for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                    for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                        (0,_helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_1__.copyToChannel)(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[j];\n                }\n            }\n            if (!activeSourceFlag) {\n                break;\n            }\n        }\n        catch (error) {\n            proxy.dispatchEvent(new ErrorEvent('processorerror', {\n                colno: error.colno,\n                filename: error.filename,\n                lineno: error.lineno,\n                message: error.message\n            }));\n            break;\n        }\n    }\n    return processedBuffer;\n};\nconst createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (name, options, processorConstructor) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let processedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioWorkletNode = getNativeAudioNode(proxy);\n            let nativeOutputNodes = null;\n            const nativeAudioWorkletNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_5__.isOwnedByContext)(nativeAudioWorkletNode, nativeOfflineAudioContext);\n            const outputChannelCount = Array.isArray(options.outputChannelCount)\n                ? options.outputChannelCount\n                : Array.from(options.outputChannelCount);\n            // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.\n            if (nativeAudioWorkletNodeConstructor === null) {\n                const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {\n                    channelCount: Math.max(1, numberOfOutputChannels),\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    numberOfOutputs: Math.max(1, numberOfOutputChannels)\n                });\n                const outputChannelMergerNodes = [];\n                for (let i = 0; i < proxy.numberOfOutputs; i += 1) {\n                    outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: outputChannelCount[i]\n                    }));\n                }\n                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                    channelCount: options.channelCount,\n                    channelCountMode: options.channelCountMode,\n                    channelInterpretation: options.channelInterpretation,\n                    gain: 1\n                });\n                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];\n            }\n            else if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);\n            if (nativeOutputNodes !== null) {\n                if (processedBufferPromise === null) {\n                    if (processorConstructor === undefined) {\n                        throw new Error('Missing the processor constructor.');\n                    }\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;\n                    const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n                    const numberOfChannels = numberOfInputChannels + numberOfParameters;\n                    const renderBuffer = async () => {\n                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, \n                        // Ceil the length to the next full render quantum.\n                        // Bug #17: Safari does not yet expose the length.\n                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);\n                        const gainNodes = [];\n                        const inputChannelSplitterNodes = [];\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: options.channelCountMode,\n                                channelInterpretation: options.channelInterpretation,\n                                gain: 1\n                            }));\n                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                numberOfOutputs: options.channelCount\n                            }));\n                        }\n                        const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam) => {\n                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: audioParam.value\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset);\n                            return constantSourceNode;\n                        }));\n                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                            channelCount: 1,\n                            channelCountMode: 'explicit',\n                            channelInterpretation: 'speakers',\n                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n                        });\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n                            for (let j = 0; j < options.channelCount; j += 1) {\n                                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n                            }\n                        }\n                        for (const [index, constantSourceNode] of constantSourceNodes.entries()) {\n                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                            constantSourceNode.start(0);\n                        }\n                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                        await Promise.all(gainNodes.map((gainNode) => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode)));\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    };\n                    processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);\n                }\n                const processedBuffer = await processedBufferPromise;\n                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;\n                if (processedBuffer !== null) {\n                    audioBufferSourceNode.buffer = processedBuffer;\n                    audioBufferSourceNode.start(0);\n                }\n                audioBufferSourceNode.connect(outputChannelSplitterNode);\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[i];\n                }\n                return outputGainNode;\n            }\n            if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await renderAutomation(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm));\n                }\n            }\n            else {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await connectAudioParam(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm));\n                }\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode);\n            return nativeAudioWorkletNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);\n                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-worklet-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBaseAudioContextConstructor\": () => (/* binding */ createBaseAudioContextConstructor)\n/* harmony export */ });\nconst createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor) => {\n    return class BaseAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext, numberOfChannels);\n            this._nativeContext = _nativeContext;\n            this._audioWorklet =\n                addAudioWorkletModule === undefined\n                    ? undefined\n                    : {\n                        addModule: (moduleURL, options) => {\n                            return addAudioWorkletModule(this, moduleURL, options);\n                        }\n                    };\n        }\n        get audioWorklet() {\n            return this._audioWorklet;\n        }\n        createAnalyser() {\n            return new analyserNodeConstructor(this);\n        }\n        createBiquadFilter() {\n            return new biquadFilterNodeConstructor(this);\n        }\n        createBuffer(numberOfChannels, length, sampleRate) {\n            return new audioBufferConstructor({ length, numberOfChannels, sampleRate });\n        }\n        createBufferSource() {\n            return new audioBufferSourceNodeConstructor(this);\n        }\n        createChannelMerger(numberOfInputs = 6) {\n            return new channelMergerNodeConstructor(this, { numberOfInputs });\n        }\n        createChannelSplitter(numberOfOutputs = 6) {\n            return new channelSplitterNodeConstructor(this, { numberOfOutputs });\n        }\n        createConstantSource() {\n            return new constantSourceNodeConstructor(this);\n        }\n        createConvolver() {\n            return new convolverNodeConstructor(this);\n        }\n        createDelay(maxDelayTime = 1) {\n            return new delayNodeConstructor(this, { maxDelayTime });\n        }\n        createDynamicsCompressor() {\n            return new dynamicsCompressorNodeConstructor(this);\n        }\n        createGain() {\n            return new gainNodeConstructor(this);\n        }\n        createIIRFilter(feedforward, feedback) {\n            return new iIRFilterNodeConstructor(this, { feedback, feedforward });\n        }\n        createOscillator() {\n            return new oscillatorNodeConstructor(this);\n        }\n        createPanner() {\n            return new pannerNodeConstructor(this);\n        }\n        createPeriodicWave(real, imag, constraints = { disableNormalization: false }) {\n            return new periodicWaveConstructor(this, { ...constraints, imag, real });\n        }\n        createStereoPanner() {\n            return new stereoPannerNodeConstructor(this);\n        }\n        createWaveShaper() {\n            return new waveShaperNodeConstructor(this);\n        }\n        decodeAudioData(audioData, successCallback, errorCallback) {\n            return decodeAudioData(this._nativeContext, audioData).then((audioBuffer) => {\n                if (typeof successCallback === 'function') {\n                    successCallback(audioBuffer);\n                }\n                return audioBuffer;\n            }, (err) => {\n                if (typeof errorCallback === 'function') {\n                    errorCallback(err);\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBiquadFilterNodeConstructor\": () => (/* binding */ createBiquadFilterNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    Q: 1,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 350,\n    gain: 0,\n    type: 'lowpass'\n};\nconst createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class BiquadFilterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const biquadFilterNodeRenderer = (isOffline ? createBiquadFilterNodeRenderer() : null);\n            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);\n            // Bug #80: Safari does not export the correct values for maxValue and minValue.\n            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT), -1200 * Math.log2(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT));\n            // Bug #77: Firefox & Safari do not export the correct value for minValue.\n            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);\n            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT), _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._nativeBiquadFilterNode = nativeBiquadFilterNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get gain() {\n            return this._gain;\n        }\n        get Q() {\n            return this._Q;\n        }\n        get type() {\n            return this._nativeBiquadFilterNode.type;\n        }\n        set type(value) {\n            this._nativeBiquadFilterNode.type = value;\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            // Bug #189: Safari does throw an InvalidStateError.\n            try {\n                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n            }\n            catch (err) {\n                if (err.code === 11) {\n                    throw createInvalidAccessError();\n                }\n                throw err;\n            }\n            // Bug #68: Safari does not throw an error if the parameters differ in their length.\n            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                throw createInvalidAccessError();\n            }\n        }\n    };\n};\n//# sourceMappingURL=biquad-filter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBiquadFilterNodeRendererFactory\": () => (/* binding */ createBiquadFilterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeBiquadFilterNodes = new WeakMap();\n        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeBiquadFilterNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeBiquadFilterNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeBiquadFilterNode, nativeOfflineAudioContext);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                const options = {\n                    Q: nativeBiquadFilterNode.Q.value,\n                    channelCount: nativeBiquadFilterNode.channelCount,\n                    channelCountMode: nativeBiquadFilterNode.channelCountMode,\n                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,\n                    detune: nativeBiquadFilterNode.detune.value,\n                    frequency: nativeBiquadFilterNode.frequency.value,\n                    gain: nativeBiquadFilterNode.gain.value,\n                    type: nativeBiquadFilterNode.type\n                };\n                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode);\n            return nativeBiquadFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeBiquadFilterNode !== undefined) {\n                    return Promise.resolve(renderedNativeBiquadFilterNode);\n                }\n                return createBiquadFilterNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=biquad-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createCacheTestResult\": () => (/* binding */ createCacheTestResult)\n/* harmony export */ });\nconst createCacheTestResult = (ongoingTests, testResults) => {\n    return (tester, test) => {\n        const cachedTestResult = testResults.get(tester);\n        if (cachedTestResult !== undefined) {\n            return cachedTestResult;\n        }\n        const ongoingTest = ongoingTests.get(tester);\n        if (ongoingTest !== undefined) {\n            return ongoingTest;\n        }\n        try {\n            const synchronousTestResult = test();\n            if (synchronousTestResult instanceof Promise) {\n                ongoingTests.set(tester, synchronousTestResult);\n                return synchronousTestResult\n                    .catch(() => false)\n                    .then((finalTestResult) => {\n                    ongoingTests.delete(tester);\n                    testResults.set(tester, finalTestResult);\n                    return finalTestResult;\n                });\n            }\n            testResults.set(tester, synchronousTestResult);\n            return synchronousTestResult;\n        }\n        catch {\n            testResults.set(tester, false);\n            return false;\n        }\n    };\n};\n//# sourceMappingURL=cache-test-result.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelMergerNodeConstructor\": () => (/* binding */ createChannelMergerNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 1,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 6\n};\nconst createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class ChannelMergerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);\n            const channelMergerNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null));\n            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=channel-merger-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelMergerNodeRendererFactory\": () => (/* binding */ createChannelMergerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfInputs: nativeAudioNode.numberOfInputs\n                };\n                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=channel-merger-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelSplitterNodeConstructor\": () => (/* binding */ createChannelSplitterNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 6,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'discrete',\n    numberOfOutputs: 6\n};\nconst createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions) => {\n    return class ChannelSplitterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = sanitizeChannelSplitterOptions({ ...DEFAULT_OPTIONS, ...options });\n            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);\n            const channelSplitterNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null));\n            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=channel-splitter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelSplitterNodeRendererFactory\": () => (/* binding */ createChannelSplitterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfOutputs: nativeAudioNode.numberOfOutputs\n                };\n                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=channel-splitter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectAudioParam\": () => (/* binding */ createConnectAudioParam)\n/* harmony export */ });\nconst createConnectAudioParam = (renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam) => {\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);\n    };\n};\n//# sourceMappingURL=connect-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectMultipleOutputs\": () => (/* binding */ createConnectMultipleOutputs)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst createConnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destination, output = 0, input = 0) => {\n        const outputAudioNode = outputAudioNodes[output];\n        if (outputAudioNode === undefined) {\n            throw createIndexSizeError();\n        }\n        if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination)) {\n            return outputAudioNode.connect(destination, 0, input);\n        }\n        return outputAudioNode.connect(destination, 0);\n    };\n};\n//# sourceMappingURL=connect-multiple-outputs.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectedNativeAudioBufferSourceNodeFactory\": () => (/* binding */ createConnectedNativeAudioBufferSourceNodeFactory)\n/* harmony export */ });\nconst createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode) => {\n    return (nativeContext, nativeAudioNode) => {\n        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);\n        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n        nativeAudioBufferSourceNode.loop = true;\n        nativeAudioBufferSourceNode.connect(nativeAudioNode);\n        nativeAudioBufferSourceNode.start();\n        return () => {\n            nativeAudioBufferSourceNode.stop();\n            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);\n        };\n    };\n};\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConstantSourceNodeConstructor\": () => (/* binding */ createConstantSourceNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    offset: 1\n};\nconst createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class ConstantSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const constantSourceNodeRenderer = ((isOffline ? createConstantSourceNodeRendererFactory() : null));\n            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);\n            this._constantSourceNodeRenderer = constantSourceNodeRenderer;\n            this._nativeConstantSourceNode = nativeConstantSourceNode;\n            /*\n             * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue\n             * for GainNodes.\n             */\n            this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._onended = null;\n        }\n        get offset() {\n            return this._offset;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeConstantSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeConstantSourceNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        start(when = 0) {\n            this._nativeConstantSourceNode.start(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.start = when;\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeConstantSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeConstantSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeConstantSourceNode.stop(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=constant-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConstantSourceNodeRendererFactory\": () => (/* binding */ createConstantSourceNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConstantSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeConstantSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeConstantSourceNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeConstantSourceNode, nativeOfflineAudioContext);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeConstantSourceNode.channelCount,\n                    channelCountMode: nativeConstantSourceNode.channelCountMode,\n                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,\n                    offset: nativeConstantSourceNode.offset.value\n                };\n                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeConstantSourceNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeConstantSourceNode.stop(stop);\n                }\n            }\n            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode);\n            return nativeConstantSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConstantSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeConstantSourceNode);\n                }\n                return createConstantSourceNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=constant-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvertNumberToUnsignedLong\": () => (/* binding */ createConvertNumberToUnsignedLong)\n/* harmony export */ });\nconst createConvertNumberToUnsignedLong = (unit32Array) => {\n    return (value) => {\n        unit32Array[0] = value;\n        return unit32Array[0];\n    };\n};\n//# sourceMappingURL=convert-number-to-unsigned-long.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvolverNodeConstructor\": () => (/* binding */ createConvolverNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    disableNormalization: false\n};\nconst createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class ConvolverNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const convolverNodeRenderer = (isOffline ? createConvolverNodeRenderer() : null);\n            super(context, false, nativeConvolverNode, convolverNodeRenderer);\n            this._isBufferNullified = false;\n            this._nativeConvolverNode = nativeConvolverNode;\n            if (mergedOptions.buffer !== null) {\n                setAudioNodeTailTime(this, mergedOptions.buffer.duration);\n            }\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeConvolverNode.buffer;\n        }\n        set buffer(value) {\n            this._nativeConvolverNode.buffer = value;\n            // Bug #115: Safari does not allow to set the buffer to null.\n            if (value === null && this._nativeConvolverNode.buffer !== null) {\n                const nativeContext = this._nativeConvolverNode.context;\n                this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, 44100);\n                this._isBufferNullified = true;\n                setAudioNodeTailTime(this, 0);\n            }\n            else {\n                this._isBufferNullified = false;\n                setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);\n            }\n        }\n        get normalize() {\n            return this._nativeConvolverNode.normalize;\n        }\n        set normalize(value) {\n            this._nativeConvolverNode.normalize = value;\n        }\n    };\n};\n//# sourceMappingURL=convolver-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvolverNodeRendererFactory\": () => (/* binding */ createConvolverNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConvolverNodes = new WeakMap();\n        const createConvolverNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeConvolverNode = getNativeAudioNode(proxy);\n            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeConvolverNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeConvolverNode, nativeOfflineAudioContext);\n            if (!nativeConvolverNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeConvolverNode.buffer,\n                    channelCount: nativeConvolverNode.channelCount,\n                    channelCountMode: nativeConvolverNode.channelCountMode,\n                    channelInterpretation: nativeConvolverNode.channelInterpretation,\n                    disableNormalization: !nativeConvolverNode.normalize\n                };\n                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeConvolverNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode);\n            }\n            return nativeConvolverNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConvolverNode !== undefined) {\n                    return Promise.resolve(renderedNativeConvolverNode);\n                }\n                return createConvolverNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=convolver-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createCreateNativeOfflineAudioContext\": () => (/* binding */ createCreateNativeOfflineAudioContext)\n/* harmony export */ });\nconst createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor) => {\n    return (numberOfChannels, length, sampleRate) => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n        }\n        try {\n            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);\n        }\n        catch (err) {\n            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.\n            if (err.name === 'SyntaxError') {\n                throw createNotSupportedError();\n            }\n            throw err;\n        }\n    };\n};\n//# sourceMappingURL=create-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDataCloneError\": () => (/* binding */ createDataCloneError)\n/* harmony export */ });\nconst createDataCloneError = () => new DOMException('', 'DataCloneError');\n//# sourceMappingURL=data-clone-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDecodeAudioData\": () => (/* binding */ createDecodeAudioData)\n/* harmony export */ });\n/* harmony import */ var _helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/detach-array-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\n\nconst createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    return (anyContext, audioData) => {\n        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);\n        // Bug #43: Only Chrome, Edge and Opera do throw a DataCloneError.\n        if (detachedArrayBuffers.has(audioData)) {\n            const err = createDataCloneError();\n            return Promise.reject(err);\n        }\n        // The audioData parameter maybe of a type which can't be added to a WeakSet.\n        try {\n            detachedArrayBuffers.add(audioData);\n        }\n        catch {\n            // Ignore errors.\n        }\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeContext))) {\n            return nativeContext.decodeAudioData(audioData).then((audioBuffer) => {\n                // Bug #133: Safari does neuter the ArrayBuffer.\n                (0,_helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__.detachArrayBuffer)(audioData).catch(() => {\n                    // Ignore errors.\n                });\n                // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n                if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n                    wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n                }\n                audioBufferStore.add(audioBuffer);\n                return audioBuffer;\n            });\n        }\n        // Bug #21: Safari does not return a Promise yet.\n        return new Promise((resolve, reject) => {\n            const complete = async () => {\n                // Bug #133: Safari does neuter the ArrayBuffer.\n                try {\n                    await (0,_helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__.detachArrayBuffer)(audioData);\n                }\n                catch {\n                    // Ignore errors.\n                }\n            };\n            const fail = (err) => {\n                reject(err);\n                complete();\n            };\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                // Bug #1: Safari requires a successCallback.\n                nativeContext.decodeAudioData(audioData, (audioBuffer) => {\n                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n                    if (typeof audioBuffer.copyFromChannel !== 'function') {\n                        wrapAudioBufferCopyChannelMethods(audioBuffer);\n                        (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n                    }\n                    audioBufferStore.add(audioBuffer);\n                    complete().then(() => resolve(audioBuffer));\n                }, (err) => {\n                    // Bug #4: Safari returns null instead of an error.\n                    if (err === null) {\n                        fail(createEncodingError());\n                    }\n                    else {\n                        fail(err);\n                    }\n                });\n            }\n            catch (err) {\n                fail(err);\n            }\n        });\n    };\n};\n//# sourceMappingURL=decode-audio-data.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDecrementCycleCounter\": () => (/* binding */ createDecrementCycleCounter)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n\nconst createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext) => {\n    return (audioNode, count) => {\n        const cycleCounter = cycleCounters.get(audioNode);\n        if (cycleCounter === undefined) {\n            throw new Error('Missing the expected cycle count.');\n        }\n        const nativeContext = getNativeContext(audioNode.context);\n        const isOffline = isNativeOfflineAudioContext(nativeContext);\n        if (cycleCounter === count) {\n            cycleCounters.delete(audioNode);\n            if (!isOffline && isActiveAudioNode(audioNode)) {\n                const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                const { outputs } = getAudioNodeConnections(audioNode);\n                for (const output of outputs) {\n                    if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__.isAudioNodeOutputConnection)(output)) {\n                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                        connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                    }\n                    else {\n                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                        nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);\n                    }\n                }\n            }\n        }\n        else {\n            cycleCounters.set(audioNode, cycleCounter - count);\n        }\n    };\n};\n//# sourceMappingURL=decrement-cycle-counter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDelayNodeConstructor\": () => (/* binding */ createDelayNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    delayTime: 0,\n    maxDelayTime: 1\n};\nconst createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class DelayNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const delayNodeRenderer = (isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null);\n            super(context, false, nativeDelayNode, delayNodeRenderer);\n            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);\n            setAudioNodeTailTime(this, mergedOptions.maxDelayTime);\n        }\n        get delayTime() {\n            return this._delayTime;\n        }\n    };\n};\n//# sourceMappingURL=delay-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDelayNodeRendererFactory\": () => (/* binding */ createDelayNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return (maxDelayTime) => {\n        const renderedNativeDelayNodes = new WeakMap();\n        const createDelayNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeDelayNode = getNativeAudioNode(proxy);\n            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeDelayNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeDelayNode, nativeOfflineAudioContext);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeDelayNode.channelCount,\n                    channelCountMode: nativeDelayNode.channelCountMode,\n                    channelInterpretation: nativeDelayNode.channelInterpretation,\n                    delayTime: nativeDelayNode.delayTime.value,\n                    maxDelayTime\n                };\n                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode);\n            return nativeDelayNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDelayNode !== undefined) {\n                    return Promise.resolve(renderedNativeDelayNode);\n                }\n                return createDelayNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=delay-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDeleteActiveInputConnectionToAudioNode\": () => (/* binding */ createDeleteActiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createDeleteActiveInputConnectionToAudioNode = (pickElementFromSet) => {\n    return (activeInputs, source, output, input) => {\n        return pickElementFromSet(activeInputs[input], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);\n    };\n};\n//# sourceMappingURL=delete-active-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDeleteUnrenderedAudioWorkletNode\": () => (/* binding */ createDeleteUnrenderedAudioWorkletNode)\n/* harmony export */ });\nconst createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=delete-unrendered-audio-worklet-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDetectCycles\": () => (/* binding */ createDetectCycles)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n/* harmony import */ var _guards_delay_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/delay-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js\");\n\n\nconst createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey) => {\n    return function detectCycles(chain, nextLink) {\n        const audioNode = (0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);\n        if ((0,_guards_delay_node__WEBPACK_IMPORTED_MODULE_1__.isDelayNode)(audioNode)) {\n            return [];\n        }\n        if (chain[0] === audioNode) {\n            return [chain];\n        }\n        if (chain.includes(audioNode)) {\n            return [];\n        }\n        const { outputs } = getAudioNodeConnections(audioNode);\n        return Array.from(outputs)\n            .map((outputConnection) => detectCycles([...chain, audioNode], outputConnection[0]))\n            .reduce((mergedCycles, nestedCycles) => mergedCycles.concat(nestedCycles), []);\n    };\n};\n//# sourceMappingURL=detect-cycles.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDisconnectMultipleOutputs\": () => (/* binding */ createDisconnectMultipleOutputs)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output) => {\n    const outputAudioNode = outputAudioNodes[output];\n    if (outputAudioNode === undefined) {\n        throw createIndexSizeError();\n    }\n    return outputAudioNode;\n};\nconst createDisconnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destinationOrOutput = undefined, output = undefined, input = 0) => {\n        if (destinationOrOutput === undefined) {\n            return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect());\n        }\n        if (typeof destinationOrOutput === 'number') {\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();\n        }\n        if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destinationOrOutput)) {\n            if (output === undefined) {\n                return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n            }\n            if (input === undefined) {\n                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);\n            }\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);\n        }\n        if (output === undefined) {\n            return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n        }\n        return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);\n    };\n};\n//# sourceMappingURL=disconnect-multiple-outputs.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDynamicsCompressorNodeConstructor\": () => (/* binding */ createDynamicsCompressorNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    attack: 0.003,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    knee: 30,\n    ratio: 12,\n    release: 0.25,\n    threshold: -24\n};\nconst createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class DynamicsCompressorNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const dynamicsCompressorNodeRenderer = (isOffline ? createDynamicsCompressorNodeRenderer() : null);\n            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);\n            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);\n            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);\n            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;\n            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);\n            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);\n            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);\n            setAudioNodeTailTime(this, 0.006);\n        }\n        get attack() {\n            return this._attack;\n        }\n        // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.\n        get channelCount() {\n            return this._nativeDynamicsCompressorNode.channelCount;\n        }\n        set channelCount(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;\n            this._nativeDynamicsCompressorNode.channelCount = value;\n            if (value > 2) {\n                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        /*\n         * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be\n         * overwritten here.\n         */\n        get channelCountMode() {\n            return this._nativeDynamicsCompressorNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;\n            this._nativeDynamicsCompressorNode.channelCountMode = value;\n            if (value === 'max') {\n                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        get knee() {\n            return this._knee;\n        }\n        get ratio() {\n            return this._ratio;\n        }\n        get reduction() {\n            // Bug #111: Safari returns an AudioParam instead of a number.\n            if (typeof this._nativeDynamicsCompressorNode.reduction.value === 'number') {\n                return this._nativeDynamicsCompressorNode.reduction.value;\n            }\n            return this._nativeDynamicsCompressorNode.reduction;\n        }\n        get release() {\n            return this._release;\n        }\n        get threshold() {\n            return this._threshold;\n        }\n    };\n};\n//# sourceMappingURL=dynamics-compressor-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDynamicsCompressorNodeRendererFactory\": () => (/* binding */ createDynamicsCompressorNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeDynamicsCompressorNodes = new WeakMap();\n        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be\n             * created again.\n             */\n            const nativeDynamicsCompressorNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeDynamicsCompressorNode, nativeOfflineAudioContext);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                const options = {\n                    attack: nativeDynamicsCompressorNode.attack.value,\n                    channelCount: nativeDynamicsCompressorNode.channelCount,\n                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,\n                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,\n                    knee: nativeDynamicsCompressorNode.knee.value,\n                    ratio: nativeDynamicsCompressorNode.ratio.value,\n                    release: nativeDynamicsCompressorNode.release.value,\n                    threshold: nativeDynamicsCompressorNode.threshold.value\n                };\n                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);\n                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);\n                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);\n                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);\n                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode);\n            return nativeDynamicsCompressorNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDynamicsCompressorNode !== undefined) {\n                    return Promise.resolve(renderedNativeDynamicsCompressorNode);\n                }\n                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEncodingError\": () => (/* binding */ createEncodingError)\n/* harmony export */ });\nconst createEncodingError = () => new DOMException('', 'EncodingError');\n//# sourceMappingURL=encoding-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEvaluateSource\": () => (/* binding */ createEvaluateSource)\n/* harmony export */ });\nconst createEvaluateSource = (window) => {\n    return (source) => new Promise((resolve, reject) => {\n        if (window === null) {\n            // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n            reject(new SyntaxError());\n            return;\n        }\n        const head = window.document.head;\n        if (head === null) {\n            // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n            reject(new SyntaxError());\n        }\n        else {\n            const script = window.document.createElement('script');\n            // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.\n            const blob = new Blob([source], { type: 'application/javascript' });\n            const url = URL.createObjectURL(blob);\n            const originalOnErrorHandler = window.onerror;\n            const removeErrorEventListenerAndRevokeUrl = () => {\n                window.onerror = originalOnErrorHandler;\n                URL.revokeObjectURL(url);\n            };\n            window.onerror = (message, src, lineno, colno, error) => {\n                // @todo Edge thinks the source is the one of the html document.\n                if (src === url || (src === window.location.href && lineno === 1 && colno === 1)) {\n                    removeErrorEventListenerAndRevokeUrl();\n                    reject(error);\n                    return false;\n                }\n                if (originalOnErrorHandler !== null) {\n                    return originalOnErrorHandler(message, src, lineno, colno, error);\n                }\n            };\n            script.onerror = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n                reject(new SyntaxError());\n            };\n            script.onload = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                resolve();\n            };\n            script.src = url;\n            script.type = 'module';\n            head.appendChild(script);\n        }\n    });\n};\n//# sourceMappingURL=evaluate-source.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEventTargetConstructor\": () => (/* binding */ createEventTargetConstructor)\n/* harmony export */ });\nconst createEventTargetConstructor = (wrapEventListener) => {\n    return class EventTarget {\n        constructor(_nativeEventTarget) {\n            this._nativeEventTarget = _nativeEventTarget;\n            this._listeners = new WeakMap();\n        }\n        addEventListener(type, listener, options) {\n            if (listener !== null) {\n                let wrappedEventListener = this._listeners.get(listener);\n                if (wrappedEventListener === undefined) {\n                    wrappedEventListener = wrapEventListener(this, listener);\n                    if (typeof listener === 'function') {\n                        this._listeners.set(listener, wrappedEventListener);\n                    }\n                }\n                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);\n            }\n        }\n        dispatchEvent(event) {\n            return this._nativeEventTarget.dispatchEvent(event);\n        }\n        removeEventListener(type, listener, options) {\n            const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);\n            this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);\n        }\n    };\n};\n//# sourceMappingURL=event-target-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createExposeCurrentFrameAndCurrentTime\": () => (/* binding */ createExposeCurrentFrameAndCurrentTime)\n/* harmony export */ });\nconst createExposeCurrentFrameAndCurrentTime = (window) => {\n    return (currentTime, sampleRate, fn) => {\n        Object.defineProperties(window, {\n            currentFrame: {\n                configurable: true,\n                get() {\n                    return Math.round(currentTime * sampleRate);\n                }\n            },\n            currentTime: {\n                configurable: true,\n                get() {\n                    return currentTime;\n                }\n            }\n        });\n        try {\n            return fn();\n        }\n        finally {\n            if (window !== null) {\n                delete window.currentFrame;\n                delete window.currentTime;\n            }\n        }\n    };\n};\n//# sourceMappingURL=expose-current-frame-and-current-time.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createFetchSource\": () => (/* binding */ createFetchSource)\n/* harmony export */ });\nconst createFetchSource = (createAbortError) => {\n    return async (url) => {\n        try {\n            const response = await fetch(url);\n            if (response.ok) {\n                return [await response.text(), response.url];\n            }\n        }\n        catch {\n            // Ignore errors.\n        } // tslint:disable-line:no-empty\n        throw createAbortError();\n    };\n};\n//# sourceMappingURL=fetch-source.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGainNodeConstructor\": () => (/* binding */ createGainNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    gain: 1\n};\nconst createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class GainNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const gainNodeRenderer = (isOffline ? createGainNodeRenderer() : null);\n            super(context, false, nativeGainNode, gainNodeRenderer);\n            // Bug #74: Safari does not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get gain() {\n            return this._gain;\n        }\n    };\n};\n//# sourceMappingURL=gain-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGainNodeRendererFactory\": () => (/* binding */ createGainNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeGainNodes = new WeakMap();\n        const createGainNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeGainNode = getNativeAudioNode(proxy);\n            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeGainNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeGainNode, nativeOfflineAudioContext);\n            if (!nativeGainNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeGainNode.channelCount,\n                    channelCountMode: nativeGainNode.channelCountMode,\n                    channelInterpretation: nativeGainNode.channelInterpretation,\n                    gain: nativeGainNode.gain.value\n                };\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);\n            if (!nativeGainNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode);\n            return nativeGainNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNode);\n                }\n                return createGainNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=gain-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetActiveAudioWorkletNodeInputs\": () => (/* binding */ createGetActiveAudioWorkletNodeInputs)\n/* harmony export */ });\nconst createGetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore, getValueForKey) => {\n    return (nativeAudioWorkletNode) => getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode);\n};\n//# sourceMappingURL=get-active-audio-worklet-node-inputs.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioNodeRenderer\": () => (/* binding */ createGetAudioNodeRenderer)\n/* harmony export */ });\nconst createGetAudioNodeRenderer = (getAudioNodeConnections) => {\n    return (audioNode) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        if (audioNodeConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioNode in the audio graph.');\n        }\n        return audioNodeConnections.renderer;\n    };\n};\n//# sourceMappingURL=get-audio-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioNodeTailTime\": () => (/* binding */ createGetAudioNodeTailTime)\n/* harmony export */ });\nconst createGetAudioNodeTailTime = (audioNodeTailTimeStore) => {\n    return (audioNode) => { var _a; return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0; };\n};\n//# sourceMappingURL=get-audio-node-tail-time.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioParamRenderer\": () => (/* binding */ createGetAudioParamRenderer)\n/* harmony export */ });\nconst createGetAudioParamRenderer = (getAudioParamConnections) => {\n    return (audioParam) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        if (audioParamConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioParam in the audio graph.');\n        }\n        return audioParamConnections.renderer;\n    };\n};\n//# sourceMappingURL=get-audio-param-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetBackupOfflineAudioContext\": () => (/* binding */ createGetBackupOfflineAudioContext)\n/* harmony export */ });\nconst createGetBackupOfflineAudioContext = (backupOfflineAudioContextStore) => {\n    return (nativeContext) => {\n        return backupOfflineAudioContextStore.get(nativeContext);\n    };\n};\n//# sourceMappingURL=get-backup-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetNativeContext\": () => (/* binding */ createGetNativeContext)\n/* harmony export */ });\n/* harmony import */ var _invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst createGetNativeContext = (contextStore) => {\n    return (context) => {\n        const nativeContext = contextStore.get(context);\n        if (nativeContext === undefined) {\n            throw (0,_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n        }\n        return (nativeContext);\n    };\n};\n//# sourceMappingURL=get-native-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetOrCreateBackupOfflineAudioContext\": () => (/* binding */ createGetOrCreateBackupOfflineAudioContext)\n/* harmony export */ });\nconst createGetOrCreateBackupOfflineAudioContext = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor) => {\n    return (nativeContext) => {\n        let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);\n        if (backupOfflineAudioContext !== undefined) {\n            return backupOfflineAudioContext;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n        }\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);\n        return backupOfflineAudioContext;\n    };\n};\n//# sourceMappingURL=get-or-create-backup-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetUnrenderedAudioWorkletNodes\": () => (/* binding */ createGetUnrenderedAudioWorkletNodes)\n/* harmony export */ });\nconst createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore) => {\n    return (nativeContext) => {\n        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);\n        if (unrenderedAudioWorkletNodes === undefined) {\n            throw new Error('The context has no set of AudioWorkletNodes.');\n        }\n        return unrenderedAudioWorkletNodes;\n    };\n};\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIIRFilterNodeConstructor\": () => (/* binding */ createIIRFilterNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_wrap_iir_filter_node_get_frequency_response_method__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/wrap-iir-filter-node-get-frequency-response-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers'\n};\nconst createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class IIRFilterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);\n            const iirFilterNodeRenderer = ((isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null));\n            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);\n            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.\n            // @todo Write a test which allows other browsers to remain unpatched.\n            (0,_helpers_wrap_iir_filter_node_get_frequency_response_method__WEBPACK_IMPORTED_MODULE_0__.wrapIIRFilterNodeGetFrequencyResponseMethod)(nativeIIRFilterNode);\n            this._nativeIIRFilterNode = nativeIIRFilterNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n        }\n    };\n};\n//# sourceMappingURL=iir-filter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIIRFilterNodeRendererFactory\": () => (/* binding */ createIIRFilterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/filter-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward) => {\n    const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);\n    const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);\n    const feedbackLength = convertedFeedback.length;\n    const feedforwardLength = convertedFeedforward.length;\n    const minLength = Math.min(feedbackLength, feedforwardLength);\n    if (convertedFeedback[0] !== 1) {\n        for (let i = 0; i < feedbackLength; i += 1) {\n            convertedFeedforward[i] /= convertedFeedback[0];\n        }\n        for (let i = 1; i < feedforwardLength; i += 1) {\n            convertedFeedback[i] /= convertedFeedback[0];\n        }\n    }\n    const bufferLength = 32;\n    const xBuffer = new Float32Array(bufferLength);\n    const yBuffer = new Float32Array(bufferLength);\n    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);\n    const numberOfChannels = renderedBuffer.numberOfChannels;\n    for (let i = 0; i < numberOfChannels; i += 1) {\n        const input = renderedBuffer.getChannelData(i);\n        const output = filteredBuffer.getChannelData(i);\n        xBuffer.fill(0);\n        yBuffer.fill(0);\n        (0,_helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_0__.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);\n    }\n    return filteredBuffer;\n};\nconst createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (feedback, feedforward) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let filteredBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioBufferSourceNode = null;\n            let nativeIIRFilterNode = getNativeAudioNode(proxy);\n            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeIIRFilterNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeIIRFilterNode, nativeOfflineAudioContext);\n            // Bug #9: Safari does not support IIRFilterNodes.\n            if (nativeOfflineAudioContext.createIIRFilter === undefined) {\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n            }\n            else if (!nativeIIRFilterNodeIsOwnedByContext) {\n                // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.\n                nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);\n            if (nativeAudioBufferSourceNode !== null) {\n                if (filteredBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(\n                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n                    proxy.context.destination.channelCount, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    filteredBufferPromise = (async () => {\n                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination);\n                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                        return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);\n                    })();\n                }\n                const filteredBuffer = await filteredBufferPromise;\n                nativeAudioBufferSourceNode.buffer = filteredBuffer;\n                nativeAudioBufferSourceNode.start(0);\n                return nativeAudioBufferSourceNode;\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode);\n            return nativeIIRFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=iir-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIncrementCycleCounterFactory\": () => (/* binding */ createIncrementCycleCounterFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n\nconst createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode) => {\n    return (isOffline) => {\n        return (audioNode, count) => {\n            const cycleCounter = cycleCounters.get(audioNode);\n            if (cycleCounter === undefined) {\n                if (!isOffline && isActiveAudioNode(audioNode)) {\n                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                    const { outputs } = getAudioNodeConnections(audioNode);\n                    for (const output of outputs) {\n                        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__.isAudioNodeOutputConnection)(output)) {\n                            const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                            disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                        }\n                        else {\n                            const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                            nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);\n                        }\n                    }\n                }\n                cycleCounters.set(audioNode, count);\n            }\n            else {\n                cycleCounters.set(audioNode, cycleCounter + count);\n            }\n        };\n    };\n};\n//# sourceMappingURL=increment-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIndexSizeError\": () => (/* binding */ createIndexSizeError)\n/* harmony export */ });\nconst createIndexSizeError = () => new DOMException('', 'IndexSizeError');\n//# sourceMappingURL=index-size-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createInvalidAccessError\": () => (/* binding */ createInvalidAccessError)\n/* harmony export */ });\nconst createInvalidAccessError = () => new DOMException('', 'InvalidAccessError');\n//# sourceMappingURL=invalid-access-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createInvalidStateError\": () => (/* binding */ createInvalidStateError)\n/* harmony export */ });\nconst createInvalidStateError = () => new DOMException('', 'InvalidStateError');\n//# sourceMappingURL=invalid-state-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioContext\": () => (/* binding */ createIsAnyAudioContext)\n/* harmony export */ });\nconst createIsAnyAudioContext = (contextStore, isNativeAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-any-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioNode\": () => (/* binding */ createIsAnyAudioNode)\n/* harmony export */ });\nconst createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode) => {\n    return (anything) => audioNodeStore.has(anything) || isNativeAudioNode(anything);\n};\n//# sourceMappingURL=is-any-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioParam\": () => (/* binding */ createIsAnyAudioParam)\n/* harmony export */ });\nconst createIsAnyAudioParam = (audioParamStore, isNativeAudioParam) => {\n    return (anything) => audioParamStore.has(anything) || isNativeAudioParam(anything);\n};\n//# sourceMappingURL=is-any-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyOfflineAudioContext\": () => (/* binding */ createIsAnyOfflineAudioContext)\n/* harmony export */ });\nconst createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-any-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioContext\": () => (/* binding */ createIsNativeAudioContext)\n/* harmony export */ });\nconst createIsNativeAudioContext = (nativeAudioContextConstructor) => {\n    return (anything) => {\n        return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;\n    };\n};\n//# sourceMappingURL=is-native-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioNode\": () => (/* binding */ createIsNativeAudioNode)\n/* harmony export */ });\nconst createIsNativeAudioNode = (window) => {\n    return (anything) => {\n        return window !== null && typeof window.AudioNode === 'function' && anything instanceof window.AudioNode;\n    };\n};\n//# sourceMappingURL=is-native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioParam\": () => (/* binding */ createIsNativeAudioParam)\n/* harmony export */ });\nconst createIsNativeAudioParam = (window) => {\n    return (anything) => {\n        return window !== null && typeof window.AudioParam === 'function' && anything instanceof window.AudioParam;\n    };\n};\n//# sourceMappingURL=is-native-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeContext\": () => (/* binding */ createIsNativeContext)\n/* harmony export */ });\nconst createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-native-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeOfflineAudioContext\": () => (/* binding */ createIsNativeOfflineAudioContext)\n/* harmony export */ });\nconst createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor) => {\n    return (anything) => {\n        return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;\n    };\n};\n//# sourceMappingURL=is-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsSecureContext\": () => (/* binding */ createIsSecureContext)\n/* harmony export */ });\nconst createIsSecureContext = (window) => window !== null && window.isSecureContext;\n//# sourceMappingURL=is-secure-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsSupportedPromise\": () => (/* binding */ createIsSupportedPromise)\n/* harmony export */ });\nconst createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport) => {\n    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) &&\n        cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) &&\n        cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) &&\n        cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) &&\n        cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) &&\n        cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) &&\n        cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) &&\n        cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) &&\n        cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) &&\n        cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) &&\n        cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {\n        const results = await Promise.all([\n            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),\n            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),\n            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),\n            cacheTestResult(testTransferablesSupport, testTransferablesSupport)\n        ]);\n        return results.every((result) => result);\n    }\n    return false;\n};\n//# sourceMappingURL=is-supported-promise.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaElementAudioSourceNodeConstructor\": () => (/* binding */ createMediaElementAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaElementAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);\n            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw TypeError();\n            }\n            super(context, true, nativeMediaElementAudioSourceNode, null);\n            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;\n        }\n        get mediaElement() {\n            return this._nativeMediaElementAudioSourceNode.mediaElement;\n        }\n    };\n};\n//# sourceMappingURL=media-element-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamAudioDestinationNodeConstructor\": () => (/* binding */ createMediaStreamAudioDestinationNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers'\n};\nconst createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioDestinationNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);\n            super(context, false, nativeMediaStreamAudioDestinationNode, null);\n            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;\n        }\n        get stream() {\n            return this._nativeMediaStreamAudioDestinationNode.stream;\n        }\n    };\n};\n//# sourceMappingURL=media-stream-audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamAudioSourceNodeConstructor\": () => (/* binding */ createMediaStreamAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);\n            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            super(context, true, nativeMediaStreamAudioSourceNode, null);\n            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;\n        }\n        get mediaStream() {\n            return this._nativeMediaStreamAudioSourceNode.mediaStream;\n        }\n    };\n};\n//# sourceMappingURL=media-stream-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamTrackAudioSourceNodeConstructor\": () => (/* binding */ createMediaStreamTrackAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext) => {\n    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);\n            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);\n        }\n    };\n};\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalAudioContextConstructor\": () => (/* binding */ createMinimalAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-valid-latency-hint */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js\");\n\n\nconst createMinimalAudioContextConstructor = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor) => {\n    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            let nativeAudioContext;\n            try {\n                nativeAudioContext = new nativeAudioContextConstructor(options);\n            }\n            catch (err) {\n                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.\n                if (err.code === 12 && err.message === 'sampleRate is not in range') {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome Edge, and Opera throw an error if the given latencyHint is invalid.\n            if (!(0,_helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__.isValidLatencyHint)(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Safari does not support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency =\n                typeof nativeAudioContext.baseLatency === 'number'\n                    ? nativeAudioContext.baseLatency\n                    : latencyHint === 'balanced'\n                        ? 512 / sampleRate\n                        : latencyHint === 'interactive' || latencyHint === undefined\n                            ? 256 / sampleRate\n                            : latencyHint === 'playback'\n                                ? 1024 / sampleRate\n                                : /*\n                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                                   * ScriptProcessorNode.\n                                   */\n                                    (Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate;\n            this._nativeAudioContext = nativeAudioContext;\n            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.\n            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                this._nativeGainNode = nativeAudioContext.createGain();\n                this._nativeOscillatorNode = nativeAudioContext.createOscillator();\n                this._nativeGainNode.gain.value = 1e-37;\n                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);\n                this._nativeOscillatorNode.start();\n            }\n            else {\n                this._nativeGainNode = null;\n                this._nativeOscillatorNode = null;\n            }\n            this._state = null;\n            /*\n             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually\n             * changes to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return this._state !== null ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext.close().then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close().then(() => {\n                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {\n                    this._nativeOscillatorNode.stop();\n                    this._nativeGainNode.disconnect();\n                    this._nativeOscillatorNode.disconnect();\n                }\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this.resume().then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext.resume().catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext.suspend().catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=minimal-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalBaseAudioContextConstructor\": () => (/* binding */ createMinimalBaseAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener) => {\n    return class MinimalBaseAudioContext extends eventTargetConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext);\n            this._nativeContext = _nativeContext;\n            _globals__WEBPACK_IMPORTED_MODULE_0__.CONTEXT_STORE.set(this, _nativeContext);\n            if (isNativeOfflineAudioContext(_nativeContext)) {\n                unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());\n            }\n            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);\n            this._listener = createAudioListener(this, _nativeContext);\n            this._onstatechange = null;\n        }\n        get currentTime() {\n            return this._nativeContext.currentTime;\n        }\n        get destination() {\n            return this._destination;\n        }\n        get listener() {\n            return this._listener;\n        }\n        get onstatechange() {\n            return this._onstatechange;\n        }\n        set onstatechange(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeContext.onstatechange = wrappedListener;\n            const nativeOnStateChange = this._nativeContext.onstatechange;\n            this._onstatechange = nativeOnStateChange !== null && nativeOnStateChange === wrappedListener ? value : nativeOnStateChange;\n        }\n        get sampleRate() {\n            return this._nativeContext.sampleRate;\n        }\n        get state() {\n            return this._nativeContext.state;\n        }\n    };\n};\n//# sourceMappingURL=minimal-base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalOfflineAudioContextConstructor\": () => (/* binding */ createMinimalOfflineAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createMinimalOfflineAudioContextConstructor = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering) => {\n    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options) {\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport)(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(() => {\n                this._state = null;\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=minimal-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMonitorConnections\": () => (/* binding */ createMonitorConnections)\n/* harmony export */ });\nconst createMonitorConnections = (insertElementInSet, isNativeAudioNode) => {\n    return (nativeAudioNode, whenConnected, whenDisconnected) => {\n        const connections = new Set();\n        nativeAudioNode.connect = ((connect) => {\n            // tslint:disable-next-line:invalid-void no-inferrable-types\n            return (destination, output = 0, input = 0) => {\n                const wasDisconnected = connections.size === 0;\n                if (isNativeAudioNode(destination)) {\n                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                    connect.call(nativeAudioNode, destination, output, input);\n                    insertElementInSet(connections, [destination, output, input], (connection) => connection[0] === destination && connection[1] === output && connection[2] === input, true);\n                    if (wasDisconnected) {\n                        whenConnected();\n                    }\n                    return destination;\n                }\n                connect.call(nativeAudioNode, destination, output);\n                insertElementInSet(connections, [destination, output], (connection) => connection[0] === destination && connection[1] === output, true);\n                if (wasDisconnected) {\n                    whenConnected();\n                }\n                return;\n            };\n        })(nativeAudioNode.connect);\n        nativeAudioNode.disconnect = ((disconnect) => {\n            return (destinationOrOutput, output, input) => {\n                const wasConnected = connections.size > 0;\n                if (destinationOrOutput === undefined) {\n                    disconnect.apply(nativeAudioNode);\n                    connections.clear();\n                }\n                else if (typeof destinationOrOutput === 'number') {\n                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n                    disconnect.call(nativeAudioNode, destinationOrOutput);\n                    for (const connection of connections) {\n                        if (connection[1] === destinationOrOutput) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                else {\n                    if (isNativeAudioNode(destinationOrOutput)) {\n                        // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output, input);\n                    }\n                    else {\n                        // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output);\n                    }\n                    for (const connection of connections) {\n                        if (connection[0] === destinationOrOutput &&\n                            (output === undefined || connection[1] === output) &&\n                            (input === undefined || connection[2] === input)) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                const isDisconnected = connections.size === 0;\n                if (wasConnected && isDisconnected) {\n                    whenDisconnected();\n                }\n            };\n        })(nativeAudioNode.disconnect);\n        return nativeAudioNode;\n    };\n};\n//# sourceMappingURL=monitor-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAnalyserNodeFactory\": () => (/* binding */ createNativeAnalyserNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/test-analyser-node-get-float-time-domain-data-method-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js\");\n/* harmony import */ var _helpers_wrap_analyser_node_get_float_time_domain_data_method__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-analyser-node-get-float-time-domain-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js\");\n\n\n\n\nconst createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError) => {\n    return (nativeContext, options) => {\n        const nativeAnalyserNode = nativeContext.createAnalyser();\n        // Bug #37: Firefox does not create an AnalyserNode with the default properties.\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeAnalyserNode, options);\n        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n        if (!(options.maxDecibels > options.minDecibels)) {\n            throw createIndexSizeError();\n        }\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'fftSize');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'maxDecibels');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'minDecibels');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'smoothingTimeConstant');\n        // Bug #36: Safari does not support getFloatTimeDomainData() yet.\n        if (!cacheTestResult(_helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__.testAnalyserNodeGetFloatTimeDomainDataMethodSupport, () => (0,_helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__.testAnalyserNodeGetFloatTimeDomainDataMethodSupport)(nativeAnalyserNode))) {\n            (0,_helpers_wrap_analyser_node_get_float_time_domain_data_method__WEBPACK_IMPORTED_MODULE_3__.wrapAnalyserNodeGetFloatTimeDomainDataMethod)(nativeAnalyserNode);\n        }\n        return nativeAnalyserNode;\n    };\n};\n//# sourceMappingURL=native-analyser-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioBufferConstructor\": () => (/* binding */ createNativeAudioBufferConstructor)\n/* harmony export */ });\nconst createNativeAudioBufferConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioBuffer')) {\n        return window.AudioBuffer;\n    }\n    return null;\n};\n//# sourceMappingURL=native-audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioBufferSourceNodeFactory\": () => (/* binding */ createNativeAudioBufferSourceNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_source_node_start_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\n\n\nconst createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeAudioBufferSourceNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeAudioBufferSourceNode, options, 'playbackRate');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'buffer');\n        // Bug #149: Safari does not yet support the detune AudioParam.\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loop');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loopEnd');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loopStart');\n        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, () => testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_buffer_source_node_start_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_3__.wrapAudioBufferSourceNodeStartMethodConsecutiveCalls)(nativeAudioBufferSourceNode);\n        }\n        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, () => testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);\n        }\n        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.\n        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, () => testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Safari does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeAudioBufferSourceNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_5__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeAudioBufferSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);\n        return nativeAudioBufferSourceNode;\n    };\n};\n//# sourceMappingURL=native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioContextConstructor\": () => (/* binding */ createNativeAudioContextConstructor)\n/* harmony export */ });\nconst createNativeAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioContext')) {\n        return window.AudioContext;\n    }\n    return window.hasOwnProperty('webkitAudioContext') ? window.webkitAudioContext : null;\n};\n//# sourceMappingURL=native-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioDestinationNodeFactory\": () => (/* binding */ createNativeAudioDestinationNodeFactory)\n/* harmony export */ });\nconst createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors) => {\n    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext) => {\n        const nativeAudioDestinationNode = nativeContext.destination;\n        // Bug #132: Safari does not have the correct channelCount.\n        if (nativeAudioDestinationNode.channelCount !== channelCount) {\n            try {\n                nativeAudioDestinationNode.channelCount = channelCount;\n            }\n            catch {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n            }\n        }\n        // Bug #83: Safari does not have the correct channelCountMode.\n        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') {\n            nativeAudioDestinationNode.channelCountMode = 'explicit';\n        }\n        // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.\n        if (nativeAudioDestinationNode.maxChannelCount === 0) {\n            Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {\n                value: channelCount\n            });\n        }\n        // Bug #168: No browser does yet have an AudioDestinationNode with an output.\n        const gainNode = createNativeGainNode(nativeContext, {\n            channelCount,\n            channelCountMode: nativeAudioDestinationNode.channelCountMode,\n            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,\n            gain: 1\n        });\n        overwriteAccessors(gainNode, 'channelCount', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            try {\n                nativeAudioDestinationNode.channelCount = value;\n            }\n            catch (err) {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n                if (value > nativeAudioDestinationNode.maxChannelCount) {\n                    throw err;\n                }\n            }\n        });\n        overwriteAccessors(gainNode, 'channelCountMode', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelCountMode = value;\n        });\n        overwriteAccessors(gainNode, 'channelInterpretation', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelInterpretation = value;\n        });\n        Object.defineProperty(gainNode, 'maxChannelCount', {\n            get: () => nativeAudioDestinationNode.maxChannelCount\n        });\n        // @todo This should be disconnected when the context is closed.\n        gainNode.connect(nativeAudioDestinationNode);\n        return gainNode;\n    };\n};\n//# sourceMappingURL=native-audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeConstructor\": () => (/* binding */ createNativeAudioWorkletNodeConstructor)\n/* harmony export */ });\nconst createNativeAudioWorkletNodeConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    return window.hasOwnProperty('AudioWorkletNode') ? window.AudioWorkletNode : null;\n};\n//# sourceMappingURL=native-audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeFactory\": () => (/* binding */ createNativeAudioWorkletNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_clonability_of_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-clonability-of-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js\");\n\nconst createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections) => {\n    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options) => {\n        if (nativeAudioWorkletNodeConstructor !== null) {\n            try {\n                const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);\n                const patchedEventListeners = new Map();\n                let onprocessorerror = null;\n                Object.defineProperties(nativeAudioWorkletNode, {\n                    /*\n                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some\n                     * browsers have no native implementation to achieve a consistent behavior.\n                     */\n                    channelCount: {\n                        get: () => options.channelCount,\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    channelCountMode: {\n                        get: () => 'explicit',\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.\n                    onprocessorerror: {\n                        get: () => onprocessorerror,\n                        set: (value) => {\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.removeEventListener('processorerror', onprocessorerror);\n                            }\n                            onprocessorerror = typeof value === 'function' ? value : null;\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.addEventListener('processorerror', onprocessorerror);\n                            }\n                        }\n                    }\n                });\n                nativeAudioWorkletNode.addEventListener = ((addEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const unpatchedEventListener = typeof args[1] === 'function'\n                                ? args[1]\n                                : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'\n                                    ? args[1].handleEvent\n                                    : null;\n                            if (unpatchedEventListener !== null) {\n                                const patchedEventListener = patchedEventListeners.get(args[1]);\n                                if (patchedEventListener !== undefined) {\n                                    args[1] = patchedEventListener;\n                                }\n                                else {\n                                    args[1] = (event) => {\n                                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                                        if (event.type === 'error') {\n                                            Object.defineProperties(event, {\n                                                type: { value: 'processorerror' }\n                                            });\n                                            unpatchedEventListener(event);\n                                        }\n                                        else {\n                                            unpatchedEventListener(new ErrorEvent(args[0], { ...event }));\n                                        }\n                                    };\n                                    patchedEventListeners.set(unpatchedEventListener, args[1]);\n                                }\n                            }\n                        }\n                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                        addEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);\n                        return addEventListener.call(nativeAudioWorkletNode, ...args);\n                    };\n                })(nativeAudioWorkletNode.addEventListener);\n                nativeAudioWorkletNode.removeEventListener = ((removeEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const patchedEventListener = patchedEventListeners.get(args[1]);\n                            if (patchedEventListener !== undefined) {\n                                patchedEventListeners.delete(args[1]);\n                                args[1] = patchedEventListener;\n                            }\n                        }\n                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                        removeEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);\n                        return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);\n                    };\n                })(nativeAudioWorkletNode.removeEventListener);\n                /*\n                 * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but\n                 * has an output.\n                 */\n                if (options.numberOfOutputs !== 0) {\n                    const nativeGainNode = createNativeGainNode(nativeContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'discrete',\n                        gain: 0\n                    });\n                    nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);\n                    const whenConnected = () => nativeGainNode.disconnect();\n                    const whenDisconnected = () => nativeGainNode.connect(nativeContext.destination);\n                    // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.\n                    return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);\n                }\n                return nativeAudioWorkletNode;\n            }\n            catch (err) {\n                // Bug #60: Chrome, Edge & Opera throw an InvalidStateError instead of a NotSupportedError.\n                if (err.code === 11) {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n        }\n        // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.\n        if (processorConstructor === undefined) {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_test_clonability_of_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__.testClonabilityOfAudioWorkletNodeOptions)(options);\n        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);\n    };\n};\n//# sourceMappingURL=native-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeFakerFactory\": () => (/* binding */ createNativeAudioWorkletNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/compute-buffer-size */ \"./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js\");\n/* harmony import */ var _helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/copy-from-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js\");\n/* harmony import */ var _helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/copy-to-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js\");\n/* harmony import */ var _helpers_create_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/create-audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js\");\n/* harmony import */ var _helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/create-nested-arrays */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/read-only-map.js\");\n\n\n\n\n\n\n\nconst createNativeAudioWorkletNodeFakerFactory = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections) => {\n    return (nativeContext, baseLatency, processorConstructor, options) => {\n        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) {\n            throw createNotSupportedError();\n        }\n        const outputChannelCount = Array.isArray(options.outputChannelCount)\n            ? options.outputChannelCount\n            : Array.from(options.outputChannelCount);\n        // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.\n        if (outputChannelCount.some((channelCount) => channelCount < 1)) {\n            throw createNotSupportedError();\n        }\n        if (outputChannelCount.length !== options.numberOfOutputs) {\n            throw createIndexSizeError();\n        }\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (options.channelCountMode !== 'explicit') {\n            throw createNotSupportedError();\n        }\n        const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n        const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) {\n            throw createNotSupportedError();\n        }\n        const messageChannel = new MessageChannel();\n        const gainNodes = [];\n        const inputChannelSplitterNodes = [];\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes.push(createNativeGainNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: options.channelCountMode,\n                channelInterpretation: options.channelInterpretation,\n                gain: 1\n            }));\n            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                numberOfOutputs: options.channelCount\n            }));\n        }\n        const constantSourceNodes = [];\n        if (processorConstructor.parameterDescriptors !== undefined) {\n            for (const { defaultValue, maxValue, minValue, name } of processorConstructor.parameterDescriptors) {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {\n                    channelCount: 1,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    offset: options.parameterData[name] !== undefined\n                        ? options.parameterData[name]\n                        : defaultValue === undefined\n                            ? 0\n                            : defaultValue\n                });\n                Object.defineProperties(constantSourceNode.offset, {\n                    defaultValue: {\n                        get: () => (defaultValue === undefined ? 0 : defaultValue)\n                    },\n                    maxValue: {\n                        get: () => (maxValue === undefined ? _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT : maxValue)\n                    },\n                    minValue: {\n                        get: () => (minValue === undefined ? _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT : minValue)\n                    }\n                });\n                constantSourceNodes.push(constantSourceNode);\n            }\n        }\n        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'speakers',\n            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n        });\n        const bufferSize = (0,_helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_1__.computeBufferSize)(baseLatency, nativeContext.sampleRate);\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, \n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        Math.max(1, numberOfOutputChannels));\n        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: Math.max(1, numberOfOutputChannels),\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: Math.max(1, numberOfOutputChannels)\n        });\n        const outputChannelMergerNodes = [];\n        for (let i = 0; i < options.numberOfOutputs; i += 1) {\n            outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'speakers',\n                numberOfInputs: outputChannelCount[i]\n            }));\n        }\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n            for (let j = 0; j < options.channelCount; j += 1) {\n                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n            }\n        }\n        const parameterMap = new _read_only_map__WEBPACK_IMPORTED_MODULE_6__.ReadOnlyMap(processorConstructor.parameterDescriptors === undefined\n            ? []\n            : processorConstructor.parameterDescriptors.map(({ name }, index) => {\n                const constantSourceNode = constantSourceNodes[index];\n                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                constantSourceNode.start(0);\n                return [name, constantSourceNode.offset];\n            }));\n        inputChannelMergerNode.connect(scriptProcessorNode);\n        let channelInterpretation = options.channelInterpretation;\n        let onprocessorerror = null;\n        // Bug #87: Expose at least one output to make this node connectable.\n        const outputAudioNodes = options.numberOfOutputs === 0 ? [scriptProcessorNode] : outputChannelMergerNodes;\n        const nativeAudioWorkletNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return options.channelCount;\n            },\n            set channelCount(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelCountMode() {\n                return options.channelCountMode;\n            },\n            set channelCountMode(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelInterpretation() {\n                return channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                for (const gainNode of gainNodes) {\n                    gainNode.channelInterpretation = value;\n                }\n                channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return gainNodes;\n            },\n            get numberOfInputs() {\n                return options.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return options.numberOfOutputs;\n            },\n            get onprocessorerror() {\n                return onprocessorerror;\n            },\n            set onprocessorerror(value) {\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.removeEventListener('processorerror', onprocessorerror);\n                }\n                onprocessorerror = typeof value === 'function' ? value : null;\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.addEventListener('processorerror', onprocessorerror);\n                }\n            },\n            get parameters() {\n                return parameterMap;\n            },\n            get port() {\n                return messageChannel.port2;\n            },\n            addEventListener(...args) {\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            connect: connectMultipleOutputs.bind(null, outputAudioNodes),\n            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        const patchedEventListeners = new Map();\n        messageChannel.port1.addEventListener = ((addEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const unpatchedEventListener = typeof args[1] === 'function'\n                        ? args[1]\n                        : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'\n                            ? args[1].handleEvent\n                            : null;\n                    if (unpatchedEventListener !== null) {\n                        const patchedEventListener = patchedEventListeners.get(args[1]);\n                        if (patchedEventListener !== undefined) {\n                            args[1] = patchedEventListener;\n                        }\n                        else {\n                            args[1] = (event) => {\n                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => unpatchedEventListener(event));\n                            };\n                            patchedEventListeners.set(unpatchedEventListener, args[1]);\n                        }\n                    }\n                }\n                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.addEventListener);\n        messageChannel.port1.removeEventListener = ((removeEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const patchedEventListener = patchedEventListeners.get(args[1]);\n                    if (patchedEventListener !== undefined) {\n                        patchedEventListeners.delete(args[1]);\n                        args[1] = patchedEventListener;\n                    }\n                }\n                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.removeEventListener);\n        let onmessage = null;\n        Object.defineProperty(messageChannel.port1, 'onmessage', {\n            get: () => onmessage,\n            set: (value) => {\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.removeEventListener('message', onmessage);\n                }\n                onmessage = typeof value === 'function' ? value : null;\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.addEventListener('message', onmessage);\n                    messageChannel.port1.start();\n                }\n            }\n        });\n        processorConstructor.prototype.port = messageChannel.port1;\n        let audioWorkletProcessor = null;\n        const audioWorkletProcessorPromise = (0,_helpers_create_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__.createAudioWorkletProcessor)(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);\n        audioWorkletProcessorPromise.then((dWrkltPrcssr) => (audioWorkletProcessor = dWrkltPrcssr));\n        const inputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__.createNestedArrays)(options.numberOfInputs, options.channelCount);\n        const outputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__.createNestedArrays)(options.numberOfOutputs, outputChannelCount);\n        const parameters = processorConstructor.parameterDescriptors === undefined\n            ? []\n            : processorConstructor.parameterDescriptors.reduce((prmtrs, { name }) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n        let isActive = true;\n        const disconnectOutputsGraph = () => {\n            if (options.numberOfOutputs > 0) {\n                scriptProcessorNode.disconnect(outputChannelSplitterNode);\n            }\n            for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                const outputChannelMergerNode = outputChannelMergerNodes[i];\n                for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                    outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                }\n                outputChannelSplitterNodeOutput += outputChannelCount[i];\n            }\n        };\n        const activeInputIndexes = new Map();\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer, outputBuffer }) => {\n            if (audioWorkletProcessor !== null) {\n                const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);\n                for (let i = 0; i < bufferSize; i += 128) {\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < options.channelCount; k += 1) {\n                            (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__.copyFromChannel)(inputBuffer, inputs[j], k, k, i);\n                        }\n                    }\n                    if (processorConstructor.parameterDescriptors !== undefined) {\n                        processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                            (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__.copyFromChannel)(inputBuffer, parameters, name, numberOfInputChannels + index, i);\n                        });\n                    }\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                            // The byteLength will be 0 when the ArrayBuffer was transferred.\n                            if (outputs[j][k].byteLength === 0) {\n                                outputs[j][k] = new Float32Array(128);\n                            }\n                        }\n                    }\n                    try {\n                        const potentiallyEmptyInputs = inputs.map((input, index) => {\n                            const activeInput = activeInputs[index];\n                            if (activeInput.size > 0) {\n                                activeInputIndexes.set(index, bufferSize / 128);\n                                return input;\n                            }\n                            const count = activeInputIndexes.get(index);\n                            if (count === undefined) {\n                                return [];\n                            }\n                            if (input.every((channelData) => channelData.every((sample) => sample === 0))) {\n                                if (count === 1) {\n                                    activeInputIndexes.delete(index);\n                                }\n                                else {\n                                    activeInputIndexes.set(index, count - 1);\n                                }\n                            }\n                            return input;\n                        });\n                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i / nativeContext.sampleRate, nativeContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n                        isActive = activeSourceFlag;\n                        for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                            for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                                (0,_helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_3__.copyToChannel)(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                            }\n                            outputChannelSplitterNodeOutput += outputChannelCount[j];\n                        }\n                    }\n                    catch (error) {\n                        isActive = false;\n                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent('processorerror', {\n                            colno: error.colno,\n                            filename: error.filename,\n                            lineno: error.lineno,\n                            message: error.message\n                        }));\n                    }\n                    if (!isActive) {\n                        for (let j = 0; j < options.numberOfInputs; j += 1) {\n                            gainNodes[j].disconnect(inputChannelSplitterNodes[j]);\n                            for (let k = 0; k < options.channelCount; k += 1) {\n                                inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, j * options.channelCount + k);\n                            }\n                        }\n                        if (processorConstructor.parameterDescriptors !== undefined) {\n                            const length = processorConstructor.parameterDescriptors.length;\n                            for (let j = 0; j < length; j += 1) {\n                                const constantSourceNode = constantSourceNodes[j];\n                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);\n                                constantSourceNode.stop();\n                            }\n                        }\n                        inputChannelMergerNode.disconnect(scriptProcessorNode);\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        if (isConnected) {\n                            disconnectOutputsGraph();\n                        }\n                        else {\n                            disconnectFakeGraph();\n                        }\n                        break;\n                    }\n                }\n            }\n        };\n        let isConnected = false;\n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        const nativeGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        const connectFakeGraph = () => scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination);\n        const disconnectFakeGraph = () => {\n            scriptProcessorNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        const whenConnected = () => {\n            if (isActive) {\n                disconnectFakeGraph();\n                if (options.numberOfOutputs > 0) {\n                    scriptProcessorNode.connect(outputChannelSplitterNode);\n                }\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[i];\n                }\n            }\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            if (isActive) {\n                connectFakeGraph();\n                disconnectOutputsGraph();\n            }\n            isConnected = false;\n        };\n        connectFakeGraph();\n        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-audio-worklet-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeBiquadFilterNode\": () => (/* binding */ createNativeBiquadFilterNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\n\nconst createNativeBiquadFilterNode = (nativeContext, options) => {\n    const nativeBiquadFilterNode = nativeContext.createBiquadFilter();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeBiquadFilterNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'Q');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'detune');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'frequency');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'gain');\n    (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeBiquadFilterNode, options, 'type');\n    return nativeBiquadFilterNode;\n};\n//# sourceMappingURL=native-biquad-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeChannelMergerNodeFactory\": () => (/* binding */ createNativeChannelMergerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeChannelMergerNodeFactory = (nativeAudioContextConstructor, wrapChannelMergerNode) => {\n    return (nativeContext, options) => {\n        const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);\n        /*\n         * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.\n         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of\n         * the webkitAudioContext is used as a workaround here.\n         */\n        if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {\n            wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeChannelMergerNode, options);\n        return nativeChannelMergerNode;\n    };\n};\n//# sourceMappingURL=native-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeChannelSplitterNode\": () => (/* binding */ createNativeChannelSplitterNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_channel_splitter_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js\");\n\n\nconst createNativeChannelSplitterNode = (nativeContext, options) => {\n    const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);\n    // Bug #96: Safari does not have the correct channelCount.\n    // Bug #29: Safari does not have the correct channelCountMode.\n    // Bug #31: Safari does not have the correct channelInterpretation.\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeChannelSplitterNode, options);\n    // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge, Firefox & Opera partially support the spec yet.\n    (0,_helpers_wrap_channel_splitter_node__WEBPACK_IMPORTED_MODULE_1__.wrapChannelSplitterNode)(nativeChannelSplitterNode);\n    return nativeChannelSplitterNode;\n};\n//# sourceMappingURL=native-channel-splitter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConstantSourceNodeFactory\": () => (/* binding */ createNativeConstantSourceNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\nconst createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport) => {\n    return (nativeContext, options) => {\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeContext.createConstantSource === undefined) {\n            return createNativeConstantSourceNodeFaker(nativeContext, options);\n        }\n        const nativeConstantSourceNode = nativeContext.createConstantSource();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeConstantSourceNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeConstantSourceNode, options, 'offset');\n        // Bug #44: Safari does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_2__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeConstantSourceNode);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeConstantSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeConstantSourceNode);\n        return nativeConstantSourceNode;\n    };\n};\n//# sourceMappingURL=native-constant-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConstantSourceNodeFakerFactory\": () => (/* binding */ createNativeConstantSourceNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections) => {\n    return (nativeContext, { offset, ...audioNodeOptions }) => {\n        const audioBuffer = nativeContext.createBuffer(1, 2, 44100);\n        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const gainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: offset });\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        const channelData = audioBuffer.getChannelData(0);\n        // Bug #95: Safari does not play or loop one sample buffers.\n        channelData[0] = 1;\n        channelData[1] = 1;\n        audioBufferSourceNode.buffer = audioBuffer;\n        audioBufferSourceNode.loop = true;\n        const nativeConstantSourceNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return gainNode.channelCount;\n            },\n            set channelCount(value) {\n                gainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return gainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                gainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return gainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                gainNode.channelInterpretation = value;\n            },\n            get context() {\n                return gainNode.context;\n            },\n            get inputs() {\n                return [];\n            },\n            get numberOfInputs() {\n                return audioBufferSourceNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return gainNode.numberOfOutputs;\n            },\n            get offset() {\n                return gainNode.gain;\n            },\n            get onended() {\n                return audioBufferSourceNode.onended;\n            },\n            set onended(value) {\n                audioBufferSourceNode.onended = value;\n            },\n            addEventListener(...args) {\n                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return audioBufferSourceNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);\n            },\n            start(when = 0) {\n                audioBufferSourceNode.start.call(audioBufferSourceNode, when);\n            },\n            stop(when = 0) {\n                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);\n            }\n        };\n        const whenConnected = () => audioBufferSourceNode.connect(gainNode);\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(gainNode);\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, audioBufferSourceNode);\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-constant-source-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConvolverNodeFactory\": () => (/* binding */ createNativeConvolverNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeConvolverNodeFactory = (createNotSupportedError, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeConvolverNode = nativeContext.createConvolver();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeConvolverNode, options);\n        // The normalize property needs to be set before setting the buffer.\n        if (options.disableNormalization === nativeConvolverNode.normalize) {\n            nativeConvolverNode.normalize = !options.disableNormalization;\n        }\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeConvolverNode, options, 'buffer');\n        // Bug #113: Safari does allow to set the channelCount to a value larger than 2.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCount', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value > 2) {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        // Bug #114: Safari allows to set the channelCountMode to 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCountMode', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value === 'max') {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        return nativeConvolverNode;\n    };\n};\n//# sourceMappingURL=native-convolver-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeDelayNode\": () => (/* binding */ createNativeDelayNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeDelayNode = (nativeContext, options) => {\n    const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeDelayNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDelayNode, options, 'delayTime');\n    return nativeDelayNode;\n};\n//# sourceMappingURL=native-delay-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeDynamicsCompressorNodeFactory\": () => (/* binding */ createNativeDynamicsCompressorNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeDynamicsCompressorNodeFactory = (createNotSupportedError) => {\n    return (nativeContext, options) => {\n        const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeDynamicsCompressorNode, options);\n        // Bug #108: Safari allows a channelCount of three and above.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'attack');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'knee');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'ratio');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'release');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'threshold');\n        return nativeDynamicsCompressorNode;\n    };\n};\n//# sourceMappingURL=native-dynamics-compressor-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeGainNode\": () => (/* binding */ createNativeGainNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeGainNode = (nativeContext, options) => {\n    const nativeGainNode = nativeContext.createGain();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeGainNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeGainNode, options, 'gain');\n    return nativeGainNode;\n};\n//# sourceMappingURL=native-gain-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeIIRFilterNodeFactory\": () => (/* binding */ createNativeIIRFilterNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeIIRFilterNodeFactory = (createNativeIIRFilterNodeFaker) => {\n    return (nativeContext, baseLatency, options) => {\n        // Bug #9: Safari does not support IIRFilterNodes.\n        if (nativeContext.createIIRFilter === undefined) {\n            return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);\n        }\n        // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.\n        const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeIIRFilterNode, options);\n        return nativeIIRFilterNode;\n    };\n};\n//# sourceMappingURL=native-iir-filter-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeIIRFilterNodeFakerFactory\": () => (/* binding */ createNativeIIRFilterNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/compute-buffer-size */ \"./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js\");\n/* harmony import */ var _helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/filter-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\n\nfunction divide(a, b) {\n    const denominator = b[0] * b[0] + b[1] * b[1];\n    return [(a[0] * b[0] + a[1] * b[1]) / denominator, (a[1] * b[0] - a[0] * b[1]) / denominator];\n}\nfunction multiply(a, b) {\n    return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];\n}\nfunction evaluatePolynomial(coefficient, z) {\n    let result = [0, 0];\n    for (let i = coefficient.length - 1; i >= 0; i -= 1) {\n        result = multiply(result, z);\n        result[0] += coefficient[i];\n    }\n    return result;\n}\nconst createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError) => {\n    return (nativeContext, baseLatency, { channelCount, channelCountMode, channelInterpretation, feedback, feedforward }) => {\n        const bufferSize = (0,_helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_0__.computeBufferSize)(baseLatency, nativeContext.sampleRate);\n        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);\n        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);\n        const feedbackLength = convertedFeedback.length;\n        const feedforwardLength = convertedFeedforward.length;\n        const minLength = Math.min(feedbackLength, feedforwardLength);\n        if (feedbackLength === 0 || feedbackLength > 20) {\n            throw createNotSupportedError();\n        }\n        if (convertedFeedback[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (feedforwardLength === 0 || feedforwardLength > 20) {\n            throw createNotSupportedError();\n        }\n        if (convertedFeedforward[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (convertedFeedback[0] !== 1) {\n            for (let i = 0; i < feedforwardLength; i += 1) {\n                convertedFeedforward[i] /= convertedFeedback[0];\n            }\n            for (let i = 1; i < feedbackLength; i += 1) {\n                convertedFeedback[i] /= convertedFeedback[0];\n            }\n        }\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);\n        scriptProcessorNode.channelCount = channelCount;\n        scriptProcessorNode.channelCountMode = channelCountMode;\n        scriptProcessorNode.channelInterpretation = channelInterpretation;\n        const bufferLength = 32;\n        const bufferIndexes = [];\n        const xBuffers = [];\n        const yBuffers = [];\n        for (let i = 0; i < channelCount; i += 1) {\n            bufferIndexes.push(0);\n            const xBuffer = new Float32Array(bufferLength);\n            const yBuffer = new Float32Array(bufferLength);\n            xBuffer.fill(0);\n            yBuffer.fill(0);\n            xBuffers.push(xBuffer);\n            yBuffers.push(yBuffer);\n        }\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = (event) => {\n            const inputBuffer = event.inputBuffer;\n            const outputBuffer = event.outputBuffer;\n            const numberOfChannels = inputBuffer.numberOfChannels;\n            for (let i = 0; i < numberOfChannels; i += 1) {\n                const input = inputBuffer.getChannelData(i);\n                const output = outputBuffer.getChannelData(i);\n                bufferIndexes[i] = (0,_helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_1__.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);\n            }\n        };\n        const nyquist = nativeContext.sampleRate / 2;\n        const nativeIIRFilterNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return scriptProcessorNode.channelCount;\n            },\n            set channelCount(value) {\n                scriptProcessorNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return scriptProcessorNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                scriptProcessorNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return scriptProcessorNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                scriptProcessorNode.channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return [scriptProcessorNode];\n            },\n            get numberOfInputs() {\n                return scriptProcessorNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return scriptProcessorNode.numberOfOutputs;\n            },\n            addEventListener(...args) {\n                // @todo Dissallow adding an audioprocess listener.\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                    throw createInvalidAccessError();\n                }\n                const length = frequencyHz.length;\n                for (let i = 0; i < length; i += 1) {\n                    const omega = -Math.PI * (frequencyHz[i] / nyquist);\n                    const z = [Math.cos(omega), Math.sin(omega)];\n                    const numerator = evaluatePolynomial(convertedFeedforward, z);\n                    const denominator = evaluatePolynomial(convertedFeedback, z);\n                    const response = divide(numerator, denominator);\n                    magResponse[i] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);\n                    phaseResponse[i] = Math.atan2(response[1], response[0]);\n                }\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        return (0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_2__.interceptConnections)(nativeIIRFilterNodeFaker, scriptProcessorNode);\n    };\n};\n//# sourceMappingURL=native-iir-filter-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaElementAudioSourceNode\": () => (/* binding */ createNativeMediaElementAudioSourceNode)\n/* harmony export */ });\nconst createNativeMediaElementAudioSourceNode = (nativeAudioContext, options) => {\n    return nativeAudioContext.createMediaElementSource(options.mediaElement);\n};\n//# sourceMappingURL=native-media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamAudioDestinationNode\": () => (/* binding */ createNativeMediaStreamAudioDestinationNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeMediaStreamAudioDestinationNode = (nativeAudioContext, options) => {\n    const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeMediaStreamAudioDestinationNode, options);\n    // Bug #174: Safari does expose a wrong numberOfOutputs.\n    if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) {\n        Object.defineProperty(nativeMediaStreamAudioDestinationNode, 'numberOfOutputs', { get: () => 0 });\n    }\n    return nativeMediaStreamAudioDestinationNode;\n};\n//# sourceMappingURL=native-media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamAudioSourceNode\": () => (/* binding */ createNativeMediaStreamAudioSourceNode)\n/* harmony export */ });\nconst createNativeMediaStreamAudioSourceNode = (nativeAudioContext, { mediaStream }) => {\n    const audioStreamTracks = mediaStream.getAudioTracks();\n    /*\n     * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.\n     * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.\n     */\n    audioStreamTracks.sort((a, b) => (a.id < b.id ? -1 : a.id > b.id ? 1 : 0));\n    const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);\n    const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));\n    /*\n     * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs\n     * to be overwritten as it would otherwise expose the reconstructed version.\n     */\n    Object.defineProperty(nativeMediaStreamAudioSourceNode, 'mediaStream', { value: mediaStream });\n    return nativeMediaStreamAudioSourceNode;\n};\n//# sourceMappingURL=native-media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamTrackAudioSourceNodeFactory\": () => (/* binding */ createNativeMediaStreamTrackAudioSourceNodeFactory)\n/* harmony export */ });\nconst createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, isNativeOfflineAudioContext) => {\n    return (nativeAudioContext, { mediaStreamTrack }) => {\n        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.\n        if (typeof nativeAudioContext.createMediaStreamTrackSource === 'function') {\n            return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);\n        }\n        const mediaStream = new MediaStream([mediaStreamTrack]);\n        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);\n        // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.\n        if (mediaStreamTrack.kind !== 'audio') {\n            throw createInvalidStateError();\n        }\n        // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n        if (isNativeOfflineAudioContext(nativeAudioContext)) {\n            throw new TypeError();\n        }\n        return nativeMediaStreamAudioSourceNode;\n    };\n};\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeOfflineAudioContextConstructor\": () => (/* binding */ createNativeOfflineAudioContextConstructor)\n/* harmony export */ });\nconst createNativeOfflineAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('OfflineAudioContext')) {\n        return window.OfflineAudioContext;\n    }\n    return window.hasOwnProperty('webkitOfflineAudioContext') ? window.webkitOfflineAudioContext : null;\n};\n//# sourceMappingURL=native-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeOscillatorNodeFactory\": () => (/* binding */ createNativeOscillatorNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\n\nconst createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeOscillatorNode = nativeContext.createOscillator();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeOscillatorNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, 'detune');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, 'frequency');\n        if (options.periodicWave !== undefined) {\n            nativeOscillatorNode.setPeriodicWave(options.periodicWave);\n        }\n        else {\n            (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeOscillatorNode, options, 'type');\n        }\n        // Bug #44: Only Chrome, Edge & Opera throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeOscillatorNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeOscillatorNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.\n        addSilentConnection(nativeContext, nativeOscillatorNode);\n        return nativeOscillatorNode;\n    };\n};\n//# sourceMappingURL=native-oscillator-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePannerNodeFactory\": () => (/* binding */ createNativePannerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\n\nconst createNativePannerNodeFactory = (createNativePannerNodeFaker) => {\n    return (nativeContext, options) => {\n        const nativePannerNode = nativeContext.createPanner();\n        // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.\n        if (nativePannerNode.orientationX === undefined) {\n            return createNativePannerNodeFaker(nativeContext, options);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativePannerNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationX');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationY');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationZ');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionX');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionY');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionZ');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneInnerAngle');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneOuterAngle');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneOuterGain');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'distanceModel');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'maxDistance');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'panningModel');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'refDistance');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'rolloffFactor');\n        return nativePannerNode;\n    };\n};\n//# sourceMappingURL=native-panner-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePannerNodeFakerFactory\": () => (/* binding */ createNativePannerNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\nconst createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, getFirstSample, monitorConnections) => {\n    return (nativeContext, { coneInnerAngle, coneOuterAngle, coneOuterGain, distanceModel, maxDistance, orientationX, orientationY, orientationZ, panningModel, positionX, positionY, positionZ, refDistance, rolloffFactor, ...audioNodeOptions }) => {\n        const pannerNode = nativeContext.createPanner();\n        // Bug #125: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #126: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(pannerNode, audioNodeOptions);\n        const SINGLE_CHANNEL_OPTIONS = {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete'\n        };\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            ...SINGLE_CHANNEL_OPTIONS,\n            channelInterpretation: 'speakers',\n            numberOfInputs: 6\n        });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const orientationXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 1 });\n        const orientationYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const orientationZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);\n        const waveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_OPTIONS,\n            curve: new Float32Array([1, 1]),\n            oversample: 'none'\n        });\n        let lastOrientation = [orientationX, orientationY, orientationZ];\n        let lastPosition = [positionX, positionY, positionZ];\n        const buffer = new Float32Array(1);\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n            const orientation = [\n                getFirstSample(inputBuffer, buffer, 0),\n                getFirstSample(inputBuffer, buffer, 1),\n                getFirstSample(inputBuffer, buffer, 2)\n            ];\n            if (orientation.some((value, index) => value !== lastOrientation[index])) {\n                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation\n                lastOrientation = orientation;\n            }\n            const positon = [\n                getFirstSample(inputBuffer, buffer, 3),\n                getFirstSample(inputBuffer, buffer, 4),\n                getFirstSample(inputBuffer, buffer, 5)\n            ];\n            if (positon.some((value, index) => value !== lastPosition[index])) {\n                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation\n                lastPosition = positon;\n            }\n        };\n        Object.defineProperty(orientationYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(orientationZGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionXGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionZGainNode.gain, 'defaultValue', { get: () => 0 });\n        const nativePannerNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return pannerNode.channelCount;\n            },\n            set channelCount(value) {\n                // Bug #125: Safari does not throw an error yet.\n                if (value > 2) {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCount = value;\n                pannerNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return pannerNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                // Bug #126: Safari does not throw an error yet.\n                if (value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n                pannerNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return pannerNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                pannerNode.channelInterpretation = value;\n            },\n            get coneInnerAngle() {\n                return pannerNode.coneInnerAngle;\n            },\n            set coneInnerAngle(value) {\n                pannerNode.coneInnerAngle = value;\n            },\n            get coneOuterAngle() {\n                return pannerNode.coneOuterAngle;\n            },\n            set coneOuterAngle(value) {\n                pannerNode.coneOuterAngle = value;\n            },\n            get coneOuterGain() {\n                return pannerNode.coneOuterGain;\n            },\n            set coneOuterGain(value) {\n                // Bug #127: Safari does not throw an InvalidStateError yet.\n                if (value < 0 || value > 1) {\n                    throw createInvalidStateError();\n                }\n                pannerNode.coneOuterGain = value;\n            },\n            get context() {\n                return pannerNode.context;\n            },\n            get distanceModel() {\n                return pannerNode.distanceModel;\n            },\n            set distanceModel(value) {\n                pannerNode.distanceModel = value;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get maxDistance() {\n                return pannerNode.maxDistance;\n            },\n            set maxDistance(value) {\n                // Bug #128: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.maxDistance = value;\n            },\n            get numberOfInputs() {\n                return pannerNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return pannerNode.numberOfOutputs;\n            },\n            get orientationX() {\n                return orientationXGainNode.gain;\n            },\n            get orientationY() {\n                return orientationYGainNode.gain;\n            },\n            get orientationZ() {\n                return orientationZGainNode.gain;\n            },\n            get panningModel() {\n                return pannerNode.panningModel;\n            },\n            set panningModel(value) {\n                pannerNode.panningModel = value;\n            },\n            get positionX() {\n                return positionXGainNode.gain;\n            },\n            get positionY() {\n                return positionYGainNode.gain;\n            },\n            get positionZ() {\n                return positionZGainNode.gain;\n            },\n            get refDistance() {\n                return pannerNode.refDistance;\n            },\n            set refDistance(value) {\n                // Bug #129: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.refDistance = value;\n            },\n            get rolloffFactor() {\n                return pannerNode.rolloffFactor;\n            },\n            set rolloffFactor(value) {\n                // Bug #130: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.rolloffFactor = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) {\n            nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;\n        }\n        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) {\n            nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;\n        }\n        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) {\n            nativePannerNodeFaker.coneOuterGain = coneOuterGain;\n        }\n        if (distanceModel !== nativePannerNodeFaker.distanceModel) {\n            nativePannerNodeFaker.distanceModel = distanceModel;\n        }\n        if (maxDistance !== nativePannerNodeFaker.maxDistance) {\n            nativePannerNodeFaker.maxDistance = maxDistance;\n        }\n        if (orientationX !== nativePannerNodeFaker.orientationX.value) {\n            nativePannerNodeFaker.orientationX.value = orientationX;\n        }\n        if (orientationY !== nativePannerNodeFaker.orientationY.value) {\n            nativePannerNodeFaker.orientationY.value = orientationY;\n        }\n        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) {\n            nativePannerNodeFaker.orientationZ.value = orientationZ;\n        }\n        if (panningModel !== nativePannerNodeFaker.panningModel) {\n            nativePannerNodeFaker.panningModel = panningModel;\n        }\n        if (positionX !== nativePannerNodeFaker.positionX.value) {\n            nativePannerNodeFaker.positionX.value = positionX;\n        }\n        if (positionY !== nativePannerNodeFaker.positionY.value) {\n            nativePannerNodeFaker.positionY.value = positionY;\n        }\n        if (positionZ !== nativePannerNodeFaker.positionZ.value) {\n            nativePannerNodeFaker.positionZ.value = positionZ;\n        }\n        if (refDistance !== nativePannerNodeFaker.refDistance) {\n            nativePannerNodeFaker.refDistance = refDistance;\n        }\n        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) {\n            nativePannerNodeFaker.rolloffFactor = rolloffFactor;\n        }\n        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) {\n            pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation\n        }\n        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) {\n            pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation\n        }\n        const whenConnected = () => {\n            inputGainNode.connect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);\n            waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);\n            waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);\n            waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);\n            waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);\n            waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);\n            channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode.disconnect(orientationXGainNode);\n            orientationXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationYGainNode);\n            orientationYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationZGainNode);\n            orientationZGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionXGainNode);\n            positionXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionYGainNode);\n            positionYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionZGainNode);\n            positionZGainNode.disconnect(channelMergerNode);\n            channelMergerNode.disconnect(scriptProcessorNode);\n            scriptProcessorNode.disconnect(nativeContext.destination);\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__.interceptConnections)(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePeriodicWaveFactory\": () => (/* binding */ createNativePeriodicWaveFactory)\n/* harmony export */ });\nconst createNativePeriodicWaveFactory = (createIndexSizeError) => {\n    return (nativeContext, { disableNormalization, imag, real }) => {\n        // Bug #180: Safari does not allow to use ordinary arrays.\n        const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);\n        const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);\n        const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, { disableNormalization });\n        // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.\n        if (Array.from(imag).length < 2) {\n            throw createIndexSizeError();\n        }\n        return nativePeriodicWave;\n    };\n};\n//# sourceMappingURL=native-periodic-wave-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeScriptProcessorNode\": () => (/* binding */ createNativeScriptProcessorNode)\n/* harmony export */ });\nconst createNativeScriptProcessorNode = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels) => {\n    return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels); // tslint:disable-line deprecation\n};\n//# sourceMappingURL=native-script-processor-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeStereoPannerNodeFactory\": () => (/* binding */ createNativeStereoPannerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeStereoPannerNodeFactory = (createNativeStereoPannerNodeFaker, createNotSupportedError) => {\n    return (nativeContext, options) => {\n        const channelCountMode = options.channelCountMode;\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        if (channelCountMode === 'clamped-max') {\n            throw createNotSupportedError();\n        }\n        // Bug #105: Safari does not support the StereoPannerNode.\n        if (nativeContext.createStereoPanner === undefined) {\n            return createNativeStereoPannerNodeFaker(nativeContext, options);\n        }\n        const nativeStereoPannerNode = nativeContext.createStereoPanner();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeStereoPannerNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeStereoPannerNode, options, 'pan');\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        Object.defineProperty(nativeStereoPannerNode, 'channelCountMode', {\n            get: () => channelCountMode,\n            set: (value) => {\n                if (value !== channelCountMode) {\n                    throw createNotSupportedError();\n                }\n            }\n        });\n        return nativeStereoPannerNode;\n    };\n};\n//# sourceMappingURL=native-stereo-panner-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeStereoPannerNodeFakerFactory\": () => (/* binding */ createNativeStereoPannerNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections) => {\n    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.\n    const CURVE_SIZE = 16385;\n    const DC_CURVE = new Float32Array([1, 1]);\n    const HALF_PI = Math.PI / 2;\n    const SINGLE_CHANNEL_OPTIONS = { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete' };\n    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = { ...SINGLE_CHANNEL_OPTIONS, oversample: 'none' };\n    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            const x = (i / (CURVE_SIZE - 1)) * HALF_PI;\n            leftWaveShaperCurve[i] = Math.cos(x);\n            rightWaveShaperCurve[i] = Math.sin(x);\n        }\n        const leftGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftWaveShaperCurve }));\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));\n        const rightGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightWaveShaperCurve }));\n        return {\n            connectGraph() {\n                inputGainNode.connect(leftGainNode);\n                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                inputGainNode.connect(rightGainNode);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.connect(leftGainNode.gain);\n                rightWaveShaperNode.connect(rightGainNode.gain);\n                leftGainNode.connect(channelMergerNode, 0, 0);\n                rightGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(leftGainNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                inputGainNode.disconnect(rightGainNode);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.disconnect(leftGainNode.gain);\n                rightWaveShaperNode.disconnect(rightGainNode.gain);\n                leftGainNode.disconnect(channelMergerNode, 0, 0);\n                rightGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const centerIndex = Math.floor(CURVE_SIZE / 2);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            if (i > centerIndex) {\n                const x = ((i - centerIndex) / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n                rightInputForLeftOutputWaveShaperCurve[i] = 0;\n                rightInputForRightOutputWaveShaperCurve[i] = 1;\n            }\n            else {\n                const x = (i / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = 1;\n                leftInputForRightOutputWaveShaperCurve[i] = 0;\n                rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n            }\n        }\n        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: 2,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: 2\n        });\n        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: leftInputForLeftOutputWaveShaperCurve\n        });\n        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: leftInputForRightOutputWaveShaperCurve\n        });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));\n        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: rightInputForLeftOutputWaveShaperCurve\n        });\n        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: rightInputForRightOutputWaveShaperCurve\n        });\n        return {\n            connectGraph() {\n                inputGainNode.connect(channelSplitterNode);\n                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);\n                channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);\n                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForLeftOutputWaveShaperNode\n                    : leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForRightOutputWaveShaperNode\n                    : leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForLeftOutputWaveShaperNode\n                    : rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForRightOutputWaveShaperNode\n                    : rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(channelSplitterNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);\n                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);\n                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForLeftOutputWaveShaperNode\n                    : leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForRightOutputWaveShaperNode\n                    : leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForLeftOutputWaveShaperNode\n                    : rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForRightOutputWaveShaperNode\n                    : rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode) => {\n        if (channelCount === 1) {\n            return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        if (channelCount === 2) {\n            return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        throw createNotSupportedError();\n    };\n    return (nativeContext, { channelCount, channelCountMode, pan, ...audioNodeOptions }) => {\n        if (channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            ...audioNodeOptions,\n            channelCount: 1,\n            channelCountMode,\n            numberOfInputs: 2\n        });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, channelCount, channelCountMode, gain: 1 });\n        const panGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: pan\n        });\n        let { connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);\n        Object.defineProperty(panGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(panGainNode.gain, 'maxValue', { get: () => 1 });\n        Object.defineProperty(panGainNode.gain, 'minValue', { get: () => -1 });\n        const nativeStereoPannerNodeFakerFactory = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return inputGainNode.channelCount;\n            },\n            set channelCount(value) {\n                if (inputGainNode.channelCount !== value) {\n                    if (isConnected) {\n                        disconnectGraph();\n                    }\n                    ({ connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));\n                    if (isConnected) {\n                        connectGraph();\n                    }\n                }\n                inputGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return inputGainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                if (value === 'clamped-max' || value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return inputGainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return inputGainNode.context;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return inputGainNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return inputGainNode.numberOfOutputs;\n            },\n            get pan() {\n                return panGainNode.gain;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        let isConnected = false;\n        const whenConnected = () => {\n            connectGraph();\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            disconnectGraph();\n            isConnected = false;\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-stereo-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeWaveShaperNodeFactory\": () => (/* binding */ createNativeWaveShaperNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeWaveShaperNode = nativeContext.createWaveShaper();\n        /*\n         * Bug #119: Safari does not correctly map the values.\n         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of\n         * the webkitAudioContext is used as a workaround here. Testing for the automationRate property is necessary because this workaround\n         * isn't necessary anymore since v14.0.2 of Safari.\n         */\n        if (nativeAudioContextConstructor !== null &&\n            nativeAudioContextConstructor.name === 'webkitAudioContext' &&\n            nativeContext.createGain().gain.automationRate === undefined) {\n            return createNativeWaveShaperNodeFaker(nativeContext, options);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeWaveShaperNode, options);\n        const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);\n        // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.\n        if (curve !== null && curve.length < 2) {\n            throw createInvalidStateError();\n        }\n        // Only values of type Float32Array can be assigned to the curve property.\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeWaveShaperNode, { curve }, 'curve');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeWaveShaperNode, options, 'oversample');\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        overwriteAccessors(nativeWaveShaperNode, 'curve', (get) => () => get.call(nativeWaveShaperNode), (set) => (value) => {\n            set.call(nativeWaveShaperNode, value);\n            if (isConnected) {\n                if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) {\n                    disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n                }\n                else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {\n                    disconnectNativeAudioBufferSourceNode();\n                    disconnectNativeAudioBufferSourceNode = null;\n                }\n            }\n            return value;\n        });\n        const whenConnected = () => {\n            isConnected = true;\n            if (isDCCurve(nativeWaveShaperNode.curve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n            }\n        };\n        const whenDisconnected = () => {\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-wave-shaper-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeWaveShaperNodeFakerFactory\": () => (/* binding */ createNativeWaveShaperNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\nconst createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections) => {\n    return (nativeContext, { curve, oversample, ...audioNodeOptions }) => {\n        const negativeWaveShaperNode = nativeContext.createWaveShaper();\n        const positiveWaveShaperNode = nativeContext.createWaveShaper();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(negativeWaveShaperNode, audioNodeOptions);\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(positiveWaveShaperNode, audioNodeOptions);\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const invertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        const outputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const revertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        let unmodifiedCurve = null;\n        const nativeWaveShaperNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return negativeWaveShaperNode.channelCount;\n            },\n            set channelCount(value) {\n                inputGainNode.channelCount = value;\n                invertGainNode.channelCount = value;\n                negativeWaveShaperNode.channelCount = value;\n                outputGainNode.channelCount = value;\n                positiveWaveShaperNode.channelCount = value;\n                revertGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return negativeWaveShaperNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                inputGainNode.channelCountMode = value;\n                invertGainNode.channelCountMode = value;\n                negativeWaveShaperNode.channelCountMode = value;\n                outputGainNode.channelCountMode = value;\n                positiveWaveShaperNode.channelCountMode = value;\n                revertGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return negativeWaveShaperNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                invertGainNode.channelInterpretation = value;\n                negativeWaveShaperNode.channelInterpretation = value;\n                outputGainNode.channelInterpretation = value;\n                positiveWaveShaperNode.channelInterpretation = value;\n                revertGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return negativeWaveShaperNode.context;\n            },\n            get curve() {\n                return unmodifiedCurve;\n            },\n            set curve(value) {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                if (value !== null && value.length < 2) {\n                    throw createInvalidStateError();\n                }\n                if (value === null) {\n                    negativeWaveShaperNode.curve = value;\n                    positiveWaveShaperNode.curve = value;\n                }\n                else {\n                    const curveLength = value.length;\n                    const negativeCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    const positiveCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    negativeCurve[0] = value[0];\n                    positiveCurve[0] = -value[curveLength - 1];\n                    const length = Math.ceil((curveLength + 1) / 2);\n                    const centerIndex = (curveLength + 1) / 2 - 1;\n                    for (let i = 1; i < length; i += 1) {\n                        const theoreticIndex = (i / length) * centerIndex;\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        negativeCurve[i] =\n                            lowerIndex === upperIndex\n                                ? value[lowerIndex]\n                                : (1 - (theoreticIndex - lowerIndex)) * value[lowerIndex] +\n                                    (1 - (upperIndex - theoreticIndex)) * value[upperIndex];\n                        positiveCurve[i] =\n                            lowerIndex === upperIndex\n                                ? -value[curveLength - 1 - lowerIndex]\n                                : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex]) -\n                                    (1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex];\n                    }\n                    negativeCurve[length] = curveLength % 2 === 1 ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;\n                    negativeWaveShaperNode.curve = negativeCurve;\n                    positiveWaveShaperNode.curve = positiveCurve;\n                }\n                unmodifiedCurve = value;\n                if (isConnected) {\n                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) {\n                        disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n                    }\n                    else if (disconnectNativeAudioBufferSourceNode !== null) {\n                        disconnectNativeAudioBufferSourceNode();\n                        disconnectNativeAudioBufferSourceNode = null;\n                    }\n                }\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return negativeWaveShaperNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return negativeWaveShaperNode.numberOfOutputs;\n            },\n            get oversample() {\n                return negativeWaveShaperNode.oversample;\n            },\n            set oversample(value) {\n                negativeWaveShaperNode.oversample = value;\n                positiveWaveShaperNode.oversample = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (curve !== null) {\n            // Only values of type Float32Array can be assigned to the curve property.\n            nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);\n        }\n        if (oversample !== nativeWaveShaperNodeFaker.oversample) {\n            nativeWaveShaperNodeFaker.oversample = oversample;\n        }\n        const whenConnected = () => {\n            inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);\n            inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);\n            isConnected = true;\n            if (isDCCurve(unmodifiedCurve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n            }\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(negativeWaveShaperNode);\n            negativeWaveShaperNode.disconnect(outputGainNode);\n            inputGainNode.disconnect(invertGainNode);\n            invertGainNode.disconnect(positiveWaveShaperNode);\n            positiveWaveShaperNode.disconnect(revertGainNode);\n            revertGainNode.disconnect(outputGainNode);\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__.interceptConnections)(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-wave-shaper-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNotSupportedError\": () => (/* binding */ createNotSupportedError)\n/* harmony export */ });\nconst createNotSupportedError = () => new DOMException('', 'NotSupportedError');\n//# sourceMappingURL=not-supported-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOfflineAudioContextConstructor\": () => (/* binding */ createOfflineAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering) => {\n    return class OfflineAudioContext extends baseAudioContextConstructor {\n        constructor(a, b, c) {\n            let options;\n            if (typeof a === 'number' && b !== undefined && c !== undefined) {\n                options = { length: b, numberOfChannels: a, sampleRate: c };\n            }\n            else if (typeof a === 'object') {\n                options = a;\n            }\n            else {\n                throw new Error('The given parameters are not valid.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport)(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(() => {\n                this._state = null;\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOscillatorNodeConstructor\": () => (/* binding */ createOscillatorNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 440,\n    periodicWave: undefined,\n    type: 'sine'\n};\nconst createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class OscillatorNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const oscillatorNodeRenderer = (isOffline ? createOscillatorNodeRenderer() : null);\n            const nyquist = context.sampleRate / 2;\n            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);\n            // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);\n            // Bug #76: Safari does not export the correct values for maxValue and minValue.\n            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);\n            this._nativeOscillatorNode = nativeOscillatorNode;\n            this._onended = null;\n            this._oscillatorNodeRenderer = oscillatorNodeRenderer;\n            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) {\n                this._oscillatorNodeRenderer.periodicWave =\n                    mergedOptions.periodicWave;\n            }\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeOscillatorNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeOscillatorNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        get type() {\n            return this._nativeOscillatorNode.type;\n        }\n        set type(value) {\n            this._nativeOscillatorNode.type = value;\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = null;\n            }\n        }\n        setPeriodicWave(periodicWave) {\n            this._nativeOscillatorNode.setPeriodicWave(periodicWave);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = periodicWave;\n            }\n        }\n        start(when = 0) {\n            this._nativeOscillatorNode.start(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.start = when;\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeOscillatorNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_0__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeOscillatorNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeOscillatorNode.stop(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=oscillator-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOscillatorNodeRendererFactory\": () => (/* binding */ createOscillatorNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeOscillatorNodes = new WeakMap();\n        let periodicWave = null;\n        let start = null;\n        let stop = null;\n        const createOscillatorNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeOscillatorNode = getNativeAudioNode(proxy);\n            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeOscillatorNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeOscillatorNode, nativeOfflineAudioContext);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeOscillatorNode.channelCount,\n                    channelCountMode: nativeOscillatorNode.channelCountMode,\n                    channelInterpretation: nativeOscillatorNode.channelInterpretation,\n                    detune: nativeOscillatorNode.detune.value,\n                    frequency: nativeOscillatorNode.frequency.value,\n                    periodicWave: periodicWave === null ? undefined : periodicWave,\n                    type: nativeOscillatorNode.type\n                };\n                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeOscillatorNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeOscillatorNode.stop(stop);\n                }\n            }\n            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode);\n            return nativeOscillatorNode;\n        };\n        return {\n            set periodicWave(value) {\n                periodicWave = value;\n            },\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeOscillatorNode !== undefined) {\n                    return Promise.resolve(renderedNativeOscillatorNode);\n                }\n                return createOscillatorNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=oscillator-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPannerNodeConstructor\": () => (/* binding */ createPannerNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    coneInnerAngle: 360,\n    coneOuterAngle: 360,\n    coneOuterGain: 0,\n    distanceModel: 'inverse',\n    maxDistance: 10000,\n    orientationX: 1,\n    orientationY: 0,\n    orientationZ: 0,\n    panningModel: 'equalpower',\n    positionX: 0,\n    positionY: 0,\n    positionZ: 0,\n    refDistance: 1,\n    rolloffFactor: 1\n};\nconst createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class PannerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const pannerNodeRenderer = (isOffline ? createPannerNodeRenderer() : null);\n            super(context, false, nativePannerNode, pannerNodeRenderer);\n            this._nativePannerNode = nativePannerNode;\n            // Bug #74: Safari does not export the correct values for maxValue and minValue.\n            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get coneInnerAngle() {\n            return this._nativePannerNode.coneInnerAngle;\n        }\n        set coneInnerAngle(value) {\n            this._nativePannerNode.coneInnerAngle = value;\n        }\n        get coneOuterAngle() {\n            return this._nativePannerNode.coneOuterAngle;\n        }\n        set coneOuterAngle(value) {\n            this._nativePannerNode.coneOuterAngle = value;\n        }\n        get coneOuterGain() {\n            return this._nativePannerNode.coneOuterGain;\n        }\n        set coneOuterGain(value) {\n            this._nativePannerNode.coneOuterGain = value;\n        }\n        get distanceModel() {\n            return this._nativePannerNode.distanceModel;\n        }\n        set distanceModel(value) {\n            this._nativePannerNode.distanceModel = value;\n        }\n        get maxDistance() {\n            return this._nativePannerNode.maxDistance;\n        }\n        set maxDistance(value) {\n            this._nativePannerNode.maxDistance = value;\n        }\n        get orientationX() {\n            return this._orientationX;\n        }\n        get orientationY() {\n            return this._orientationY;\n        }\n        get orientationZ() {\n            return this._orientationZ;\n        }\n        get panningModel() {\n            return this._nativePannerNode.panningModel;\n        }\n        set panningModel(value) {\n            this._nativePannerNode.panningModel = value;\n        }\n        get positionX() {\n            return this._positionX;\n        }\n        get positionY() {\n            return this._positionY;\n        }\n        get positionZ() {\n            return this._positionZ;\n        }\n        get refDistance() {\n            return this._nativePannerNode.refDistance;\n        }\n        set refDistance(value) {\n            this._nativePannerNode.refDistance = value;\n        }\n        get rolloffFactor() {\n            return this._nativePannerNode.rolloffFactor;\n        }\n        set rolloffFactor(value) {\n            this._nativePannerNode.rolloffFactor = value;\n        }\n    };\n};\n//# sourceMappingURL=panner-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPannerNodeRendererFactory\": () => (/* binding */ createPannerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let renderedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeGainNode = null;\n            let nativePannerNode = getNativeAudioNode(proxy);\n            const commonAudioNodeOptions = {\n                channelCount: nativePannerNode.channelCount,\n                channelCountMode: nativePannerNode.channelCountMode,\n                channelInterpretation: nativePannerNode.channelInterpretation\n            };\n            const commonNativePannerNodeOptions = {\n                ...commonAudioNodeOptions,\n                coneInnerAngle: nativePannerNode.coneInnerAngle,\n                coneOuterAngle: nativePannerNode.coneOuterAngle,\n                coneOuterGain: nativePannerNode.coneOuterGain,\n                distanceModel: nativePannerNode.distanceModel,\n                maxDistance: nativePannerNode.maxDistance,\n                panningModel: nativePannerNode.panningModel,\n                refDistance: nativePannerNode.refDistance,\n                rolloffFactor: nativePannerNode.rolloffFactor\n            };\n            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativePannerNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativePannerNode, nativeOfflineAudioContext);\n            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.\n            if ('bufferSize' in nativePannerNode) {\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n            }\n            else if (!nativePannerNodeIsOwnedByContext) {\n                const options = {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: nativePannerNode.orientationX.value,\n                    orientationY: nativePannerNode.orientationY.value,\n                    orientationZ: nativePannerNode.orientationZ.value,\n                    positionX: nativePannerNode.positionX.value,\n                    positionY: nativePannerNode.positionY.value,\n                    positionZ: nativePannerNode.positionZ.value\n                };\n                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);\n            if (nativeGainNode !== null) {\n                if (renderedBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: 6\n                    });\n                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                    renderedBufferPromise = (async () => {\n                        const nativeConstantSourceNodes = await Promise.all([\n                            proxy.orientationX,\n                            proxy.orientationY,\n                            proxy.orientationZ,\n                            proxy.positionX,\n                            proxy.positionY,\n                            proxy.positionZ\n                        ].map(async (audioParam, index) => {\n                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: index === 0 ? 1 : 0\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset);\n                            return nativeConstantSourceNode;\n                        }));\n                        for (let i = 0; i < 6; i += 1) {\n                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);\n                            nativeConstantSourceNodes[i].start(0);\n                        }\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    })();\n                }\n                const renderedBuffer = await renderedBufferPromise;\n                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode);\n                const channelDatas = [];\n                for (let i = 0; i < renderedBuffer.numberOfChannels; i += 1) {\n                    channelDatas.push(renderedBuffer.getChannelData(i));\n                }\n                let lastOrientation = [channelDatas[0][0], channelDatas[1][0], channelDatas[2][0]];\n                let lastPosition = [channelDatas[3][0], channelDatas[4][0], channelDatas[5][0]];\n                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: lastOrientation[0],\n                    orientationY: lastOrientation[1],\n                    orientationZ: lastOrientation[2],\n                    positionX: lastPosition[0],\n                    positionY: lastPosition[1],\n                    positionZ: lastPosition[2]\n                });\n                inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                partialPannerNode.connect(nativeGainNode);\n                for (let i = 128; i < renderedBuffer.length; i += 128) {\n                    const orientation = [channelDatas[0][i], channelDatas[1][i], channelDatas[2][i]];\n                    const positon = [channelDatas[3][i], channelDatas[4][i], channelDatas[5][i]];\n                    if (orientation.some((value, index) => value !== lastOrientation[index]) ||\n                        positon.some((value, index) => value !== lastPosition[index])) {\n                        lastOrientation = orientation;\n                        lastPosition = positon;\n                        const currentTime = i / nativeOfflineAudioContext.sampleRate;\n                        gateGainNode.gain.setValueAtTime(0, currentTime);\n                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 0 });\n                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                            ...commonNativePannerNodeOptions,\n                            orientationX: lastOrientation[0],\n                            orientationY: lastOrientation[1],\n                            orientationZ: lastOrientation[2],\n                            positionX: lastPosition[0],\n                            positionY: lastPosition[1],\n                            positionZ: lastPosition[2]\n                        });\n                        gateGainNode.gain.setValueAtTime(1, currentTime);\n                        inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                        partialPannerNode.connect(nativeGainNode);\n                    }\n                }\n                return nativeGainNode;\n            }\n            if (!nativePannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);\n            }\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativePannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode);\n            }\n            return nativePannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNodeOrNativePannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPeriodicWaveConstructor\": () => (/* binding */ createPeriodicWaveConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    disableNormalization: false\n};\nconst createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions) => {\n    return class PeriodicWave {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = sanitizePeriodicWaveOptions({ ...DEFAULT_OPTIONS, ...options });\n            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);\n            periodicWaveStore.add(periodicWave);\n            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.\n            return periodicWave;\n        }\n        static [Symbol.hasInstance](instance) {\n            return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === PeriodicWave.prototype) ||\n                periodicWaveStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=periodic-wave-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderAutomation\": () => (/* binding */ createRenderAutomation)\n/* harmony export */ });\nconst createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam) => {\n        const audioParamRenderer = getAudioParamRenderer(audioParam);\n        audioParamRenderer.replay(nativeAudioParam);\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);\n    };\n};\n//# sourceMappingURL=render-automation.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderInputsOfAudioNode\": () => (/* binding */ createRenderInputsOfAudioNode)\n/* harmony export */ });\nconst createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle) => {\n    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        await Promise.all(audioNodeConnections.activeInputs\n            .map((connections, input) => Array.from(connections).map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);\n            const destination = audioNode.context.destination;\n            if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) {\n                renderedNativeAudioNode.connect(nativeAudioNode, output, input);\n            }\n        }))\n            .reduce((allRenderingPromises, renderingPromises) => [...allRenderingPromises, ...renderingPromises], []));\n    };\n};\n//# sourceMappingURL=render-inputs-of-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderInputsOfAudioParam\": () => (/* binding */ createRenderInputsOfAudioParam)\n/* harmony export */ });\nconst createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle) => {\n    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);\n            if (!isPartOfACycle(source)) {\n                renderedNativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }));\n    };\n};\n//# sourceMappingURL=render-inputs-of-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderNativeOfflineAudioContext\": () => (/* binding */ createRenderNativeOfflineAudioContext)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\nconst createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport) => {\n    return (nativeOfflineAudioContext) => {\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__.testPromiseSupport)(nativeOfflineAudioContext))) {\n            // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.\n            return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported) => {\n                if (!isOfflineAudioContextCurrentTimeSupported) {\n                    const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);\n                    nativeOfflineAudioContext.oncomplete = () => {\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        scriptProcessorNode.disconnect();\n                    };\n                    scriptProcessorNode.onaudioprocess = () => nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation\n                    scriptProcessorNode.connect(nativeOfflineAudioContext.destination);\n                }\n                return nativeOfflineAudioContext.startRendering();\n            });\n        }\n        return new Promise((resolve) => {\n            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                gain: 0\n            });\n            nativeOfflineAudioContext.oncomplete = (event) => {\n                gainNode.disconnect();\n                resolve(event.renderedBuffer);\n            };\n            gainNode.connect(nativeOfflineAudioContext.destination);\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=render-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createSetActiveAudioWorkletNodeInputs\": () => (/* binding */ createSetActiveAudioWorkletNodeInputs)\n/* harmony export */ });\nconst createSetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore) => {\n    return (nativeAudioWorkletNode, activeInputs) => {\n        activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);\n    };\n};\n//# sourceMappingURL=set-active-audio-worklet-node-inputs.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createSetAudioNodeTailTime\": () => (/* binding */ createSetAudioNodeTailTime)\n/* harmony export */ });\nconst createSetAudioNodeTailTime = (audioNodeTailTimeStore) => {\n    return (audioNode, tailTime) => audioNodeTailTimeStore.set(audioNode, tailTime);\n};\n//# sourceMappingURL=set-audio-node-tail-time.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStartRendering\": () => (/* binding */ createStartRendering)\n/* harmony export */ });\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\nconst createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    return (destination, nativeOfflineAudioContext) => getAudioNodeRenderer(destination)\n        .render(destination, nativeOfflineAudioContext)\n        /*\n         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the\n         * destination.\n         */\n        .then(() => Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode) => getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext))))\n        .then(() => renderNativeOfflineAudioContext(nativeOfflineAudioContext))\n        .then((audioBuffer) => {\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n        if (typeof audioBuffer.copyFromChannel !== 'function') {\n            wrapAudioBufferCopyChannelMethods(audioBuffer);\n            (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_0__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n        }\n        else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n            wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n        }\n        audioBufferStore.add(audioBuffer);\n        return audioBuffer;\n    });\n};\n//# sourceMappingURL=start-rendering.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStereoPannerNodeConstructor\": () => (/* binding */ createStereoPannerNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    /*\n     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent\n     * behavior.\n     */\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    pan: 0\n};\nconst createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class StereoPannerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const stereoPannerNodeRenderer = (isOffline ? createStereoPannerNodeRenderer() : null);\n            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);\n            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);\n        }\n        get pan() {\n            return this._pan;\n        }\n    };\n};\n//# sourceMappingURL=stereo-panner-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStereoPannerNodeRendererFactory\": () => (/* binding */ createStereoPannerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeStereoPannerNodes = new WeakMap();\n        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeStereoPannerNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeStereoPannerNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeStereoPannerNode, nativeOfflineAudioContext);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeStereoPannerNode.channelCount,\n                    channelCountMode: nativeStereoPannerNode.channelCountMode,\n                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,\n                    pan: nativeStereoPannerNode.pan.value\n                };\n                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);\n            }\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeStereoPannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode);\n            }\n            return nativeStereoPannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeStereoPannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeStereoPannerNode);\n                }\n                return createStereoPannerNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=stereo-panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioBufferConstructorSupport\": () => (/* binding */ createTestAudioBufferConstructorSupport)\n/* harmony export */ });\n// Bug #33: Safari exposes an AudioBuffer but it can't be used as a constructor.\nconst createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor) => {\n    return () => {\n        if (nativeAudioBufferConstructor === null) {\n            return false;\n        }\n        try {\n            new nativeAudioBufferConstructor({ length: 1, sampleRate: 44100 }); // tslint:disable-line:no-unused-expression\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-buffer-constructor-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioBufferCopyChannelMethodsSubarraySupport\": () => (/* binding */ createTestAudioBufferCopyChannelMethodsSubarraySupport)\n/* harmony export */ });\n/*\n * Firefox up to version 67 didn't fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those methods\n * is enough to know if the other one is supported as well.\n */\nconst createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        if (nativeAudioBuffer.copyToChannel === undefined) {\n            return true;\n        }\n        const source = new Float32Array(2);\n        try {\n            nativeAudioBuffer.copyFromChannel(source, 0, 0);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-subarray-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextCloseMethodSupport\": () => (/* binding */ createTestAudioContextCloseMethodSupport)\n/* harmony export */ });\nconst createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        // Try to check the prototype before constructing the AudioContext.\n        if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) {\n            return true;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        const isAudioContextClosable = audioContext.close !== undefined;\n        try {\n            audioContext.close();\n        }\n        catch {\n            // Ignore errors.\n        }\n        return isAudioContextClosable;\n    };\n};\n//# sourceMappingURL=test-audio-context-close-method-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextDecodeAudioDataMethodTypeErrorSupport\": () => (/* binding */ createTestAudioContextDecodeAudioDataMethodTypeErrorSupport)\n/* harmony export */ });\n/**\n * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers\n * did not refuse to decode invalid parameters with a TypeError.\n */\nconst createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            let isPending = true;\n            const resolvePromise = (err) => {\n                if (isPending) {\n                    isPending = false;\n                    offlineAudioContext.startRendering();\n                    resolve(err instanceof TypeError);\n                }\n            };\n            let promise;\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                promise = offlineAudioContext\n                    // Bug #1: Safari requires a successCallback.\n                    .decodeAudioData(null, () => {\n                    // Ignore the success callback.\n                }, resolvePromise);\n            }\n            catch (err) {\n                resolvePromise(err);\n            }\n            // Bug #21: Safari does not support promises yet.\n            if (promise !== undefined) {\n                // Bug #6: Chrome, Edge, Firefox and Opera do not call the errorCallback.\n                promise.catch(resolvePromise);\n            }\n        });\n    };\n};\n//# sourceMappingURL=test-audio-context-decode-audio-data-method-type-error-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextOptionsSupport\": () => (/* binding */ createTestAudioContextOptionsSupport)\n/* harmony export */ });\nconst createTestAudioContextOptionsSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        let audioContext;\n        try {\n            audioContext = new nativeAudioContextConstructor({ latencyHint: 'balanced' });\n        }\n        catch {\n            return false;\n        }\n        audioContext.close();\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-context-options-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioNodeConnectMethodSupport\": () => (/* binding */ createTestAudioNodeConnectMethodSupport)\n/* harmony export */ });\n// Safari up to version 12.0 (but not v12.1) didn't return the destination in case it was an AudioNode.\nconst createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeGainNode = nativeOfflineAudioContext.createGain();\n        const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;\n        nativeGainNode.disconnect(nativeGainNode);\n        return isSupported;\n    };\n};\n//# sourceMappingURL=test-audio-node-connect-method-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioWorkletProcessorNoOutputsSupport\": () => (/* binding */ createTestAudioWorkletProcessorNoOutputsSupport)\n/* harmony export */ });\n/**\n * Chrome version 66 and 67 did not call the process() function of an AudioWorkletProcessor if it had no outputs. AudioWorklet support was\n * enabled by default in version 66.\n */\nconst createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {\n    return async () => {\n        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.\n        if (nativeAudioWorkletNodeConstructor === null) {\n            return true;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const blob = new Blob([\n            'let c,p;class A extends AudioWorkletProcessor{constructor(){super();this.port.onmessage=(e)=>{p=e.data;p.onmessage=()=>{p.postMessage(c);p.close()};this.port.postMessage(0)}}process(){c=1}}registerProcessor(\"a\",A)'\n        ], {\n            type: 'application/javascript; charset=utf-8'\n        });\n        const messageChannel = new MessageChannel();\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);\n        const url = URL.createObjectURL(blob);\n        let isCallingProcess = false;\n        try {\n            await offlineAudioContext.audioWorklet.addModule(url);\n            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });\n            const oscillator = offlineAudioContext.createOscillator();\n            await new Promise((resolve) => {\n                audioWorkletNode.port.onmessage = () => resolve();\n                audioWorkletNode.port.postMessage(messageChannel.port2, [messageChannel.port2]);\n            });\n            audioWorkletNode.port.onmessage = () => (isCallingProcess = true);\n            oscillator.connect(audioWorkletNode);\n            oscillator.start(0);\n            await offlineAudioContext.startRendering();\n            isCallingProcess = await new Promise((resolve) => {\n                messageChannel.port1.onmessage = ({ data }) => resolve(data === 1);\n                messageChannel.port1.postMessage(0);\n            });\n        }\n        catch {\n            // Ignore errors.\n        }\n        finally {\n            messageChannel.port1.close();\n            URL.revokeObjectURL(url);\n        }\n        return isCallingProcess;\n    };\n};\n//# sourceMappingURL=test-audio-worklet-processor-no-outputs-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioWorkletProcessorPostMessageSupport\": () => (/* binding */ createTestAudioWorkletProcessorPostMessageSupport)\n/* harmony export */ });\n// Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\nconst createTestAudioWorkletProcessorPostMessageSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {\n    return async () => {\n        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.\n        if (nativeAudioWorkletNodeConstructor === null) {\n            return true;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const blob = new Blob(['class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor(\"a\",A)'], {\n            type: 'application/javascript; charset=utf-8'\n        });\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);\n        const url = URL.createObjectURL(blob);\n        let isEmittingMessageEvents = false;\n        let isEmittingProcessorErrorEvents = false;\n        try {\n            await offlineAudioContext.audioWorklet.addModule(url);\n            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });\n            const oscillator = offlineAudioContext.createOscillator();\n            audioWorkletNode.port.onmessage = () => (isEmittingMessageEvents = true);\n            audioWorkletNode.onprocessorerror = () => (isEmittingProcessorErrorEvents = true);\n            oscillator.connect(audioWorkletNode);\n            oscillator.start(0);\n            await offlineAudioContext.startRendering();\n        }\n        catch {\n            // Ignore errors.\n        }\n        finally {\n            URL.revokeObjectURL(url);\n        }\n        return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;\n    };\n};\n//# sourceMappingURL=test-audio-worklet-processor-post-message-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestChannelMergerNodeChannelCountSupport\": () => (/* binding */ createTestChannelMergerNodeChannelCountSupport)\n/* harmony export */ });\n/**\n * Firefox up to version 69 did not throw an error when setting a different channelCount or channelCountMode.\n */\nconst createTestChannelMergerNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();\n        /**\n         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support\n         * in other browsers.\n         */\n        if (nativeChannelMergerNode.channelCountMode === 'max') {\n            return true;\n        }\n        try {\n            nativeChannelMergerNode.channelCount = 2;\n        }\n        catch {\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=test-channel-merger-node-channel-count-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConstantSourceNodeAccurateSchedulingSupport\": () => (/* binding */ createTestConstantSourceNodeAccurateSchedulingSupport)\n/* harmony export */ });\nconst createTestConstantSourceNodeAccurateSchedulingSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return true;\n        }\n        const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();\n        /*\n         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to\n         * the implementation of Firefox right now, but it could probably be done in a better way.\n         */\n        return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;\n    };\n};\n//# sourceMappingURL=test-constant-source-node-accurate-scheduling-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConvolverNodeBufferReassignabilitySupport\": () => (/* binding */ createTestConvolverNodeBufferReassignabilitySupport)\n/* harmony export */ });\n// Opera up to version 57 did not allow to reassign the buffer of a ConvolverNode.\nconst createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeConvolverNode = offlineAudioContext.createConvolver();\n        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        try {\n            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-convolver-node-buffer-reassignability-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConvolverNodeChannelCountSupport\": () => (/* binding */ createTestConvolverNodeChannelCountSupport)\n/* harmony export */ });\n// Chrome up to version v80, Edge up to version v80 and Opera up to version v67 did not allow to set the channelCount property of a ConvolverNode to 1. They also did not allow to set the channelCountMode to 'explicit'.\nconst createTestConvolverNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeConvolverNode = offlineAudioContext.createConvolver();\n        try {\n            nativeConvolverNode.channelCount = 1;\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-convolver-node-channel-count-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestIsSecureContextSupport\": () => (/* binding */ createTestIsSecureContextSupport)\n/* harmony export */ });\nconst createTestIsSecureContextSupport = (window) => {\n    return () => window !== null && window.hasOwnProperty('isSecureContext');\n};\n//# sourceMappingURL=test-is-secure-context-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js":
/*!********************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js ***!
  \********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport\": () => (/* binding */ createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)\n/* harmony export */ });\n// Firefox up to version 68 did not throw an error when creating a MediaStreamAudioSourceNode with a mediaStream that had no audio track.\nconst createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        try {\n            audioContext.createMediaStreamSource(new MediaStream());\n            return false;\n        }\n        catch (err) {\n            return true;\n        }\n        finally {\n            audioContext.close();\n        }\n    };\n};\n//# sourceMappingURL=test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestOfflineAudioContextCurrentTimeSupport\": () => (/* binding */ createTestOfflineAudioContextCurrentTimeSupport)\n/* harmony export */ });\nconst createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            nativeOfflineAudioContext.oncomplete = () => {\n                gainNode.disconnect();\n                resolve(nativeOfflineAudioContext.currentTime !== 0);\n            };\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=test-offline-audio-context-current-time-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestStereoPannerNodeDefaultValueSupport\": () => (/* binding */ createTestStereoPannerNodeDefaultValueSupport)\n/* harmony export */ });\n/**\n * Firefox up to version 62 did not kick off the processing of the StereoPannerNode if the value of pan was zero.\n */\nconst createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        /*\n         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does\n         * support the tested behaviour.\n         */\n        if (nativeOfflineAudioContext.createStereoPanner === undefined) {\n            return Promise.resolve(true);\n        }\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return Promise.resolve(true);\n        }\n        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();\n        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();\n        constantSourceNode.channelCount = 1;\n        constantSourceNode.offset.value = 1;\n        stereoPanner.channelCount = 1;\n        constantSourceNode.start();\n        constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);\n        return nativeOfflineAudioContext.startRendering().then((buffer) => buffer.getChannelData(0)[0] !== 1);\n    };\n};\n//# sourceMappingURL=test-stereo-panner-node-default-value-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createUnknownError\": () => (/* binding */ createUnknownError)\n/* harmony export */ });\nconst createUnknownError = () => new DOMException('', 'UnknownError');\n//# sourceMappingURL=unknown-error.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWaveShaperNodeConstructor\": () => (/* binding */ createWaveShaperNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    curve: null,\n    oversample: 'none'\n};\nconst createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class WaveShaperNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const waveShaperNodeRenderer = (isOffline ? createWaveShaperNodeRenderer() : null);\n            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.\n            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);\n            this._isCurveNullified = false;\n            this._nativeWaveShaperNode = nativeWaveShaperNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get curve() {\n            if (this._isCurveNullified) {\n                return null;\n            }\n            return this._nativeWaveShaperNode.curve;\n        }\n        set curve(value) {\n            // Bug #103: Safari does not allow to set the curve to null.\n            if (value === null) {\n                this._isCurveNullified = true;\n                this._nativeWaveShaperNode.curve = new Float32Array([0, 0]);\n            }\n            else {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.\n                if (value.length < 2) {\n                    throw createInvalidStateError();\n                }\n                this._isCurveNullified = false;\n                this._nativeWaveShaperNode.curve = value;\n            }\n        }\n        get oversample() {\n            return this._nativeWaveShaperNode.oversample;\n        }\n        set oversample(value) {\n            this._nativeWaveShaperNode.oversample = value;\n        }\n    };\n};\n//# sourceMappingURL=wave-shaper-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWaveShaperNodeRendererFactory\": () => (/* binding */ createWaveShaperNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeWaveShaperNodes = new WeakMap();\n        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeWaveShaperNode = getNativeAudioNode(proxy);\n            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeWaveShaperNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeWaveShaperNode, nativeOfflineAudioContext);\n            if (!nativeWaveShaperNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeWaveShaperNode.channelCount,\n                    channelCountMode: nativeWaveShaperNode.channelCountMode,\n                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,\n                    curve: nativeWaveShaperNode.curve,\n                    oversample: nativeWaveShaperNode.oversample\n                };\n                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeWaveShaperNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode);\n            }\n            return nativeWaveShaperNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeWaveShaperNode !== undefined) {\n                    return Promise.resolve(renderedNativeWaveShaperNode);\n                }\n                return createWaveShaperNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=wave-shaper-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/window.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/window.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWindow\": () => (/* binding */ createWindow)\n/* harmony export */ });\nconst createWindow = () => (typeof window === 'undefined' ? null : window);\n//# sourceMappingURL=window.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/window.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferCopyChannelMethodsOutOfBounds\": () => (/* binding */ createWrapAudioBufferCopyChannelMethodsOutOfBounds)\n/* harmony export */ });\nconst createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = ((copyFromChannel) => {\n            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyFromChannel);\n        audioBuffer.copyToChannel = ((copyToChannel) => {\n            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyToChannel);\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferCopyChannelMethods\": () => (/* binding */ createWrapAudioBufferCopyChannelMethods)\n/* harmony export */ });\nconst createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const destinationLength = destination.length;\n            for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1) {\n                destination[i] = channelData[i + bufferOffset];\n            }\n        };\n        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const sourceLength = source.length;\n            for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1) {\n                channelData[i + bufferOffset] = source[i];\n            }\n        };\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer\": () => (/* binding */ createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer)\n/* harmony export */ });\nconst createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors) => {\n    return (nativeAudioBufferSourceNode, nativeContext) => {\n        const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);\n        if (nativeAudioBufferSourceNode.buffer === null) {\n            nativeAudioBufferSourceNode.buffer = nullifiedBuffer;\n        }\n        overwriteAccessors(nativeAudioBufferSourceNode, 'buffer', (get) => () => {\n            const value = get.call(nativeAudioBufferSourceNode);\n            return value === nullifiedBuffer ? null : value;\n        }, (set) => (value) => {\n            return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);\n        });\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapChannelMergerNode\": () => (/* binding */ createWrapChannelMergerNode)\n/* harmony export */ });\nconst createWrapChannelMergerNode = (createInvalidStateError, monitorConnections) => {\n    return (nativeContext, channelMergerNode) => {\n        // Bug #15: Safari does not return the default properties.\n        channelMergerNode.channelCount = 1;\n        channelMergerNode.channelCountMode = 'explicit';\n        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.\n        Object.defineProperty(channelMergerNode, 'channelCount', {\n            get: () => 1,\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        Object.defineProperty(channelMergerNode, 'channelCountMode', {\n            get: () => 'explicit',\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.\n        const audioBufferSourceNode = nativeContext.createBufferSource();\n        const whenConnected = () => {\n            const length = channelMergerNode.numberOfInputs;\n            for (let i = 0; i < length; i += 1) {\n                audioBufferSourceNode.connect(channelMergerNode, 0, i);\n            }\n        };\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(channelMergerNode);\n        monitorConnections(channelMergerNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=wrap-channel-merger-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/globals.js":
/*!*************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/globals.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ACTIVE_AUDIO_NODE_STORE\": () => (/* binding */ ACTIVE_AUDIO_NODE_STORE),\n/* harmony export */   \"AUDIO_NODE_CONNECTIONS_STORE\": () => (/* binding */ AUDIO_NODE_CONNECTIONS_STORE),\n/* harmony export */   \"AUDIO_NODE_STORE\": () => (/* binding */ AUDIO_NODE_STORE),\n/* harmony export */   \"AUDIO_PARAM_CONNECTIONS_STORE\": () => (/* binding */ AUDIO_PARAM_CONNECTIONS_STORE),\n/* harmony export */   \"AUDIO_PARAM_STORE\": () => (/* binding */ AUDIO_PARAM_STORE),\n/* harmony export */   \"CONTEXT_STORE\": () => (/* binding */ CONTEXT_STORE),\n/* harmony export */   \"CYCLE_COUNTERS\": () => (/* binding */ CYCLE_COUNTERS),\n/* harmony export */   \"EVENT_LISTENERS\": () => (/* binding */ EVENT_LISTENERS),\n/* harmony export */   \"NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS\": () => (/* binding */ NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS),\n/* harmony export */   \"NODE_TO_PROCESSOR_MAPS\": () => (/* binding */ NODE_TO_PROCESSOR_MAPS)\n/* harmony export */ });\nconst ACTIVE_AUDIO_NODE_STORE = new WeakSet();\nconst AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();\nconst AUDIO_NODE_STORE = new WeakMap();\nconst AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();\nconst AUDIO_PARAM_STORE = new WeakMap();\nconst CONTEXT_STORE = new WeakMap();\nconst EVENT_LISTENERS = new WeakMap();\nconst CYCLE_COUNTERS = new WeakMap();\n// This clunky name is borrowed from the spec. :-)\nconst NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();\nconst NODE_TO_PROCESSOR_MAPS = new WeakMap();\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/globals.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioBufferSourceNode\": () => (/* binding */ isAudioBufferSourceNode)\n/* harmony export */ });\nconst isAudioBufferSourceNode = (audioNode) => {\n    return 'playbackRate' in audioNode;\n};\n//# sourceMappingURL=audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioNodeOutputConnection\": () => (/* binding */ isAudioNodeOutputConnection)\n/* harmony export */ });\n/* harmony import */ var _audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n\nconst isAudioNodeOutputConnection = (outputConnection) => {\n    return (0,_audio_node__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(outputConnection[0]);\n};\n//# sourceMappingURL=audio-node-output-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioNode\": () => (/* binding */ isAudioNode)\n/* harmony export */ });\nconst isAudioNode = (audioNodeOrAudioParam) => {\n    return 'context' in audioNodeOrAudioParam;\n};\n//# sourceMappingURL=audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioWorkletNode\": () => (/* binding */ isAudioWorkletNode)\n/* harmony export */ });\nconst isAudioWorkletNode = (audioNode) => {\n    return 'port' in audioNode;\n};\n//# sourceMappingURL=audio-worklet-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isBiquadFilterNode\": () => (/* binding */ isBiquadFilterNode)\n/* harmony export */ });\nconst isBiquadFilterNode = (audioNode) => {\n    return 'frequency' in audioNode && 'gain' in audioNode;\n};\n//# sourceMappingURL=biquad-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isConstantSourceNode\": () => (/* binding */ isConstantSourceNode)\n/* harmony export */ });\nconst isConstantSourceNode = (audioNode) => {\n    return 'offset' in audioNode;\n};\n//# sourceMappingURL=constant-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isDelayNode\": () => (/* binding */ isDelayNode)\n/* harmony export */ });\nconst isDelayNode = (audioNode) => {\n    return 'delayTime' in audioNode;\n};\n//# sourceMappingURL=delay-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isGainNode\": () => (/* binding */ isGainNode)\n/* harmony export */ });\nconst isGainNode = (audioNode) => {\n    return !('frequency' in audioNode) && 'gain' in audioNode;\n};\n//# sourceMappingURL=gain-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isNativeAudioNodeFaker\": () => (/* binding */ isNativeAudioNodeFaker)\n/* harmony export */ });\nconst isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker) => {\n    return 'inputs' in nativeAudioNodeOrNativeAudioNodeFaker;\n};\n//# sourceMappingURL=native-audio-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isNativeAudioNode\": () => (/* binding */ isNativeAudioNode)\n/* harmony export */ });\nconst isNativeAudioNode = (nativeAudioNodeOrAudioParam) => {\n    return 'context' in nativeAudioNodeOrAudioParam;\n};\n//# sourceMappingURL=native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isOscillatorNode\": () => (/* binding */ isOscillatorNode)\n/* harmony export */ });\nconst isOscillatorNode = (audioNode) => {\n    return 'detune' in audioNode && 'frequency' in audioNode;\n};\n//# sourceMappingURL=oscillator-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isStereoPannerNode\": () => (/* binding */ isStereoPannerNode)\n/* harmony export */ });\nconst isStereoPannerNode = (audioNode) => {\n    return 'pan' in audioNode;\n};\n//# sourceMappingURL=stereo-panner-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addActiveInputConnectionToAudioParam\": () => (/* binding */ addActiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n\nconst addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates) => {\n    (0,_insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__.insertElementInSet)(activeInputs, [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);\n};\n//# sourceMappingURL=add-active-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addPassiveInputConnectionToAudioParam\": () => (/* binding */ addPassiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n\nconst addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates) => {\n    const passiveInputConnections = passiveInputs.get(source);\n    if (passiveInputConnections === undefined) {\n        passiveInputs.set(source, new Set([[output, eventListener]]));\n    }\n    else {\n        (0,_insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__.insertElementInSet)(passiveInputConnections, [output, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output, ignoreDuplicates);\n    }\n};\n//# sourceMappingURL=add-passive-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeAudioParamValue\": () => (/* binding */ assignNativeAudioNodeAudioParamValue)\n/* harmony export */ });\nconst assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam) => {\n    const value = options[audioParam];\n    if (value !== undefined && value !== nativeAudioNode[audioParam].value) {\n        nativeAudioNode[audioParam].value = value;\n    }\n};\n//# sourceMappingURL=assign-native-audio-node-audio-param-value.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeOption\": () => (/* binding */ assignNativeAudioNodeOption)\n/* harmony export */ });\nconst assignNativeAudioNodeOption = (nativeAudioNode, options, option) => {\n    const value = options[option];\n    if (value !== undefined && value !== nativeAudioNode[option]) {\n        nativeAudioNode[option] = value;\n    }\n};\n//# sourceMappingURL=assign-native-audio-node-option.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeOptions\": () => (/* binding */ assignNativeAudioNodeOptions)\n/* harmony export */ });\n/* harmony import */ var _assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n\nconst assignNativeAudioNodeOptions = (nativeAudioNode, options) => {\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelCount');\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelCountMode');\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelInterpretation');\n};\n//# sourceMappingURL=assign-native-audio-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"cloneAudioWorkletNodeOptions\": () => (/* binding */ cloneAudioWorkletNodeOptions)\n/* harmony export */ });\nconst cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    return new Promise((resolve, reject) => {\n        const { port1, port2 } = new MessageChannel();\n        port1.onmessage = ({ data }) => {\n            port1.close();\n            port2.close();\n            resolve(data);\n        };\n        port1.onmessageerror = ({ data }) => {\n            port1.close();\n            port2.close();\n            reject(data);\n        };\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port2.postMessage(audioWorkletNodeOptions);\n    });\n};\n//# sourceMappingURL=clone-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"computeBufferSize\": () => (/* binding */ computeBufferSize)\n/* harmony export */ });\nconst computeBufferSize = (baseLatency, sampleRate) => {\n    if (baseLatency === null) {\n        return 512;\n    }\n    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));\n};\n//# sourceMappingURL=compute-buffer-size.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"connectNativeAudioNodeToNativeAudioNode\": () => (/* binding */ connectNativeAudioNodeToNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n\nconst connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) {\n        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];\n        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);\n        return [fakeNativeDestinationAudioNode, output, 0];\n    }\n    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);\n    return [nativeDestinationAudioNode, output, input];\n};\n//# sourceMappingURL=connect-native-audio-node-to-native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"copyFromChannel\": () => (/* binding */ copyFromChannel)\n/* harmony export */ });\nfunction copyFromChannel(audioBuffer, \n// @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }\nparent, key, channelNumber, bufferOffset) {\n    if (typeof audioBuffer.copyFromChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = new Float32Array(128);\n        }\n        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);\n        // Bug #5: Safari does not support copyFromChannel().\n    }\n    else {\n        const channelData = audioBuffer.getChannelData(channelNumber);\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);\n        }\n        else {\n            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);\n            parent[key].set(slicedInput);\n        }\n    }\n}\n//# sourceMappingURL=copy-from-channel.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"copyToChannel\": () => (/* binding */ copyToChannel)\n/* harmony export */ });\nconst copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset) => {\n    if (typeof audioBuffer.copyToChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);\n        }\n        // Bug #5: Safari does not support copyToChannel().\n    }\n    else {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);\n        }\n    }\n};\n//# sourceMappingURL=copy-to-channel.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletProcessorPromise\": () => (/* binding */ createAudioWorkletProcessorPromise)\n/* harmony export */ });\n/* harmony import */ var _clone_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./clone-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js\");\n\nconst createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions) => {\n    const clonedAudioWorkletNodeOptions = await (0,_clone_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__.cloneAudioWorkletNodeOptions)(audioWorkletNodeOptions);\n    return new processorConstructor(clonedAudioWorkletNodeOptions);\n};\n//# sourceMappingURL=create-audio-worklet-processor-promise.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletProcessor\": () => (/* binding */ createAudioWorkletProcessor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _create_audio_worklet_processor_promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./create-audio-worklet-processor-promise */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js\");\n\n\nconst createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions) => {\n    let nodeToProcessorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS.get(nativeContext);\n    if (nodeToProcessorMap === undefined) {\n        nodeToProcessorMap = new WeakMap();\n        _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);\n    }\n    const audioWorkletProcessorPromise = (0,_create_audio_worklet_processor_promise__WEBPACK_IMPORTED_MODULE_1__.createAudioWorkletProcessorPromise)(processorConstructor, audioWorkletNodeOptions);\n    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);\n    return audioWorkletProcessorPromise;\n};\n//# sourceMappingURL=create-audio-worklet-processor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNestedArrays\": () => (/* binding */ createNestedArrays)\n/* harmony export */ });\nconst createNestedArrays = (x, y) => {\n    const arrays = [];\n    for (let i = 0; i < x; i += 1) {\n        const array = [];\n        const length = typeof y === 'number' ? y : y[i];\n        for (let j = 0; j < length; j += 1) {\n            array.push(new Float32Array(128));\n        }\n        arrays.push(array);\n    }\n    return arrays;\n};\n//# sourceMappingURL=create-nested-arrays.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deactivateActiveAudioNodeInputConnections\": () => (/* binding */ deactivateActiveAudioNodeInputConnections)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js\");\n/* harmony import */ var _guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js\");\n/* harmony import */ var _guards_biquad_filter_node__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../guards/biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js\");\n/* harmony import */ var _guards_constant_source_node__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../guards/constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js\");\n/* harmony import */ var _guards_gain_node__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../guards/gain-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js\");\n/* harmony import */ var _guards_oscillator_node__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../guards/oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js\");\n/* harmony import */ var _guards_stereo_panner_node__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../guards/stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js\");\n/* harmony import */ var _get_audio_node_connections__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _get_audio_param_connections__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _is_active_audio_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\n\n\n\n\n\n\n\nconst deactivateActiveAudioNodeInputConnections = (audioNode, trace) => {\n    const { activeInputs } = (0,_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_7__.getAudioNodeConnections)(audioNode);\n    activeInputs.forEach((connections) => connections.forEach(([source]) => {\n        if (!trace.includes(audioNode)) {\n            deactivateActiveAudioNodeInputConnections(source, [...trace, audioNode]);\n        }\n    }));\n    const audioParams = (0,_guards_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_0__.isAudioBufferSourceNode)(audioNode)\n        ? [\n            // Bug #149: Safari does not yet support the detune AudioParam.\n            audioNode.playbackRate\n        ]\n        : (0,_guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_1__.isAudioWorkletNode)(audioNode)\n            ? Array.from(audioNode.parameters.values())\n            : (0,_guards_biquad_filter_node__WEBPACK_IMPORTED_MODULE_2__.isBiquadFilterNode)(audioNode)\n                ? [audioNode.Q, audioNode.detune, audioNode.frequency, audioNode.gain]\n                : (0,_guards_constant_source_node__WEBPACK_IMPORTED_MODULE_3__.isConstantSourceNode)(audioNode)\n                    ? [audioNode.offset]\n                    : (0,_guards_gain_node__WEBPACK_IMPORTED_MODULE_4__.isGainNode)(audioNode)\n                        ? [audioNode.gain]\n                        : (0,_guards_oscillator_node__WEBPACK_IMPORTED_MODULE_5__.isOscillatorNode)(audioNode)\n                            ? [audioNode.detune, audioNode.frequency]\n                            : (0,_guards_stereo_panner_node__WEBPACK_IMPORTED_MODULE_6__.isStereoPannerNode)(audioNode)\n                                ? [audioNode.pan]\n                                : [];\n    for (const audioParam of audioParams) {\n        const audioParamConnections = (0,_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_8__.getAudioParamConnections)(audioParam);\n        if (audioParamConnections !== undefined) {\n            audioParamConnections.activeInputs.forEach(([source]) => deactivateActiveAudioNodeInputConnections(source, trace));\n        }\n    }\n    if ((0,_is_active_audio_node__WEBPACK_IMPORTED_MODULE_9__.isActiveAudioNode)(audioNode)) {\n        (0,_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_10__.setInternalStateToPassive)(audioNode);\n    }\n};\n//# sourceMappingURL=deactivate-active-audio-node-input-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deactivateAudioGraph\": () => (/* binding */ deactivateAudioGraph)\n/* harmony export */ });\n/* harmony import */ var _deactivate_active_audio_node_input_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./deactivate-active-audio-node-input-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js\");\n\nconst deactivateAudioGraph = (context) => {\n    (0,_deactivate_active_audio_node_input_connections__WEBPACK_IMPORTED_MODULE_0__.deactivateActiveAudioNodeInputConnections)(context.destination, []);\n};\n//# sourceMappingURL=deactivate-audio-graph.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteActiveInputConnectionToAudioParam\": () => (/* binding */ deleteActiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\nconst deleteActiveInputConnectionToAudioParam = (activeInputs, source, output) => {\n    return (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_0__.pickElementFromSet)(activeInputs, (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);\n};\n//# sourceMappingURL=delete-active-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteActiveInputConnection\": () => (/* binding */ deleteActiveInputConnection)\n/* harmony export */ });\nconst deleteActiveInputConnection = (activeInputConnections, source, output) => {\n    for (const activeInputConnection of activeInputConnections) {\n        if (activeInputConnection[0] === source && activeInputConnection[1] === output) {\n            activeInputConnections.delete(activeInputConnection);\n            return activeInputConnection;\n        }\n    }\n    return null;\n};\n//# sourceMappingURL=delete-active-input-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteEventListenerOfAudioNode\": () => (/* binding */ deleteEventListenerOfAudioNode)\n/* harmony export */ });\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\nconst deleteEventListenerOfAudioNode = (audioNode, eventListener) => {\n    const eventListeners = (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_0__.getEventListenersOfAudioNode)(audioNode);\n    if (!eventListeners.delete(eventListener)) {\n        throw new Error('Missing the expected event listener.');\n    }\n};\n//# sourceMappingURL=delete-event-listeners-of-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deletePassiveInputConnectionToAudioNode\": () => (/* binding */ deletePassiveInputConnectionToAudioNode)\n/* harmony export */ });\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\n\nconst deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input) => {\n    const passiveInputConnections = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_0__.getValueForKey)(passiveInputs, source);\n    const matchingConnection = (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__.pickElementFromSet)(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input);\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\n//# sourceMappingURL=delete-passive-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deletePassiveInputConnectionToAudioParam\": () => (/* binding */ deletePassiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\n\nconst deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output) => {\n    const passiveInputConnections = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_0__.getValueForKey)(passiveInputs, source);\n    const matchingConnection = (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__.pickElementFromSet)(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output);\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\n//# sourceMappingURL=delete-passive-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"detachArrayBuffer\": () => (/* binding */ detachArrayBuffer)\n/* harmony export */ });\nconst detachArrayBuffer = (arrayBuffer) => {\n    const { port1, port2 } = new MessageChannel();\n    return new Promise((resolve) => {\n        const closeAndResolve = () => {\n            port2.onmessage = null;\n            port1.close();\n            port2.close();\n            resolve();\n        };\n        port2.onmessage = () => closeAndResolve();\n        try {\n            port1.postMessage(arrayBuffer, [arrayBuffer]);\n        }\n        finally {\n            closeAndResolve();\n        }\n    });\n};\n//# sourceMappingURL=detach-array-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"disconnectNativeAudioNodeFromNativeAudioNode\": () => (/* binding */ disconnectNativeAudioNodeFromNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n\nconst disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);\n    }\n    else {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);\n    }\n};\n//# sourceMappingURL=disconnect-native-audio-node-from-native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"filterBuffer\": () => (/* binding */ filterBuffer)\n/* harmony export */ });\n// This implementation as shamelessly inspired by source code of\n// tslint:disable-next-line:max-line-length\n// {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.\nconst filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output) => {\n    const inputLength = input.length;\n    let i = bufferIndex;\n    for (let j = 0; j < inputLength; j += 1) {\n        let y = feedforward[0] * input[j];\n        for (let k = 1; k < minLength; k += 1) {\n            const x = (i - k) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n            y += feedforward[k] * xBuffer[x];\n            y -= feedback[k] * yBuffer[x];\n        }\n        for (let k = minLength; k < feedforwardLength; k += 1) {\n            y += feedforward[k] * xBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        for (let k = minLength; k < feedbackLength; k += 1) {\n            y -= feedback[k] * yBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        xBuffer[i] = input[j];\n        yBuffer[i] = y;\n        i = (i + 1) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n        output[j] = y;\n    }\n    return i;\n};\n//# sourceMappingURL=filter-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioNodeConnections\": () => (/* binding */ getAudioNodeConnections)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getAudioNodeConnections = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_CONNECTIONS_STORE, audioNode);\n};\n//# sourceMappingURL=get-audio-node-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioParamConnections\": () => (/* binding */ getAudioParamConnections)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getAudioParamConnections = (audioParam) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_PARAM_CONNECTIONS_STORE, audioParam);\n};\n//# sourceMappingURL=get-audio-param-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioWorkletProcessor\": () => (/* binding */ getAudioWorkletProcessor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_native_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\n\nconst getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy) => {\n    const nodeToProcessorMap = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_2__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS, nativeOfflineAudioContext);\n    const nativeAudioWorkletNode = (0,_get_native_audio_node__WEBPACK_IMPORTED_MODULE_1__.getNativeAudioNode)(proxy);\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_2__.getValueForKey)(nodeToProcessorMap, nativeAudioWorkletNode);\n};\n//# sourceMappingURL=get-audio-worklet-processor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getEventListenersOfAudioNode\": () => (/* binding */ getEventListenersOfAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getEventListenersOfAudioNode = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.EVENT_LISTENERS, audioNode);\n};\n//# sourceMappingURL=get-event-listeners-of-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getFirstSample\": () => (/* binding */ getFirstSample)\n/* harmony export */ });\nconst getFirstSample = (audioBuffer, buffer, channelNumber) => {\n    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n    if (audioBuffer.copyFromChannel === undefined) {\n        return audioBuffer.getChannelData(channelNumber)[0];\n    }\n    audioBuffer.copyFromChannel(buffer, channelNumber);\n    return buffer[0];\n};\n//# sourceMappingURL=get-first-sample.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getNativeAudioNode\": () => (/* binding */ getNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getNativeAudioNode = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_STORE, audioNode);\n};\n//# sourceMappingURL=get-native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getNativeAudioParam\": () => (/* binding */ getNativeAudioParam)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getNativeAudioParam = (audioParam) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_PARAM_STORE, audioParam);\n};\n//# sourceMappingURL=get-native-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getValueForKey\": () => (/* binding */ getValueForKey)\n/* harmony export */ });\nconst getValueForKey = (map, key) => {\n    const value = map.get(key);\n    if (value === undefined) {\n        throw new Error('A value with the given key could not be found.');\n    }\n    return value;\n};\n//# sourceMappingURL=get-value-for-key.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"insertElementInSet\": () => (/* binding */ insertElementInSet)\n/* harmony export */ });\nconst insertElementInSet = (set, element, predicate, ignoreDuplicates) => {\n    for (const lmnt of set) {\n        if (predicate(lmnt)) {\n            if (ignoreDuplicates) {\n                return false;\n            }\n            throw Error('The set contains at least one similar element.');\n        }\n    }\n    set.add(element);\n    return true;\n};\n//# sourceMappingURL=insert-element-in-set.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"interceptConnections\": () => (/* binding */ interceptConnections)\n/* harmony export */ });\nconst interceptConnections = (original, interceptor) => {\n    original.connect = interceptor.connect.bind(interceptor);\n    original.disconnect = interceptor.disconnect.bind(interceptor);\n    return original;\n};\n//# sourceMappingURL=intercept-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isActiveAudioNode\": () => (/* binding */ isActiveAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isActiveAudioNode = (audioNode) => _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n//# sourceMappingURL=is-active-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isConstructible\": () => (/* binding */ isConstructible)\n/* harmony export */ });\nconst handler = {\n    construct() {\n        return handler;\n    }\n};\nconst isConstructible = (constructible) => {\n    try {\n        const proxy = new Proxy(constructible, handler);\n        new proxy(); // tslint:disable-line:no-unused-expression\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=is-constructible.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isDCCurve\": () => (/* binding */ isDCCurve)\n/* harmony export */ });\nconst isDCCurve = (curve) => {\n    if (curve === null) {\n        return false;\n    }\n    const length = curve.length;\n    if (length % 2 !== 0) {\n        return curve[Math.floor(length / 2)] !== 0;\n    }\n    return curve[length / 2 - 1] + curve[length / 2] !== 0;\n};\n//# sourceMappingURL=is-dc-curve.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isOwnedByContext\": () => (/* binding */ isOwnedByContext)\n/* harmony export */ });\nconst isOwnedByContext = (nativeAudioNode, nativeContext) => {\n    return nativeAudioNode.context === nativeContext;\n};\n//# sourceMappingURL=is-owned-by-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isPartOfACycle\": () => (/* binding */ isPartOfACycle)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isPartOfACycle = (audioNode) => {\n    return _globals__WEBPACK_IMPORTED_MODULE_0__.CYCLE_COUNTERS.has(audioNode);\n};\n//# sourceMappingURL=is-part-of-a-cycle.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isPassiveAudioNode\": () => (/* binding */ isPassiveAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isPassiveAudioNode = (audioNode) => {\n    return !_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n};\n//# sourceMappingURL=is-passive-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isValidLatencyHint\": () => (/* binding */ isValidLatencyHint)\n/* harmony export */ });\nconst isValidLatencyHint = (latencyHint) => {\n    return (latencyHint === undefined ||\n        typeof latencyHint === 'number' ||\n        (typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback')));\n};\n//# sourceMappingURL=is-valid-latency-hint.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"overwriteAccessors\": () => (/* binding */ overwriteAccessors)\n/* harmony export */ });\nconst overwriteAccessors = (object, property, createGetter, createSetter) => {\n    let prototype = object;\n    while (!prototype.hasOwnProperty(property)) {\n        prototype = Object.getPrototypeOf(prototype);\n    }\n    const { get, set } = Object.getOwnPropertyDescriptor(prototype, property);\n    Object.defineProperty(object, property, { get: createGetter(get), set: createSetter(set) });\n};\n//# sourceMappingURL=overwrite-accessors.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"pickElementFromSet\": () => (/* binding */ pickElementFromSet)\n/* harmony export */ });\nconst pickElementFromSet = (set, predicate) => {\n    const matchingElements = Array.from(set).filter(predicate);\n    if (matchingElements.length > 1) {\n        throw Error('More than one element was found.');\n    }\n    if (matchingElements.length === 0) {\n        throw Error('No element was found.');\n    }\n    const [matchingElement] = matchingElements;\n    set.delete(matchingElement);\n    return matchingElement;\n};\n//# sourceMappingURL=pick-element-from-set.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizeAudioWorkletNodeOptions\": () => (/* binding */ sanitizeAudioWorkletNodeOptions)\n/* harmony export */ });\nconst sanitizeAudioWorkletNodeOptions = (options) => {\n    return {\n        ...options,\n        outputChannelCount: options.outputChannelCount !== undefined\n            ? options.outputChannelCount\n            : options.numberOfInputs === 1 && options.numberOfOutputs === 1\n                ? /*\n                   * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why\n                   * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That\n                   * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.\n                   */\n                    [options.channelCount]\n                : Array.from({ length: options.numberOfOutputs }, () => 1)\n    };\n};\n//# sourceMappingURL=sanitize-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizeChannelSplitterOptions\": () => (/* binding */ sanitizeChannelSplitterOptions)\n/* harmony export */ });\nconst sanitizeChannelSplitterOptions = (options) => {\n    return { ...options, channelCount: options.numberOfOutputs };\n};\n//# sourceMappingURL=sanitize-channel-splitter-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizePeriodicWaveOptions\": () => (/* binding */ sanitizePeriodicWaveOptions)\n/* harmony export */ });\nconst sanitizePeriodicWaveOptions = (options) => {\n    const { imag, real } = options;\n    if (imag === undefined) {\n        if (real === undefined) {\n            return { ...options, imag: [0, 0], real: [0, 0] };\n        }\n        return { ...options, imag: Array.from(real, () => 0), real };\n    }\n    if (real === undefined) {\n        return { ...options, imag, real: Array.from(imag, () => 0) };\n    }\n    return { ...options, imag, real };\n};\n//# sourceMappingURL=sanitize-periodic-wave-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToActive\": () => (/* binding */ setInternalStateToActive)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\n\nconst setInternalStateToActive = (audioNode) => {\n    if (_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is already stored.');\n    }\n    _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.add(audioNode);\n    (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__.getEventListenersOfAudioNode)(audioNode).forEach((eventListener) => eventListener(true));\n};\n//# sourceMappingURL=set-internal-state-to-active.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToPassiveWhenNecessary\": () => (/* binding */ setInternalStateToPassiveWhenNecessary)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js\");\n/* harmony import */ var _set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n// Set the internalState of the audioNode to 'passive' if it is not an AudioWorkletNode and if it has no 'active' input connections.\nconst setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs) => {\n    if (!(0,_guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_0__.isAudioWorkletNode)(audioNode) && activeInputs.every((connections) => connections.size === 0)) {\n        (0,_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToPassive)(audioNode);\n    }\n};\n//# sourceMappingURL=set-internal-state-to-passive-when-necessary.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToPassive\": () => (/* binding */ setInternalStateToPassive)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\n\nconst setInternalStateToPassive = (audioNode) => {\n    if (!_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is not stored.');\n    }\n    _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE[\"delete\"](audioNode);\n    (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__.getEventListenersOfAudioNode)(audioNode).forEach((eventListener) => eventListener(false));\n};\n//# sourceMappingURL=set-internal-state-to-passive.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setValueAtTimeUntilPossible\": () => (/* binding */ setValueAtTimeUntilPossible)\n/* harmony export */ });\nconst setValueAtTimeUntilPossible = (audioParam, value, startTime) => {\n    try {\n        audioParam.setValueAtTime(value, startTime);\n    }\n    catch (err) {\n        if (err.code !== 9) {\n            throw err;\n        }\n        setValueAtTimeUntilPossible(audioParam, value, startTime + 1e-7);\n    }\n};\n//# sourceMappingURL=set-value-at-time-until-possible.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"splitImportStatements\": () => (/* binding */ splitImportStatements)\n/* harmony export */ });\n/*\n * This massive regex tries to cover all the following cases.\n *\n * import './path';\n * import defaultImport from './path';\n * import { namedImport } from './path';\n * import { namedImport as renamendImport } from './path';\n * import * as namespaceImport from './path';\n * import defaultImport, { namedImport } from './path';\n * import defaultImport, { namedImport as renamendImport } from './path';\n * import defaultImport, * as namespaceImport from './path';\n */\nconst IMPORT_STATEMENT_REGEX = /^import(?:(?:[\\s]+[\\w]+|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\{[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?(?:[\\s]*,[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?)*[\\s]*}|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\*[\\s]+as[\\s]+[\\w]+)[\\s]+from)?(?:[\\s]*)(\"([^\"\\\\]|\\\\.)+\"|'([^'\\\\]|\\\\.)+')(?:[\\s]*);?/; // tslint:disable-line:max-line-length\nconst splitImportStatements = (source, url) => {\n    const importStatements = [];\n    let sourceWithoutImportStatements = source.replace(/^[\\s]+/, '');\n    let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    while (result !== null) {\n        const unresolvedUrl = result[1].slice(1, -1);\n        const importStatementWithResolvedUrl = result[0]\n            .replace(/([\\s]+)?;?$/, '')\n            .replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());\n        importStatements.push(importStatementWithResolvedUrl);\n        sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\\s]+/, '');\n        result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    }\n    return [importStatements.join(';'), sourceWithoutImportStatements];\n};\n//# sourceMappingURL=split-import-statements.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAnalyserNodeGetFloatTimeDomainDataMethodSupport\": () => (/* binding */ testAnalyserNodeGetFloatTimeDomainDataMethodSupport)\n/* harmony export */ });\nconst testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode) => {\n    return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';\n};\n//# sourceMappingURL=test-analyser-node-get-float-time-domain-data-method-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferCopyChannelMethodsOutOfBoundsSupport\": () => (/* binding */ testAudioBufferCopyChannelMethodsOutOfBoundsSupport)\n/* harmony export */ });\nconst testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer) => {\n    try {\n        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-out-of-bounds-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport\": () => (/* binding */ testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.start();\n    try {\n        nativeAudioBufferSourceNode.start();\n    }\n    catch {\n        return true;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-start-method-consecutive-calls-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStartMethodOffsetClampingSupport\": () => (/* binding */ testAudioBufferSourceNodeStartMethodOffsetClampingSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStartMethodOffsetClampingSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n    try {\n        nativeAudioBufferSourceNode.start(0, 1);\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-start-method-offset-clamping-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStopMethodNullifiedBufferSupport\": () => (/* binding */ testAudioBufferSourceNodeStopMethodNullifiedBufferSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.start();\n    try {\n        nativeAudioBufferSourceNode.stop();\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-stop-method-nullified-buffer-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioNodeDisconnectMethodSupport\": () => (/* binding */ testAudioNodeDisconnectMethodSupport)\n/* harmony export */ });\nconst testAudioNodeDisconnectMethodSupport = (nativeAudioContext, nativeAudioWorkletNodeConstructor) => {\n    return new Promise((resolve) => {\n        /*\n         * This bug existed in Safari up until v14.0.2. Since AudioWorklets were not supported in Safari until v14.1 the presence of the\n         * constructor for an AudioWorkletNode can be used here to skip the test.\n         */\n        if (nativeAudioWorkletNodeConstructor !== null) {\n            resolve(true);\n        }\n        else {\n            const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1); // tslint:disable-line deprecation\n            const dummy = nativeAudioContext.createGain();\n            // Bug #95: Safari does not play one sample buffers.\n            const ones = nativeAudioContext.createBuffer(1, 2, 44100);\n            const channelData = ones.getChannelData(0);\n            channelData[0] = 1;\n            channelData[1] = 1;\n            const source = nativeAudioContext.createBufferSource();\n            source.buffer = ones;\n            source.loop = true;\n            source.connect(analyzer).connect(nativeAudioContext.destination);\n            source.connect(dummy);\n            source.disconnect(dummy);\n            // tslint:disable-next-line:deprecation\n            analyzer.onaudioprocess = (event) => {\n                const chnnlDt = event.inputBuffer.getChannelData(0); // tslint:disable-line deprecation\n                if (Array.prototype.some.call(chnnlDt, (sample) => sample === 1)) {\n                    resolve(true);\n                }\n                else {\n                    resolve(false);\n                }\n                source.stop();\n                analyzer.onaudioprocess = null; // tslint:disable-line:deprecation\n                source.disconnect(analyzer);\n                analyzer.disconnect(nativeAudioContext.destination);\n            };\n            source.start();\n        }\n    });\n};\n//# sourceMappingURL=test-audio-node-disconnect-method-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js":
/*!***************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js ***!
  \***************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStartMethodNegativeParametersSupport\": () => (/* binding */ testAudioScheduledSourceNodeStartMethodNegativeParametersSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createOscillator();\n    try {\n        nativeAudioBufferSourceNode.start(-1);\n    }\n    catch (err) {\n        return err instanceof RangeError;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-start-method-negative-parameters-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport\": () => (/* binding */ testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (nativeContext) => {\n    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n    nativeAudioBufferSourceNode.start();\n    nativeAudioBufferSourceNode.stop();\n    try {\n        nativeAudioBufferSourceNode.stop();\n        return true;\n    }\n    catch {\n        return false;\n    }\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js":
/*!**************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js ***!
  \**************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStopMethodNegativeParametersSupport\": () => (/* binding */ testAudioScheduledSourceNodeStopMethodNegativeParametersSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createOscillator();\n    try {\n        nativeAudioBufferSourceNode.stop(-1);\n    }\n    catch (err) {\n        return err instanceof RangeError;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-stop-method-negative-parameters-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioWorkletNodeOptionsClonability\": () => (/* binding */ testAudioWorkletNodeOptionsClonability)\n/* harmony export */ });\nconst testAudioWorkletNodeOptionsClonability = (audioWorkletNodeOptions) => {\n    const { port1, port2 } = new MessageChannel();\n    try {\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port1.postMessage(audioWorkletNodeOptions);\n    }\n    finally {\n        port1.close();\n        port2.close();\n    }\n};\n//# sourceMappingURL=test-audio-worklet-node-options-clonability.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testClonabilityOfAudioWorkletNodeOptions\": () => (/* binding */ testClonabilityOfAudioWorkletNodeOptions)\n/* harmony export */ });\nconst testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    const { port1 } = new MessageChannel();\n    try {\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port1.postMessage(audioWorkletNodeOptions);\n    }\n    finally {\n        port1.close();\n    }\n};\n//# sourceMappingURL=test-clonability-of-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testDomExceptionConstructorSupport\": () => (/* binding */ testDomExceptionConstructorSupport)\n/* harmony export */ });\n/*\n * Bug #122: Edge up to version v18 did not allow to construct a DOMException'. It also had a couple more bugs but since this is easy to\n * test it's used here as a placeholder.\n *\n * Bug #27: Edge up to version v18 did reject an invalid arrayBuffer passed to decodeAudioData() with a DOMException.\n *\n * Bug #50: Edge up to version v18 did not allow to create AudioNodes on a closed context.\n *\n * Bug #57: Edge up to version v18 did not throw an error when assigning the type of an OscillatorNode to 'custom'.\n *\n * Bug #63: Edge up to version v18 did not expose the mediaElement property of a MediaElementAudioSourceNode.\n *\n * Bug #64: Edge up to version v18 did not support the MediaStreamAudioDestinationNode.\n *\n * Bug #71: Edge up to version v18 did not allow to set the buffer of an AudioBufferSourceNode to null.\n *\n * Bug #93: Edge up to version v18 did set the sampleRate of an AudioContext to zero when it was closed.\n *\n * Bug #101: Edge up to version v18 refused to execute decodeAudioData() on a closed context.\n *\n * Bug #106: Edge up to version v18 did not expose the maxValue and minValue properties of the pan AudioParam of a StereoPannerNode.\n *\n * Bug #110: Edge up to version v18 did not expose the maxValue and minValue properties of the attack, knee, ratio, release and threshold AudioParams of a DynamicsCompressorNode.\n *\n * Bug #123: Edge up to version v18 did not support HRTF as the panningModel for a PannerNode.\n *\n * Bug #145: Edge up to version v18 did throw an IndexSizeError when an OfflineAudioContext was created with a sampleRate of zero.\n *\n * Bug #161: Edge up to version v18 did not expose the maxValue and minValue properties of the delayTime AudioParam of a DelayNode.\n */\nconst testDomExceptionConstructorSupport = () => {\n    try {\n        new DOMException(); // tslint:disable-line:no-unused-expression\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-dom-exception-constructor-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testPromiseSupport\": () => (/* binding */ testPromiseSupport)\n/* harmony export */ });\nconst testPromiseSupport = (nativeContext) => {\n    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.\n    const uint32Array = new Uint32Array([1179011410, 40, 1163280727, 544501094, 16, 131073, 44100, 176400, 1048580, 1635017060, 4, 0]);\n    try {\n        // Bug #1: Safari requires a successCallback.\n        const promise = nativeContext.decodeAudioData(uint32Array.buffer, () => {\n            // Ignore the success callback.\n        });\n        if (promise === undefined) {\n            return false;\n        }\n        promise.catch(() => {\n            // Ignore rejected errors.\n        });\n        return true;\n    }\n    catch {\n        // Ignore errors.\n    }\n    return false;\n};\n//# sourceMappingURL=test-promise-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testTransferablesSupport\": () => (/* binding */ testTransferablesSupport)\n/* harmony export */ });\n// Safari at version 11 did not support transferables.\nconst testTransferablesSupport = () => new Promise((resolve) => {\n    const arrayBuffer = new ArrayBuffer(0);\n    const { port1, port2 } = new MessageChannel();\n    port1.onmessage = ({ data }) => resolve(data !== null);\n    port2.postMessage(arrayBuffer, [arrayBuffer]);\n});\n//# sourceMappingURL=test-transferables-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"visitEachAudioNodeOnce\": () => (/* binding */ visitEachAudioNodeOnce)\n/* harmony export */ });\nconst visitEachAudioNodeOnce = (cycles, visitor) => {\n    const counts = new Map();\n    for (const cycle of cycles) {\n        for (const audioNode of cycle) {\n            const count = counts.get(audioNode);\n            counts.set(audioNode, count === undefined ? 1 : count + 1);\n        }\n    }\n    counts.forEach((count, audioNode) => visitor(audioNode, count));\n};\n//# sourceMappingURL=visit-each-audio-node-once.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAnalyserNodeGetFloatTimeDomainDataMethod\": () => (/* binding */ wrapAnalyserNodeGetFloatTimeDomainDataMethod)\n/* harmony export */ });\nconst wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode) => {\n    nativeAnalyserNode.getFloatTimeDomainData = (array) => {\n        const byteTimeDomainData = new Uint8Array(array.length);\n        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);\n        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;\n        }\n        return array;\n    };\n};\n//# sourceMappingURL=wrap-analyser-node-get-float-time-domain-data-method.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferGetChannelDataMethod\": () => (/* binding */ wrapAudioBufferGetChannelDataMethod)\n/* harmony export */ });\n/* harmony import */ var _factories_index_size_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/index-size-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js\");\n\nconst wrapAudioBufferGetChannelDataMethod = (audioBuffer) => {\n    audioBuffer.getChannelData = ((getChannelData) => {\n        return (channel) => {\n            try {\n                return getChannelData.call(audioBuffer, channel);\n            }\n            catch (err) {\n                if (err.code === 12) {\n                    throw (0,_factories_index_size_error__WEBPACK_IMPORTED_MODULE_0__.createIndexSizeError)();\n                }\n                throw err;\n            }\n        };\n    })(audioBuffer.getChannelData);\n};\n//# sourceMappingURL=wrap-audio-buffer-get-channel-data-method.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferSourceNodeStartMethodConsecutiveCalls\": () => (/* binding */ wrapAudioBufferSourceNodeStartMethodConsecutiveCalls)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        let isScheduled = false;\n        return (when = 0, offset = 0, duration) => {\n            if (isScheduled) {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n            start.call(nativeAudioBufferSourceNode, when, offset, duration);\n            isScheduled = true;\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-consecutive-calls.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferSourceNodeStartMethodOffsetClamping\": () => (/* binding */ wrapAudioBufferSourceNodeStartMethodOffsetClamping)\n/* harmony export */ });\nconst wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            const buffer = nativeAudioBufferSourceNode.buffer;\n            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.\n            const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);\n            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.\n            if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) {\n                start.call(nativeAudioBufferSourceNode, when, 0, 0);\n            }\n            else {\n                start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);\n            }\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-offset-clamping.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioNodeDisconnectMethod\": () => (/* binding */ wrapAudioNodeDisconnectMethod)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst wrapAudioNodeDisconnectMethod = (nativeAudioNode) => {\n    const connections = new Map();\n    nativeAudioNode.connect = ((connect) => {\n        // tslint:disable-next-line:invalid-void no-inferrable-types\n        return (destination, output = 0, input = 0) => {\n            const returnValue = (0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination) ? connect(destination, output, input) : connect(destination, output);\n            // Save the new connection only if the calls to connect above didn't throw an error.\n            const connectionsToDestination = connections.get(destination);\n            if (connectionsToDestination === undefined) {\n                connections.set(destination, [{ input, output }]);\n            }\n            else {\n                if (connectionsToDestination.every((connection) => connection.input !== input || connection.output !== output)) {\n                    connectionsToDestination.push({ input, output });\n                }\n            }\n            return returnValue;\n        };\n    })(nativeAudioNode.connect.bind(nativeAudioNode));\n    nativeAudioNode.disconnect = ((disconnect) => {\n        return (destinationOrOutput, output, input) => {\n            disconnect.apply(nativeAudioNode);\n            if (destinationOrOutput === undefined) {\n                connections.clear();\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                for (const [destination, connectionsToDestination] of connections) {\n                    const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== destinationOrOutput);\n                    if (filteredConnections.length === 0) {\n                        connections.delete(destination);\n                    }\n                    else {\n                        connections.set(destination, filteredConnections);\n                    }\n                }\n            }\n            else if (connections.has(destinationOrOutput)) {\n                if (output === undefined) {\n                    connections.delete(destinationOrOutput);\n                }\n                else {\n                    const connectionsToDestination = connections.get(destinationOrOutput);\n                    if (connectionsToDestination !== undefined) {\n                        const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== output && (connection.input !== input || input === undefined));\n                        if (filteredConnections.length === 0) {\n                            connections.delete(destinationOrOutput);\n                        }\n                        else {\n                            connections.set(destinationOrOutput, filteredConnections);\n                        }\n                    }\n                }\n            }\n            for (const [destination, connectionsToDestination] of connections) {\n                connectionsToDestination.forEach((connection) => {\n                    if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination)) {\n                        nativeAudioNode.connect(destination, connection.output, connection.input);\n                    }\n                    else {\n                        nativeAudioNode.connect(destination, connection.output);\n                    }\n                });\n            }\n        };\n    })(nativeAudioNode.disconnect);\n};\n//# sourceMappingURL=wrap-audio-node-disconnect-method.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStartMethodNegativeParameters\": () => (/* binding */ wrapAudioScheduledSourceNodeStartMethodNegativeParameters)\n/* harmony export */ });\nconst wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            if ((typeof duration === 'number' && duration < 0) || offset < 0 || when < 0) {\n                throw new RangeError(\"The parameters can't be negative.\");\n            }\n            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n            start.call(nativeAudioScheduledSourceNode, when, offset, duration);\n        };\n    })(nativeAudioScheduledSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-start-method-negative-parameters.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls\": () => (/* binding */ wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)\n/* harmony export */ });\n/* harmony import */ var _intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (nativeAudioScheduledSourceNode, nativeContext) => {\n    const nativeGainNode = nativeContext.createGain();\n    nativeAudioScheduledSourceNode.connect(nativeGainNode);\n    const disconnectGainNode = ((disconnect) => {\n        return () => {\n            // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n            disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);\n            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);\n        };\n    })(nativeAudioScheduledSourceNode.disconnect);\n    nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);\n    (0,_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeAudioScheduledSourceNode, nativeGainNode);\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        let isStopped = false;\n        return (when = 0) => {\n            if (isStopped) {\n                try {\n                    stop.call(nativeAudioScheduledSourceNode, when);\n                }\n                catch {\n                    nativeGainNode.gain.setValueAtTime(0, when);\n                }\n            }\n            else {\n                stop.call(nativeAudioScheduledSourceNode, when);\n                isStopped = true;\n            }\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStopMethodNegativeParameters\": () => (/* binding */ wrapAudioScheduledSourceNodeStopMethodNegativeParameters)\n/* harmony export */ });\nconst wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        return (when = 0) => {\n            if (when < 0) {\n                throw new RangeError(\"The parameter can't be negative.\");\n            }\n            stop.call(nativeAudioScheduledSourceNode, when);\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-negative-parameters.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapChannelSplitterNode\": () => (/* binding */ wrapChannelSplitterNode)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst wrapChannelSplitterNode = (channelSplitterNode) => {\n    const channelCount = channelSplitterNode.numberOfOutputs;\n    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.\n    Object.defineProperty(channelSplitterNode, 'channelCount', {\n        get: () => channelCount,\n        set: (value) => {\n            if (value !== channelCount) {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n    // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.\n    Object.defineProperty(channelSplitterNode, 'channelCountMode', {\n        get: () => 'explicit',\n        set: (value) => {\n            if (value !== 'explicit') {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n    // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.\n    Object.defineProperty(channelSplitterNode, 'channelInterpretation', {\n        get: () => 'discrete',\n        set: (value) => {\n            if (value !== 'discrete') {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n};\n//# sourceMappingURL=wrap-channel-splitter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapEventListener\": () => (/* binding */ wrapEventListener)\n/* harmony export */ });\nconst wrapEventListener = (target, eventListener) => {\n    return (event) => {\n        const descriptor = { value: target };\n        Object.defineProperties(event, {\n            currentTarget: descriptor,\n            target: descriptor\n        });\n        if (typeof eventListener === 'function') {\n            return eventListener.call(target, event);\n        }\n        return eventListener.handleEvent.call(target, event);\n    };\n};\n//# sourceMappingURL=wrap-event-listener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapIIRFilterNodeGetFrequencyResponseMethod\": () => (/* binding */ wrapIIRFilterNodeGetFrequencyResponseMethod)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-access-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js\");\n\nconst wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode) => {\n    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse) => {\n        return (frequencyHz, magResponse, phaseResponse) => {\n            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                throw (0,_factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidAccessError)();\n            }\n            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);\n        };\n    })(nativeIIRFilterNode.getFrequencyResponse);\n};\n//# sourceMappingURL=wrap-iir-filter-node-get-frequency-response-method.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-descriptor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-scheduled-source-node-event-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-scheduled-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-event-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-processor-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-processor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=automation.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=common-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=common-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/index.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/index.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _analyser_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./analyser-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js\");\n/* harmony import */ var _analyser_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./analyser-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js\");\n/* harmony import */ var _audio_buffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js\");\n/* harmony import */ var _audio_buffer_options__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./audio-buffer-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js\");\n/* harmony import */ var _audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js\");\n/* harmony import */ var _audio_buffer_source_options__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./audio-buffer-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js\");\n/* harmony import */ var _audio_context__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js\");\n/* harmony import */ var _audio_context_options__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./audio-context-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js\");\n/* harmony import */ var _audio_destination_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js\");\n/* harmony import */ var _audio_listener__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./audio-listener */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js\");\n/* harmony import */ var _audio_node__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./audio-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js\");\n/* harmony import */ var _audio_node_options__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js\");\n/* harmony import */ var _audio_node_renderer__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js\");\n/* harmony import */ var _audio_param__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./audio-param */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js\");\n/* harmony import */ var _audio_param_descriptor__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./audio-param-descriptor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js\");\n/* harmony import */ var _audio_param_renderer__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js\");\n/* harmony import */ var _audio_scheduled_source_node__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./audio-scheduled-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js\");\n/* harmony import */ var _audio_scheduled_source_node_event_map__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./audio-scheduled-source-node-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js\");\n/* harmony import */ var _audio_worklet__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./audio-worklet */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js\");\n/* harmony import */ var _audio_worklet_node__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js\");\n/* harmony import */ var _audio_worklet_node_event_map__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./audio-worklet-node-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js\");\n/* harmony import */ var _audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js\");\n/* harmony import */ var _audio_worklet_processor__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js\");\n/* harmony import */ var _audio_worklet_processor_constructor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./audio-worklet-processor-constructor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js\");\n/* harmony import */ var _automation__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./automation */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js\");\n/* harmony import */ var _base_audio_context__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./base-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js\");\n/* harmony import */ var _biquad_filter_node__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js\");\n/* harmony import */ var _biquad_filter_options__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./biquad-filter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js\");\n/* harmony import */ var _channel_merger_options__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./channel-merger-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js\");\n/* harmony import */ var _channel_splitter_options__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./channel-splitter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js\");\n/* harmony import */ var _common_audio_context__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./common-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js\");\n/* harmony import */ var _common_offline_audio_context__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./common-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js\");\n/* harmony import */ var _constant_source_node__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js\");\n/* harmony import */ var _constant_source_node_renderer__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./constant-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js\");\n/* harmony import */ var _constant_source_options__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./constant-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js\");\n/* harmony import */ var _convolver_node__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./convolver-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js\");\n/* harmony import */ var _convolver_options__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./convolver-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js\");\n/* harmony import */ var _delay_node__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./delay-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js\");\n/* harmony import */ var _delay_options__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./delay-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js\");\n/* harmony import */ var _dynamics_compressor_node__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./dynamics-compressor-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js\");\n/* harmony import */ var _dynamics_compressor_options__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./dynamics-compressor-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js\");\n/* harmony import */ var _event_target__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./event-target */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js\");\n/* harmony import */ var _gain_node__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./gain-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js\");\n/* harmony import */ var _gain_options__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./gain-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js\");\n/* harmony import */ var _iir_filter_node__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./iir-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js\");\n/* harmony import */ var _iir_filter_options__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./iir-filter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js\");\n/* harmony import */ var _media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js\");\n/* harmony import */ var _media_element_audio_source_options__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./media-element-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js\");\n/* harmony import */ var _media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js\");\n/* harmony import */ var _media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js\");\n/* harmony import */ var _media_stream_audio_source_options__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./media-stream-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js\");\n/* harmony import */ var _media_stream_track_audio_source_node__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./media-stream-track-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js\");\n/* harmony import */ var _media_stream_track_audio_source_options__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./media-stream-track-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js\");\n/* harmony import */ var _minimal_audio_context__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./minimal-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js\");\n/* harmony import */ var _minimal_base_audio_context__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./minimal-base-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js\");\n/* harmony import */ var _minimal_base_audio_context_event_map__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./minimal-base-audio-context-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js\");\n/* harmony import */ var _minimal_offline_audio_context__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./minimal-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js\");\n/* harmony import */ var _native_audio_node_faker__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js\");\n/* harmony import */ var _native_audio_worklet_node_faker__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./native-audio-worklet-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js\");\n/* harmony import */ var _native_constant_source_node_faker__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./native-constant-source-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js\");\n/* harmony import */ var _native_convolver_node_faker__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./native-convolver-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js\");\n/* harmony import */ var _native_iir_filter_node_faker__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./native-iir-filter-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js\");\n/* harmony import */ var _native_panner_node_faker__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./native-panner-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js\");\n/* harmony import */ var _native_stereo_panner_node_faker__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./native-stereo-panner-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js\");\n/* harmony import */ var _native_wave_shaper_node_faker__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./native-wave-shaper-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js\");\n/* harmony import */ var _offline_audio_completion_event__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./offline-audio-completion-event */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js\");\n/* harmony import */ var _offline_audio_context__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js\");\n/* harmony import */ var _offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js\");\n/* harmony import */ var _offline_audio_context_options__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./offline-audio-context-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js\");\n/* harmony import */ var _oscillator_node__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js\");\n/* harmony import */ var _oscillator_node_renderer__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./oscillator-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js\");\n/* harmony import */ var _oscillator_options__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./oscillator-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js\");\n/* harmony import */ var _panner_node__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./panner-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js\");\n/* harmony import */ var _panner_options__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./panner-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js\");\n/* harmony import */ var _periodic_wave__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./periodic-wave */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js\");\n/* harmony import */ var _periodic_wave_constraints__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./periodic-wave-constraints */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js\");\n/* harmony import */ var _periodic_wave_options__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./periodic-wave-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js\");\n/* harmony import */ var _stereo_panner_node__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js\");\n/* harmony import */ var _stereo_panner_options__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./stereo-panner-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js\");\n/* harmony import */ var _wave_shaper_node__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./wave-shaper-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js\");\n/* harmony import */ var _wave_shaper_options__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./wave-shaper-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js\");\n/* harmony import */ var _worklet_options__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./worklet-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/index.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-event-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-completion-event.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constraints.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=read-only-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// @todo This is currently named IWorkletOptions and not IAudioWorkletOptions because it defines the options of a generic Worklet.\n\n//# sourceMappingURL=worklet-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/module.js":
/*!************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/module.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AnalyserNode\": () => (/* binding */ analyserNodeConstructor),\n/* harmony export */   \"AudioBuffer\": () => (/* binding */ audioBufferConstructor),\n/* harmony export */   \"AudioBufferSourceNode\": () => (/* binding */ audioBufferSourceNodeConstructor),\n/* harmony export */   \"AudioContext\": () => (/* binding */ audioContextConstructor),\n/* harmony export */   \"AudioWorkletNode\": () => (/* binding */ audioWorkletNodeConstructor),\n/* harmony export */   \"BiquadFilterNode\": () => (/* binding */ biquadFilterNodeConstructor),\n/* harmony export */   \"ChannelMergerNode\": () => (/* binding */ channelMergerNodeConstructor),\n/* harmony export */   \"ChannelSplitterNode\": () => (/* binding */ channelSplitterNodeConstructor),\n/* harmony export */   \"ConstantSourceNode\": () => (/* binding */ constantSourceNodeConstructor),\n/* harmony export */   \"ConvolverNode\": () => (/* binding */ convolverNodeConstructor),\n/* harmony export */   \"DelayNode\": () => (/* binding */ delayNodeConstructor),\n/* harmony export */   \"DynamicsCompressorNode\": () => (/* binding */ dynamicsCompressorNodeConstructor),\n/* harmony export */   \"GainNode\": () => (/* binding */ gainNodeConstructor),\n/* harmony export */   \"IIRFilterNode\": () => (/* binding */ iIRFilterNodeConstructor),\n/* harmony export */   \"MediaElementAudioSourceNode\": () => (/* binding */ mediaElementAudioSourceNodeConstructor),\n/* harmony export */   \"MediaStreamAudioDestinationNode\": () => (/* binding */ mediaStreamAudioDestinationNodeConstructor),\n/* harmony export */   \"MediaStreamAudioSourceNode\": () => (/* binding */ mediaStreamAudioSourceNodeConstructor),\n/* harmony export */   \"MediaStreamTrackAudioSourceNode\": () => (/* binding */ mediaStreamTrackAudioSourceNodeConstructor),\n/* harmony export */   \"MinimalAudioContext\": () => (/* binding */ minimalAudioContextConstructor),\n/* harmony export */   \"MinimalOfflineAudioContext\": () => (/* binding */ minimalOfflineAudioContextConstructor),\n/* harmony export */   \"OfflineAudioContext\": () => (/* binding */ offlineAudioContextConstructor),\n/* harmony export */   \"OscillatorNode\": () => (/* binding */ oscillatorNodeConstructor),\n/* harmony export */   \"PannerNode\": () => (/* binding */ pannerNodeConstructor),\n/* harmony export */   \"PeriodicWave\": () => (/* binding */ periodicWaveConstructor),\n/* harmony export */   \"StereoPannerNode\": () => (/* binding */ stereoPannerNodeConstructor),\n/* harmony export */   \"WaveShaperNode\": () => (/* binding */ waveShaperNodeConstructor),\n/* harmony export */   \"addAudioWorkletModule\": () => (/* binding */ addAudioWorkletModule),\n/* harmony export */   \"decodeAudioData\": () => (/* binding */ decodeAudioData),\n/* harmony export */   \"isAnyAudioContext\": () => (/* binding */ isAnyAudioContext),\n/* harmony export */   \"isAnyAudioNode\": () => (/* binding */ isAnyAudioNode),\n/* harmony export */   \"isAnyAudioParam\": () => (/* binding */ isAnyAudioParam),\n/* harmony export */   \"isAnyOfflineAudioContext\": () => (/* binding */ isAnyOfflineAudioContext),\n/* harmony export */   \"isSupported\": () => (/* binding */ isSupported)\n/* harmony export */ });\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! automation-events */ \"./node_modules/automation-events/build/es5/bundle.js\");\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(automation_events__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _factories_abort_error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./factories/abort-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js\");\n/* harmony import */ var _factories_add_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./factories/add-active-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./factories/add-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js\");\n/* harmony import */ var _factories_add_audio_param_connections__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./factories/add-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js\");\n/* harmony import */ var _factories_add_audio_worklet_module__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./factories/add-audio-worklet-module */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js\");\n/* harmony import */ var _factories_add_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./factories/add-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./factories/add-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_silent_connection__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./factories/add-silent-connection */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js\");\n/* harmony import */ var _factories_add_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./factories/add-unrendered-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js\");\n/* harmony import */ var _factories_analyser_node_constructor__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./factories/analyser-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js\");\n/* harmony import */ var _factories_analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./factories/analyser-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./factories/audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js\");\n/* harmony import */ var _factories_audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./factories/audio-buffer-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js\");\n/* harmony import */ var _factories_audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./factories/audio-buffer-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_context_constructor__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./factories/audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js\");\n/* harmony import */ var _factories_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./factories/audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js\");\n/* harmony import */ var _factories_audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./factories/audio-destination-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_listener_factory__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./factories/audio-listener-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js\");\n/* harmony import */ var _factories_audio_node_constructor__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./factories/audio-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js\");\n/* harmony import */ var _factories_audio_param_factory__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./factories/audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js\");\n/* harmony import */ var _factories_audio_param_renderer__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./factories/audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js\");\n/* harmony import */ var _factories_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./factories/audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js\");\n/* harmony import */ var _factories_audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./factories/audio-worklet-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js\");\n/* harmony import */ var _factories_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./factories/base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js\");\n/* harmony import */ var _factories_biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./factories/biquad-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js\");\n/* harmony import */ var _factories_biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./factories/biquad-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js\");\n/* harmony import */ var _factories_cache_test_result__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./factories/cache-test-result */ \"./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js\");\n/* harmony import */ var _factories_channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./factories/channel-merger-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js\");\n/* harmony import */ var _factories_channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./factories/channel-merger-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js\");\n/* harmony import */ var _factories_channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./factories/channel-splitter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js\");\n/* harmony import */ var _factories_channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./factories/channel-splitter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js\");\n/* harmony import */ var _factories_connect_audio_param__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./factories/connect-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js\");\n/* harmony import */ var _factories_connect_multiple_outputs__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./factories/connect-multiple-outputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js\");\n/* harmony import */ var _factories_connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./factories/connected-native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _factories_constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./factories/constant-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js\");\n/* harmony import */ var _factories_constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./factories/constant-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js\");\n/* harmony import */ var _factories_convert_number_to_unsigned_long__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./factories/convert-number-to-unsigned-long */ \"./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js\");\n/* harmony import */ var _factories_convolver_node_constructor__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./factories/convolver-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js\");\n/* harmony import */ var _factories_convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./factories/convolver-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js\");\n/* harmony import */ var _factories_create_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./factories/create-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js\");\n/* harmony import */ var _factories_data_clone_error__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./factories/data-clone-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js\");\n/* harmony import */ var _factories_decode_audio_data__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./factories/decode-audio-data */ \"./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js\");\n/* harmony import */ var _factories_decrement_cycle_counter__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./factories/decrement-cycle-counter */ \"./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js\");\n/* harmony import */ var _factories_delay_node_constructor__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./factories/delay-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js\");\n/* harmony import */ var _factories_delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./factories/delay-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js\");\n/* harmony import */ var _factories_delete_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./factories/delete-active-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_delete_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./factories/delete-unrendered-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js\");\n/* harmony import */ var _factories_detect_cycles__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./factories/detect-cycles */ \"./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js\");\n/* harmony import */ var _factories_disconnect_multiple_outputs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./factories/disconnect-multiple-outputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js\");\n/* harmony import */ var _factories_dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./factories/dynamics-compressor-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js\");\n/* harmony import */ var _factories_dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./factories/dynamics-compressor-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js\");\n/* harmony import */ var _factories_encoding_error__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./factories/encoding-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js\");\n/* harmony import */ var _factories_evaluate_source__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./factories/evaluate-source */ \"./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js\");\n/* harmony import */ var _factories_event_target_constructor__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./factories/event-target-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js\");\n/* harmony import */ var _factories_expose_current_frame_and_current_time__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./factories/expose-current-frame-and-current-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js\");\n/* harmony import */ var _factories_fetch_source__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./factories/fetch-source */ \"./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js\");\n/* harmony import */ var _factories_gain_node_constructor__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./factories/gain-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js\");\n/* harmony import */ var _factories_gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./factories/gain-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js\");\n/* harmony import */ var _factories_get_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./factories/get-active-audio-worklet-node-inputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js\");\n/* harmony import */ var _factories_get_audio_node_renderer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./factories/get-audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js\");\n/* harmony import */ var _factories_get_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./factories/get-audio-node-tail-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js\");\n/* harmony import */ var _factories_get_audio_param_renderer__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./factories/get-audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js\");\n/* harmony import */ var _factories_get_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./factories/get-backup-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js\");\n/* harmony import */ var _factories_get_native_context__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./factories/get-native-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js\");\n/* harmony import */ var _factories_get_or_create_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./factories/get-or-create-backup-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js\");\n/* harmony import */ var _factories_get_unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./factories/get-unrendered-audio-worklet-nodes */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js\");\n/* harmony import */ var _factories_iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./factories/iir-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js\");\n/* harmony import */ var _factories_iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./factories/iir-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js\");\n/* harmony import */ var _factories_increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./factories/increment-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js\");\n/* harmony import */ var _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./factories/index-size-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js\");\n/* harmony import */ var _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./factories/invalid-access-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js\");\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n/* harmony import */ var _factories_is_any_audio_context__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./factories/is-any-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js\");\n/* harmony import */ var _factories_is_any_audio_node__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./factories/is-any-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js\");\n/* harmony import */ var _factories_is_any_audio_param__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./factories/is-any-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js\");\n/* harmony import */ var _factories_is_any_offline_audio_context__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./factories/is-any-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js\");\n/* harmony import */ var _factories_is_native_audio_context__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./factories/is-native-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js\");\n/* harmony import */ var _factories_is_native_audio_node__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./factories/is-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js\");\n/* harmony import */ var _factories_is_native_audio_param__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./factories/is-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js\");\n/* harmony import */ var _factories_is_native_context__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./factories/is-native-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js\");\n/* harmony import */ var _factories_is_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./factories/is-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js\");\n/* harmony import */ var _factories_is_secure_context__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./factories/is-secure-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js\");\n/* harmony import */ var _factories_is_supported_promise__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./factories/is-supported-promise */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js\");\n/* harmony import */ var _factories_media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./factories/media-element-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./factories/media-stream-audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./factories/media-stream-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./factories/media-stream-track-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./factories/minimal-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js\");\n/* harmony import */ var _factories_minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./factories/minimal-base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js\");\n/* harmony import */ var _factories_minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./factories/minimal-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_monitor_connections__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./factories/monitor-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js\");\n/* harmony import */ var _factories_native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./factories/native-analyser-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js\");\n/* harmony import */ var _factories_native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./factories/native-audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js\");\n/* harmony import */ var _factories_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./factories/native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _factories_native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./factories/native-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js\");\n/* harmony import */ var _factories_native_audio_destination_node__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./factories/native-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_97__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_98__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_99__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js\");\n/* harmony import */ var _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__ = __webpack_require__(/*! ./factories/native-biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js\");\n/* harmony import */ var _factories_native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_101__ = __webpack_require__(/*! ./factories/native-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js\");\n/* harmony import */ var _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__ = __webpack_require__(/*! ./factories/native-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js\");\n/* harmony import */ var _factories_native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_103__ = __webpack_require__(/*! ./factories/native-constant-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js\");\n/* harmony import */ var _factories_native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_104__ = __webpack_require__(/*! ./factories/native-constant-source-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js\");\n/* harmony import */ var _factories_native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_105__ = __webpack_require__(/*! ./factories/native-convolver-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js\");\n/* harmony import */ var _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__ = __webpack_require__(/*! ./factories/native-delay-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js\");\n/* harmony import */ var _factories_native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_107__ = __webpack_require__(/*! ./factories/native-dynamics-compressor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js\");\n/* harmony import */ var _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__ = __webpack_require__(/*! ./factories/native-gain-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js\");\n/* harmony import */ var _factories_native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_109__ = __webpack_require__(/*! ./factories/native-iir-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js\");\n/* harmony import */ var _factories_native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_110__ = __webpack_require__(/*! ./factories/native-iir-filter-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js\");\n/* harmony import */ var _factories_native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_111__ = __webpack_require__(/*! ./factories/native-media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js\");\n/* harmony import */ var _factories_native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_112__ = __webpack_require__(/*! ./factories/native-media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js\");\n/* harmony import */ var _factories_native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_113__ = __webpack_require__(/*! ./factories/native-media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js\");\n/* harmony import */ var _factories_native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_114__ = __webpack_require__(/*! ./factories/native-media-stream-track-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js\");\n/* harmony import */ var _factories_native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_115__ = __webpack_require__(/*! ./factories/native-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_116__ = __webpack_require__(/*! ./factories/native-oscillator-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js\");\n/* harmony import */ var _factories_native_panner_node_factory__WEBPACK_IMPORTED_MODULE_117__ = __webpack_require__(/*! ./factories/native-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js\");\n/* harmony import */ var _factories_native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_118__ = __webpack_require__(/*! ./factories/native-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js\");\n/* harmony import */ var _factories_native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_119__ = __webpack_require__(/*! ./factories/native-periodic-wave-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js\");\n/* harmony import */ var _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__ = __webpack_require__(/*! ./factories/native-script-processor-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js\");\n/* harmony import */ var _factories_native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_121__ = __webpack_require__(/*! ./factories/native-stereo-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js\");\n/* harmony import */ var _factories_native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_122__ = __webpack_require__(/*! ./factories/native-stereo-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js\");\n/* harmony import */ var _factories_native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_123__ = __webpack_require__(/*! ./factories/native-wave-shaper-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js\");\n/* harmony import */ var _factories_native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_124__ = __webpack_require__(/*! ./factories/native-wave-shaper-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js\");\n/* harmony import */ var _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__ = __webpack_require__(/*! ./factories/not-supported-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js\");\n/* harmony import */ var _factories_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_126__ = __webpack_require__(/*! ./factories/offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_127__ = __webpack_require__(/*! ./factories/oscillator-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js\");\n/* harmony import */ var _factories_oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_128__ = __webpack_require__(/*! ./factories/oscillator-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js\");\n/* harmony import */ var _factories_panner_node_constructor__WEBPACK_IMPORTED_MODULE_129__ = __webpack_require__(/*! ./factories/panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js\");\n/* harmony import */ var _factories_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__ = __webpack_require__(/*! ./factories/panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js\");\n/* harmony import */ var _factories_periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_131__ = __webpack_require__(/*! ./factories/periodic-wave-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js\");\n/* harmony import */ var _factories_render_automation__WEBPACK_IMPORTED_MODULE_132__ = __webpack_require__(/*! ./factories/render-automation */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js\");\n/* harmony import */ var _factories_render_inputs_of_audio_node__WEBPACK_IMPORTED_MODULE_133__ = __webpack_require__(/*! ./factories/render-inputs-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js\");\n/* harmony import */ var _factories_render_inputs_of_audio_param__WEBPACK_IMPORTED_MODULE_134__ = __webpack_require__(/*! ./factories/render-inputs-of-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js\");\n/* harmony import */ var _factories_render_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_135__ = __webpack_require__(/*! ./factories/render-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js\");\n/* harmony import */ var _factories_set_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_136__ = __webpack_require__(/*! ./factories/set-active-audio-worklet-node-inputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js\");\n/* harmony import */ var _factories_set_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_137__ = __webpack_require__(/*! ./factories/set-audio-node-tail-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js\");\n/* harmony import */ var _factories_start_rendering__WEBPACK_IMPORTED_MODULE_138__ = __webpack_require__(/*! ./factories/start-rendering */ \"./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js\");\n/* harmony import */ var _factories_stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_139__ = __webpack_require__(/*! ./factories/stereo-panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js\");\n/* harmony import */ var _factories_stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_140__ = __webpack_require__(/*! ./factories/stereo-panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js\");\n/* harmony import */ var _factories_test_audio_buffer_constructor_support__WEBPACK_IMPORTED_MODULE_141__ = __webpack_require__(/*! ./factories/test-audio-buffer-constructor-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js\");\n/* harmony import */ var _factories_test_audio_buffer_copy_channel_methods_subarray_support__WEBPACK_IMPORTED_MODULE_142__ = __webpack_require__(/*! ./factories/test-audio-buffer-copy-channel-methods-subarray-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js\");\n/* harmony import */ var _factories_test_audio_context_close_method_support__WEBPACK_IMPORTED_MODULE_143__ = __webpack_require__(/*! ./factories/test-audio-context-close-method-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js\");\n/* harmony import */ var _factories_test_audio_context_decode_audio_data_method_type_error_support__WEBPACK_IMPORTED_MODULE_144__ = __webpack_require__(/*! ./factories/test-audio-context-decode-audio-data-method-type-error-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js\");\n/* harmony import */ var _factories_test_audio_context_options_support__WEBPACK_IMPORTED_MODULE_145__ = __webpack_require__(/*! ./factories/test-audio-context-options-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js\");\n/* harmony import */ var _factories_test_audio_node_connect_method_support__WEBPACK_IMPORTED_MODULE_146__ = __webpack_require__(/*! ./factories/test-audio-node-connect-method-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js\");\n/* harmony import */ var _factories_test_audio_worklet_processor_no_outputs_support__WEBPACK_IMPORTED_MODULE_147__ = __webpack_require__(/*! ./factories/test-audio-worklet-processor-no-outputs-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js\");\n/* harmony import */ var _factories_test_audio_worklet_processor_post_message_support__WEBPACK_IMPORTED_MODULE_148__ = __webpack_require__(/*! ./factories/test-audio-worklet-processor-post-message-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js\");\n/* harmony import */ var _factories_test_channel_merger_node_channel_count_support__WEBPACK_IMPORTED_MODULE_149__ = __webpack_require__(/*! ./factories/test-channel-merger-node-channel-count-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js\");\n/* harmony import */ var _factories_test_constant_source_node_accurate_scheduling_support__WEBPACK_IMPORTED_MODULE_150__ = __webpack_require__(/*! ./factories/test-constant-source-node-accurate-scheduling-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js\");\n/* harmony import */ var _factories_test_convolver_node_buffer_reassignability_support__WEBPACK_IMPORTED_MODULE_151__ = __webpack_require__(/*! ./factories/test-convolver-node-buffer-reassignability-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js\");\n/* harmony import */ var _factories_test_convolver_node_channel_count_support__WEBPACK_IMPORTED_MODULE_152__ = __webpack_require__(/*! ./factories/test-convolver-node-channel-count-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js\");\n/* harmony import */ var _factories_test_is_secure_context_support__WEBPACK_IMPORTED_MODULE_153__ = __webpack_require__(/*! ./factories/test-is-secure-context-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js\");\n/* harmony import */ var _factories_test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_154__ = __webpack_require__(/*! ./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js\");\n/* harmony import */ var _factories_test_offline_audio_context_current_time_support__WEBPACK_IMPORTED_MODULE_155__ = __webpack_require__(/*! ./factories/test-offline-audio-context-current-time-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js\");\n/* harmony import */ var _factories_test_stereo_panner_node_default_value_support__WEBPACK_IMPORTED_MODULE_156__ = __webpack_require__(/*! ./factories/test-stereo-panner-node-default-value-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js\");\n/* harmony import */ var _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__ = __webpack_require__(/*! ./factories/unknown-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js\");\n/* harmony import */ var _factories_wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_158__ = __webpack_require__(/*! ./factories/wave-shaper-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js\");\n/* harmony import */ var _factories_wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_159__ = __webpack_require__(/*! ./factories/wave-shaper-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js\");\n/* harmony import */ var _factories_window__WEBPACK_IMPORTED_MODULE_160__ = __webpack_require__(/*! ./factories/window */ \"./node_modules/standardized-audio-context/build/es2019/factories/window.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_copy_channel_methods__WEBPACK_IMPORTED_MODULE_161__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-copy-channel-methods */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_copy_channel_methods_out_of_bounds__WEBPACK_IMPORTED_MODULE_162__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_source_node_stop_method_nullified_buffer__WEBPACK_IMPORTED_MODULE_163__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js\");\n/* harmony import */ var _factories_wrap_channel_merger_node__WEBPACK_IMPORTED_MODULE_164__ = __webpack_require__(/*! ./factories/wrap-channel-merger-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js\");\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_165__ = __webpack_require__(/*! ./globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__ = __webpack_require__(/*! ./helpers/connect-native-audio-node-to-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js\");\n/* harmony import */ var _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__ = __webpack_require__(/*! ./helpers/disconnect-native-audio-node-from-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__ = __webpack_require__(/*! ./helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__ = __webpack_require__(/*! ./helpers/get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_170__ = __webpack_require__(/*! ./helpers/get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__ = __webpack_require__(/*! ./helpers/get-first-sample */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js\");\n/* harmony import */ var _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__ = __webpack_require__(/*! ./helpers/get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__ = __webpack_require__(/*! ./helpers/get-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js\");\n/* harmony import */ var _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__ = __webpack_require__(/*! ./helpers/get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__ = __webpack_require__(/*! ./helpers/insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__ = __webpack_require__(/*! ./helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__ = __webpack_require__(/*! ./helpers/is-dc-curve */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js\");\n/* harmony import */ var _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__ = __webpack_require__(/*! ./helpers/is-part-of-a-cycle */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js\");\n/* harmony import */ var _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_179__ = __webpack_require__(/*! ./helpers/is-passive-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js\");\n/* harmony import */ var _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__ = __webpack_require__(/*! ./helpers/overwrite-accessors */ \"./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js\");\n/* harmony import */ var _helpers_pick_element_from_set__WEBPACK_IMPORTED_MODULE_181__ = __webpack_require__(/*! ./helpers/pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n/* harmony import */ var _helpers_sanitize_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_182__ = __webpack_require__(/*! ./helpers/sanitize-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js\");\n/* harmony import */ var _helpers_sanitize_channel_splitter_options__WEBPACK_IMPORTED_MODULE_183__ = __webpack_require__(/*! ./helpers/sanitize-channel-splitter-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js\");\n/* harmony import */ var _helpers_sanitize_periodic_wave_options__WEBPACK_IMPORTED_MODULE_184__ = __webpack_require__(/*! ./helpers/sanitize-periodic-wave-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js\");\n/* harmony import */ var _helpers_set_value_at_time_until_possible__WEBPACK_IMPORTED_MODULE_185__ = __webpack_require__(/*! ./helpers/set-value-at-time-until-possible */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js\");\n/* harmony import */ var _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__ = __webpack_require__(/*! ./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_start_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_187__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_start_method_offset_clamping_support__WEBPACK_IMPORTED_MODULE_188__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_stop_method_nullified_buffer_support__WEBPACK_IMPORTED_MODULE_189__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js\");\n/* harmony import */ var _helpers_test_audio_worklet_node_options_clonability__WEBPACK_IMPORTED_MODULE_193__ = __webpack_require__(/*! ./helpers/test-audio-worklet-node-options-clonability */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js\");\n/* harmony import */ var _helpers_test_dom_exception_constructor_support__WEBPACK_IMPORTED_MODULE_194__ = __webpack_require__(/*! ./helpers/test-dom-exception-constructor-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_195__ = __webpack_require__(/*! ./helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n/* harmony import */ var _helpers_test_transferables_support__WEBPACK_IMPORTED_MODULE_196__ = __webpack_require__(/*! ./helpers/test-transferables-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_source_node_start_method_offset_clamping__WEBPACK_IMPORTED_MODULE_197__ = __webpack_require__(/*! ./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__ = __webpack_require__(/*! ./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js\");\n/* harmony import */ var _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__ = __webpack_require__(/*! ./helpers/wrap-event-listener */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js\");\n/* harmony import */ var _interfaces_index__WEBPACK_IMPORTED_MODULE_200__ = __webpack_require__(/*! ./interfaces/index */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/index.js\");\n/* harmony import */ var _types_index__WEBPACK_IMPORTED_MODULE_201__ = __webpack_require__(/*! ./types/index */ \"./node_modules/standardized-audio-context/build/es2019/types/index.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*\n * @todo Explicitly referencing the barrel file seems to be necessary when enabling the\n * isolatedModules compiler option.\n */\n\n\nconst addActiveInputConnectionToAudioNode = (0,_factories_add_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_2__.createAddActiveInputConnectionToAudioNode)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet);\nconst addPassiveInputConnectionToAudioNode = (0,_factories_add_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_7__.createAddPassiveInputConnectionToAudioNode)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet);\nconst deleteActiveInputConnectionToAudioNode = (0,_factories_delete_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_46__.createDeleteActiveInputConnectionToAudioNode)(_helpers_pick_element_from_set__WEBPACK_IMPORTED_MODULE_181__.pickElementFromSet);\nconst audioNodeTailTimeStore = new WeakMap();\nconst getAudioNodeTailTime = (0,_factories_get_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_61__.createGetAudioNodeTailTime)(audioNodeTailTimeStore);\nconst cacheTestResult = (0,_factories_cache_test_result__WEBPACK_IMPORTED_MODULE_27__.createCacheTestResult)(new Map(), new WeakMap());\nconst window = (0,_factories_window__WEBPACK_IMPORTED_MODULE_160__.createWindow)();\nconst createNativeAnalyserNode = (0,_factories_native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_92__.createNativeAnalyserNodeFactory)(cacheTestResult, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst getAudioNodeRenderer = (0,_factories_get_audio_node_renderer__WEBPACK_IMPORTED_MODULE_60__.createGetAudioNodeRenderer)(_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections);\nconst renderInputsOfAudioNode = (0,_factories_render_inputs_of_audio_node__WEBPACK_IMPORTED_MODULE_133__.createRenderInputsOfAudioNode)(_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getAudioNodeRenderer, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle);\nconst createAnalyserNodeRenderer = (0,_factories_analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_11__.createAnalyserNodeRendererFactory)(createNativeAnalyserNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst getNativeContext = (0,_factories_get_native_context__WEBPACK_IMPORTED_MODULE_64__.createGetNativeContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE);\nconst nativeOfflineAudioContextConstructor = (0,_factories_native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_115__.createNativeOfflineAudioContextConstructor)(window);\nconst isNativeOfflineAudioContext = (0,_factories_is_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_81__.createIsNativeOfflineAudioContext)(nativeOfflineAudioContextConstructor);\nconst audioParamAudioNodeStore = new WeakMap();\nconst eventTargetConstructor = (0,_factories_event_target_constructor__WEBPACK_IMPORTED_MODULE_54__.createEventTargetConstructor)(_helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst nativeAudioContextConstructor = (0,_factories_native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_95__.createNativeAudioContextConstructor)(window);\nconst isNativeAudioContext = (0,_factories_is_native_audio_context__WEBPACK_IMPORTED_MODULE_77__.createIsNativeAudioContext)(nativeAudioContextConstructor);\nconst isNativeAudioNode = (0,_factories_is_native_audio_node__WEBPACK_IMPORTED_MODULE_78__.createIsNativeAudioNode)(window);\nconst isNativeAudioParam = (0,_factories_is_native_audio_param__WEBPACK_IMPORTED_MODULE_79__.createIsNativeAudioParam)(window);\nconst nativeAudioWorkletNodeConstructor = (0,_factories_native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_97__.createNativeAudioWorkletNodeConstructor)(window);\nconst audioNodeConstructor = (0,_factories_audio_node_constructor__WEBPACK_IMPORTED_MODULE_19__.createAudioNodeConstructor)((0,_factories_add_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__.createAddAudioNodeConnections)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_NODE_CONNECTIONS_STORE), (0,_factories_add_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_6__.createAddConnectionToAudioNode)(addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getAudioNodeTailTime, _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_170__.getEventListenersOfAudioNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle, _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_179__.isPassiveAudioNode), cacheTestResult, (0,_factories_increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_69__.createIncrementCycleCounterFactory)(_globals__WEBPACK_IMPORTED_MODULE_165__.CYCLE_COUNTERS, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__.getNativeAudioParam, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode), _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, (0,_factories_decrement_cycle_counter__WEBPACK_IMPORTED_MODULE_43__.createDecrementCycleCounter)(_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, _globals__WEBPACK_IMPORTED_MODULE_165__.CYCLE_COUNTERS, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__.getNativeAudioParam, getNativeContext, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode, isNativeOfflineAudioContext), (0,_factories_detect_cycles__WEBPACK_IMPORTED_MODULE_48__.createDetectCycles)(audioParamAudioNodeStore, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__.getValueForKey), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor);\nconst analyserNodeConstructor = (0,_factories_analyser_node_constructor__WEBPACK_IMPORTED_MODULE_10__.createAnalyserNodeConstructor)(audioNodeConstructor, createAnalyserNodeRenderer, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);\n\nconst audioBufferStore = new WeakSet();\nconst nativeAudioBufferConstructor = (0,_factories_native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_93__.createNativeAudioBufferConstructor)(window);\nconst convertNumberToUnsignedLong = (0,_factories_convert_number_to_unsigned_long__WEBPACK_IMPORTED_MODULE_37__.createConvertNumberToUnsignedLong)(new Uint32Array(1));\nconst wrapAudioBufferCopyChannelMethods = (0,_factories_wrap_audio_buffer_copy_channel_methods__WEBPACK_IMPORTED_MODULE_161__.createWrapAudioBufferCopyChannelMethods)(convertNumberToUnsignedLong, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst wrapAudioBufferCopyChannelMethodsOutOfBounds = (0,_factories_wrap_audio_buffer_copy_channel_methods_out_of_bounds__WEBPACK_IMPORTED_MODULE_162__.createWrapAudioBufferCopyChannelMethodsOutOfBounds)(convertNumberToUnsignedLong);\nconst audioBufferConstructor = (0,_factories_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_12__.createAudioBufferConstructor)(audioBufferStore, cacheTestResult, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, (0,_factories_test_audio_buffer_constructor_support__WEBPACK_IMPORTED_MODULE_141__.createTestAudioBufferConstructorSupport)(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\n\nconst addSilentConnection = (0,_factories_add_silent_connection__WEBPACK_IMPORTED_MODULE_8__.createAddSilentConnection)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode);\nconst renderInputsOfAudioParam = (0,_factories_render_inputs_of_audio_param__WEBPACK_IMPORTED_MODULE_134__.createRenderInputsOfAudioParam)(getAudioNodeRenderer, _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__.getAudioParamConnections, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle);\nconst connectAudioParam = (0,_factories_connect_audio_param__WEBPACK_IMPORTED_MODULE_32__.createConnectAudioParam)(renderInputsOfAudioParam);\nconst createNativeAudioBufferSourceNode = (0,_factories_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_94__.createNativeAudioBufferSourceNodeFactory)(addSilentConnection, cacheTestResult, _helpers_test_audio_buffer_source_node_start_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_187__.testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, _helpers_test_audio_buffer_source_node_start_method_offset_clamping_support__WEBPACK_IMPORTED_MODULE_188__.testAudioBufferSourceNodeStartMethodOffsetClampingSupport, _helpers_test_audio_buffer_source_node_stop_method_nullified_buffer_support__WEBPACK_IMPORTED_MODULE_189__.testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _helpers_wrap_audio_buffer_source_node_start_method_offset_clamping__WEBPACK_IMPORTED_MODULE_197__.wrapAudioBufferSourceNodeStartMethodOffsetClamping, (0,_factories_wrap_audio_buffer_source_node_stop_method_nullified_buffer__WEBPACK_IMPORTED_MODULE_163__.createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer)(_helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors), _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst renderAutomation = (0,_factories_render_automation__WEBPACK_IMPORTED_MODULE_132__.createRenderAutomation)((0,_factories_get_audio_param_renderer__WEBPACK_IMPORTED_MODULE_62__.createGetAudioParamRenderer)(_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__.getAudioParamConnections), renderInputsOfAudioParam);\nconst createAudioBufferSourceNodeRenderer = (0,_factories_audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_14__.createAudioBufferSourceNodeRendererFactory)(connectAudioParam, createNativeAudioBufferSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst createAudioParam = (0,_factories_audio_param_factory__WEBPACK_IMPORTED_MODULE_20__.createAudioParamFactory)((0,_factories_add_audio_param_connections__WEBPACK_IMPORTED_MODULE_4__.createAddAudioParamConnections)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_CONNECTIONS_STORE), audioParamAudioNodeStore, _globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_STORE, _factories_audio_param_renderer__WEBPACK_IMPORTED_MODULE_21__.createAudioParamRenderer, automation_events__WEBPACK_IMPORTED_MODULE_0__.createCancelAndHoldAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createCancelScheduledValuesAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createExponentialRampToValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createLinearRampToValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetTargetAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetValueCurveAutomationEvent, nativeAudioContextConstructor, _helpers_set_value_at_time_until_possible__WEBPACK_IMPORTED_MODULE_185__.setValueAtTimeUntilPossible);\nconst audioBufferSourceNodeConstructor = (0,_factories_audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_13__.createAudioBufferSourceNodeConstructor)(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\n\nconst audioDestinationNodeConstructor = (0,_factories_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_16__.createAudioDestinationNodeConstructor)(audioNodeConstructor, _factories_audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_17__.createAudioDestinationNodeRenderer, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, (0,_factories_native_audio_destination_node__WEBPACK_IMPORTED_MODULE_96__.createNativeAudioDestinationNodeFactory)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);\nconst createBiquadFilterNodeRenderer = (0,_factories_biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_26__.createBiquadFilterNodeRendererFactory)(connectAudioParam, _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__.createNativeBiquadFilterNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst setAudioNodeTailTime = (0,_factories_set_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_137__.createSetAudioNodeTailTime)(audioNodeTailTimeStore);\nconst biquadFilterNodeConstructor = (0,_factories_biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_25__.createBiquadFilterNodeConstructor)(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__.createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst monitorConnections = (0,_factories_monitor_connections__WEBPACK_IMPORTED_MODULE_91__.createMonitorConnections)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet, isNativeAudioNode);\nconst wrapChannelMergerNode = (0,_factories_wrap_channel_merger_node__WEBPACK_IMPORTED_MODULE_164__.createWrapChannelMergerNode)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, monitorConnections);\nconst createNativeChannelMergerNode = (0,_factories_native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_101__.createNativeChannelMergerNodeFactory)(nativeAudioContextConstructor, wrapChannelMergerNode);\nconst createChannelMergerNodeRenderer = (0,_factories_channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_29__.createChannelMergerNodeRendererFactory)(createNativeChannelMergerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst channelMergerNodeConstructor = (0,_factories_channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_28__.createChannelMergerNodeConstructor)(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);\nconst createChannelSplitterNodeRenderer = (0,_factories_channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_31__.createChannelSplitterNodeRendererFactory)(_factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst channelSplitterNodeConstructor = (0,_factories_channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_30__.createChannelSplitterNodeConstructor)(audioNodeConstructor, createChannelSplitterNodeRenderer, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, _helpers_sanitize_channel_splitter_options__WEBPACK_IMPORTED_MODULE_183__.sanitizeChannelSplitterOptions);\nconst createNativeConstantSourceNodeFaker = (0,_factories_native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_104__.createNativeConstantSourceNodeFakerFactory)(addSilentConnection, createNativeAudioBufferSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, monitorConnections);\nconst createNativeConstantSourceNode = (0,_factories_native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_103__.createNativeConstantSourceNodeFactory)(addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);\nconst createConstantSourceNodeRenderer = (0,_factories_constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_36__.createConstantSourceNodeRendererFactory)(connectAudioParam, createNativeConstantSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst constantSourceNodeConstructor = (0,_factories_constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_35__.createConstantSourceNodeConstructor)(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createNativeConvolverNode = (0,_factories_native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_105__.createNativeConvolverNodeFactory)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst createConvolverNodeRenderer = (0,_factories_convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__.createConvolverNodeRendererFactory)(createNativeConvolverNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst convolverNodeConstructor = (0,_factories_convolver_node_constructor__WEBPACK_IMPORTED_MODULE_38__.createConvolverNodeConstructor)(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createDelayNodeRenderer = (0,_factories_delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_45__.createDelayNodeRendererFactory)(connectAudioParam, _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__.createNativeDelayNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst delayNodeConstructor = (0,_factories_delay_node_constructor__WEBPACK_IMPORTED_MODULE_44__.createDelayNodeConstructor)(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__.createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createNativeDynamicsCompressorNode = (0,_factories_native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_107__.createNativeDynamicsCompressorNodeFactory)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst createDynamicsCompressorNodeRenderer = (0,_factories_dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_51__.createDynamicsCompressorNodeRendererFactory)(connectAudioParam, createNativeDynamicsCompressorNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst dynamicsCompressorNodeConstructor = (0,_factories_dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_50__.createDynamicsCompressorNodeConstructor)(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createGainNodeRenderer = (0,_factories_gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_58__.createGainNodeRendererFactory)(connectAudioParam, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst gainNodeConstructor = (0,_factories_gain_node_constructor__WEBPACK_IMPORTED_MODULE_57__.createGainNodeConstructor)(audioNodeConstructor, createAudioParam, createGainNodeRenderer, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeIIRFilterNodeFaker = (0,_factories_native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_110__.createNativeIIRFilterNodeFakerFactory)(_factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst renderNativeOfflineAudioContext = (0,_factories_render_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_135__.createRenderNativeOfflineAudioContext)(cacheTestResult, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, (0,_factories_test_offline_audio_context_current_time_support__WEBPACK_IMPORTED_MODULE_155__.createTestOfflineAudioContextCurrentTimeSupport)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, nativeOfflineAudioContextConstructor));\nconst createIIRFilterNodeRenderer = (0,_factories_iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__.createIIRFilterNodeRendererFactory)(createNativeAudioBufferSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst createNativeIIRFilterNode = (0,_factories_native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_109__.createNativeIIRFilterNodeFactory)(createNativeIIRFilterNodeFaker);\nconst iIRFilterNodeConstructor = (0,_factories_iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_67__.createIIRFilterNodeConstructor)(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createAudioListener = (0,_factories_audio_listener_factory__WEBPACK_IMPORTED_MODULE_18__.createAudioListenerFactory)(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__.getFirstSample, isNativeOfflineAudioContext, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst unrenderedAudioWorkletNodeStore = new WeakMap();\nconst minimalBaseAudioContextConstructor = (0,_factories_minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_89__.createMinimalBaseAudioContextConstructor)(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createNativeOscillatorNode = (0,_factories_native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_116__.createNativeOscillatorNodeFactory)(addSilentConnection, cacheTestResult, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst createOscillatorNodeRenderer = (0,_factories_oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_128__.createOscillatorNodeRendererFactory)(connectAudioParam, createNativeOscillatorNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst oscillatorNodeConstructor = (0,_factories_oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_127__.createOscillatorNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createConnectedNativeAudioBufferSourceNode = (0,_factories_connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_34__.createConnectedNativeAudioBufferSourceNodeFactory)(createNativeAudioBufferSourceNode);\nconst createNativeWaveShaperNodeFaker = (0,_factories_native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_124__.createNativeWaveShaperNodeFakerFactory)(createConnectedNativeAudioBufferSourceNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__.isDCCurve, monitorConnections);\nconst createNativeWaveShaperNode = (0,_factories_native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_123__.createNativeWaveShaperNodeFactory)(createConnectedNativeAudioBufferSourceNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeWaveShaperNodeFaker, _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__.isDCCurve, monitorConnections, nativeAudioContextConstructor, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst createNativePannerNodeFaker = (0,_factories_native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_118__.createNativePannerNodeFakerFactory)(_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeChannelMergerNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, createNativeWaveShaperNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__.getFirstSample, monitorConnections);\nconst createNativePannerNode = (0,_factories_native_panner_node_factory__WEBPACK_IMPORTED_MODULE_117__.createNativePannerNodeFactory)(createNativePannerNodeFaker);\nconst createPannerNodeRenderer = (0,_factories_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__.createPannerNodeRendererFactory)(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, createNativePannerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst pannerNodeConstructor = (0,_factories_panner_node_constructor__WEBPACK_IMPORTED_MODULE_129__.createPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createNativePeriodicWave = (0,_factories_native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_119__.createNativePeriodicWaveFactory)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst periodicWaveConstructor = (0,_factories_periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_131__.createPeriodicWaveConstructor)(createNativePeriodicWave, getNativeContext, new WeakSet(), _helpers_sanitize_periodic_wave_options__WEBPACK_IMPORTED_MODULE_184__.sanitizePeriodicWaveOptions);\nconst nativeStereoPannerNodeFakerFactory = (0,_factories_native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_122__.createNativeStereoPannerNodeFakerFactory)(createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, createNativeWaveShaperNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, monitorConnections);\nconst createNativeStereoPannerNode = (0,_factories_native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_121__.createNativeStereoPannerNodeFactory)(nativeStereoPannerNodeFakerFactory, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst createStereoPannerNodeRenderer = (0,_factories_stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_140__.createStereoPannerNodeRendererFactory)(connectAudioParam, createNativeStereoPannerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst stereoPannerNodeConstructor = (0,_factories_stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_139__.createStereoPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst createWaveShaperNodeRenderer = (0,_factories_wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_159__.createWaveShaperNodeRendererFactory)(createNativeWaveShaperNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst waveShaperNodeConstructor = (0,_factories_wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_158__.createWaveShaperNodeConstructor)(audioNodeConstructor, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst isSecureContext = (0,_factories_is_secure_context__WEBPACK_IMPORTED_MODULE_82__.createIsSecureContext)(window);\nconst exposeCurrentFrameAndCurrentTime = (0,_factories_expose_current_frame_and_current_time__WEBPACK_IMPORTED_MODULE_55__.createExposeCurrentFrameAndCurrentTime)(window);\nconst backupOfflineAudioContextStore = new WeakMap();\nconst getOrCreateBackupOfflineAudioContext = (0,_factories_get_or_create_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_65__.createGetOrCreateBackupOfflineAudioContext)(backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor);\n// The addAudioWorkletModule() function is only available in a SecureContext.\nconst addAudioWorkletModule = isSecureContext\n    ? (0,_factories_add_audio_worklet_module__WEBPACK_IMPORTED_MODULE_5__.createAddAudioWorkletModule)(cacheTestResult, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, (0,_factories_evaluate_source__WEBPACK_IMPORTED_MODULE_53__.createEvaluateSource)(window), exposeCurrentFrameAndCurrentTime, (0,_factories_fetch_source__WEBPACK_IMPORTED_MODULE_56__.createFetchSource)(_factories_abort_error__WEBPACK_IMPORTED_MODULE_1__.createAbortError), getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, new WeakMap(), new WeakMap(), (0,_factories_test_audio_worklet_processor_post_message_support__WEBPACK_IMPORTED_MODULE_148__.createTestAudioWorkletProcessorPostMessageSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), \n    // @todo window is guaranteed to be defined because isSecureContext checks that as well.\n    window)\n    : undefined;\nconst isNativeContext = (0,_factories_is_native_context__WEBPACK_IMPORTED_MODULE_80__.createIsNativeContext)(isNativeAudioContext, isNativeOfflineAudioContext);\nconst decodeAudioData = (0,_factories_decode_audio_data__WEBPACK_IMPORTED_MODULE_42__.createDecodeAudioData)(audioBufferStore, cacheTestResult, _factories_data_clone_error__WEBPACK_IMPORTED_MODULE_41__.createDataCloneError, _factories_encoding_error__WEBPACK_IMPORTED_MODULE_52__.createEncodingError, new WeakSet(), getNativeContext, isNativeContext, _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_195__.testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst baseAudioContextConstructor = (0,_factories_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_24__.createBaseAudioContextConstructor)(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);\nconst mediaElementAudioSourceNodeConstructor = (0,_factories_media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_84__.createMediaElementAudioSourceNodeConstructor)(audioNodeConstructor, _factories_native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_111__.createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst mediaStreamAudioDestinationNodeConstructor = (0,_factories_media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_85__.createMediaStreamAudioDestinationNodeConstructor)(audioNodeConstructor, _factories_native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_112__.createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext);\nconst mediaStreamAudioSourceNodeConstructor = (0,_factories_media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_86__.createMediaStreamAudioSourceNodeConstructor)(audioNodeConstructor, _factories_native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_113__.createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeMediaStreamTrackAudioSourceNode = (0,_factories_native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_114__.createNativeMediaStreamTrackAudioSourceNodeFactory)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, isNativeOfflineAudioContext);\nconst mediaStreamTrackAudioSourceNodeConstructor = (0,_factories_media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_87__.createMediaStreamTrackAudioSourceNodeConstructor)(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);\nconst audioContextConstructor = (0,_factories_audio_context_constructor__WEBPACK_IMPORTED_MODULE_15__.createAudioContextConstructor)(baseAudioContextConstructor, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__.createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);\n\nconst getUnrenderedAudioWorkletNodes = (0,_factories_get_unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_66__.createGetUnrenderedAudioWorkletNodes)(unrenderedAudioWorkletNodeStore);\nconst addUnrenderedAudioWorkletNode = (0,_factories_add_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_9__.createAddUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);\nconst connectMultipleOutputs = (0,_factories_connect_multiple_outputs__WEBPACK_IMPORTED_MODULE_33__.createConnectMultipleOutputs)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst deleteUnrenderedAudioWorkletNode = (0,_factories_delete_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_47__.createDeleteUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);\nconst disconnectMultipleOutputs = (0,_factories_disconnect_multiple_outputs__WEBPACK_IMPORTED_MODULE_49__.createDisconnectMultipleOutputs)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst activeAudioWorkletNodeInputsStore = new WeakMap();\nconst getActiveAudioWorkletNodeInputs = (0,_factories_get_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_59__.createGetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore, _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__.getValueForKey);\nconst createNativeAudioWorkletNodeFaker = (0,_factories_native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_99__.createNativeAudioWorkletNodeFakerFactory)(connectMultipleOutputs, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections);\nconst createNativeAudioWorkletNode = (0,_factories_native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_98__.createNativeAudioWorkletNodeFactory)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeAudioWorkletNodeFaker, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, monitorConnections);\nconst createAudioWorkletNodeRenderer = (0,_factories_audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_23__.createAudioWorkletNodeRendererFactory)(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst getBackupOfflineAudioContext = (0,_factories_get_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_63__.createGetBackupOfflineAudioContext)(backupOfflineAudioContextStore);\nconst setActiveAudioWorkletNodeInputs = (0,_factories_set_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_136__.createSetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore);\n// The AudioWorkletNode constructor is only available in a SecureContext.\nconst audioWorkletNodeConstructor = isSecureContext\n    ? (0,_factories_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_22__.createAudioWorkletNodeConstructor)(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, _helpers_sanitize_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_182__.sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, _helpers_test_audio_worklet_node_options_clonability__WEBPACK_IMPORTED_MODULE_193__.testAudioWorkletNodeOptionsClonability, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener)\n    : undefined;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst minimalAudioContextConstructor = (0,_factories_minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_88__.createMinimalAudioContextConstructor)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__.createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor);\n\nconst createNativeOfflineAudioContext = (0,_factories_create_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_40__.createCreateNativeOfflineAudioContext)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, nativeOfflineAudioContextConstructor);\nconst startRendering = (0,_factories_start_rendering__WEBPACK_IMPORTED_MODULE_138__.createStartRendering)(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst minimalOfflineAudioContextConstructor = (0,_factories_minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_90__.createMinimalOfflineAudioContextConstructor)(cacheTestResult, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering);\n\nconst offlineAudioContextConstructor = (0,_factories_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_126__.createOfflineAudioContextConstructor)(baseAudioContextConstructor, cacheTestResult, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeOfflineAudioContext, startRendering);\n\n\n\n\n\n\nconst isAnyAudioContext = (0,_factories_is_any_audio_context__WEBPACK_IMPORTED_MODULE_73__.createIsAnyAudioContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE, isNativeAudioContext);\nconst isAnyAudioNode = (0,_factories_is_any_audio_node__WEBPACK_IMPORTED_MODULE_74__.createIsAnyAudioNode)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_NODE_STORE, isNativeAudioNode);\nconst isAnyAudioParam = (0,_factories_is_any_audio_param__WEBPACK_IMPORTED_MODULE_75__.createIsAnyAudioParam)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_STORE, isNativeAudioParam);\nconst isAnyOfflineAudioContext = (0,_factories_is_any_offline_audio_context__WEBPACK_IMPORTED_MODULE_76__.createIsAnyOfflineAudioContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE, isNativeOfflineAudioContext);\nconst isSupported = () => (0,_factories_is_supported_promise__WEBPACK_IMPORTED_MODULE_83__.createIsSupportedPromise)(cacheTestResult, (0,_factories_test_audio_buffer_copy_channel_methods_subarray_support__WEBPACK_IMPORTED_MODULE_142__.createTestAudioBufferCopyChannelMethodsSubarraySupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_context_close_method_support__WEBPACK_IMPORTED_MODULE_143__.createTestAudioContextCloseMethodSupport)(nativeAudioContextConstructor), (0,_factories_test_audio_context_decode_audio_data_method_type_error_support__WEBPACK_IMPORTED_MODULE_144__.createTestAudioContextDecodeAudioDataMethodTypeErrorSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_context_options_support__WEBPACK_IMPORTED_MODULE_145__.createTestAudioContextOptionsSupport)(nativeAudioContextConstructor), (0,_factories_test_audio_node_connect_method_support__WEBPACK_IMPORTED_MODULE_146__.createTestAudioNodeConnectMethodSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_worklet_processor_no_outputs_support__WEBPACK_IMPORTED_MODULE_147__.createTestAudioWorkletProcessorNoOutputsSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), (0,_factories_test_channel_merger_node_channel_count_support__WEBPACK_IMPORTED_MODULE_149__.createTestChannelMergerNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_constant_source_node_accurate_scheduling_support__WEBPACK_IMPORTED_MODULE_150__.createTestConstantSourceNodeAccurateSchedulingSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_convolver_node_buffer_reassignability_support__WEBPACK_IMPORTED_MODULE_151__.createTestConvolverNodeBufferReassignabilitySupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_convolver_node_channel_count_support__WEBPACK_IMPORTED_MODULE_152__.createTestConvolverNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), _helpers_test_dom_exception_constructor_support__WEBPACK_IMPORTED_MODULE_194__.testDomExceptionConstructorSupport, (0,_factories_test_is_secure_context_support__WEBPACK_IMPORTED_MODULE_153__.createTestIsSecureContextSupport)(window), (0,_factories_test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_154__.createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)(nativeAudioContextConstructor), (0,_factories_test_stereo_panner_node_default_value_support__WEBPACK_IMPORTED_MODULE_156__.createTestStereoPannerNodeDefaultValueSupport)(nativeOfflineAudioContextConstructor), _helpers_test_transferables_support__WEBPACK_IMPORTED_MODULE_196__.testTransferablesSupport);\n//# sourceMappingURL=module.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/module.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/read-only-map.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/read-only-map.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReadOnlyMap\": () => (/* binding */ ReadOnlyMap)\n/* harmony export */ });\nclass ReadOnlyMap {\n    constructor(parameters) {\n        this._map = new Map(parameters);\n    }\n    get size() {\n        return this._map.size;\n    }\n    entries() {\n        return this._map.entries();\n    }\n    forEach(callback, thisArg = null) {\n        return this._map.forEach((value, key) => callback.call(thisArg, value, key, this));\n    }\n    get(name) {\n        return this._map.get(name);\n    }\n    has(name) {\n        return this._map.has(name);\n    }\n    keys() {\n        return this._map.keys();\n    }\n    values() {\n        return this._map.values();\n    }\n}\n//# sourceMappingURL=read-only-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/read-only-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=abort-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=active-audio-worklet-node-inputs-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=active-input-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-active-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-active-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-node-connections-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-node-connections-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-param-connections-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-param-connections-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-worklet-module-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-worklet-module-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-passive-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-passive-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-silent-connection-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-silent-connection-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-unrendered-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-unrendered-audio-worklet-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=any-audio-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/any-context.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/any-context.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=any-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/any-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-latency-category.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-state.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-connections-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-output-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-tail-time-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-audio-node-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-connections-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-connections.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-output-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=backup-offline-audio-context-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-type.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cache-test-result-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cache-test-result-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-count-mode.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-interpretation.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-audio-param-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-multiple-outputs-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-multiple-outputs-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-native-audio-node-to-native-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constructor.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constructor.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/context-store.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/context-store.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=context-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/context-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/context.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/context.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convert-number-to-unsigned-long-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convert-number-to-unsigned-long-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=create-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=create-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cycle-counters.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=data-clone-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-audio-data-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-audio-data-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-error-callback.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-success-callback.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decrement-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decrement-cycle-counter-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-active-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-active-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-unrendered-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-unrendered-audio-worklet-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=detect-cycles-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=detect-cycles-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-multiple-outputs-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-multiple-outputs-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-native-audio-node-from-native-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=distance-model-type.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=encoding-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=error-event-handler.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-audio-worklet-global-scope-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-source-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-source-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-handler.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-handler.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-handler.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/event-handler.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=expose-current-frame-and-current-time-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=expose-current-frame-and-current-time-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=fetch-source-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=fetch-source-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-active-audio-worklet-node-inputs-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-active-audio-worklet-node-inputs-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-connections-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-renderer-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-tail-time-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-tail-time-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-connections-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-renderer-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-backup-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-backup-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-event-listeners-of-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-first-sample-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-audio-param-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-or-create-backup-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-or-create-backup-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-value-for-key-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=index-size-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/index.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _abort_error_factory__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./abort-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js\");\n/* harmony import */ var _active_audio_worklet_node_inputs_store__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./active-audio-worklet-node-inputs-store */ \"./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js\");\n/* harmony import */ var _active_input_connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./active-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js\");\n/* harmony import */ var _add_active_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./add-active-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_active_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./add-active-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_audio_node_connections_factory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./add-audio-node-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js\");\n/* harmony import */ var _add_audio_node_connections_function__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./add-audio-node-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js\");\n/* harmony import */ var _add_audio_param_connections_factory__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./add-audio-param-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js\");\n/* harmony import */ var _add_audio_param_connections_function__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./add-audio-param-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js\");\n/* harmony import */ var _add_audio_worklet_module_factory__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./add-audio-worklet-module-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js\");\n/* harmony import */ var _add_audio_worklet_module_function__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./add-audio-worklet-module-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js\");\n/* harmony import */ var _add_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./add-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./add-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_passive_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./add-passive-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_passive_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./add-passive-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_silent_connection_factory__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./add-silent-connection-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js\");\n/* harmony import */ var _add_silent_connection_function__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./add-silent-connection-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js\");\n/* harmony import */ var _add_unrendered_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./add-unrendered-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js\");\n/* harmony import */ var _add_unrendered_audio_worklet_node_function__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./add-unrendered-audio-worklet-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js\");\n/* harmony import */ var _analyser_node_constructor__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./analyser-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js\");\n/* harmony import */ var _analyser_node_constructor_factory__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./analyser-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js\");\n/* harmony import */ var _analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./analyser-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js\");\n/* harmony import */ var _analyser_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./analyser-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js\");\n/* harmony import */ var _any_audio_buffer__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./any-audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js\");\n/* harmony import */ var _any_context__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./any-context */ \"./node_modules/standardized-audio-context/build/es2019/types/any-context.js\");\n/* harmony import */ var _audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js\");\n/* harmony import */ var _audio_buffer_constructor_factory__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./audio-buffer-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./audio-buffer-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js\");\n/* harmony import */ var _audio_buffer_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./audio-buffer-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js\");\n/* harmony import */ var _audio_buffer_store__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./audio-buffer-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js\");\n/* harmony import */ var _audio_context_constructor__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js\");\n/* harmony import */ var _audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js\");\n/* harmony import */ var _audio_context_latency_category__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./audio-context-latency-category */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js\");\n/* harmony import */ var _audio_context_state__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./audio-context-state */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js\");\n/* harmony import */ var _audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js\");\n/* harmony import */ var _audio_destination_node_constructor_factory__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./audio-destination-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js\");\n/* harmony import */ var _audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./audio-destination-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js\");\n/* harmony import */ var _audio_listener_factory__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./audio-listener-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js\");\n/* harmony import */ var _audio_listener_factory_factory__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./audio-listener-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js\");\n/* harmony import */ var _audio_node_connections__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js\");\n/* harmony import */ var _audio_node_connections_store__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./audio-node-connections-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js\");\n/* harmony import */ var _audio_node_constructor__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./audio-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js\");\n/* harmony import */ var _audio_node_constructor_factory__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./audio-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js\");\n/* harmony import */ var _audio_node_output_connection__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js\");\n/* harmony import */ var _audio_node_renderer__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js\");\n/* harmony import */ var _audio_node_store__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./audio-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js\");\n/* harmony import */ var _audio_node_tail_time_store__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./audio-node-tail-time-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js\");\n/* harmony import */ var _audio_param_audio_node_store__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./audio-param-audio-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js\");\n/* harmony import */ var _audio_param_connections__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js\");\n/* harmony import */ var _audio_param_connections_store__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./audio-param-connections-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js\");\n/* harmony import */ var _audio_param_factory__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js\");\n/* harmony import */ var _audio_param_factory_factory__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./audio-param-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js\");\n/* harmony import */ var _audio_param_map__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./audio-param-map */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js\");\n/* harmony import */ var _audio_param_output_connection__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./audio-param-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js\");\n/* harmony import */ var _audio_param_renderer_factory__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./audio-param-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js\");\n/* harmony import */ var _audio_param_store__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./audio-param-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js\");\n/* harmony import */ var _audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js\");\n/* harmony import */ var _audio_worklet_node_constructor_factory__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./audio-worklet-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js\");\n/* harmony import */ var _audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./audio-worklet-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js\");\n/* harmony import */ var _audio_worklet_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./audio-worklet-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js\");\n/* harmony import */ var _backup_offline_audio_context_store__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./backup-offline-audio-context-store */ \"./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js\");\n/* harmony import */ var _base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js\");\n/* harmony import */ var _base_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./base-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js\");\n/* harmony import */ var _biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./biquad-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js\");\n/* harmony import */ var _biquad_filter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./biquad-filter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js\");\n/* harmony import */ var _biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./biquad-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js\");\n/* harmony import */ var _biquad_filter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./biquad-filter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js\");\n/* harmony import */ var _biquad_filter_type__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./biquad-filter-type */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js\");\n/* harmony import */ var _channel_count_mode__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./channel-count-mode */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js\");\n/* harmony import */ var _channel_interpretation__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./channel-interpretation */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js\");\n/* harmony import */ var _channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./channel-merger-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js\");\n/* harmony import */ var _channel_merger_node_constructor_factory__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./channel-merger-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js\");\n/* harmony import */ var _channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./channel-merger-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js\");\n/* harmony import */ var _channel_merger_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./channel-merger-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js\");\n/* harmony import */ var _channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./channel-splitter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js\");\n/* harmony import */ var _channel_splitter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./channel-splitter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js\");\n/* harmony import */ var _channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./channel-splitter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js\");\n/* harmony import */ var _channel_splitter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./channel-splitter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js\");\n/* harmony import */ var _cache_test_result_factory__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./cache-test-result-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js\");\n/* harmony import */ var _cache_test_result_function__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./cache-test-result-function */ \"./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js\");\n/* harmony import */ var _connect_audio_param_factory__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./connect-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js\");\n/* harmony import */ var _connect_audio_param_function__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./connect-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js\");\n/* harmony import */ var _connect_multiple_outputs_factory__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./connect-multiple-outputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js\");\n/* harmony import */ var _connect_multiple_outputs_function__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./connect-multiple-outputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js\");\n/* harmony import */ var _connect_native_audio_node_to_native_audio_node_function__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./connect-native-audio-node-to-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js\");\n/* harmony import */ var _connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./connected-native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _connected_native_audio_buffer_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./connected-native-audio-buffer-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js\");\n/* harmony import */ var _constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./constant-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js\");\n/* harmony import */ var _constant_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./constant-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js\");\n/* harmony import */ var _constant_source_node_renderer__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./constant-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js\");\n/* harmony import */ var _constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./constant-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js\");\n/* harmony import */ var _constant_source_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./constant-source-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js\");\n/* harmony import */ var _constructor__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/constructor.js\");\n/* harmony import */ var _context__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./context */ \"./node_modules/standardized-audio-context/build/es2019/types/context.js\");\n/* harmony import */ var _context_store__WEBPACK_IMPORTED_MODULE_97__ = __webpack_require__(/*! ./context-store */ \"./node_modules/standardized-audio-context/build/es2019/types/context-store.js\");\n/* harmony import */ var _convert_number_to_unsigned_long_factory__WEBPACK_IMPORTED_MODULE_98__ = __webpack_require__(/*! ./convert-number-to-unsigned-long-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js\");\n/* harmony import */ var _convert_number_to_unsigned_long_function__WEBPACK_IMPORTED_MODULE_99__ = __webpack_require__(/*! ./convert-number-to-unsigned-long-function */ \"./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js\");\n/* harmony import */ var _convolver_node_constructor__WEBPACK_IMPORTED_MODULE_100__ = __webpack_require__(/*! ./convolver-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js\");\n/* harmony import */ var _convolver_node_constructor_factory__WEBPACK_IMPORTED_MODULE_101__ = __webpack_require__(/*! ./convolver-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js\");\n/* harmony import */ var _convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_102__ = __webpack_require__(/*! ./convolver-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js\");\n/* harmony import */ var _convolver_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_103__ = __webpack_require__(/*! ./convolver-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js\");\n/* harmony import */ var _create_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_104__ = __webpack_require__(/*! ./create-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js\");\n/* harmony import */ var _create_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_105__ = __webpack_require__(/*! ./create-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js\");\n/* harmony import */ var _cycle_counters__WEBPACK_IMPORTED_MODULE_106__ = __webpack_require__(/*! ./cycle-counters */ \"./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js\");\n/* harmony import */ var _data_clone_error_factory__WEBPACK_IMPORTED_MODULE_107__ = __webpack_require__(/*! ./data-clone-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js\");\n/* harmony import */ var _decode_audio_data_factory__WEBPACK_IMPORTED_MODULE_108__ = __webpack_require__(/*! ./decode-audio-data-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js\");\n/* harmony import */ var _decode_audio_data_function__WEBPACK_IMPORTED_MODULE_109__ = __webpack_require__(/*! ./decode-audio-data-function */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js\");\n/* harmony import */ var _decode_error_callback__WEBPACK_IMPORTED_MODULE_110__ = __webpack_require__(/*! ./decode-error-callback */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js\");\n/* harmony import */ var _decode_success_callback__WEBPACK_IMPORTED_MODULE_111__ = __webpack_require__(/*! ./decode-success-callback */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js\");\n/* harmony import */ var _decrement_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_112__ = __webpack_require__(/*! ./decrement-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js\");\n/* harmony import */ var _decrement_cycle_counter_function__WEBPACK_IMPORTED_MODULE_113__ = __webpack_require__(/*! ./decrement-cycle-counter-function */ \"./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js\");\n/* harmony import */ var _delay_node_constructor__WEBPACK_IMPORTED_MODULE_114__ = __webpack_require__(/*! ./delay-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js\");\n/* harmony import */ var _delay_node_constructor_factory__WEBPACK_IMPORTED_MODULE_115__ = __webpack_require__(/*! ./delay-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js\");\n/* harmony import */ var _delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_116__ = __webpack_require__(/*! ./delay-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js\");\n/* harmony import */ var _delay_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_117__ = __webpack_require__(/*! ./delay-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js\");\n/* harmony import */ var _delete_active_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_118__ = __webpack_require__(/*! ./delete-active-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _delete_active_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_119__ = __webpack_require__(/*! ./delete-active-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _delete_unrendered_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_120__ = __webpack_require__(/*! ./delete-unrendered-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js\");\n/* harmony import */ var _delete_unrendered_audio_worklet_node_function__WEBPACK_IMPORTED_MODULE_121__ = __webpack_require__(/*! ./delete-unrendered-audio-worklet-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js\");\n/* harmony import */ var _detect_cycles_factory__WEBPACK_IMPORTED_MODULE_122__ = __webpack_require__(/*! ./detect-cycles-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js\");\n/* harmony import */ var _detect_cycles_function__WEBPACK_IMPORTED_MODULE_123__ = __webpack_require__(/*! ./detect-cycles-function */ \"./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js\");\n/* harmony import */ var _disconnect_multiple_outputs_factory__WEBPACK_IMPORTED_MODULE_124__ = __webpack_require__(/*! ./disconnect-multiple-outputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js\");\n/* harmony import */ var _disconnect_multiple_outputs_function__WEBPACK_IMPORTED_MODULE_125__ = __webpack_require__(/*! ./disconnect-multiple-outputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js\");\n/* harmony import */ var _disconnect_native_audio_node_from_native_audio_node_function__WEBPACK_IMPORTED_MODULE_126__ = __webpack_require__(/*! ./disconnect-native-audio-node-from-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js\");\n/* harmony import */ var _distance_model_type__WEBPACK_IMPORTED_MODULE_127__ = __webpack_require__(/*! ./distance-model-type */ \"./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js\");\n/* harmony import */ var _dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_128__ = __webpack_require__(/*! ./dynamics-compressor-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js\");\n/* harmony import */ var _dynamics_compressor_node_constructor_factory__WEBPACK_IMPORTED_MODULE_129__ = __webpack_require__(/*! ./dynamics-compressor-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js\");\n/* harmony import */ var _dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__ = __webpack_require__(/*! ./dynamics-compressor-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js\");\n/* harmony import */ var _dynamics_compressor_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_131__ = __webpack_require__(/*! ./dynamics-compressor-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js\");\n/* harmony import */ var _encoding_error_factory__WEBPACK_IMPORTED_MODULE_132__ = __webpack_require__(/*! ./encoding-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js\");\n/* harmony import */ var _error_event_handler__WEBPACK_IMPORTED_MODULE_133__ = __webpack_require__(/*! ./error-event-handler */ \"./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js\");\n/* harmony import */ var _evaluate_audio_worklet_global_scope_function__WEBPACK_IMPORTED_MODULE_134__ = __webpack_require__(/*! ./evaluate-audio-worklet-global-scope-function */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js\");\n/* harmony import */ var _evaluate_source_factory__WEBPACK_IMPORTED_MODULE_135__ = __webpack_require__(/*! ./evaluate-source-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js\");\n/* harmony import */ var _evaluate_source_function__WEBPACK_IMPORTED_MODULE_136__ = __webpack_require__(/*! ./evaluate-source-function */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js\");\n/* harmony import */ var _event_handler__WEBPACK_IMPORTED_MODULE_137__ = __webpack_require__(/*! ./event-handler */ \"./node_modules/standardized-audio-context/build/es2019/types/event-handler.js\");\n/* harmony import */ var _event_target_constructor__WEBPACK_IMPORTED_MODULE_138__ = __webpack_require__(/*! ./event-target-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js\");\n/* harmony import */ var _event_target_constructor_factory__WEBPACK_IMPORTED_MODULE_139__ = __webpack_require__(/*! ./event-target-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js\");\n/* harmony import */ var _expose_current_frame_and_current_time_factory__WEBPACK_IMPORTED_MODULE_140__ = __webpack_require__(/*! ./expose-current-frame-and-current-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js\");\n/* harmony import */ var _expose_current_frame_and_current_time_function__WEBPACK_IMPORTED_MODULE_141__ = __webpack_require__(/*! ./expose-current-frame-and-current-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js\");\n/* harmony import */ var _fetch_source_factory__WEBPACK_IMPORTED_MODULE_142__ = __webpack_require__(/*! ./fetch-source-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js\");\n/* harmony import */ var _fetch_source_function__WEBPACK_IMPORTED_MODULE_143__ = __webpack_require__(/*! ./fetch-source-function */ \"./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js\");\n/* harmony import */ var _gain_node_constructor__WEBPACK_IMPORTED_MODULE_144__ = __webpack_require__(/*! ./gain-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js\");\n/* harmony import */ var _gain_node_constructor_factory__WEBPACK_IMPORTED_MODULE_145__ = __webpack_require__(/*! ./gain-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js\");\n/* harmony import */ var _gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_146__ = __webpack_require__(/*! ./gain-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js\");\n/* harmony import */ var _gain_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_147__ = __webpack_require__(/*! ./gain-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js\");\n/* harmony import */ var _get_active_audio_worklet_node_inputs_factory__WEBPACK_IMPORTED_MODULE_148__ = __webpack_require__(/*! ./get-active-audio-worklet-node-inputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js\");\n/* harmony import */ var _get_active_audio_worklet_node_inputs_function__WEBPACK_IMPORTED_MODULE_149__ = __webpack_require__(/*! ./get-active-audio-worklet-node-inputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js\");\n/* harmony import */ var _get_audio_node_connections_function__WEBPACK_IMPORTED_MODULE_150__ = __webpack_require__(/*! ./get-audio-node-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js\");\n/* harmony import */ var _get_audio_node_renderer_factory__WEBPACK_IMPORTED_MODULE_151__ = __webpack_require__(/*! ./get-audio-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js\");\n/* harmony import */ var _get_audio_node_renderer_function__WEBPACK_IMPORTED_MODULE_152__ = __webpack_require__(/*! ./get-audio-node-renderer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js\");\n/* harmony import */ var _get_audio_node_tail_time_factory__WEBPACK_IMPORTED_MODULE_153__ = __webpack_require__(/*! ./get-audio-node-tail-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js\");\n/* harmony import */ var _get_audio_node_tail_time_function__WEBPACK_IMPORTED_MODULE_154__ = __webpack_require__(/*! ./get-audio-node-tail-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js\");\n/* harmony import */ var _get_audio_param_connections_function__WEBPACK_IMPORTED_MODULE_155__ = __webpack_require__(/*! ./get-audio-param-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js\");\n/* harmony import */ var _get_audio_param_renderer_factory__WEBPACK_IMPORTED_MODULE_156__ = __webpack_require__(/*! ./get-audio-param-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js\");\n/* harmony import */ var _get_audio_param_renderer_function__WEBPACK_IMPORTED_MODULE_157__ = __webpack_require__(/*! ./get-audio-param-renderer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js\");\n/* harmony import */ var _get_backup_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_158__ = __webpack_require__(/*! ./get-backup-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js\");\n/* harmony import */ var _get_backup_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_159__ = __webpack_require__(/*! ./get-backup-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node_function__WEBPACK_IMPORTED_MODULE_160__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js\");\n/* harmony import */ var _get_first_sample_function__WEBPACK_IMPORTED_MODULE_161__ = __webpack_require__(/*! ./get-first-sample-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js\");\n/* harmony import */ var _get_native_audio_node_function__WEBPACK_IMPORTED_MODULE_162__ = __webpack_require__(/*! ./get-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js\");\n/* harmony import */ var _get_native_audio_param_function__WEBPACK_IMPORTED_MODULE_163__ = __webpack_require__(/*! ./get-native-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js\");\n/* harmony import */ var _get_native_context_factory__WEBPACK_IMPORTED_MODULE_164__ = __webpack_require__(/*! ./get-native-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js\");\n/* harmony import */ var _get_native_context_function__WEBPACK_IMPORTED_MODULE_165__ = __webpack_require__(/*! ./get-native-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js\");\n/* harmony import */ var _get_or_create_backup_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_166__ = __webpack_require__(/*! ./get-or-create-backup-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js\");\n/* harmony import */ var _get_or_create_backup_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_167__ = __webpack_require__(/*! ./get-or-create-backup-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js\");\n/* harmony import */ var _get_unrendered_audio_worklet_nodes_factory__WEBPACK_IMPORTED_MODULE_168__ = __webpack_require__(/*! ./get-unrendered-audio-worklet-nodes-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js\");\n/* harmony import */ var _get_unrendered_audio_worklet_nodes_function__WEBPACK_IMPORTED_MODULE_169__ = __webpack_require__(/*! ./get-unrendered-audio-worklet-nodes-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js\");\n/* harmony import */ var _get_value_for_key_function__WEBPACK_IMPORTED_MODULE_170__ = __webpack_require__(/*! ./get-value-for-key-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js\");\n/* harmony import */ var _iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_171__ = __webpack_require__(/*! ./iir-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js\");\n/* harmony import */ var _iir_filter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_172__ = __webpack_require__(/*! ./iir-filter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js\");\n/* harmony import */ var _iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_173__ = __webpack_require__(/*! ./iir-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js\");\n/* harmony import */ var _iir_filter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_174__ = __webpack_require__(/*! ./iir-filter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js\");\n/* harmony import */ var _increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_175__ = __webpack_require__(/*! ./increment-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js\");\n/* harmony import */ var _increment_cycle_counter_factory_factory__WEBPACK_IMPORTED_MODULE_176__ = __webpack_require__(/*! ./increment-cycle-counter-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js\");\n/* harmony import */ var _increment_cycle_counter_function__WEBPACK_IMPORTED_MODULE_177__ = __webpack_require__(/*! ./increment-cycle-counter-function */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js\");\n/* harmony import */ var _index_size_error_factory__WEBPACK_IMPORTED_MODULE_178__ = __webpack_require__(/*! ./index-size-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js\");\n/* harmony import */ var _insert_element_in_set_function__WEBPACK_IMPORTED_MODULE_179__ = __webpack_require__(/*! ./insert-element-in-set-function */ \"./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js\");\n/* harmony import */ var _internal_state_event_listener__WEBPACK_IMPORTED_MODULE_180__ = __webpack_require__(/*! ./internal-state-event-listener */ \"./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js\");\n/* harmony import */ var _invalid_access_error_factory__WEBPACK_IMPORTED_MODULE_181__ = __webpack_require__(/*! ./invalid-access-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js\");\n/* harmony import */ var _invalid_state_error_factory__WEBPACK_IMPORTED_MODULE_182__ = __webpack_require__(/*! ./invalid-state-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js\");\n/* harmony import */ var _is_active_audio_node_function__WEBPACK_IMPORTED_MODULE_183__ = __webpack_require__(/*! ./is-active-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js\");\n/* harmony import */ var _is_any_audio_context_factory__WEBPACK_IMPORTED_MODULE_184__ = __webpack_require__(/*! ./is-any-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js\");\n/* harmony import */ var _is_any_audio_context_function__WEBPACK_IMPORTED_MODULE_185__ = __webpack_require__(/*! ./is-any-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js\");\n/* harmony import */ var _is_any_audio_node_factory__WEBPACK_IMPORTED_MODULE_186__ = __webpack_require__(/*! ./is-any-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js\");\n/* harmony import */ var _is_any_audio_node_function__WEBPACK_IMPORTED_MODULE_187__ = __webpack_require__(/*! ./is-any-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js\");\n/* harmony import */ var _is_any_audio_param_factory__WEBPACK_IMPORTED_MODULE_188__ = __webpack_require__(/*! ./is-any-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js\");\n/* harmony import */ var _is_any_audio_param_function__WEBPACK_IMPORTED_MODULE_189__ = __webpack_require__(/*! ./is-any-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js\");\n/* harmony import */ var _is_any_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_190__ = __webpack_require__(/*! ./is-any-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js\");\n/* harmony import */ var _is_any_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_191__ = __webpack_require__(/*! ./is-any-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js\");\n/* harmony import */ var _is_dc_curve_function__WEBPACK_IMPORTED_MODULE_192__ = __webpack_require__(/*! ./is-dc-curve-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js\");\n/* harmony import */ var _is_native_audio_context_factory__WEBPACK_IMPORTED_MODULE_193__ = __webpack_require__(/*! ./is-native-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js\");\n/* harmony import */ var _is_native_audio_context_function__WEBPACK_IMPORTED_MODULE_194__ = __webpack_require__(/*! ./is-native-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js\");\n/* harmony import */ var _is_native_audio_node_factory__WEBPACK_IMPORTED_MODULE_195__ = __webpack_require__(/*! ./is-native-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js\");\n/* harmony import */ var _is_native_audio_node_function__WEBPACK_IMPORTED_MODULE_196__ = __webpack_require__(/*! ./is-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js\");\n/* harmony import */ var _is_native_audio_param_factory__WEBPACK_IMPORTED_MODULE_197__ = __webpack_require__(/*! ./is-native-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js\");\n/* harmony import */ var _is_native_audio_param_function__WEBPACK_IMPORTED_MODULE_198__ = __webpack_require__(/*! ./is-native-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js\");\n/* harmony import */ var _is_native_context_factory__WEBPACK_IMPORTED_MODULE_199__ = __webpack_require__(/*! ./is-native-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js\");\n/* harmony import */ var _is_native_context_function__WEBPACK_IMPORTED_MODULE_200__ = __webpack_require__(/*! ./is-native-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js\");\n/* harmony import */ var _is_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_201__ = __webpack_require__(/*! ./is-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js\");\n/* harmony import */ var _is_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_202__ = __webpack_require__(/*! ./is-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js\");\n/* harmony import */ var _is_part_of_a_cycle_function__WEBPACK_IMPORTED_MODULE_203__ = __webpack_require__(/*! ./is-part-of-a-cycle-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js\");\n/* harmony import */ var _is_passive_audio_node_function__WEBPACK_IMPORTED_MODULE_204__ = __webpack_require__(/*! ./is-passive-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js\");\n/* harmony import */ var _is_secure_context_factory__WEBPACK_IMPORTED_MODULE_205__ = __webpack_require__(/*! ./is-secure-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js\");\n/* harmony import */ var _is_supported_promise_factory__WEBPACK_IMPORTED_MODULE_206__ = __webpack_require__(/*! ./is-supported-promise-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js\");\n/* harmony import */ var _media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_207__ = __webpack_require__(/*! ./media-element-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js\");\n/* harmony import */ var _media_element_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_208__ = __webpack_require__(/*! ./media-element-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_209__ = __webpack_require__(/*! ./media-stream-audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js\");\n/* harmony import */ var _media_stream_audio_destination_node_constructor_factory__WEBPACK_IMPORTED_MODULE_210__ = __webpack_require__(/*! ./media-stream-audio-destination-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_211__ = __webpack_require__(/*! ./media-stream-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js\");\n/* harmony import */ var _media_stream_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_212__ = __webpack_require__(/*! ./media-stream-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_213__ = __webpack_require__(/*! ./media-stream-track-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js\");\n/* harmony import */ var _media_stream_track_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_214__ = __webpack_require__(/*! ./media-stream-track-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_215__ = __webpack_require__(/*! ./minimal-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js\");\n/* harmony import */ var _minimal_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_216__ = __webpack_require__(/*! ./minimal-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js\");\n/* harmony import */ var _minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_217__ = __webpack_require__(/*! ./minimal-base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js\");\n/* harmony import */ var _minimal_base_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_218__ = __webpack_require__(/*! ./minimal-base-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js\");\n/* harmony import */ var _minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_219__ = __webpack_require__(/*! ./minimal-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js\");\n/* harmony import */ var _minimal_offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_220__ = __webpack_require__(/*! ./minimal-offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _monitor_connections_factory__WEBPACK_IMPORTED_MODULE_221__ = __webpack_require__(/*! ./monitor-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js\");\n/* harmony import */ var _monitor_connections_function__WEBPACK_IMPORTED_MODULE_222__ = __webpack_require__(/*! ./monitor-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js\");\n/* harmony import */ var _native_analyser_node__WEBPACK_IMPORTED_MODULE_223__ = __webpack_require__(/*! ./native-analyser-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js\");\n/* harmony import */ var _native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_224__ = __webpack_require__(/*! ./native-analyser-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js\");\n/* harmony import */ var _native_analyser_node_factory_factory__WEBPACK_IMPORTED_MODULE_225__ = __webpack_require__(/*! ./native-analyser-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js\");\n/* harmony import */ var _native_audio_buffer__WEBPACK_IMPORTED_MODULE_226__ = __webpack_require__(/*! ./native-audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js\");\n/* harmony import */ var _native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_227__ = __webpack_require__(/*! ./native-audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js\");\n/* harmony import */ var _native_audio_buffer_constructor_factory__WEBPACK_IMPORTED_MODULE_228__ = __webpack_require__(/*! ./native-audio-buffer-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js\");\n/* harmony import */ var _native_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_229__ = __webpack_require__(/*! ./native-audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js\");\n/* harmony import */ var _native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_230__ = __webpack_require__(/*! ./native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _native_audio_buffer_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_231__ = __webpack_require__(/*! ./native-audio-buffer-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js\");\n/* harmony import */ var _native_audio_context__WEBPACK_IMPORTED_MODULE_232__ = __webpack_require__(/*! ./native-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js\");\n/* harmony import */ var _native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_233__ = __webpack_require__(/*! ./native-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js\");\n/* harmony import */ var _native_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_234__ = __webpack_require__(/*! ./native-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js\");\n/* harmony import */ var _native_audio_destination_node__WEBPACK_IMPORTED_MODULE_235__ = __webpack_require__(/*! ./native-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js\");\n/* harmony import */ var _native_audio_destination_node_factory__WEBPACK_IMPORTED_MODULE_236__ = __webpack_require__(/*! ./native-audio-destination-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js\");\n/* harmony import */ var _native_audio_destination_node_factory_factory__WEBPACK_IMPORTED_MODULE_237__ = __webpack_require__(/*! ./native-audio-destination-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js\");\n/* harmony import */ var _native_audio_listener__WEBPACK_IMPORTED_MODULE_238__ = __webpack_require__(/*! ./native-audio-listener */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js\");\n/* harmony import */ var _native_audio_node__WEBPACK_IMPORTED_MODULE_239__ = __webpack_require__(/*! ./native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js\");\n/* harmony import */ var _native_audio_param__WEBPACK_IMPORTED_MODULE_240__ = __webpack_require__(/*! ./native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js\");\n/* harmony import */ var _native_audio_param_map__WEBPACK_IMPORTED_MODULE_241__ = __webpack_require__(/*! ./native-audio-param-map */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js\");\n/* harmony import */ var _native_audio_worklet__WEBPACK_IMPORTED_MODULE_242__ = __webpack_require__(/*! ./native-audio-worklet */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js\");\n/* harmony import */ var _native_audio_worklet_node__WEBPACK_IMPORTED_MODULE_243__ = __webpack_require__(/*! ./native-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js\");\n/* harmony import */ var _native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_244__ = __webpack_require__(/*! ./native-audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js\");\n/* harmony import */ var _native_audio_worklet_node_constructor_factory__WEBPACK_IMPORTED_MODULE_245__ = __webpack_require__(/*! ./native-audio-worklet-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_246__ = __webpack_require__(/*! ./native-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_factory_factory__WEBPACK_IMPORTED_MODULE_247__ = __webpack_require__(/*! ./native-audio-worklet-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_248__ = __webpack_require__(/*! ./native-audio-worklet-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_249__ = __webpack_require__(/*! ./native-audio-worklet-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_250__ = __webpack_require__(/*! ./native-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js\");\n/* harmony import */ var _native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_251__ = __webpack_require__(/*! ./native-biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js\");\n/* harmony import */ var _native_biquad_filter_node_factory__WEBPACK_IMPORTED_MODULE_252__ = __webpack_require__(/*! ./native-biquad-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js\");\n/* harmony import */ var _native_channel_merger_node__WEBPACK_IMPORTED_MODULE_253__ = __webpack_require__(/*! ./native-channel-merger-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js\");\n/* harmony import */ var _native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_254__ = __webpack_require__(/*! ./native-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js\");\n/* harmony import */ var _native_channel_merger_node_factory_factory__WEBPACK_IMPORTED_MODULE_255__ = __webpack_require__(/*! ./native-channel-merger-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js\");\n/* harmony import */ var _native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_256__ = __webpack_require__(/*! ./native-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js\");\n/* harmony import */ var _native_channel_splitter_node_factory__WEBPACK_IMPORTED_MODULE_257__ = __webpack_require__(/*! ./native-channel-splitter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js\");\n/* harmony import */ var _native_constant_source_node__WEBPACK_IMPORTED_MODULE_258__ = __webpack_require__(/*! ./native-constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js\");\n/* harmony import */ var _native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_259__ = __webpack_require__(/*! ./native-constant-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js\");\n/* harmony import */ var _native_constant_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_260__ = __webpack_require__(/*! ./native-constant-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js\");\n/* harmony import */ var _native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_261__ = __webpack_require__(/*! ./native-constant-source-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js\");\n/* harmony import */ var _native_constant_source_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_262__ = __webpack_require__(/*! ./native-constant-source-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js\");\n/* harmony import */ var _native_context__WEBPACK_IMPORTED_MODULE_263__ = __webpack_require__(/*! ./native-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-context.js\");\n/* harmony import */ var _native_convolver_node__WEBPACK_IMPORTED_MODULE_264__ = __webpack_require__(/*! ./native-convolver-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js\");\n/* harmony import */ var _native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_265__ = __webpack_require__(/*! ./native-convolver-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js\");\n/* harmony import */ var _native_convolver_node_factory_factory__WEBPACK_IMPORTED_MODULE_266__ = __webpack_require__(/*! ./native-convolver-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js\");\n/* harmony import */ var _native_delay_node_factory__WEBPACK_IMPORTED_MODULE_267__ = __webpack_require__(/*! ./native-delay-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js\");\n/* harmony import */ var _native_delay_node__WEBPACK_IMPORTED_MODULE_268__ = __webpack_require__(/*! ./native-delay-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js\");\n/* harmony import */ var _native_dynamics_compressor_node__WEBPACK_IMPORTED_MODULE_269__ = __webpack_require__(/*! ./native-dynamics-compressor-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js\");\n/* harmony import */ var _native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_270__ = __webpack_require__(/*! ./native-dynamics-compressor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js\");\n/* harmony import */ var _native_dynamics_compressor_node_factory_factory__WEBPACK_IMPORTED_MODULE_271__ = __webpack_require__(/*! ./native-dynamics-compressor-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js\");\n/* harmony import */ var _native_event_target__WEBPACK_IMPORTED_MODULE_272__ = __webpack_require__(/*! ./native-event-target */ \"./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js\");\n/* harmony import */ var _native_gain_node__WEBPACK_IMPORTED_MODULE_273__ = __webpack_require__(/*! ./native-gain-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js\");\n/* harmony import */ var _native_gain_node_factory__WEBPACK_IMPORTED_MODULE_274__ = __webpack_require__(/*! ./native-gain-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js\");\n/* harmony import */ var _native_iir_filter_node__WEBPACK_IMPORTED_MODULE_275__ = __webpack_require__(/*! ./native-iir-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js\");\n/* harmony import */ var _native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_276__ = __webpack_require__(/*! ./native-iir-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js\");\n/* harmony import */ var _native_iir_filter_node_factory_factory__WEBPACK_IMPORTED_MODULE_277__ = __webpack_require__(/*! ./native-iir-filter-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js\");\n/* harmony import */ var _native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_278__ = __webpack_require__(/*! ./native-iir-filter-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js\");\n/* harmony import */ var _native_iir_filter_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_279__ = __webpack_require__(/*! ./native-iir-filter-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js\");\n/* harmony import */ var _native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_280__ = __webpack_require__(/*! ./native-media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js\");\n/* harmony import */ var _native_media_element_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_281__ = __webpack_require__(/*! ./native-media-element-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_282__ = __webpack_require__(/*! ./native-media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js\");\n/* harmony import */ var _native_media_stream_audio_destination_node_factory__WEBPACK_IMPORTED_MODULE_283__ = __webpack_require__(/*! ./native-media-stream-audio-destination-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js\");\n/* harmony import */ var _native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_284__ = __webpack_require__(/*! ./native-media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js\");\n/* harmony import */ var _native_media_stream_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_285__ = __webpack_require__(/*! ./native-media-stream-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node__WEBPACK_IMPORTED_MODULE_286__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_287__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_288__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js\");\n/* harmony import */ var _native_offline_audio_context__WEBPACK_IMPORTED_MODULE_289__ = __webpack_require__(/*! ./native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js\");\n/* harmony import */ var _native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_290__ = __webpack_require__(/*! ./native-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js\");\n/* harmony import */ var _native_offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_291__ = __webpack_require__(/*! ./native-offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _native_oscillator_node__WEBPACK_IMPORTED_MODULE_292__ = __webpack_require__(/*! ./native-oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js\");\n/* harmony import */ var _native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_293__ = __webpack_require__(/*! ./native-oscillator-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js\");\n/* harmony import */ var _native_oscillator_node_factory_factory__WEBPACK_IMPORTED_MODULE_294__ = __webpack_require__(/*! ./native-oscillator-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js\");\n/* harmony import */ var _native_panner_node__WEBPACK_IMPORTED_MODULE_295__ = __webpack_require__(/*! ./native-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js\");\n/* harmony import */ var _native_panner_node_factory__WEBPACK_IMPORTED_MODULE_296__ = __webpack_require__(/*! ./native-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js\");\n/* harmony import */ var _native_panner_node_factory_factory__WEBPACK_IMPORTED_MODULE_297__ = __webpack_require__(/*! ./native-panner-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js\");\n/* harmony import */ var _native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_298__ = __webpack_require__(/*! ./native-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js\");\n/* harmony import */ var _native_panner_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_299__ = __webpack_require__(/*! ./native-panner-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js\");\n/* harmony import */ var _native_periodic_wave__WEBPACK_IMPORTED_MODULE_300__ = __webpack_require__(/*! ./native-periodic-wave */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js\");\n/* harmony import */ var _native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_301__ = __webpack_require__(/*! ./native-periodic-wave-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js\");\n/* harmony import */ var _native_periodic_wave_factory_factory__WEBPACK_IMPORTED_MODULE_302__ = __webpack_require__(/*! ./native-periodic-wave-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js\");\n/* harmony import */ var _native_script_processor_node__WEBPACK_IMPORTED_MODULE_303__ = __webpack_require__(/*! ./native-script-processor-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js\");\n/* harmony import */ var _native_script_processor_node_factory__WEBPACK_IMPORTED_MODULE_304__ = __webpack_require__(/*! ./native-script-processor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js\");\n/* harmony import */ var _native_stereo_panner_node__WEBPACK_IMPORTED_MODULE_305__ = __webpack_require__(/*! ./native-stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js\");\n/* harmony import */ var _native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_306__ = __webpack_require__(/*! ./native-stereo-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_factory_factory__WEBPACK_IMPORTED_MODULE_307__ = __webpack_require__(/*! ./native-stereo-panner-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_308__ = __webpack_require__(/*! ./native-stereo-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_309__ = __webpack_require__(/*! ./native-stereo-panner-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js\");\n/* harmony import */ var _native_wave_shaper_node__WEBPACK_IMPORTED_MODULE_310__ = __webpack_require__(/*! ./native-wave-shaper-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js\");\n/* harmony import */ var _native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_311__ = __webpack_require__(/*! ./native-wave-shaper-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_factory_factory__WEBPACK_IMPORTED_MODULE_312__ = __webpack_require__(/*! ./native-wave-shaper-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_313__ = __webpack_require__(/*! ./native-wave-shaper-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_314__ = __webpack_require__(/*! ./native-wave-shaper-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js\");\n/* harmony import */ var _not_supported_error_factory__WEBPACK_IMPORTED_MODULE_315__ = __webpack_require__(/*! ./not-supported-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js\");\n/* harmony import */ var _offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_316__ = __webpack_require__(/*! ./offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_317__ = __webpack_require__(/*! ./oscillator-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js\");\n/* harmony import */ var _oscillator_node_constructor_factory__WEBPACK_IMPORTED_MODULE_318__ = __webpack_require__(/*! ./oscillator-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js\");\n/* harmony import */ var _oscillator_node_renderer__WEBPACK_IMPORTED_MODULE_319__ = __webpack_require__(/*! ./oscillator-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js\");\n/* harmony import */ var _oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_320__ = __webpack_require__(/*! ./oscillator-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js\");\n/* harmony import */ var _oscillator_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_321__ = __webpack_require__(/*! ./oscillator-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js\");\n/* harmony import */ var _oscillator_type__WEBPACK_IMPORTED_MODULE_322__ = __webpack_require__(/*! ./oscillator-type */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js\");\n/* harmony import */ var _output_connection__WEBPACK_IMPORTED_MODULE_323__ = __webpack_require__(/*! ./output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/output-connection.js\");\n/* harmony import */ var _over_sample_type__WEBPACK_IMPORTED_MODULE_324__ = __webpack_require__(/*! ./over-sample-type */ \"./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js\");\n/* harmony import */ var _overwrite_accessors_function__WEBPACK_IMPORTED_MODULE_325__ = __webpack_require__(/*! ./overwrite-accessors-function */ \"./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js\");\n/* harmony import */ var _panner_node_constructor__WEBPACK_IMPORTED_MODULE_326__ = __webpack_require__(/*! ./panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js\");\n/* harmony import */ var _panner_node_constructor_factory__WEBPACK_IMPORTED_MODULE_327__ = __webpack_require__(/*! ./panner-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js\");\n/* harmony import */ var _panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_328__ = __webpack_require__(/*! ./panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js\");\n/* harmony import */ var _panner_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_329__ = __webpack_require__(/*! ./panner-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js\");\n/* harmony import */ var _panning_model_type__WEBPACK_IMPORTED_MODULE_330__ = __webpack_require__(/*! ./panning-model-type */ \"./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js\");\n/* harmony import */ var _passive_audio_node_input_connection__WEBPACK_IMPORTED_MODULE_331__ = __webpack_require__(/*! ./passive-audio-node-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js\");\n/* harmony import */ var _passive_audio_param_input_connection__WEBPACK_IMPORTED_MODULE_332__ = __webpack_require__(/*! ./passive-audio-param-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js\");\n/* harmony import */ var _periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_333__ = __webpack_require__(/*! ./periodic-wave-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js\");\n/* harmony import */ var _periodic_wave_constructor_factory__WEBPACK_IMPORTED_MODULE_334__ = __webpack_require__(/*! ./periodic-wave-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js\");\n/* harmony import */ var _pick_element_from_set_function__WEBPACK_IMPORTED_MODULE_335__ = __webpack_require__(/*! ./pick-element-from-set-function */ \"./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js\");\n/* harmony import */ var _render_automation_factory__WEBPACK_IMPORTED_MODULE_336__ = __webpack_require__(/*! ./render-automation-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js\");\n/* harmony import */ var _render_automation_function__WEBPACK_IMPORTED_MODULE_337__ = __webpack_require__(/*! ./render-automation-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js\");\n/* harmony import */ var _render_inputs_of_audio_node_factory__WEBPACK_IMPORTED_MODULE_338__ = __webpack_require__(/*! ./render-inputs-of-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js\");\n/* harmony import */ var _render_inputs_of_audio_node_function__WEBPACK_IMPORTED_MODULE_339__ = __webpack_require__(/*! ./render-inputs-of-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js\");\n/* harmony import */ var _render_inputs_of_audio_param_factory__WEBPACK_IMPORTED_MODULE_340__ = __webpack_require__(/*! ./render-inputs-of-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js\");\n/* harmony import */ var _render_inputs_of_audio_param_function__WEBPACK_IMPORTED_MODULE_341__ = __webpack_require__(/*! ./render-inputs-of-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js\");\n/* harmony import */ var _render_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_342__ = __webpack_require__(/*! ./render-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js\");\n/* harmony import */ var _render_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_343__ = __webpack_require__(/*! ./render-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js\");\n/* harmony import */ var _sanitize_audio_worklet_node_options_function__WEBPACK_IMPORTED_MODULE_344__ = __webpack_require__(/*! ./sanitize-audio-worklet-node-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js\");\n/* harmony import */ var _sanitize_channel_splitter_options_function__WEBPACK_IMPORTED_MODULE_345__ = __webpack_require__(/*! ./sanitize-channel-splitter-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js\");\n/* harmony import */ var _sanitize_periodic_wave_options_function__WEBPACK_IMPORTED_MODULE_346__ = __webpack_require__(/*! ./sanitize-periodic-wave-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js\");\n/* harmony import */ var _set_active_audio_worklet_node_inputs_factory__WEBPACK_IMPORTED_MODULE_347__ = __webpack_require__(/*! ./set-active-audio-worklet-node-inputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js\");\n/* harmony import */ var _set_active_audio_worklet_node_inputs_function__WEBPACK_IMPORTED_MODULE_348__ = __webpack_require__(/*! ./set-active-audio-worklet-node-inputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js\");\n/* harmony import */ var _set_audio_node_tail_time_factory__WEBPACK_IMPORTED_MODULE_349__ = __webpack_require__(/*! ./set-audio-node-tail-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js\");\n/* harmony import */ var _set_audio_node_tail_time_function__WEBPACK_IMPORTED_MODULE_350__ = __webpack_require__(/*! ./set-audio-node-tail-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js\");\n/* harmony import */ var _set_value_at_time_until_possible_function__WEBPACK_IMPORTED_MODULE_351__ = __webpack_require__(/*! ./set-value-at-time-until-possible-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js\");\n/* harmony import */ var _start_rendering_factory__WEBPACK_IMPORTED_MODULE_352__ = __webpack_require__(/*! ./start-rendering-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js\");\n/* harmony import */ var _start_rendering_function__WEBPACK_IMPORTED_MODULE_353__ = __webpack_require__(/*! ./start-rendering-function */ \"./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js\");\n/* harmony import */ var _stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_354__ = __webpack_require__(/*! ./stereo-panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js\");\n/* harmony import */ var _stereo_panner_node_constructor_factory__WEBPACK_IMPORTED_MODULE_355__ = __webpack_require__(/*! ./stereo-panner-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js\");\n/* harmony import */ var _stereo_panner_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_356__ = __webpack_require__(/*! ./stereo-panner-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js\");\n/* harmony import */ var _stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_357__ = __webpack_require__(/*! ./stereo-panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js\");\n/* harmony import */ var _test_audio_buffer_copy_channel_methods_subarray_support_factory__WEBPACK_IMPORTED_MODULE_358__ = __webpack_require__(/*! ./test-audio-buffer-copy-channel-methods-subarray-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js\");\n/* harmony import */ var _test_audio_buffer_constructor_support_factory__WEBPACK_IMPORTED_MODULE_359__ = __webpack_require__(/*! ./test-audio-buffer-constructor-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js\");\n/* harmony import */ var _test_audio_context_close_method_support_factory__WEBPACK_IMPORTED_MODULE_360__ = __webpack_require__(/*! ./test-audio-context-close-method-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js\");\n/* harmony import */ var _test_audio_context_decode_audio_data_method_type_error_support_factory__WEBPACK_IMPORTED_MODULE_361__ = __webpack_require__(/*! ./test-audio-context-decode-audio-data-method-type-error-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js\");\n/* harmony import */ var _test_audio_context_options_support_factory__WEBPACK_IMPORTED_MODULE_362__ = __webpack_require__(/*! ./test-audio-context-options-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js\");\n/* harmony import */ var _test_audio_node_connect_method_support_factory__WEBPACK_IMPORTED_MODULE_363__ = __webpack_require__(/*! ./test-audio-node-connect-method-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js\");\n/* harmony import */ var _test_audio_worklet_node_options_clonability_function__WEBPACK_IMPORTED_MODULE_364__ = __webpack_require__(/*! ./test-audio-worklet-node-options-clonability-function */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js\");\n/* harmony import */ var _test_audio_worklet_processor_no_outputs_support_factory__WEBPACK_IMPORTED_MODULE_365__ = __webpack_require__(/*! ./test-audio-worklet-processor-no-outputs-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js\");\n/* harmony import */ var _test_audio_worklet_processor_post_message_support_factory__WEBPACK_IMPORTED_MODULE_366__ = __webpack_require__(/*! ./test-audio-worklet-processor-post-message-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js\");\n/* harmony import */ var _test_channel_merger_node_channel_count_support_factory__WEBPACK_IMPORTED_MODULE_367__ = __webpack_require__(/*! ./test-channel-merger-node-channel-count-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js\");\n/* harmony import */ var _test_constant_source_node_accurate_scheduling_support_factory__WEBPACK_IMPORTED_MODULE_368__ = __webpack_require__(/*! ./test-constant-source-node-accurate-scheduling-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js\");\n/* harmony import */ var _test_convolver_node_buffer_reassignability_support_factory__WEBPACK_IMPORTED_MODULE_369__ = __webpack_require__(/*! ./test-convolver-node-buffer-reassignability-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js\");\n/* harmony import */ var _test_convolver_node_channel_count_support_factory__WEBPACK_IMPORTED_MODULE_370__ = __webpack_require__(/*! ./test-convolver-node-channel-count-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js\");\n/* harmony import */ var _test_is_secure_context_support_factory__WEBPACK_IMPORTED_MODULE_371__ = __webpack_require__(/*! ./test-is-secure-context-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js\");\n/* harmony import */ var _test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_372__ = __webpack_require__(/*! ./test-media-stream-audio-source-node-media-stream-without-audio-track-support */ \"./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js\");\n/* harmony import */ var _test_offline_audio_context_current_time_support_factory__WEBPACK_IMPORTED_MODULE_373__ = __webpack_require__(/*! ./test-offline-audio-context-current-time-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js\");\n/* harmony import */ var _test_stereo_panner_node_default_value_support_factory__WEBPACK_IMPORTED_MODULE_374__ = __webpack_require__(/*! ./test-stereo-panner-node-default-value-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js\");\n/* harmony import */ var _unknown_error_factory__WEBPACK_IMPORTED_MODULE_375__ = __webpack_require__(/*! ./unknown-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js\");\n/* harmony import */ var _unrendered_audio_worklet_node_store__WEBPACK_IMPORTED_MODULE_376__ = __webpack_require__(/*! ./unrendered-audio-worklet-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js\");\n/* harmony import */ var _unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_377__ = __webpack_require__(/*! ./unrendered-audio-worklet-nodes */ \"./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js\");\n/* harmony import */ var _wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_378__ = __webpack_require__(/*! ./wave-shaper-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js\");\n/* harmony import */ var _wave_shaper_node_constructor_factory__WEBPACK_IMPORTED_MODULE_379__ = __webpack_require__(/*! ./wave-shaper-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js\");\n/* harmony import */ var _wave_shaper_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_380__ = __webpack_require__(/*! ./wave-shaper-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js\");\n/* harmony import */ var _wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_381__ = __webpack_require__(/*! ./wave-shaper-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js\");\n/* harmony import */ var _window__WEBPACK_IMPORTED_MODULE_382__ = __webpack_require__(/*! ./window */ \"./node_modules/standardized-audio-context/build/es2019/types/window.js\");\n/* harmony import */ var _window_factory__WEBPACK_IMPORTED_MODULE_383__ = __webpack_require__(/*! ./window-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/window-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_factory__WEBPACK_IMPORTED_MODULE_384__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_function__WEBPACK_IMPORTED_MODULE_385__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_out_of_bounds_factory__WEBPACK_IMPORTED_MODULE_386__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_out_of_bounds_function__WEBPACK_IMPORTED_MODULE_387__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_start_method_offset_clamping_function__WEBPACK_IMPORTED_MODULE_388__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-start-method-offset-clamping-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_stop_method_nullified_buffer_factory__WEBPACK_IMPORTED_MODULE_389__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_stop_method_nullified_buffer_function__WEBPACK_IMPORTED_MODULE_390__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js\");\n/* harmony import */ var _wrap_audio_scheduled_source_node_stop_method_consecutive_calls_function__WEBPACK_IMPORTED_MODULE_391__ = __webpack_require__(/*! ./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js\");\n/* harmony import */ var _wrap_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_392__ = __webpack_require__(/*! ./wrap-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js\");\n/* harmony import */ var _wrap_channel_merger_node_function__WEBPACK_IMPORTED_MODULE_393__ = __webpack_require__(/*! ./wrap-channel-merger-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js\");\n/* harmony import */ var _wrap_event_listener_function__WEBPACK_IMPORTED_MODULE_394__ = __webpack_require__(/*! ./wrap-event-listener-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/index.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=insert-element-in-set-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=internal-state-event-listener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=invalid-access-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=invalid-state-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-active-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-param-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-dc-curve-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-param-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-part-of-a-cycle-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-passive-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-secure-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-supported-promise-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=monitor-connections-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=monitor-connections-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-listener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-param-map.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-biquad-filter-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-biquad-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-splitter-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-splitter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-context.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-context.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-delay-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-delay-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-event-target.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-gain-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-gain-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-element-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-destination-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-script-processor-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-script-processor-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=not-supported-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-type.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/output-connection.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/output-connection.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=output-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=over-sample-type.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=overwrite-accessors-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panning-model-type.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=passive-audio-node-input-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=passive-audio-param-input-connection.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=pick-element-from-set-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-automation-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-automation-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-param-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-param-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-audio-worklet-node-options-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-channel-splitter-options-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-periodic-wave-options-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-active-audio-worklet-node-inputs-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-active-audio-worklet-node-inputs-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-audio-node-tail-time-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-audio-node-tail-time-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-value-at-time-until-possible-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=start-rendering-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=start-rendering-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-buffer-constructor-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-subarray-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-close-method-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-decode-audio-data-method-type-error-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-options-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-node-connect-method-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-node-options-clonability-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-processor-no-outputs-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-processor-post-message-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-channel-merger-node-channel-count-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-constant-source-node-accurate-scheduling-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-convolver-node-buffer-reassignability-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-convolver-node-channel-count-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-is-secure-context-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js":
/*!****************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js ***!
  \****************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-offline-audio-context-current-time-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-stereo-panner-node-default-value-support-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unknown-error-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unrendered-audio-worklet-node-store.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unrendered-audio-worklet-nodes.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-constructor-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-constructor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-renderer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/window-factory.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/window-factory.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=window-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/window-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/window.js":
/*!******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/window.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=window.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/window.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-offset-clamping-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js ***!
  \***********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-channel-merger-node-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-event-listener-function.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js?");

/***/ }),

/***/ "./src/App.css":
/*!*********************!*\
  !*** ./src/App.css ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js */ \"./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/styleDomAPI.js */ \"./node_modules/style-loader/dist/runtime/styleDomAPI.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/insertBySelector.js */ \"./node_modules/style-loader/dist/runtime/insertBySelector.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js */ \"./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/insertStyleElement.js */ \"./node_modules/style-loader/dist/runtime/insertStyleElement.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! !../node_modules/style-loader/dist/runtime/styleTagTransform.js */ \"./node_modules/style-loader/dist/runtime/styleTagTransform.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var _node_modules_css_loader_dist_cjs_js_App_css__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! !!../node_modules/css-loader/dist/cjs.js!./App.css */ \"./node_modules/css-loader/dist/cjs.js!./src/App.css\");\n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n\nvar options = {};\n\noptions.styleTagTransform = (_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default());\noptions.setAttributes = (_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default());\n\n      options.insert = _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default().bind(null, \"head\");\n    \noptions.domAPI = (_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default());\noptions.insertStyleElement = (_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default());\n\nvar update = _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default()(_node_modules_css_loader_dist_cjs_js_App_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"], options);\n\n\n\n\n       /* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_node_modules_css_loader_dist_cjs_js_App_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"] && _node_modules_css_loader_dist_cjs_js_App_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals ? _node_modules_css_loader_dist_cjs_js_App_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals : undefined);\n\n\n//# sourceURL=webpack://react-demo/./src/App.css?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js":
/*!****************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar stylesInDOM = [];\n\nfunction getIndexByIdentifier(identifier) {\n  var result = -1;\n\n  for (var i = 0; i < stylesInDOM.length; i++) {\n    if (stylesInDOM[i].identifier === identifier) {\n      result = i;\n      break;\n    }\n  }\n\n  return result;\n}\n\nfunction modulesToDom(list, options) {\n  var idCountMap = {};\n  var identifiers = [];\n\n  for (var i = 0; i < list.length; i++) {\n    var item = list[i];\n    var id = options.base ? item[0] + options.base : item[0];\n    var count = idCountMap[id] || 0;\n    var identifier = \"\".concat(id, \" \").concat(count);\n    idCountMap[id] = count + 1;\n    var indexByIdentifier = getIndexByIdentifier(identifier);\n    var obj = {\n      css: item[1],\n      media: item[2],\n      sourceMap: item[3],\n      supports: item[4],\n      layer: item[5]\n    };\n\n    if (indexByIdentifier !== -1) {\n      stylesInDOM[indexByIdentifier].references++;\n      stylesInDOM[indexByIdentifier].updater(obj);\n    } else {\n      var updater = addElementStyle(obj, options);\n      options.byIndex = i;\n      stylesInDOM.splice(i, 0, {\n        identifier: identifier,\n        updater: updater,\n        references: 1\n      });\n    }\n\n    identifiers.push(identifier);\n  }\n\n  return identifiers;\n}\n\nfunction addElementStyle(obj, options) {\n  var api = options.domAPI(options);\n  api.update(obj);\n\n  var updater = function updater(newObj) {\n    if (newObj) {\n      if (newObj.css === obj.css && newObj.media === obj.media && newObj.sourceMap === obj.sourceMap && newObj.supports === obj.supports && newObj.layer === obj.layer) {\n        return;\n      }\n\n      api.update(obj = newObj);\n    } else {\n      api.remove();\n    }\n  };\n\n  return updater;\n}\n\nmodule.exports = function (list, options) {\n  options = options || {};\n  list = list || [];\n  var lastIdentifiers = modulesToDom(list, options);\n  return function update(newList) {\n    newList = newList || [];\n\n    for (var i = 0; i < lastIdentifiers.length; i++) {\n      var identifier = lastIdentifiers[i];\n      var index = getIndexByIdentifier(identifier);\n      stylesInDOM[index].references--;\n    }\n\n    var newLastIdentifiers = modulesToDom(newList, options);\n\n    for (var _i = 0; _i < lastIdentifiers.length; _i++) {\n      var _identifier = lastIdentifiers[_i];\n\n      var _index = getIndexByIdentifier(_identifier);\n\n      if (stylesInDOM[_index].references === 0) {\n        stylesInDOM[_index].updater();\n\n        stylesInDOM.splice(_index, 1);\n      }\n    }\n\n    lastIdentifiers = newLastIdentifiers;\n  };\n};\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertBySelector.js":
/*!********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertBySelector.js ***!
  \********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar memo = {};\n/* istanbul ignore next  */\n\nfunction getTarget(target) {\n  if (typeof memo[target] === \"undefined\") {\n    var styleTarget = document.querySelector(target); // Special case to return head of iframe instead of iframe itself\n\n    if (window.HTMLIFrameElement && styleTarget instanceof window.HTMLIFrameElement) {\n      try {\n        // This will throw an exception if access to iframe is blocked\n        // due to cross-origin restrictions\n        styleTarget = styleTarget.contentDocument.head;\n      } catch (e) {\n        // istanbul ignore next\n        styleTarget = null;\n      }\n    }\n\n    memo[target] = styleTarget;\n  }\n\n  return memo[target];\n}\n/* istanbul ignore next  */\n\n\nfunction insertBySelector(insert, style) {\n  var target = getTarget(insert);\n\n  if (!target) {\n    throw new Error(\"Couldn't find a style target. This probably means that the value for the 'insert' parameter is invalid.\");\n  }\n\n  target.appendChild(style);\n}\n\nmodule.exports = insertBySelector;\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/insertBySelector.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertStyleElement.js":
/*!**********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertStyleElement.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction insertStyleElement(options) {\n  var element = document.createElement(\"style\");\n  options.setAttributes(element, options.attributes);\n  options.insert(element, options.options);\n  return element;\n}\n\nmodule.exports = insertStyleElement;\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/insertStyleElement.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction setAttributesWithoutAttributes(styleElement) {\n  var nonce =  true ? __webpack_require__.nc : 0;\n\n  if (nonce) {\n    styleElement.setAttribute(\"nonce\", nonce);\n  }\n}\n\nmodule.exports = setAttributesWithoutAttributes;\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleDomAPI.js":
/*!***************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleDomAPI.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction apply(styleElement, options, obj) {\n  var css = \"\";\n\n  if (obj.supports) {\n    css += \"@supports (\".concat(obj.supports, \") {\");\n  }\n\n  if (obj.media) {\n    css += \"@media \".concat(obj.media, \" {\");\n  }\n\n  var needLayer = typeof obj.layer !== \"undefined\";\n\n  if (needLayer) {\n    css += \"@layer\".concat(obj.layer.length > 0 ? \" \".concat(obj.layer) : \"\", \" {\");\n  }\n\n  css += obj.css;\n\n  if (needLayer) {\n    css += \"}\";\n  }\n\n  if (obj.media) {\n    css += \"}\";\n  }\n\n  if (obj.supports) {\n    css += \"}\";\n  }\n\n  var sourceMap = obj.sourceMap;\n\n  if (sourceMap && typeof btoa !== \"undefined\") {\n    css += \"\\n/*# sourceMappingURL=data:application/json;base64,\".concat(btoa(unescape(encodeURIComponent(JSON.stringify(sourceMap)))), \" */\");\n  } // For old IE\n\n  /* istanbul ignore if  */\n\n\n  options.styleTagTransform(css, styleElement, options.options);\n}\n\nfunction removeStyleElement(styleElement) {\n  // istanbul ignore if\n  if (styleElement.parentNode === null) {\n    return false;\n  }\n\n  styleElement.parentNode.removeChild(styleElement);\n}\n/* istanbul ignore next  */\n\n\nfunction domAPI(options) {\n  var styleElement = options.insertStyleElement(options);\n  return {\n    update: function update(obj) {\n      apply(styleElement, options, obj);\n    },\n    remove: function remove() {\n      removeStyleElement(styleElement);\n    }\n  };\n}\n\nmodule.exports = domAPI;\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/styleDomAPI.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleTagTransform.js":
/*!*********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleTagTransform.js ***!
  \*********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction styleTagTransform(css, styleElement) {\n  if (styleElement.styleSheet) {\n    styleElement.styleSheet.cssText = css;\n  } else {\n    while (styleElement.firstChild) {\n      styleElement.removeChild(styleElement.firstChild);\n    }\n\n    styleElement.appendChild(document.createTextNode(css));\n  }\n}\n\nmodule.exports = styleTagTransform;\n\n//# sourceURL=webpack://react-demo/./node_modules/style-loader/dist/runtime/styleTagTransform.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/classes.js":
/*!************************************************!*\
  !*** ./node_modules/tone/build/esm/classes.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.AMOscillator),\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.AMSynth),\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Add),\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Analyser),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.AudioToGain),\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoWah),\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.BaseContext),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.BiquadFilter),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.BitCrusher),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Channel),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Chorus),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Clock),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Compressor),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Context),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.DCMeter),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Delay),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Distortion),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.DuoSynth),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.EQ3),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Emitter),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FFT),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.FMOscillator),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.FMSynth),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.FatOscillator),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FeedbackCombFilter),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.FeedbackDelay),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Follower),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Freeverb),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FrequencyEnvelope),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.FrequencyShifter),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Gain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GainToAudio),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Gate),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.GrainPlayer),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GreaterThanZero),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.IntervalTimeline),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.JCReverb),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.LFO),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Limiter),\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Loop),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.LowpassCombFilter),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MembraneSynth),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Merge),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MetalSynth),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideSplit),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.MidiClass),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Mono),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MonoSynth),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MultibandSplit),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Negate),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Noise),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.NoiseSynth),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.OfflineContext),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.OmniOscillator),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.OnePoleFilter),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.PWMOscillator),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Panner3D),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Param),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Pattern),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.PitchShift),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Players),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.PolySynth),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Pow),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.PulseOscillator),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Recorder),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Reverb),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.Sampler),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.ScaleExp),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Sequence),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Signal),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Split),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.StateTimeline),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.StereoWidener),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.SyncedSignal),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.Synth),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.ToneBufferSource),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.ToneEvent),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.ToneOscillatorNode),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TransportTimeClass),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Tremolo),\n/* harmony export */   \"Unit\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Unit),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.UserMedia),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Vibrato),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Volume),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.WaveShaper),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Waveform),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Zero),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.connectSeries),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.connectSignal),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.debug),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.gainToDb),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isUndef),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.mtof),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _core_index__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core/index */ \"./node_modules/tone/build/esm/core/index.js\");\n/* harmony import */ var _source_index__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./source/index */ \"./node_modules/tone/build/esm/source/index.js\");\n/* harmony import */ var _signal_index__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./signal/index */ \"./node_modules/tone/build/esm/signal/index.js\");\n/* harmony import */ var _instrument_index__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./instrument/index */ \"./node_modules/tone/build/esm/instrument/index.js\");\n/* harmony import */ var _event_index__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./event/index */ \"./node_modules/tone/build/esm/event/index.js\");\n/* harmony import */ var _effect_index__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./effect/index */ \"./node_modules/tone/build/esm/effect/index.js\");\n/* harmony import */ var _component_index__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./component/index */ \"./node_modules/tone/build/esm/component/index.js\");\n\n\n\n\n\n\n\n//# sourceMappingURL=classes.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/classes.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Analyser.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Analyser.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Analyser\": () => (/* binding */ Analyser)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _channel_Split__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n * Extracts FFT or Waveform data from the incoming signal.\n * @category Component\n */\nclass Analyser extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Analyser.getDefaults(), arguments, [\"type\", \"size\"]));\n        this.name = \"Analyser\";\n        /**\n         * The analyser node.\n         */\n        this._analysers = [];\n        /**\n         * The buffer that the FFT data is written to\n         */\n        this._buffers = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Analyser.getDefaults(), arguments, [\"type\", \"size\"]);\n        this.input = this.output = this._gain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        this._split = new _channel_Split__WEBPACK_IMPORTED_MODULE_2__.Split({\n            context: this.context,\n            channels: options.channels,\n        });\n        this.input.connect(this._split);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assertRange)(options.channels, 1);\n        // create the analysers\n        for (let channel = 0; channel < options.channels; channel++) {\n            this._analysers[channel] = this.context.createAnalyser();\n            this._split.connect(this._analysers[channel], channel, 0);\n        }\n        // set the values initially\n        this.size = options.size;\n        this.type = options.type;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            size: 1024,\n            smoothing: 0.8,\n            type: \"fft\",\n            channels: 1,\n        });\n    }\n    /**\n     * Run the analysis given the current settings. If [[channels]] = 1,\n     * it will return a Float32Array. If [[channels]] > 1, it will\n     * return an array of Float32Arrays where each index in the array\n     * represents the analysis done on a channel.\n     */\n    getValue() {\n        this._analysers.forEach((analyser, index) => {\n            const buffer = this._buffers[index];\n            if (this._type === \"fft\") {\n                analyser.getFloatFrequencyData(buffer);\n            }\n            else if (this._type === \"waveform\") {\n                analyser.getFloatTimeDomainData(buffer);\n            }\n        });\n        if (this.channels === 1) {\n            return this._buffers[0];\n        }\n        else {\n            return this._buffers;\n        }\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     */\n    get size() {\n        return this._analysers[0].frequencyBinCount;\n    }\n    set size(size) {\n        this._analysers.forEach((analyser, index) => {\n            analyser.fftSize = size * 2;\n            this._buffers[index] = new Float32Array(size);\n        });\n    }\n    /**\n     * The number of channels the analyser does the analysis on. Channel\n     * separation is done using [[Split]]\n     */\n    get channels() {\n        return this._analysers.length;\n    }\n    /**\n     * The analysis function returned by analyser.getValue(), either \"fft\" or \"waveform\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(type === \"waveform\" || type === \"fft\", `Analyser: invalid type: ${type}`);\n        this._type = type;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analysers[0].smoothingTimeConstant;\n    }\n    set smoothing(val) {\n        this._analysers.forEach(a => a.smoothingTimeConstant = val);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._analysers.forEach(a => a.disconnect());\n        this._split.dispose();\n        this._gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Analyser.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/Analyser.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/DCMeter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/DCMeter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DCMeter\": () => (/* binding */ DCMeter)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n\n\n/**\n * DCMeter gets the raw value of the input signal at the current time.\n *\n * @example\n * const meter = new Tone.DCMeter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * const level = meter.getValue();\n * @category Component\n */\nclass DCMeter extends _MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(DCMeter.getDefaults(), arguments));\n        this.name = \"DCMeter\";\n        this._analyser.type = \"waveform\";\n        this._analyser.size = 256;\n    }\n    /**\n     * Get the signal value of the incoming signal\n     */\n    getValue() {\n        const value = this._analyser.getValue();\n        return value[0];\n    }\n}\n//# sourceMappingURL=DCMeter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/DCMeter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/FFT.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/FFT.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FFT\": () => (/* binding */ FFT)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * Get the current frequency data of the connected audio source using a fast Fourier transform.\n * @category Component\n */\nclass FFT extends _MeterBase__WEBPACK_IMPORTED_MODULE_3__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(FFT.getDefaults(), arguments, [\"size\"]));\n        this.name = \"FFT\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(FFT.getDefaults(), arguments, [\"size\"]);\n        this.normalRange = options.normalRange;\n        this._analyser.type = \"fft\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            normalRange: false,\n            size: 1024,\n            smoothing: 0.8,\n        });\n    }\n    /**\n     * Gets the current frequency data from the connected audio source.\n     * Returns the frequency data of length [[size]] as a Float32Array of decibel values.\n     */\n    getValue() {\n        const values = this._analyser.getValue();\n        return values.map(v => this.normalRange ? (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.dbToGain)(v) : v);\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]] (i.e. the number of\n     * frequency bins). Large FFT sizes may be costly to compute.\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analyser.smoothing;\n    }\n    set smoothing(val) {\n        this._analyser.smoothing = val;\n    }\n    /**\n     * Returns the frequency value in hertz of each of the indices of the FFT's [[getValue]] response.\n     * @example\n     * const fft = new Tone.FFT(32);\n     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));\n     */\n    getFrequencyOfIndex(index) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);\n        return index * this.context.sampleRate / (this.size * 2);\n    }\n}\n//# sourceMappingURL=FFT.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/FFT.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Follower.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Follower.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Follower\": () => (/* binding */ Follower)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../filter/OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n/* harmony import */ var _signal_Abs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Abs */ \"./node_modules/tone/build/esm/signal/Abs.js\");\n\n\n\n\n/**\n * Follower is a simple envelope follower.\n * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.\n * ```\n *          +-----+    +---------------+\n * Input +--> Abs +----> OnePoleFilter +--> Output\n *          +-----+    +---------------+\n * ```\n * @category Component\n */\nclass Follower extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Follower.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Follower\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Follower.getDefaults(), arguments, [\"smoothing\"]);\n        this._abs = this.input = new _signal_Abs__WEBPACK_IMPORTED_MODULE_3__.Abs({ context: this.context });\n        this._lowpass = this.output = new _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_2__.OnePoleFilter({\n            context: this.context,\n            frequency: 1 / this.toSeconds(options.smoothing),\n            type: \"lowpass\"\n        });\n        this._abs.connect(this._lowpass);\n        this._smoothing = options.smoothing;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            smoothing: 0.05\n        });\n    }\n    /**\n     * The amount of time it takes a value change to arrive at the updated value.\n     */\n    get smoothing() {\n        return this._smoothing;\n    }\n    set smoothing(smoothing) {\n        this._smoothing = smoothing;\n        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);\n    }\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Follower.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/Follower.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Meter.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Meter.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Meter\": () => (/* binding */ Meter)\n/* harmony export */ });\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Analyser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n\n\n\n\n\n/**\n * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n * of an input signal. It can also get the raw value of the input signal.\n *\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * setInterval(() => console.log(meter.getValue()), 100);\n * @category Component\n */\nclass Meter extends _MeterBase__WEBPACK_IMPORTED_MODULE_2__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Meter.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Meter\";\n        /**\n         * The previous frame's value\n         */\n        this._rms = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Meter.getDefaults(), arguments, [\"smoothing\"]);\n        this.input = this.output = this._analyser = new _Analyser__WEBPACK_IMPORTED_MODULE_4__.Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n            channels: options.channels,\n        });\n        this.smoothing = options.smoothing,\n            this.normalRange = options.normalRange;\n    }\n    static getDefaults() {\n        return Object.assign(_MeterBase__WEBPACK_IMPORTED_MODULE_2__.MeterBase.getDefaults(), {\n            smoothing: 0.8,\n            normalRange: false,\n            channels: 1,\n        });\n    }\n    /**\n     * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.\n     * @deprecated\n     */\n    getLevel() {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.warn)(\"'getLevel' has been changed to 'getValue'\");\n        return this.getValue();\n    }\n    /**\n     * Get the current value of the incoming signal.\n     * Output is in decibels when [[normalRange]] is `false`.\n     * If [[channels]] = 1, then the output is a single number\n     * representing the value of the input signal. When [[channels]] > 1,\n     * then each channel is returned as a value in a number array.\n     */\n    getValue() {\n        const aValues = this._analyser.getValue();\n        const channelValues = this.channels === 1 ? [aValues] : aValues;\n        const vals = channelValues.map(values => {\n            const totalSquared = values.reduce((total, current) => total + current * current, 0);\n            const rms = Math.sqrt(totalSquared / values.length);\n            // the rms can only fall at the rate of the smoothing\n            // but can jump up instantly\n            this._rms = Math.max(rms, this._rms * this.smoothing);\n            return this.normalRange ? this._rms : (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.gainToDb)(this._rms);\n        });\n        if (this.channels === 1) {\n            return vals[0];\n        }\n        else {\n            return vals;\n        }\n    }\n    /**\n     * The number of channels of analysis.\n     */\n    get channels() {\n        return this._analyser.channels;\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Meter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/Meter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/MeterBase.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/MeterBase.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MeterBase\": () => (/* binding */ MeterBase)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Analyser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n\n\n\n/**\n * The base class for Metering classes.\n */\nclass MeterBase extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MeterBase.getDefaults(), arguments));\n        this.name = \"MeterBase\";\n        this.input = this.output = this._analyser = new _Analyser__WEBPACK_IMPORTED_MODULE_2__.Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MeterBase.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/MeterBase.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Waveform.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Waveform.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Waveform\": () => (/* binding */ Waveform)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n\n\n/**\n * Get the current waveform data of the connected audio source.\n * @category Component\n */\nclass Waveform extends _MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Waveform.getDefaults(), arguments, [\"size\"]));\n        this.name = \"Waveform\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Waveform.getDefaults(), arguments, [\"size\"]);\n        this._analyser.type = \"waveform\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(_MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase.getDefaults(), {\n            size: 1024,\n        });\n    }\n    /**\n     * Return the waveform for the current time as a Float32Array where each value in the array\n     * represents a sample in the waveform.\n     */\n    getValue() {\n        return this._analyser.getValue();\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]].\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n}\n//# sourceMappingURL=Waveform.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/analysis/Waveform.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Channel.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Channel.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Channel\": () => (/* binding */ Channel)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Solo__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Solo */ \"./node_modules/tone/build/esm/component/channel/Solo.js\");\n/* harmony import */ var _PanVol__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./PanVol */ \"./node_modules/tone/build/esm/component/channel/PanVol.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n\n\n\n/**\n * Channel provides a channel strip interface with volume, pan, solo and mute controls.\n * See [[PanVol]] and [[Solo]]\n * @example\n * // pan the incoming signal left and drop the volume 12db\n * const channel = new Tone.Channel(-0.25, -12);\n * @category Component\n */\nclass Channel extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]));\n        this.name = \"Channel\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]);\n        this._solo = this.input = new _Solo__WEBPACK_IMPORTED_MODULE_2__.Solo({\n            solo: options.solo,\n            context: this.context,\n        });\n        this._panVol = this.output = new _PanVol__WEBPACK_IMPORTED_MODULE_3__.PanVol({\n            context: this.context,\n            pan: options.pan,\n            volume: options.volume,\n            mute: options.mute,\n            channelCount: options.channelCount\n        });\n        this.pan = this._panVol.pan;\n        this.volume = this._panVol.volume;\n        this._solo.connect(this._panVol);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            pan: 0,\n            volume: 0,\n            mute: false,\n            solo: false,\n            channelCount: 1,\n        });\n    }\n    /**\n     * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances\n     */\n    get solo() {\n        return this._solo.solo;\n    }\n    set solo(solo) {\n        this._solo.solo = solo;\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed,\n     * or the channel is muted\n     */\n    get muted() {\n        return this._solo.muted || this.mute;\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._panVol.mute;\n    }\n    set mute(mute) {\n        this._panVol.mute = mute;\n    }\n    /**\n     * Get the gain node belonging to the bus name. Create it if\n     * it doesn't exist\n     * @param name The bus name\n     */\n    _getBus(name) {\n        if (!Channel.buses.has(name)) {\n            Channel.buses.set(name, new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context }));\n        }\n        return Channel.buses.get(name);\n    }\n    /**\n     * Send audio to another channel using a string. `send` is a lot like\n     * [[connect]], except it uses a string instead of an object. This can\n     * be useful in large applications to decouple sections since [[send]]\n     * and [[receive]] can be invoked separately in order to connect an object\n     * @param name The channel name to send the audio\n     * @param volume The amount of the signal to send.\n     * \tDefaults to 0db, i.e. send the entire signal\n     * @returns Returns the gain node of this connection.\n     */\n    send(name, volume = 0) {\n        const bus = this._getBus(name);\n        const sendKnob = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({\n            context: this.context,\n            units: \"decibels\",\n            gain: volume,\n        });\n        this.connect(sendKnob);\n        sendKnob.connect(bus);\n        return sendKnob;\n    }\n    /**\n     * Receive audio from a channel which was connected with [[send]].\n     * @param name The channel name to receive audio from.\n     */\n    receive(name) {\n        const bus = this._getBus(name);\n        bus.connect(this);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._panVol.dispose();\n        this.pan.dispose();\n        this.volume.dispose();\n        this._solo.dispose();\n        return this;\n    }\n}\n/**\n * Store the send/receive channels by name.\n */\nChannel.buses = new Map();\n//# sourceMappingURL=Channel.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Channel.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/CrossFade.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/CrossFade.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CrossFade\": () => (/* binding */ CrossFade)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_GainToAudio__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/GainToAudio */ \"./node_modules/tone/build/esm/signal/GainToAudio.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n\n\n/**\n * Tone.Crossfade provides equal power fading between two inputs.\n * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).\n * ```\n *                                             +---------+\n *                                            +> input a +>--+\n * +-----------+   +---------------------+     |         |   |\n * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |\n * +-----------+   |                     |     +---------+   |\n *               +-> pan               R +>-+                |   +--------+\n *               | +---------------------+  |                +---> output +>\n *  +------+     |                          |  +---------+   |   +--------+\n *  | fade +>----+                          | +> input b +>--+\n *  +------+                                |  |         |\n *                                          +--> gain    |\n *                                             +---------+\n * ```\n * @example\n * const crossFade = new Tone.CrossFade().toDestination();\n * // connect two inputs Tone.to a/b\n * const inputA = new Tone.Oscillator(440, \"square\").connect(crossFade.a).start();\n * const inputB = new Tone.Oscillator(440, \"sine\").connect(crossFade.b).start();\n * // use the fade to control the mix between the two\n * crossFade.fade.value = 0.5;\n * @category Component\n */\nclass CrossFade extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(CrossFade.getDefaults(), arguments, [\"fade\"])));\n        this.name = \"CrossFade\";\n        /**\n         * The crossfading is done by a StereoPannerNode\n         */\n        this._panner = this.context.createStereoPanner();\n        /**\n         * Split the output of the panner node into two values used to control the gains.\n         */\n        this._split = this.context.createChannelSplitter(2);\n        /**\n         * Convert the fade value into an audio range value so it can be connected\n         * to the panner.pan AudioParam\n         */\n        this._g2a = new _signal_GainToAudio__WEBPACK_IMPORTED_MODULE_4__.GainToAudio({ context: this.context });\n        /**\n         * The input which is at full level when fade = 0\n         */\n        this.a = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The input which is at full level when fade = 1\n         */\n        this.b = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output is a mix between `a` and `b` at the ratio of `fade`\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._internalChannels = [this.a, this.b];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(CrossFade.getDefaults(), arguments, [\"fade\"]);\n        this.fade = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"normalRange\",\n            value: options.fade,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"fade\");\n        this.context.getConstant(1).connect(this._panner);\n        this._panner.connect(this._split);\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = 1;\n        this._panner.channelCountMode = \"explicit\";\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this._split, this.a.gain, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this._split, this.b.gain, 1);\n        this.fade.chain(this._g2a, this._panner.pan);\n        this.a.connect(this.output);\n        this.b.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            fade: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.a.dispose();\n        this.b.dispose();\n        this.output.dispose();\n        this.fade.dispose();\n        this._g2a.dispose();\n        this._panner.disconnect();\n        this._split.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=CrossFade.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/CrossFade.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Merge.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Merge.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Merge\": () => (/* binding */ Merge)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n/**\n * Merge brings multiple mono input channels into a single multichannel output channel.\n *\n * @example\n * const merge = new Tone.Merge().toDestination();\n * // routing a sine tone in the left channel\n * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();\n * // and noise in the right channel\n * const noise = new Tone.Noise().connect(merge, 0, 1).start();;\n * @category Component\n */\nclass Merge extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Merge.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Merge\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Merge.getDefaults(), arguments, [\"channels\"]);\n        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._merger.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Merge.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Merge.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MidSideMerge.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MidSideMerge.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideMerge\": () => (/* binding */ MidSideMerge)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Merge__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n/**\n * MidSideMerge merges the mid and side signal after they've been separated by [[MidSideSplit]]\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nclass MidSideMerge extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_6__.optionsFromArguments)(MidSideMerge.getDefaults(), arguments));\n        this.name = \"MidSideMerge\";\n        this.mid = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this.side = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this._left = new _signal_Add__WEBPACK_IMPORTED_MODULE_2__.Add({ context: this.context });\n        this._leftMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._right = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__.Subtract({ context: this.context });\n        this._rightMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._merge = this.output = new _Merge__WEBPACK_IMPORTED_MODULE_1__.Merge({ context: this.context });\n        this.mid.fan(this._left);\n        this.side.connect(this._left.addend);\n        this.mid.connect(this._right);\n        this.side.connect(this._right.subtrahend);\n        this._left.connect(this._leftMult);\n        this._right.connect(this._rightMult);\n        this._leftMult.connect(this._merge, 0, 0);\n        this._rightMult.connect(this._merge, 0, 1);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._leftMult.dispose();\n        this._rightMult.dispose();\n        this._left.dispose();\n        this._right.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideMerge.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/MidSideMerge.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MidSideSplit.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MidSideSplit.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideSplit\": () => (/* binding */ MidSideSplit)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Split__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n/**\n * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels).\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nclass MidSideSplit extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.optionsFromArguments)(MidSideSplit.getDefaults(), arguments));\n        this.name = \"MidSideSplit\";\n        this._split = this.input = new _Split__WEBPACK_IMPORTED_MODULE_1__.Split({\n            channels: 2,\n            context: this.context\n        });\n        this._midAdd = new _signal_Add__WEBPACK_IMPORTED_MODULE_2__.Add({ context: this.context });\n        this.mid = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._sideSubtract = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__.Subtract({ context: this.context });\n        this.side = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._split.connect(this._midAdd, 0);\n        this._split.connect(this._midAdd.addend, 1);\n        this._split.connect(this._sideSubtract, 0);\n        this._split.connect(this._sideSubtract.subtrahend, 1);\n        this._midAdd.connect(this.mid);\n        this._sideSubtract.connect(this.side);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midAdd.dispose();\n        this._sideSubtract.dispose();\n        this._split.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideSplit.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/MidSideSplit.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Mono.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Mono.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Mono\": () => (/* binding */ Mono)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Merge__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n\n\n\n\n/**\n * Mono coerces the incoming mono or stereo signal into a mono signal\n * where both left and right channels have the same value. This can be useful\n * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).\n * @category Component\n */\nclass Mono extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Mono.getDefaults(), arguments));\n        this.name = \"Mono\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._merge = this.output = new _Merge__WEBPACK_IMPORTED_MODULE_3__.Merge({\n            channels: 2,\n            context: this.context,\n        });\n        this.input.connect(this._merge, 0, 0);\n        this.input.connect(this._merge, 0, 1);\n    }\n    dispose() {\n        super.dispose();\n        this._merge.dispose();\n        this.input.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Mono.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Mono.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MultibandSplit.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MultibandSplit.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MultibandSplit\": () => (/* binding */ MultibandSplit)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _filter_Filter__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n\n\n\n\n\n\n/**\n * Split the incoming signal into three bands (low, mid, high)\n * with two crossover frequency controls.\n * ```\n *            +----------------------+\n *          +-> input < lowFrequency +------------------> low\n *          | +----------------------+\n *          |\n *          | +--------------------------------------+\n * input ---+-> lowFrequency < input < highFrequency +--> mid\n *          | +--------------------------------------+\n *          |\n *          | +-----------------------+\n *          +-> highFrequency < input +-----------------> high\n *            +-----------------------+\n * ```\n * @category Component\n */\nclass MultibandSplit extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]));\n        this.name = \"MultibandSplit\";\n        /**\n         * the input\n         */\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * no output node, use either low, mid or high outputs\n         */\n        this.output = undefined;\n        /**\n         * The low band.\n         */\n        this.low = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * the lower filter of the mid band\n         */\n        this._lowMidFilter = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        /**\n         * The mid band output.\n         */\n        this.mid = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * The high band output.\n         */\n        this.high = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        this._internalChannels = [this.low, this.mid, this.high];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]);\n        this.lowFrequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.lowFrequency,\n        });\n        this.highFrequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.highFrequency,\n        });\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.input.fan(this.low, this.high);\n        this.input.chain(this._lowMidFilter, this.mid);\n        // the frequency control signal\n        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);\n        this.highFrequency.fan(this.mid.frequency, this.high.frequency);\n        // the Q value\n        this.Q.connect(this.low.Q);\n        this.Q.connect(this._lowMidFilter.Q);\n        this.Q.connect(this.mid.Q);\n        this.Q.connect(this.high.Q);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            highFrequency: 2500,\n            lowFrequency: 400,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n        this.low.dispose();\n        this._lowMidFilter.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandSplit.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/MultibandSplit.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/PanVol.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/PanVol.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PanVol\": () => (/* binding */ PanVol)\n/* harmony export */ });\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Panner__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _Volume__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n\n\n\n\n\n/**\n * PanVol is a Tone.Panner and Tone.Volume in one.\n * @example\n * // pan the incoming signal left and drop the volume\n * const panVol = new Tone.PanVol(-0.25, -12).toDestination();\n * const osc = new Tone.Oscillator().connect(panVol).start();\n * @category Component\n */\nclass PanVol extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]));\n        this.name = \"PanVol\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]);\n        this._panner = this.input = new _Panner__WEBPACK_IMPORTED_MODULE_3__.Panner({\n            context: this.context,\n            pan: options.pan,\n            channelCount: options.channelCount,\n        });\n        this.pan = this._panner.pan;\n        this._volume = this.output = new _Volume__WEBPACK_IMPORTED_MODULE_4__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        // connections\n        this._panner.connect(this._volume);\n        this.mute = options.mute;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_0__.readOnly)(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            pan: 0,\n            volume: 0,\n            channelCount: 1,\n        });\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        this.pan.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PanVol.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/PanVol.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Panner.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Panner.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Panner\": () => (/* binding */ Panner)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.\n * @example\n * return Tone.Offline(() => {\n * // move the input signal from right to left\n * \tconst panner = new Tone.Panner(1).toDestination();\n * \tpanner.pan.rampTo(-1, 0.5);\n * \tconst osc = new Tone.Oscillator(100).connect(panner).start();\n * }, 0.5, 2);\n * @category Component\n */\nclass Panner extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner.getDefaults(), arguments, [\"pan\"])));\n        this.name = \"Panner\";\n        /**\n         * the panner node\n         */\n        this._panner = this.context.createStereoPanner();\n        this.input = this._panner;\n        this.output = this._panner;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner.getDefaults(), arguments, [\"pan\"]);\n        this.pan = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.pan,\n            value: options.pan,\n            minValue: -1,\n            maxValue: 1,\n        });\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = options.channelCount;\n        this._panner.channelCountMode = \"explicit\";\n        // initial value\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"pan\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            pan: 0,\n            channelCount: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.pan.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Panner.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Panner3D.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Panner3D.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Panner3D\": () => (/* binding */ Panner3D)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Listener__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Listener */ \"./node_modules/tone/build/esm/core/context/Listener.js\");\n\n\n\n\n/**\n * A spatialized panner node which supports equalpower or HRTF panning.\n * @category Component\n */\nclass Panner3D extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]));\n        this.name = \"Panner3D\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]);\n        this._panner = this.input = this.output = this.context.createPanner();\n        // set some values\n        this.panningModel = options.panningModel;\n        this.maxDistance = options.maxDistance;\n        this.distanceModel = options.distanceModel;\n        this.coneOuterGain = options.coneOuterGain;\n        this.coneOuterAngle = options.coneOuterAngle;\n        this.coneInnerAngle = options.coneInnerAngle;\n        this.refDistance = options.refDistance;\n        this.rolloffFactor = options.rolloffFactor;\n        this.positionX = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionX,\n            value: options.positionX,\n        });\n        this.positionY = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionY,\n            value: options.positionY,\n        });\n        this.positionZ = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionZ,\n            value: options.positionZ,\n        });\n        this.orientationX = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationX,\n            value: options.orientationX,\n        });\n        this.orientationY = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationY,\n            value: options.orientationY,\n        });\n        this.orientationZ = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationZ,\n            value: options.orientationZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            coneInnerAngle: 360,\n            coneOuterAngle: 360,\n            coneOuterGain: 0,\n            distanceModel: \"inverse\",\n            maxDistance: 10000,\n            orientationX: 0,\n            orientationY: 0,\n            orientationZ: 0,\n            panningModel: \"equalpower\",\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            refDistance: 1,\n            rolloffFactor: 1,\n        });\n    }\n    /**\n     * Sets the position of the source in 3d space.\n     */\n    setPosition(x, y, z) {\n        this.positionX.value = x;\n        this.positionY.value = y;\n        this.positionZ.value = z;\n        return this;\n    }\n    /**\n     * Sets the orientation of the source in 3d space.\n     */\n    setOrientation(x, y, z) {\n        this.orientationX.value = x;\n        this.orientationY.value = y;\n        this.orientationZ.value = z;\n        return this;\n    }\n    /**\n     * The panning model. Either \"equalpower\" or \"HRTF\".\n     */\n    get panningModel() {\n        return this._panner.panningModel;\n    }\n    set panningModel(val) {\n        this._panner.panningModel = val;\n    }\n    /**\n     * A reference distance for reducing volume as source move further from the listener\n     */\n    get refDistance() {\n        return this._panner.refDistance;\n    }\n    set refDistance(val) {\n        this._panner.refDistance = val;\n    }\n    /**\n     * Describes how quickly the volume is reduced as source moves away from listener.\n     */\n    get rolloffFactor() {\n        return this._panner.rolloffFactor;\n    }\n    set rolloffFactor(val) {\n        this._panner.rolloffFactor = val;\n    }\n    /**\n     * The distance model used by,  \"linear\", \"inverse\", or \"exponential\".\n     */\n    get distanceModel() {\n        return this._panner.distanceModel;\n    }\n    set distanceModel(val) {\n        this._panner.distanceModel = val;\n    }\n    /**\n     * The angle, in degrees, inside of which there will be no volume reduction\n     */\n    get coneInnerAngle() {\n        return this._panner.coneInnerAngle;\n    }\n    set coneInnerAngle(val) {\n        this._panner.coneInnerAngle = val;\n    }\n    /**\n     * The angle, in degrees, outside of which the volume will be reduced\n     * to a constant value of coneOuterGain\n     */\n    get coneOuterAngle() {\n        return this._panner.coneOuterAngle;\n    }\n    set coneOuterAngle(val) {\n        this._panner.coneOuterAngle = val;\n    }\n    /**\n     * The gain outside of the coneOuterAngle\n     */\n    get coneOuterGain() {\n        return this._panner.coneOuterGain;\n    }\n    set coneOuterGain(val) {\n        this._panner.coneOuterGain = val;\n    }\n    /**\n     * The maximum distance between source and listener,\n     * after which the volume will not be reduced any further.\n     */\n    get maxDistance() {\n        return this._panner.maxDistance;\n    }\n    set maxDistance(val) {\n        this._panner.maxDistance = val;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.orientationX.dispose();\n        this.orientationY.dispose();\n        this.orientationZ.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner3D.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Panner3D.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Recorder.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Recorder.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Recorder\": () => (/* binding */ Recorder)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n/**\n * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer\n * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.\n * This is only natively supported in Chrome and Firefox.\n * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n * @example\n * const recorder = new Tone.Recorder();\n * const synth = new Tone.Synth().connect(recorder);\n * // start recording\n * recorder.start();\n * // generate a few notes\n * synth.triggerAttackRelease(\"C3\", 0.5);\n * synth.triggerAttackRelease(\"C4\", 0.5, \"+1\");\n * synth.triggerAttackRelease(\"C5\", 0.5, \"+2\");\n * // wait for the notes to end and stop the recording\n * setTimeout(async () => {\n * \t// the recorded audio is returned as a blob\n * \tconst recording = await recorder.stop();\n * \t// download the recording by creating an anchor element and blob url\n * \tconst url = URL.createObjectURL(recording);\n * \tconst anchor = document.createElement(\"a\");\n * \tanchor.download = \"recording.webm\";\n * \tanchor.href = url;\n * \tanchor.click();\n * }, 4000);\n * @category Component\n */\nclass Recorder extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Recorder.getDefaults(), arguments));\n        this.name = \"Recorder\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Recorder.getDefaults(), arguments);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({\n            context: this.context\n        });\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(Recorder.supported, \"Media Recorder API is not available\");\n        this._stream = this.context.createMediaStreamDestination();\n        this.input.connect(this._stream);\n        this._recorder = new MediaRecorder(this._stream.stream, {\n            mimeType: options.mimeType\n        });\n    }\n    static getDefaults() {\n        return _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults();\n    }\n    /**\n     * The mime type is the format that the audio is encoded in. For Chrome\n     * that is typically webm encoded as \"vorbis\".\n     */\n    get mimeType() {\n        return this._recorder.mimeType;\n    }\n    /**\n     * Test if your platform supports the Media Recorder API. If it's not available,\n     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n     */\n    static get supported() {\n        return _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__.theWindow !== null && Reflect.has(_core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__.theWindow, \"MediaRecorder\");\n    }\n    /**\n     * Get the playback state of the Recorder, either \"started\", \"stopped\" or \"paused\"\n     */\n    get state() {\n        if (this._recorder.state === \"inactive\") {\n            return \"stopped\";\n        }\n        else if (this._recorder.state === \"paused\") {\n            return \"paused\";\n        }\n        else {\n            return \"started\";\n        }\n    }\n    /**\n     * Start the Recorder. Returns a promise which resolves\n     * when the recorder has started.\n     */\n    start() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state !== \"started\", \"Recorder is already started\");\n            const startPromise = new Promise(done => {\n                const handleStart = () => {\n                    this._recorder.removeEventListener(\"start\", handleStart, false);\n                    done();\n                };\n                this._recorder.addEventListener(\"start\", handleStart, false);\n            });\n            this._recorder.start();\n            return yield startPromise;\n        });\n    }\n    /**\n     * Stop the recorder. Returns a promise with the recorded content until this point\n     * encoded as [[mimeType]]\n     */\n    stop() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state !== \"stopped\", \"Recorder is not started\");\n            const dataPromise = new Promise(done => {\n                const handleData = (e) => {\n                    this._recorder.removeEventListener(\"dataavailable\", handleData, false);\n                    done(e.data);\n                };\n                this._recorder.addEventListener(\"dataavailable\", handleData, false);\n            });\n            this._recorder.stop();\n            return yield dataPromise;\n        });\n    }\n    /**\n     * Pause the recorder\n     */\n    pause() {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state === \"started\", \"Recorder must be started\");\n        this._recorder.pause();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._stream.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Recorder.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Recorder.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Solo.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Solo.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Solo\": () => (/* binding */ Solo)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n/**\n * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,\n * it will mute all other instances of Solo.\n * @example\n * const soloA = new Tone.Solo().toDestination();\n * const oscA = new Tone.Oscillator(\"C4\", \"sawtooth\").connect(soloA);\n * const soloB = new Tone.Solo().toDestination();\n * const oscB = new Tone.Oscillator(\"E4\", \"square\").connect(soloB);\n * soloA.solo = true;\n * // no audio will pass through soloB\n * @category Component\n */\nclass Solo extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Solo.getDefaults(), arguments, [\"solo\"]));\n        this.name = \"Solo\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Solo.getDefaults(), arguments, [\"solo\"]);\n        this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n        });\n        if (!Solo._allSolos.has(this.context)) {\n            Solo._allSolos.set(this.context, new Set());\n        }\n        Solo._allSolos.get(this.context).add(this);\n        // set initially\n        this.solo = options.solo;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            solo: false,\n        });\n    }\n    /**\n     * Isolates this instance and mutes all other instances of Solo.\n     * Only one instance can be soloed at a time. A soloed\n     * instance will report `solo=false` when another instance is soloed.\n     */\n    get solo() {\n        return this._isSoloed();\n    }\n    set solo(solo) {\n        if (solo) {\n            this._addSolo();\n        }\n        else {\n            this._removeSolo();\n        }\n        Solo._allSolos.get(this.context).forEach(instance => instance._updateSolo());\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed\n     */\n    get muted() {\n        return this.input.gain.value === 0;\n    }\n    /**\n     * Add this to the soloed array\n     */\n    _addSolo() {\n        if (!Solo._soloed.has(this.context)) {\n            Solo._soloed.set(this.context, new Set());\n        }\n        Solo._soloed.get(this.context).add(this);\n    }\n    /**\n     * Remove this from the soloed array\n     */\n    _removeSolo() {\n        if (Solo._soloed.has(this.context)) {\n            Solo._soloed.get(this.context).delete(this);\n        }\n    }\n    /**\n     * Is this on the soloed array\n     */\n    _isSoloed() {\n        return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);\n    }\n    /**\n     * Returns true if no one is soloed\n     */\n    _noSolos() {\n        // either does not have any soloed added\n        return !Solo._soloed.has(this.context) ||\n            // or has a solo set but doesn't include any items\n            (Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0);\n    }\n    /**\n     * Solo the current instance and unsolo all other instances.\n     */\n    _updateSolo() {\n        if (this._isSoloed()) {\n            this.input.gain.value = 1;\n        }\n        else if (this._noSolos()) {\n            // no one is soloed\n            this.input.gain.value = 1;\n        }\n        else {\n            this.input.gain.value = 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        Solo._allSolos.get(this.context).delete(this);\n        this._removeSolo();\n        return this;\n    }\n}\n/**\n * Hold all of the solo'ed tracks belonging to a specific context\n */\nSolo._allSolos = new Map();\n/**\n * Hold the currently solo'ed instance(s)\n */\nSolo._soloed = new Map();\n//# sourceMappingURL=Solo.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Solo.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Split.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Split.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Split\": () => (/* binding */ Split)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n/**\n * Split splits an incoming signal into the number of given channels.\n *\n * @example\n * const split = new Tone.Split();\n * // stereoSignal.connect(split);\n * @category Component\n */\nclass Split extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Split.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Split\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Split.getDefaults(), arguments, [\"channels\"]);\n        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);\n        this._internalChannels = [this._splitter];\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Split.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Split.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Volume.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Volume.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Volume\": () => (/* binding */ Volume)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Volume is a simple volume node, useful for creating a volume fader.\n *\n * @example\n * const vol = new Tone.Volume(-12).toDestination();\n * const osc = new Tone.Oscillator().connect(vol).start();\n * @category Component\n */\nclass Volume extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Volume.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"Volume\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Volume.getDefaults(), arguments, [\"volume\"]);\n        this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.volume,\n            units: \"decibels\",\n        });\n        this.volume = this.output.gain;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"volume\");\n        this._unmutedVolume = options.volume;\n        // set the mute initially\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const vol = new Tone.Volume(-12).toDestination();\n     * const osc = new Tone.Oscillator().connect(vol).start();\n     * // mute the output\n     * vol.mute = true;\n     */\n    get mute() {\n        return this.volume.value === -Infinity;\n    }\n    set mute(mute) {\n        if (!this.mute && mute) {\n            this._unmutedVolume = this.volume.value;\n            // maybe it should ramp here?\n            this.volume.value = -Infinity;\n        }\n        else if (this.mute && !mute) {\n            this.volume.value = this._unmutedVolume;\n        }\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Volume.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/channel/Volume.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Compressor.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Compressor.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Compressor\": () => (/* binding */ Compressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Compressor is a thin wrapper around the Web Audio\n * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n * Compression reduces the volume of loud sounds or amplifies quiet sounds\n * by narrowing or \"compressing\" an audio signal's dynamic range.\n * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).\n * @example\n * const comp = new Tone.Compressor(-30, 3);\n * @category Component\n */\nclass Compressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]));\n        this.name = \"Compressor\";\n        /**\n         * the compressor node\n         */\n        this._compressor = this.context.createDynamicsCompressor();\n        this.input = this._compressor;\n        this.output = this._compressor;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]);\n        this.threshold = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.threshold.minValue,\n            maxValue: this._compressor.threshold.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.threshold,\n            units: \"decibels\",\n            value: options.threshold,\n        });\n        this.attack = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.attack.minValue,\n            maxValue: this._compressor.attack.maxValue,\n            context: this.context,\n            param: this._compressor.attack,\n            units: \"time\",\n            value: options.attack,\n        });\n        this.release = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.release.minValue,\n            maxValue: this._compressor.release.maxValue,\n            context: this.context,\n            param: this._compressor.release,\n            units: \"time\",\n            value: options.release,\n        });\n        this.knee = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.knee.minValue,\n            maxValue: this._compressor.knee.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.knee,\n            units: \"decibels\",\n            value: options.knee,\n        });\n        this.ratio = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.ratio.minValue,\n            maxValue: this._compressor.ratio.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.ratio,\n            units: \"positive\",\n            value: options.ratio,\n        });\n        // set the defaults\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"knee\", \"release\", \"attack\", \"ratio\", \"threshold\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            attack: 0.003,\n            knee: 30,\n            ratio: 12,\n            release: 0.25,\n            threshold: -24,\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.disconnect();\n        this.attack.dispose();\n        this.release.dispose();\n        this.threshold.dispose();\n        this.ratio.dispose();\n        this.knee.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Compressor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/dynamics/Compressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Gate.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Gate.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Gate\": () => (/* binding */ Gate)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _signal_GreaterThan__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../signal/GreaterThan */ \"./node_modules/tone/build/esm/signal/GreaterThan.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _analysis_Follower__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n\n\n\n\n\n\n/**\n * Gate only passes a signal through when the incoming\n * signal exceeds a specified threshold. It uses [[Follower]] to follow the ampltiude\n * of the incoming signal and compares it to the [[threshold]] value using [[GreaterThan]].\n *\n * @example\n * const gate = new Tone.Gate(-30, 0.2).toDestination();\n * const mic = new Tone.UserMedia().connect(gate);\n * // the gate will only pass through the incoming\n * // signal when it's louder than -30db\n * @category Component\n */\nclass Gate extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"])));\n        this.name = \"Gate\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"]);\n        this._follower = new _analysis_Follower__WEBPACK_IMPORTED_MODULE_3__.Follower({\n            context: this.context,\n            smoothing: options.smoothing,\n        });\n        this._gt = new _signal_GreaterThan__WEBPACK_IMPORTED_MODULE_1__.GreaterThan({\n            context: this.context,\n            value: (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(options.threshold),\n        });\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._gate = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        // connections\n        this.input.connect(this._gate);\n        // the control signal\n        this.input.chain(this._follower, this._gt, this._gate.gain);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            smoothing: 0.1,\n            threshold: -40\n        });\n    }\n    /**\n     * The threshold of the gate in decibels\n     */\n    get threshold() {\n        return (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.gainToDb)(this._gt.value);\n    }\n    set threshold(thresh) {\n        this._gt.value = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(thresh);\n    }\n    /**\n     * The attack/decay speed of the gate. See [[Follower.smoothing]]\n     */\n    get smoothing() {\n        return this._follower.smoothing;\n    }\n    set smoothing(smoothingTime) {\n        this._follower.smoothing = smoothingTime;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._follower.dispose();\n        this._gt.dispose();\n        this._gate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gate.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/dynamics/Gate.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Limiter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Limiter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Limiter\": () => (/* binding */ Limiter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n;\n/**\n * Limiter will limit the loudness of an incoming signal.\n * Under the hood it's composed of a [[Compressor]] with a fast attack\n * and release and max compression ratio.\n *\n * @example\n * const limiter = new Tone.Limiter(-20).toDestination();\n * const oscillator = new Tone.Oscillator().connect(limiter);\n * oscillator.start();\n * @category Component\n */\nclass Limiter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Limiter.getDefaults(), arguments, [\"threshold\"])));\n        this.name = \"Limiter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Limiter.getDefaults(), arguments, [\"threshold\"]);\n        this._compressor = this.input = this.output = new _Compressor__WEBPACK_IMPORTED_MODULE_2__.Compressor({\n            context: this.context,\n            ratio: 20,\n            attack: 0.003,\n            release: 0.01,\n            threshold: options.threshold\n        });\n        this.threshold = this._compressor.threshold;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"threshold\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            threshold: -12\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal.\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.dispose();\n        this.threshold.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Limiter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/dynamics/Limiter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideCompressor\": () => (/* binding */ MidSideCompressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * MidSideCompressor applies two different compressors to the [[mid]]\n * and [[side]] signal components of the input. See [[MidSideSplit]] and [[MidSideMerge]].\n * @category Component\n */\nclass MidSideCompressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MidSideCompressor.getDefaults(), arguments)));\n        this.name = \"MidSideCompressor\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MidSideCompressor.getDefaults(), arguments);\n        this._midSideSplit = this.input = new _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_3__.MidSideSplit({ context: this.context });\n        this._midSideMerge = this.output = new _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_4__.MidSideMerge({ context: this.context });\n        this.mid = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.mid, { context: this.context }));\n        this.side = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.side, { context: this.context }));\n        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);\n        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"mid\", \"side\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            side: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideCompressor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MultibandCompressor\": () => (/* binding */ MultibandCompressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n\n\n\n/**\n * A compressor with separate controls over low/mid/high dynamics. See [[Compressor]] and [[MultibandSplit]]\n *\n * @example\n * const multiband = new Tone.MultibandCompressor({\n * \tlowFrequency: 200,\n * \thighFrequency: 1300,\n * \tlow: {\n * \t\tthreshold: -12\n * \t}\n * });\n * @category Component\n */\nclass MultibandCompressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandCompressor.getDefaults(), arguments)));\n        this.name = \"MultibandCompressor\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandCompressor.getDefaults(), arguments);\n        this._splitter = this.input = new _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__.MultibandSplit({\n            context: this.context,\n            lowFrequency: options.lowFrequency,\n            highFrequency: options.highFrequency\n        });\n        this.lowFrequency = this._splitter.lowFrequency;\n        this.highFrequency = this._splitter.highFrequency;\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this.low = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.low, { context: this.context }));\n        this.mid = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.mid, { context: this.context }));\n        this.high = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.high, { context: this.context }));\n        // connect the compressor\n        this._splitter.low.chain(this.low, this.output);\n        this._splitter.mid.chain(this.mid, this.output);\n        this._splitter.high.chain(this.high, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            lowFrequency: 250,\n            highFrequency: 2000,\n            low: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            },\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            high: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.output.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandCompressor.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* binding */ AmplitudeEnvelope)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Envelope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n\n\n\n/**\n * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts\n * an audio signal as the input and will apply the envelope to the amplitude\n * of the signal.\n * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst ampEnv = new Tone.AmplitudeEnvelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 1.0,\n * \t\trelease: 0.8\n * \t}).toDestination();\n * \t// create an oscillator and connect it\n * \tconst osc = new Tone.Oscillator().connect(ampEnv).start();\n * \t// trigger the envelopes attack and release \"8t\" apart\n * \tampEnv.triggerAttackRelease(\"8t\");\n * }, 1.5, 1);\n * @category Component\n */\nclass AmplitudeEnvelope extends _Envelope__WEBPACK_IMPORTED_MODULE_2__.Envelope {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AmplitudeEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"AmplitudeEnvelope\";\n        this._gainNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n        this._sig.connect(this._gainNode.gain);\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AmplitudeEnvelope.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/Envelope.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/Envelope.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Envelope\": () => (/* binding */ Envelope)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n\n/**\n * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n * envelope generator. Envelope outputs a signal which\n * can be connected to an AudioParam or Tone.Signal.\n * ```\n *           /\\\n *          /  \\\n *         /    \\\n *        /      \\\n *       /        \\___________\n *      /                     \\\n *     /                       \\\n *    /                         \\\n *   /                           \\\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst env = new Tone.Envelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 0.5,\n * \t\trelease: 0.8,\n * \t}).toDestination();\n * \tenv.triggerAttackRelease(0.5);\n * }, 1.5, 1);\n * @category Component\n */\nclass Envelope extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"Envelope\";\n        /**\n         * the signal which is output.\n         */\n        this._sig = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: 0,\n        });\n        /**\n         * The output signal of the envelope\n         */\n        this.output = this._sig;\n        /**\n         * Envelope has no input\n         */\n        this.input = undefined;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this.attack = options.attack;\n        this.decay = options.decay;\n        this.sustain = options.sustain;\n        this.release = options.release;\n        this.attackCurve = options.attackCurve;\n        this.releaseCurve = options.releaseCurve;\n        this.decayCurve = options.decayCurve;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            attack: 0.01,\n            attackCurve: \"linear\",\n            decay: 0.1,\n            decayCurve: \"exponential\",\n            release: 1,\n            releaseCurve: \"exponential\",\n            sustain: 0.5,\n        });\n    }\n    /**\n     * Read the current value of the envelope. Useful for\n     * synchronizing visual output to the envelope.\n     */\n    get value() {\n        return this.getValueAtTime(this.now());\n    }\n    /**\n     * Get the curve\n     * @param  curve\n     * @param  direction  In/Out\n     * @return The curve name\n     */\n    _getCurve(curve, direction) {\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(curve)) {\n            return curve;\n        }\n        else {\n            // look up the name in the curves array\n            let curveName;\n            for (curveName in EnvelopeCurves) {\n                if (EnvelopeCurves[curveName][direction] === curve) {\n                    return curveName;\n                }\n            }\n            // return the custom curve\n            return curve;\n        }\n    }\n    /**\n     * Assign a the curve to the given name using the direction\n     * @param  name\n     * @param  direction In/Out\n     * @param  curve\n     */\n    _setCurve(name, direction, curve) {\n        // check if it's a valid type\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(curve) && Reflect.has(EnvelopeCurves, curve)) {\n            const curveDef = EnvelopeCurves[curve];\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isObject)(curveDef)) {\n                if (name !== \"_decayCurve\") {\n                    this[name] = curveDef[direction];\n                }\n            }\n            else {\n                this[name] = curveDef;\n            }\n        }\n        else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(curve) && name !== \"_decayCurve\") {\n            this[name] = curve;\n        }\n        else {\n            throw new Error(\"Envelope: invalid curve: \" + curve);\n        }\n    }\n    /**\n     * The shape of the attack.\n     * Can be any of these strings:\n     * * \"linear\"\n     * * \"exponential\"\n     * * \"sine\"\n     * * \"cosine\"\n     * * \"bounce\"\n     * * \"ripple\"\n     * * \"step\"\n     *\n     * Can also be an array which describes the curve. Values\n     * in the array are evenly subdivided and linearly\n     * interpolated over the duration of the attack.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope(0.4).toDestination();\n     * \tenv.attackCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get attackCurve() {\n        return this._getCurve(this._attackCurve, \"In\");\n    }\n    set attackCurve(curve) {\n        this._setCurve(\"_attackCurve\", \"In\", curve);\n    }\n    /**\n     * The shape of the release. See the attack curve types.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\trelease: 0.8\n     * \t}).toDestination();\n     * \tenv.triggerAttack();\n     * \t// release curve could also be defined by an array\n     * \tenv.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];\n     * \tenv.triggerRelease(0.2);\n     * }, 1, 1);\n     */\n    get releaseCurve() {\n        return this._getCurve(this._releaseCurve, \"Out\");\n    }\n    set releaseCurve(curve) {\n        this._setCurve(\"_releaseCurve\", \"Out\", curve);\n    }\n    /**\n     * The shape of the decay either \"linear\" or \"exponential\"\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\tsustain: 0.1,\n     * \t\tdecay: 0.5\n     * \t}).toDestination();\n     * \tenv.decayCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get decayCurve() {\n        return this._decayCurve;\n    }\n    set decayCurve(curve) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)([\"linear\", \"exponential\"].some(c => c === curve), `Invalid envelope curve: ${curve}`);\n        this._decayCurve = curve;\n    }\n    /**\n     * Trigger the attack/decay portion of the ADSR envelope.\n     * @param  time When the attack should start.\n     * @param velocity The velocity of the envelope scales the vales.\n     *                             number between 0-1\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the attack 0.5 seconds from now with a velocity of 0.2\n     * env.triggerAttack(\"+0.5\", 0.2);\n     */\n    triggerAttack(time, velocity = 1) {\n        this.log(\"triggerAttack\", time, velocity);\n        time = this.toSeconds(time);\n        const originalAttack = this.toSeconds(this.attack);\n        let attack = originalAttack;\n        const decay = this.toSeconds(this.decay);\n        // check if it's not a complete attack\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            // subtract the current value from the attack time\n            const attackRate = 1 / attack;\n            const remainingDistance = 1 - currentValue;\n            // the attack is now the remaining time\n            attack = remainingDistance / attackRate;\n        }\n        // attack\n        if (attack < this.sampleTime) {\n            this._sig.cancelScheduledValues(time);\n            // case where the attack time is 0 should set instantly\n            this._sig.setValueAtTime(velocity, time);\n        }\n        else if (this._attackCurve === \"linear\") {\n            this._sig.linearRampTo(velocity, attack, time);\n        }\n        else if (this._attackCurve === \"exponential\") {\n            this._sig.targetRampTo(velocity, attack, time);\n        }\n        else {\n            this._sig.cancelAndHoldAtTime(time);\n            let curve = this._attackCurve;\n            // find the starting position in the curve\n            for (let i = 1; i < curve.length; i++) {\n                // the starting index is between the two values\n                if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {\n                    curve = this._attackCurve.slice(i);\n                    // the first index is the current value\n                    curve[0] = currentValue;\n                    break;\n                }\n            }\n            this._sig.setValueCurveAtTime(curve, time, attack, velocity);\n        }\n        // decay\n        if (decay && this.sustain < 1) {\n            const decayValue = velocity * this.sustain;\n            const decayStart = time + attack;\n            this.log(\"decay\", decayStart);\n            if (this._decayCurve === \"linear\") {\n                this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);\n            }\n            else {\n                this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);\n            }\n        }\n        return this;\n    }\n    /**\n     * Triggers the release of the envelope.\n     * @param  time When the release portion of the envelope should start.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator({\n     * \ttype: \"sawtooth\"\n     * }).connect(env).start();\n     * env.triggerAttack();\n     * // trigger the release half a second after the attack\n     * env.triggerRelease(\"+0.5\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        time = this.toSeconds(time);\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            const release = this.toSeconds(this.release);\n            if (release < this.sampleTime) {\n                this._sig.setValueAtTime(0, time);\n            }\n            else if (this._releaseCurve === \"linear\") {\n                this._sig.linearRampTo(0, release, time);\n            }\n            else if (this._releaseCurve === \"exponential\") {\n                this._sig.targetRampTo(0, release, time);\n            }\n            else {\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(this._releaseCurve), \"releaseCurve must be either 'linear', 'exponential' or an array\");\n                this._sig.cancelAndHoldAtTime(time);\n                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);\n            }\n        }\n        return this;\n    }\n    /**\n     * Get the scheduled value at the given time. This will\n     * return the unconverted (raw) value.\n     * @example\n     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);\n     * env.triggerAttackRelease(2);\n     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);\n     */\n    getValueAtTime(time) {\n        return this._sig.getValueAtTime(time);\n    }\n    /**\n     * triggerAttackRelease is shorthand for triggerAttack, then waiting\n     * some duration, then triggerRelease.\n     * @param duration The duration of the sustain.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity of the envelope.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the release 0.5 seconds after the attack\n     * env.triggerAttackRelease(0.5);\n     */\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + this.toSeconds(duration));\n        return this;\n    }\n    /**\n     * Cancels all scheduled envelope changes after the given time.\n     */\n    cancel(after) {\n        this._sig.cancelScheduledValues(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * Connect the envelope to a destination node.\n     */\n    connect(destination, outputNumber = 0, inputNumber = 0) {\n        (0,_signal_Signal__WEBPACK_IMPORTED_MODULE_3__.connectSignal)(this, destination, outputNumber, inputNumber);\n        return this;\n    }\n    /**\n     * Render the envelope curve to an array of the given length.\n     * Good for visualizing the envelope curve. Rescales the duration of the\n     * envelope to fit the length.\n     */\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const duration = length / this.context.sampleRate;\n            const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__.OfflineContext(1, duration, this.context.sampleRate);\n            // normalize the ADSR for the given duration with 20% sustain time\n            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);\n            const envelopeDuration = attackPortion + this.toSeconds(this.release);\n            const sustainTime = envelopeDuration * 0.1;\n            const totalDuration = envelopeDuration + sustainTime;\n            // @ts-ignore\n            const clone = new this.constructor(Object.assign(this.get(), {\n                attack: duration * this.toSeconds(this.attack) / totalDuration,\n                decay: duration * this.toSeconds(this.decay) / totalDuration,\n                release: duration * this.toSeconds(this.release) / totalDuration,\n                context\n            }));\n            clone._sig.toDestination();\n            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);\n            const buffer = yield context.render();\n            return buffer.getChannelData(0);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sig.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"attack\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"decay\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.range)(0, 1)\n], Envelope.prototype, \"sustain\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"release\", void 0);\n/**\n * Generate some complex envelope curves.\n */\nconst EnvelopeCurves = (() => {\n    const curveLen = 128;\n    let i;\n    let k;\n    // cosine curve\n    const cosineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        cosineCurve[i] = Math.sin((i / (curveLen - 1)) * (Math.PI / 2));\n    }\n    // ripple curve\n    const rippleCurve = [];\n    const rippleCurveFreq = 6.4;\n    for (i = 0; i < curveLen - 1; i++) {\n        k = (i / (curveLen - 1));\n        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;\n        rippleCurve[i] = sineWave / 10 + k * 0.83;\n    }\n    rippleCurve[curveLen - 1] = 1;\n    // stairs curve\n    const stairsCurve = [];\n    const steps = 5;\n    for (i = 0; i < curveLen; i++) {\n        stairsCurve[i] = Math.ceil((i / (curveLen - 1)) * steps) / steps;\n    }\n    // in-out easing curve\n    const sineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));\n    }\n    // a bounce curve\n    const bounceCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        const freq = Math.pow(k, 3) * 4 + 0.2;\n        const val = Math.cos(freq * Math.PI * 2 * k);\n        bounceCurve[i] = Math.abs(val * (1 - k));\n    }\n    /**\n     * Invert a value curve to make it work for the release\n     */\n    function invertCurve(curve) {\n        const out = new Array(curve.length);\n        for (let j = 0; j < curve.length; j++) {\n            out[j] = 1 - curve[j];\n        }\n        return out;\n    }\n    /**\n     * reverse the curve\n     */\n    function reverseCurve(curve) {\n        return curve.slice(0).reverse();\n    }\n    /**\n     * attack and release curve arrays\n     */\n    return {\n        bounce: {\n            In: invertCurve(bounceCurve),\n            Out: bounceCurve,\n        },\n        cosine: {\n            In: cosineCurve,\n            Out: reverseCurve(cosineCurve),\n        },\n        exponential: \"exponential\",\n        linear: \"linear\",\n        ripple: {\n            In: rippleCurve,\n            Out: invertCurve(rippleCurve),\n        },\n        sine: {\n            In: sineCurve,\n            Out: invertCurve(sineCurve),\n        },\n        step: {\n            In: stairsCurve,\n            Out: invertCurve(stairsCurve),\n        },\n    };\n})();\n//# sourceMappingURL=Envelope.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/envelope/Envelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FrequencyEnvelope\": () => (/* binding */ FrequencyEnvelope)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Pow__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * FrequencyEnvelope is an [[Envelope]] which ramps between [[baseFrequency]]\n * and [[octaves]]. It can also have an optional [[exponent]] to adjust the curve\n * which it ramps.\n * @example\n * const oscillator = new Tone.Oscillator().toDestination().start();\n * const freqEnv = new Tone.FrequencyEnvelope({\n * \tattack: 0.2,\n * \tbaseFrequency: \"C2\",\n * \toctaves: 4\n * });\n * freqEnv.connect(oscillator.frequency);\n * freqEnv.triggerAttack();\n * @category Component\n */\nclass FrequencyEnvelope extends _Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"FrequencyEnvelope\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this._octaves = options.octaves;\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._exponent = this.input = new _signal_Pow__WEBPACK_IMPORTED_MODULE_3__.Pow({\n            context: this.context,\n            value: options.exponent\n        });\n        this._scale = this.output = new _signal_Scale__WEBPACK_IMPORTED_MODULE_2__.Scale({\n            context: this.context,\n            min: this._baseFrequency,\n            max: this._baseFrequency * Math.pow(2, this._octaves),\n        });\n        this._sig.chain(this._exponent, this._scale);\n    }\n    static getDefaults() {\n        return Object.assign(_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), {\n            baseFrequency: 200,\n            exponent: 1,\n            octaves: 4,\n        });\n    }\n    /**\n     * The envelope's minimum output value. This is the value which it\n     * starts at.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(min) {\n        const freq = this.toFrequency(min);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assertRange)(freq, 0);\n        this._baseFrequency = freq;\n        this._scale.min = this._baseFrequency;\n        // update the max value when the min changes\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the baseFrequency that the\n     * envelope will scale to.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        this._scale.max = this._baseFrequency * Math.pow(2, octaves);\n    }\n    /**\n     * The envelope's exponent value.\n     */\n    get exponent() {\n        return this._exponent.value;\n    }\n    set exponent(exponent) {\n        this._exponent.value = exponent;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._exponent.dispose();\n        this._scale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyEnvelope.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/BiquadFilter.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/BiquadFilter.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BiquadFilter\": () => (/* binding */ BiquadFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n/**\n * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).\n * BiquadFilter is similar to [[Filter]] but doesn't have the option to set the \"rolloff\" value.\n * @category Component\n */\nclass BiquadFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(BiquadFilter.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"BiquadFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(BiquadFilter.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this._filter = this.context.createBiquadFilter();\n        this.input = this.output = this._filter;\n        this.Q = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"number\",\n            value: options.Q,\n            param: this._filter.Q,\n        });\n        this.frequency = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n            param: this._filter.frequency,\n        });\n        this.detune = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n            param: this._filter.detune,\n        });\n        this.gain = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"decibels\",\n            convert: false,\n            value: options.gain,\n            param: this._filter.gain,\n        });\n        this.type = options.type;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            type: \"lowpass\",\n            frequency: 350,\n            detune: 0,\n            gain: 0,\n        });\n    }\n    /**\n     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the\n     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)\n     */\n    get type() {\n        return this._filter.type;\n    }\n    set type(type) {\n        const types = [\"lowpass\", \"highpass\", \"bandpass\",\n            \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);\n        this._filter.type = type;\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        // start with all 1s\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        // clone the filter to remove any connections which may be changing the value\n        const filterClone = this.context.createBiquadFilter();\n        filterClone.type = this.type;\n        filterClone.Q.value = this.Q.value;\n        filterClone.frequency.value = this.frequency.value;\n        filterClone.gain.value = this.gain.value;\n        filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);\n        return magValues;\n    }\n    dispose() {\n        super.dispose();\n        this._filter.disconnect();\n        this.Q.dispose();\n        this.frequency.dispose();\n        this.gain.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=BiquadFilter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/BiquadFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/Convolver.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/Convolver.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Convolver\": () => (/* binding */ Convolver)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Convolver is a wrapper around the Native Web Audio\n * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).\n *\n * @example\n * // initializing the convolver with an impulse response\n * const convolver = new Tone.Convolver(\"./path/to/ir.wav\").toDestination();\n * @category Component\n */\nclass Convolver extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Convolver\";\n        /**\n         * The native ConvolverNode\n         */\n        this._convolver = this.context.createConvolver();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffer(options.url, buffer => {\n            this.buffer = buffer;\n            options.onload();\n        });\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        // set if it's already loaded, set it immediately\n        if (this._buffer.loaded) {\n            this.buffer = this._buffer;\n        }\n        // initially set normalization\n        this.normalize = options.normalize;\n        // connect it up\n        this.input.chain(this._convolver, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            normalize: true,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n        });\n    }\n    /**\n     * Load an impulse response url as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            this.buffer = yield this._buffer.load(url);\n        });\n    }\n    /**\n     * The convolver's buffer\n     */\n    get buffer() {\n        if (this._buffer.length) {\n            return this._buffer;\n        }\n        else {\n            return null;\n        }\n    }\n    set buffer(buffer) {\n        if (buffer) {\n            this._buffer.set(buffer);\n        }\n        // if it's already got a buffer, create a new one\n        if (this._convolver.buffer) {\n            // disconnect the old one\n            this.input.disconnect();\n            this._convolver.disconnect();\n            // create and connect a new one\n            this._convolver = this.context.createConvolver();\n            this.input.chain(this._convolver, this.output);\n        }\n        const buff = this._buffer.get();\n        this._convolver.buffer = buff ? buff : null;\n    }\n    /**\n     * The normalize property of the ConvolverNode interface is a boolean that\n     * controls whether the impulse response from the buffer will be scaled by\n     * an equal-power normalization when the buffer attribute is set, or not.\n     */\n    get normalize() {\n        return this._convolver.normalize;\n    }\n    set normalize(norm) {\n        this._convolver.normalize = norm;\n    }\n    dispose() {\n        super.dispose();\n        this._buffer.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Convolver.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/Convolver.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/EQ3.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/EQ3.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EQ3\": () => (/* binding */ EQ3)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n\n\n\n\n\n/**\n * EQ3 provides 3 equalizer bins: Low/Mid/High.\n * @category Component\n */\nclass EQ3 extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]));\n        this.name = \"EQ3\";\n        /**\n         * the output\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._internalChannels = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]);\n        this.input = this._multibandSplit = new _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__.MultibandSplit({\n            context: this.context,\n            highFrequency: options.highFrequency,\n            lowFrequency: options.lowFrequency,\n        });\n        this._lowGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.low,\n            units: \"decibels\",\n        });\n        this._midGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.mid,\n            units: \"decibels\",\n        });\n        this._highGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.high,\n            units: \"decibels\",\n        });\n        this.low = this._lowGain.gain;\n        this.mid = this._midGain.gain;\n        this.high = this._highGain.gain;\n        this.Q = this._multibandSplit.Q;\n        this.lowFrequency = this._multibandSplit.lowFrequency;\n        this.highFrequency = this._multibandSplit.highFrequency;\n        // the frequency bands\n        this._multibandSplit.low.chain(this._lowGain, this.output);\n        this._multibandSplit.mid.chain(this._midGain, this.output);\n        this._multibandSplit.high.chain(this._highGain, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._internalChannels = [this._multibandSplit];\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            high: 0,\n            highFrequency: 2500,\n            low: 0,\n            lowFrequency: 400,\n            mid: 0,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._multibandSplit.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this._lowGain.dispose();\n        this._midGain.dispose();\n        this._highGain.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=EQ3.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/EQ3.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackCombFilter\": () => (/* binding */ FeedbackCombFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/worklet/ToneAudioWorklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js\");\n/* harmony import */ var _FeedbackCombFilter_worklet__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./FeedbackCombFilter.worklet */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js\");\n\n\n\n\n\n\n\n/**\n * Comb filters are basic building blocks for physical modeling. Read more\n * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).\n *\n * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the\n * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the\n * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.\n * @category Component\n */\nclass FeedbackCombFilter extends _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_5__.ToneAudioWorklet {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]));\n        this.name = \"FeedbackCombFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.delayTime = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            value: options.delayTime,\n            units: \"time\",\n            minValue: 0,\n            maxValue: 1,\n            param: this._dummyParam,\n            swappable: true,\n        });\n        this.resonance = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            value: options.resonance,\n            units: \"normalRange\",\n            param: this._dummyParam,\n            swappable: true,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"resonance\", \"delayTime\"]);\n    }\n    _audioWorkletName() {\n        return _FeedbackCombFilter_worklet__WEBPACK_IMPORTED_MODULE_6__.workletName;\n    }\n    /**\n     * The default parameters\n     */\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults(), {\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    onReady(node) {\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.connectSeries)(this.input, node, this.output);\n        const delayTime = node.parameters.get(\"delayTime\");\n        ;\n        this.delayTime.setParam(delayTime);\n        const feedback = node.parameters.get(\"feedback\");\n        ;\n        this.resonance.setParam(feedback);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.delayTime.dispose();\n        this.resonance.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackCombFilter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"workletName\": () => (/* binding */ workletName)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_SingleIOProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/worklet/SingleIOProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js\");\n/* harmony import */ var _core_worklet_DelayLine_worklet__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/worklet/DelayLine.worklet */ \"./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js\");\n/* harmony import */ var _core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/worklet/WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\n\nconst workletName = \"feedback-comb-filter\";\nconst feedbackCombFilter = /* javascript */ `\n\tclass FeedbackCombFilterWorklet extends SingleIOProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(options);\n\t\t\tthis.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);\n\t\t}\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"delayTime\",\n\t\t\t\tdefaultValue: 0.1,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 1,\n\t\t\t\tautomationRate: \"k-rate\"\n\t\t\t}, {\n\t\t\t\tname: \"feedback\",\n\t\t\t\tdefaultValue: 0.5,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 0.9999,\n\t\t\t\tautomationRate: \"k-rate\"\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, channel, parameters) {\n\t\t\tconst delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);\n\t\t\tthis.delayLine.push(channel, input + delayedSample * parameters.feedback);\n\t\t\treturn delayedSample;\n\t\t}\n\t}\n`;\n(0,_core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__.registerProcessor)(workletName, feedbackCombFilter);\n//# sourceMappingURL=FeedbackCombFilter.worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/Filter.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/Filter.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Filter\": () => (/* binding */ Filter)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./BiquadFilter */ \"./node_modules/tone/build/esm/component/filter/BiquadFilter.js\");\n\n\n\n\n\n\n\n\n/**\n * Tone.Filter is a filter which allows for all of the same native methods\n * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n * Tone.Filter has the added ability to set the filter rolloff at -12\n * (default), -24 and -48.\n * @example\n * const filter = new Tone.Filter(1500, \"highpass\").toDestination();\n * filter.frequency.rampTo(20000, 10);\n * const noise = new Tone.Noise().connect(filter).start();\n * @category Component\n */\nclass Filter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]));\n        this.name = \"Filter\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._filters = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]);\n        this._filters = [];\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.gain = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"decibels\",\n            convert: false,\n            value: options.gain,\n        });\n        this._type = options.type;\n        this.rolloff = options.rolloff;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            detune: 0,\n            frequency: 350,\n            gain: 0,\n            rolloff: -12,\n            type: \"lowpass\",\n        });\n    }\n    /**\n     * The type of the filter. Types: \"lowpass\", \"highpass\",\n     * \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", or \"peaking\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        const types = [\"lowpass\", \"highpass\", \"bandpass\",\n            \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);\n        this._type = type;\n        this._filters.forEach(filter => filter.type = type);\n    }\n    /**\n     * The rolloff of the filter which is the drop in db\n     * per octave. Implemented internally by cascading filters.\n     * Only accepts the values -12, -24, -48 and -96.\n     */\n    get rolloff() {\n        return this._rolloff;\n    }\n    set rolloff(rolloff) {\n        const rolloffNum = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isNumber)(rolloff) ? rolloff : parseInt(rolloff, 10);\n        const possibilities = [-12, -24, -48, -96];\n        let cascadingCount = possibilities.indexOf(rolloffNum);\n        // check the rolloff is valid\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(cascadingCount !== -1, `rolloff can only be ${possibilities.join(\", \")}`);\n        cascadingCount += 1;\n        this._rolloff = rolloffNum;\n        this.input.disconnect();\n        this._filters.forEach(filter => filter.disconnect());\n        this._filters = new Array(cascadingCount);\n        for (let count = 0; count < cascadingCount; count++) {\n            const filter = new _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__.BiquadFilter({\n                context: this.context,\n            });\n            filter.type = this._type;\n            this.frequency.connect(filter.frequency);\n            this.detune.connect(filter.detune);\n            this.Q.connect(filter.Q);\n            this.gain.connect(filter.gain);\n            this._filters[count] = filter;\n        }\n        this._internalChannels = this._filters;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._internalChannels, this.output);\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        const filterClone = new _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__.BiquadFilter({\n            frequency: this.frequency.value,\n            gain: this.gain.value,\n            Q: this.Q.value,\n            type: this._type,\n            detune: this.detune.value,\n        });\n        // start with all 1s\n        const totalResponse = new Float32Array(len).map(() => 1);\n        this._filters.forEach(() => {\n            const response = filterClone.getFrequencyResponse(len);\n            response.forEach((val, i) => totalResponse[i] *= val);\n        });\n        filterClone.dispose();\n        return totalResponse;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._filters.forEach(filter => {\n            filter.dispose();\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n        this.frequency.dispose();\n        this.Q.dispose();\n        this.detune.dispose();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Filter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/Filter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LowpassCombFilter\": () => (/* binding */ LowpassCombFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _OnePoleFilter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n\n\n\n\n/**\n * A lowpass feedback comb filter. It is similar to\n * [[FeedbackCombFilter]], but includes a lowpass filter.\n * @category Component\n */\nclass LowpassCombFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]));\n        this.name = \"LowpassCombFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]);\n        this._combFilter = this.output = new _FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_2__.FeedbackCombFilter({\n            context: this.context,\n            delayTime: options.delayTime,\n            resonance: options.resonance,\n        });\n        this.delayTime = this._combFilter.delayTime;\n        this.resonance = this._combFilter.resonance;\n        this._lowpass = this.input = new _OnePoleFilter__WEBPACK_IMPORTED_MODULE_3__.OnePoleFilter({\n            context: this.context,\n            frequency: options.dampening,\n            type: \"lowpass\",\n        });\n        // connections\n        this._lowpass.connect(this._combFilter);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            dampening: 3000,\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    /**\n     * The dampening control of the feedback\n     */\n    get dampening() {\n        return this._lowpass.frequency;\n    }\n    set dampening(fq) {\n        this._lowpass.frequency = fq;\n    }\n    dispose() {\n        super.dispose();\n        this._combFilter.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LowpassCombFilter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/OnePoleFilter.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/OnePoleFilter.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OnePoleFilter\": () => (/* binding */ OnePoleFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n/**\n * A one pole filter with 6db-per-octave rolloff. Either \"highpass\" or \"lowpass\".\n * Note that changing the type or frequency may result in a discontinuity which\n * can sound like a click or pop.\n * References:\n * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/\n * * http://www.dspguide.com/ch19/2.htm\n * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts\n * @category Component\n */\nclass OnePoleFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OnePoleFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this._frequency = options.frequency;\n        this._type = options.type;\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._createFilter();\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            frequency: 880,\n            type: \"lowpass\"\n        });\n    }\n    /**\n     * Create a filter and dispose the old one\n     */\n    _createFilter() {\n        const oldFilter = this._filter;\n        const freq = this.toFrequency(this._frequency);\n        const t = 1 / (2 * Math.PI * freq);\n        if (this._type === \"lowpass\") {\n            const a0 = 1 / (t * this.context.sampleRate);\n            const b1 = a0 - 1;\n            this._filter = this.context.createIIRFilter([a0, 0], [1, b1]);\n        }\n        else {\n            const b1 = 1 / (t * this.context.sampleRate) - 1;\n            this._filter = this.context.createIIRFilter([1, -1], [1, b1]);\n        }\n        this.input.chain(this._filter, this.output);\n        if (oldFilter) {\n            // dispose it on the next block\n            this.context.setTimeout(() => {\n                if (!this.disposed) {\n                    this.input.disconnect(oldFilter);\n                    oldFilter.disconnect();\n                }\n            }, this.blockTime);\n        }\n    }\n    /**\n     * The frequency value.\n     */\n    get frequency() {\n        return this._frequency;\n    }\n    set frequency(fq) {\n        this._frequency = fq;\n        this._createFilter();\n    }\n    /**\n     * The OnePole Filter type, either \"highpass\" or \"lowpass\"\n     */\n    get type() {\n        return this._type;\n    }\n    set type(t) {\n        this._type = t;\n        this._createFilter();\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);\n        return magValues;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this._filter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OnePoleFilter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/OnePoleFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PhaseShiftAllpass\": () => (/* binding */ PhaseShiftAllpass)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n/**\n * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform\n * using two Allpass filter banks whose outputs have a phase difference of 90°.\n * Here the `offset90` phase is offset by +90° in relation to `output`.\n * Coefficients and structure was developed by Olli Niemitalo.\n * For more details see: http://yehar.com/blog/?p=368\n * @category Component\n */\nclass PhaseShiftAllpass extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"PhaseShiftAllpass\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * The phase shifted output\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * The PhaseShifted allpass output\n         */\n        this.offset90 = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        const allpassBank1Values = [0.6923878, 0.9360654322959, 0.9882295226860, 0.9987488452737];\n        const allpassBank2Values = [0.4021921162426, 0.8561710882420, 0.9722909545651, 0.9952884791278];\n        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);\n        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);\n        this._oneSampleDelay = this.context.createIIRFilter([0.0, 1.0], [1.0, 0.0]);\n        // connect Allpass filter banks\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._bank0, this._oneSampleDelay, this.output);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._bank1, this.offset90);\n    }\n    /**\n     * Create all of the IIR filters from an array of values using the coefficient calculation.\n     */\n    _createAllPassFilterBank(bankValues) {\n        const nodes = bankValues.map(value => {\n            const coefficients = [[value * value, 0, -1], [1, 0, -(value * value)]];\n            return this.context.createIIRFilter(coefficients[0], coefficients[1]);\n        });\n        return nodes;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.offset90.dispose();\n        this._bank0.forEach(f => f.disconnect());\n        this._bank1.forEach(f => f.disconnect());\n        this._oneSampleDelay.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=PhaseShiftAllpass.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/index.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/component/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_25__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _analysis_Analyser__WEBPACK_IMPORTED_MODULE_0__.Analyser),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _filter_BiquadFilter__WEBPACK_IMPORTED_MODULE_34__.BiquadFilter),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _channel_Channel__WEBPACK_IMPORTED_MODULE_6__.Channel),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _dynamics_Compressor__WEBPACK_IMPORTED_MODULE_20__.Compressor),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _filter_Convolver__WEBPACK_IMPORTED_MODULE_33__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _channel_CrossFade__WEBPACK_IMPORTED_MODULE_7__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _analysis_DCMeter__WEBPACK_IMPORTED_MODULE_3__.DCMeter),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _filter_EQ3__WEBPACK_IMPORTED_MODULE_28__.EQ3),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _envelope_Envelope__WEBPACK_IMPORTED_MODULE_26__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _analysis_FFT__WEBPACK_IMPORTED_MODULE_2__.FFT),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_31__.FeedbackCombFilter),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _filter_Filter__WEBPACK_IMPORTED_MODULE_29__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _analysis_Follower__WEBPACK_IMPORTED_MODULE_5__.Follower),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_27__.FrequencyEnvelope),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _dynamics_Gate__WEBPACK_IMPORTED_MODULE_21__.Gate),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _dynamics_Limiter__WEBPACK_IMPORTED_MODULE_22__.Limiter),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_32__.LowpassCombFilter),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _channel_Merge__WEBPACK_IMPORTED_MODULE_8__.Merge),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _analysis_Meter__WEBPACK_IMPORTED_MODULE_1__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _dynamics_MidSideCompressor__WEBPACK_IMPORTED_MODULE_23__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_9__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_10__.MidSideSplit),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _channel_Mono__WEBPACK_IMPORTED_MODULE_11__.Mono),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _dynamics_MultibandCompressor__WEBPACK_IMPORTED_MODULE_24__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_12__.MultibandSplit),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_30__.OnePoleFilter),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _channel_PanVol__WEBPACK_IMPORTED_MODULE_15__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _channel_Panner__WEBPACK_IMPORTED_MODULE_13__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _channel_Panner3D__WEBPACK_IMPORTED_MODULE_14__.Panner3D),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _channel_Recorder__WEBPACK_IMPORTED_MODULE_16__.Recorder),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _channel_Solo__WEBPACK_IMPORTED_MODULE_17__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _channel_Split__WEBPACK_IMPORTED_MODULE_18__.Split),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _channel_Volume__WEBPACK_IMPORTED_MODULE_19__.Volume),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _analysis_Waveform__WEBPACK_IMPORTED_MODULE_4__.Waveform)\n/* harmony export */ });\n/* harmony import */ var _analysis_Analyser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./analysis/Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n/* harmony import */ var _analysis_Meter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./analysis/Meter */ \"./node_modules/tone/build/esm/component/analysis/Meter.js\");\n/* harmony import */ var _analysis_FFT__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./analysis/FFT */ \"./node_modules/tone/build/esm/component/analysis/FFT.js\");\n/* harmony import */ var _analysis_DCMeter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./analysis/DCMeter */ \"./node_modules/tone/build/esm/component/analysis/DCMeter.js\");\n/* harmony import */ var _analysis_Waveform__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./analysis/Waveform */ \"./node_modules/tone/build/esm/component/analysis/Waveform.js\");\n/* harmony import */ var _analysis_Follower__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _channel_Channel__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./channel/Channel */ \"./node_modules/tone/build/esm/component/channel/Channel.js\");\n/* harmony import */ var _channel_CrossFade__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _channel_Merge__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n/* harmony import */ var _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _channel_Mono__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./channel/Mono */ \"./node_modules/tone/build/esm/component/channel/Mono.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n/* harmony import */ var _channel_Panner__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./channel/Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _channel_Panner3D__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./channel/Panner3D */ \"./node_modules/tone/build/esm/component/channel/Panner3D.js\");\n/* harmony import */ var _channel_PanVol__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./channel/PanVol */ \"./node_modules/tone/build/esm/component/channel/PanVol.js\");\n/* harmony import */ var _channel_Recorder__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./channel/Recorder */ \"./node_modules/tone/build/esm/component/channel/Recorder.js\");\n/* harmony import */ var _channel_Solo__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./channel/Solo */ \"./node_modules/tone/build/esm/component/channel/Solo.js\");\n/* harmony import */ var _channel_Split__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _channel_Volume__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _dynamics_Compressor__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./dynamics/Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _dynamics_Gate__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./dynamics/Gate */ \"./node_modules/tone/build/esm/component/dynamics/Gate.js\");\n/* harmony import */ var _dynamics_Limiter__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./dynamics/Limiter */ \"./node_modules/tone/build/esm/component/dynamics/Limiter.js\");\n/* harmony import */ var _dynamics_MidSideCompressor__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./dynamics/MidSideCompressor */ \"./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js\");\n/* harmony import */ var _dynamics_MultibandCompressor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./dynamics/MultibandCompressor */ \"./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js\");\n/* harmony import */ var _envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _envelope_Envelope__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./envelope/FrequencyEnvelope */ \"./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js\");\n/* harmony import */ var _filter_EQ3__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./filter/EQ3 */ \"./node_modules/tone/build/esm/component/filter/EQ3.js\");\n/* harmony import */ var _filter_Filter__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./filter/OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n/* harmony import */ var _filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./filter/FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n/* harmony import */ var _filter_Convolver__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./filter/Convolver */ \"./node_modules/tone/build/esm/component/filter/Convolver.js\");\n/* harmony import */ var _filter_BiquadFilter__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./filter/BiquadFilter */ \"./node_modules/tone/build/esm/component/filter/BiquadFilter.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/component/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/Global.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/core/Global.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getContext\": () => (/* binding */ getContext),\n/* harmony export */   \"setContext\": () => (/* binding */ setContext),\n/* harmony export */   \"start\": () => (/* binding */ start)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _context_DummyContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./context/DummyContext */ \"./node_modules/tone/build/esm/core/context/DummyContext.js\");\n/* harmony import */ var _context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n\n\n\n\n\n\n/**\n * This dummy context is used to avoid throwing immediate errors when importing in Node.js\n */\nconst dummyContext = new _context_DummyContext__WEBPACK_IMPORTED_MODULE_3__.DummyContext();\n/**\n * The global audio context which is getable and assignable through\n * getContext and setContext\n */\nlet globalContext = dummyContext;\n/**\n * Returns the default system-wide [[Context]]\n * @category Core\n */\nfunction getContext() {\n    if (globalContext === dummyContext && _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.hasAudioContext) {\n        setContext(new _context_Context__WEBPACK_IMPORTED_MODULE_2__.Context());\n    }\n    return globalContext;\n}\n/**\n * Set the default audio context\n * @category Core\n */\nfunction setContext(context) {\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__.isAudioContext)(context)) {\n        globalContext = new _context_Context__WEBPACK_IMPORTED_MODULE_2__.Context(context);\n    }\n    else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__.isOfflineAudioContext)(context)) {\n        globalContext = new _context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__.OfflineContext(context);\n    }\n    else {\n        globalContext = context;\n    }\n}\n/**\n * Most browsers will not play _any_ audio until a user\n * clicks something (like a play button). Invoke this method\n * on a click or keypress event handler to start the audio context.\n * More about the Autoplay policy\n * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)\n * @example\n * document.querySelector(\"button\").addEventListener(\"click\", async () => {\n * \tawait Tone.start();\n * \tconsole.log(\"context started\");\n * });\n * @category Core\n */\nfunction start() {\n    return globalContext.resume();\n}\n/**\n * Log Tone.js + version in the console.\n */\nif (_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow && !_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow.TONE_SILENCE_LOGGING) {\n    let prefix = \"v\";\n    if (_version__WEBPACK_IMPORTED_MODULE_0__.version === \"dev\") {\n        prefix = \"\";\n    }\n    const printString = ` * Tone.js ${prefix}${_version__WEBPACK_IMPORTED_MODULE_0__.version} * `;\n    // eslint-disable-next-line no-console\n    console.log(`%c${printString}`, \"background: #000; color: #fff\");\n}\n//# sourceMappingURL=Global.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/Global.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/Tone.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/build/esm/core/Tone.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Tone\": () => (/* binding */ Tone)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/**\n * Tone.js\n * @author Yotam Mann\n * @license http://opensource.org/licenses/MIT MIT License\n * @copyright 2014-2019 Yotam Mann\n */\n\n\n\n/**\n * @class  Tone is the base class of all other classes.\n * @category Core\n * @constructor\n */\nclass Tone {\n    constructor() {\n        //-------------------------------------\n        // \tDEBUGGING\n        //-------------------------------------\n        /**\n         * Set this debug flag to log all events that happen in this class.\n         */\n        this.debug = false;\n        //-------------------------------------\n        // \tDISPOSING\n        //-------------------------------------\n        /**\n         * Indicates if the instance was disposed\n         */\n        this._wasDisposed = false;\n    }\n    /**\n     * Returns all of the default options belonging to the class.\n     */\n    static getDefaults() {\n        return {};\n    }\n    /**\n     * Prints the outputs to the console log for debugging purposes.\n     * Prints the contents only if either the object has a property\n     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS\n     * is set to the name of the class.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * // prints all logs originating from this oscillator\n     * osc.debug = true;\n     * // calls to start/stop will print in the console\n     * osc.start();\n     */\n    log(...args) {\n        // if the object is either set to debug = true\n        // or if there is a string on the Tone.global.with the class name\n        if (this.debug || (_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow && this.toString() === _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow.TONE_DEBUG_CLASS)) {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_2__.log)(this, ...args);\n        }\n    }\n    /**\n     * disconnect and dispose.\n     */\n    dispose() {\n        this._wasDisposed = true;\n        return this;\n    }\n    /**\n     * Indicates if the instance was disposed. 'Disposing' an\n     * instance means that all of the Web Audio nodes that were\n     * created for the instance are disconnected and freed for garbage collection.\n     */\n    get disposed() {\n        return this._wasDisposed;\n    }\n    /**\n     * Convert the class to a string\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.toString());\n     */\n    toString() {\n        return this.name;\n    }\n}\n/**\n * The version number semver\n */\nTone.version = _version__WEBPACK_IMPORTED_MODULE_0__.version;\n//# sourceMappingURL=Tone.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/Tone.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Clock.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Clock.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Clock\": () => (/* binding */ Clock)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _TickSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./TickSource */ \"./node_modules/tone/build/esm/core/clock/TickSource.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n/**\n * A sample accurate clock which provides a callback at the given rate.\n * While the callback is not sample-accurate (it is still susceptible to\n * loose JS timing), the time passed in as the argument to the callback\n * is precise. For most applications, it is better to use Tone.Transport\n * instead of the Clock by itself since you can synchronize multiple callbacks.\n * @example\n * // the callback will be invoked approximately once a second\n * // and will print the time exactly once a second apart.\n * const clock = new Tone.Clock(time => {\n * \tconsole.log(time);\n * }, 1);\n * clock.start();\n * @category Core\n */\nclass Clock extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]));\n        this.name = \"Clock\";\n        /**\n         * The callback function to invoke at the scheduled tick.\n         */\n        this.callback = _util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp;\n        /**\n         * The last time the loop callback was invoked\n         */\n        this._lastUpdate = 0;\n        /**\n         * Keep track of the playback state\n         */\n        this._state = new _util_StateTimeline__WEBPACK_IMPORTED_MODULE_4__.StateTimeline(\"stopped\");\n        /**\n         * Context bound reference to the _loop method\n         * This is necessary to remove the event in the end.\n         */\n        this._boundLoop = this._loop.bind(this);\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]);\n        this.callback = options.callback;\n        this._tickSource = new _TickSource__WEBPACK_IMPORTED_MODULE_5__.TickSource({\n            context: this.context,\n            frequency: options.frequency,\n            units: options.units,\n        });\n        this._lastUpdate = 0;\n        this.frequency = this._tickSource.frequency;\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"frequency\");\n        // add an initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // bind a callback to the worker thread\n        this.context.on(\"tick\", this._boundLoop);\n    }\n    static getDefaults() {\n        return Object.assign(_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext.getDefaults(), {\n            callback: _util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n            frequency: 1,\n            units: \"hertz\",\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset  Where the tick counter starts counting from.\n     */\n    start(time, offset) {\n        // make sure the context is running\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertContextRunning)(this.context);\n        // start the loop\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            this._tickSource.start(computedTime, offset);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"start\", computedTime, offset);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     * @example\n     * const clock = new Tone.Clock(time => {\n     * \tconsole.log(time);\n     * }, 1);\n     * clock.start();\n     * // stop the clock after 10 seconds\n     * clock.stop(\"+10\");\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"stop\", computedTime);\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this._tickSource.stop(computedTime);\n        if (computedTime < this._lastUpdate) {\n            this.emit(\"stop\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n            this._tickSource.pause(computedTime);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"pause\", computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked.\n     */\n    get ticks() {\n        return Math.ceil(this.getTicksAtTime(this.now()));\n    }\n    set ticks(t) {\n        this._tickSource.ticks = t;\n    }\n    /**\n     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves\n     */\n    get seconds() {\n        return this._tickSource.seconds;\n    }\n    set seconds(s) {\n        this._tickSource.seconds = s;\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._tickSource.getSecondsAtTime(time);\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        this._tickSource.setTicksAtTime(ticks, time);\n        return this;\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        return this._tickSource.getTimeOfTick(tick, before);\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return this._tickSource.getTicksAtTime(time);\n    }\n    /**\n     * Get the time of the next tick\n     * @param  offset The tick number.\n     */\n    nextTickTime(offset, when) {\n        const computedTime = this.toSeconds(when);\n        const currentTick = this.getTicksAtTime(computedTime);\n        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);\n    }\n    /**\n     * The scheduling loop.\n     */\n    _loop() {\n        const startTime = this._lastUpdate;\n        const endTime = this.now();\n        this._lastUpdate = endTime;\n        this.log(\"loop\", startTime, endTime);\n        if (startTime !== endTime) {\n            // the state change events\n            this._state.forEachBetween(startTime, endTime, e => {\n                switch (e.state) {\n                    case \"started\":\n                        const offset = this._tickSource.getTicksAtTime(e.time);\n                        this.emit(\"start\", e.time, offset);\n                        break;\n                    case \"stopped\":\n                        if (e.time !== 0) {\n                            this.emit(\"stop\", e.time);\n                        }\n                        break;\n                    case \"paused\":\n                        this.emit(\"pause\", e.time);\n                        break;\n                }\n            });\n            // the tick callbacks\n            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks) => {\n                this.callback(time, ticks);\n            });\n        }\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     * @example\n     * const clock = new Tone.Clock();\n     * clock.start(\"+0.1\");\n     * clock.getStateAtTime(\"+0.1\"); // returns \"started\"\n     */\n    getStateAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        return this._state.getValueAtTime(computedTime);\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.context.off(\"tick\", this._boundLoop);\n        this._tickSource.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\n_util_Emitter__WEBPACK_IMPORTED_MODULE_2__.Emitter.mixin(Clock);\n//# sourceMappingURL=Clock.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/Clock.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickParam.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickParam.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickParam\": () => (/* binding */ TickParam)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n/**\n * A Param class just for computing ticks. Similar to the [[Param]] class,\n * but offers conversion to BPM values as well as ability to compute tick\n * duration and elapsed ticks\n */\nclass TickParam extends _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickParam.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickParam\";\n        /**\n         * The timeline which tracks all of the automations.\n         */\n        this._events = new _util_Timeline__WEBPACK_IMPORTED_MODULE_2__.Timeline(Infinity);\n        /**\n         * The internal holder for the multiplier value\n         */\n        this._multiplier = 1;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickParam.getDefaults(), arguments, [\"value\"]);\n        // set the multiplier\n        this._multiplier = options.multiplier;\n        // clear the ticks from the beginning\n        this._events.cancel(0);\n        // set an initial event\n        this._events.add({\n            ticks: 0,\n            time: 0,\n            type: \"setValueAtTime\",\n            value: this._fromType(options.value),\n        });\n        this.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    setTargetAtTime(value, time, constant) {\n        // approximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        this.setRampPoint(time);\n        const computedValue = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        const segments = Math.round(Math.max(1 / constant, 1));\n        for (let i = 0; i <= segments; i++) {\n            const segTime = constant * i + time;\n            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.setValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.linearRampToValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        // aproximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        const computedVal = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        // approx 10 segments per second\n        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));\n        const segmentDur = ((time - prevEvent.time) / segments);\n        for (let i = 0; i <= segments; i++) {\n            const segTime = segmentDur * i + prevEvent.time;\n            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  event The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    _getTicksUntilEvent(event, time) {\n        if (event === null) {\n            event = {\n                ticks: 0,\n                time: 0,\n                type: \"setValueAtTime\",\n                value: 0,\n            };\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isUndef)(event.ticks)) {\n            const previousEvent = this._events.previousEvent(event);\n            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);\n        }\n        const val0 = this._fromType(this.getValueAtTime(event.time));\n        let val1 = this._fromType(this.getValueAtTime(time));\n        // if it's right on the line, take the previous value\n        const onTheLineEvent = this._events.get(time);\n        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === \"setValueAtTime\") {\n            val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));\n        }\n        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  time The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const event = this._events.get(computedTime);\n        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);\n    }\n    /**\n     * Return the elapsed time of the number of ticks from the given time\n     * @param ticks The number of ticks to calculate\n     * @param  time The time to get the next tick from\n     * @return The duration of the number of ticks from the given time in seconds\n     */\n    getDurationOfTicks(ticks, time) {\n        const computedTime = this.toSeconds(time);\n        const currentTick = this.getTicksAtTime(time);\n        return this.getTimeOfTick(currentTick + ticks) - computedTime;\n    }\n    /**\n     * Given a tick, returns the time that tick occurs at.\n     * @return The time that the tick occurs.\n     */\n    getTimeOfTick(tick) {\n        const before = this._events.get(tick, \"ticks\");\n        const after = this._events.getAfter(tick, \"ticks\");\n        if (before && before.ticks === tick) {\n            return before.time;\n        }\n        else if (before && after &&\n            after.type === \"linearRampToValueAtTime\" &&\n            before.value !== after.value) {\n            const val0 = this._fromType(this.getValueAtTime(before.time));\n            const val1 = this._fromType(this.getValueAtTime(after.time));\n            const delta = (val1 - val0) / (after.time - before.time);\n            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));\n            const sol1 = (-val0 + k) / delta;\n            const sol2 = (-val0 - k) / delta;\n            return (sol1 > 0 ? sol1 : sol2) + before.time;\n        }\n        else if (before) {\n            if (before.value === 0) {\n                return Infinity;\n            }\n            else {\n                return before.time + (tick - before.ticks) / before.value;\n            }\n        }\n        else {\n            return tick / this._initialValue;\n        }\n    }\n    /**\n     * Convert some number of ticks their the duration in seconds accounting\n     * for any automation curves starting at the given time.\n     * @param  ticks The number of ticks to convert to seconds.\n     * @param  when  When along the automation timeline to convert the ticks.\n     * @return The duration in seconds of the ticks.\n     */\n    ticksToTime(ticks, when) {\n        return this.getDurationOfTicks(ticks, when);\n    }\n    /**\n     * The inverse of [[ticksToTime]]. Convert a duration in\n     * seconds to the corresponding number of ticks accounting for any\n     * automation curves starting at the given time.\n     * @param  duration The time interval to convert to ticks.\n     * @param  when When along the automation timeline to convert the ticks.\n     * @return The duration in ticks.\n     */\n    timeToTicks(duration, when) {\n        const computedTime = this.toSeconds(when);\n        const computedDuration = this.toSeconds(duration);\n        const startTicks = this.getTicksAtTime(computedTime);\n        const endTicks = this.getTicksAtTime(computedTime + computedDuration);\n        return endTicks - startTicks;\n    }\n    /**\n     * Convert from the type when the unit value is BPM\n     */\n    _fromType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return 1 / (60 / val / this.multiplier);\n        }\n        else {\n            return super._fromType(val);\n        }\n    }\n    /**\n     * Special case of type conversion where the units === \"bpm\"\n     */\n    _toType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return (val / this.multiplier) * 60;\n        }\n        else {\n            return super._toType(val);\n        }\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._multiplier;\n    }\n    set multiplier(m) {\n        // get and reset the current value with the new multiplier\n        // might be necessary to clear all the previous values\n        const currentVal = this.value;\n        this._multiplier = m;\n        this.cancelScheduledValues(0);\n        this.setValueAtTime(currentVal, 0);\n    }\n}\n//# sourceMappingURL=TickParam.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/TickParam.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickSignal.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickSignal.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickSignal\": () => (/* binding */ TickSignal)\n/* harmony export */ });\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _TickParam__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TickParam */ \"./node_modules/tone/build/esm/core/clock/TickParam.js\");\n\n\n\n/**\n * TickSignal extends Tone.Signal, but adds the capability\n * to calculate the number of elapsed ticks. exponential and target curves\n * are approximated with multiple linear ramps.\n *\n * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,\n * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n * describing integrating timing functions for tempo calculations.\n */\nclass TickSignal extends _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSignal.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickSignal\";\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSignal.getDefaults(), arguments, [\"value\"]);\n        this.input = this._param = new _TickParam__WEBPACK_IMPORTED_MODULE_2__.TickParam({\n            context: this.context,\n            convert: options.convert,\n            multiplier: options.multiplier,\n            param: this._constantSource.offset,\n            units: options.units,\n            value: options.value,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    ticksToTime(ticks, when) {\n        return this._param.ticksToTime(ticks, when);\n    }\n    timeToTicks(duration, when) {\n        return this._param.timeToTicks(duration, when);\n    }\n    getTimeOfTick(tick) {\n        return this._param.getTimeOfTick(tick);\n    }\n    getDurationOfTicks(ticks, time) {\n        return this._param.getDurationOfTicks(ticks, time);\n    }\n    getTicksAtTime(time) {\n        return this._param.getTicksAtTime(time);\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._param.multiplier;\n    }\n    set multiplier(m) {\n        this._param.multiplier = m;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSignal.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/TickSignal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickSource.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickSource.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickSource\": () => (/* binding */ TickSource)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _TickSignal__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./TickSignal */ \"./node_modules/tone/build/esm/core/clock/TickSignal.js\");\n/* harmony import */ var _util_Math__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n/**\n * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.\n */\nclass TickSource extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSource.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"TickSource\";\n        /**\n         * The state timeline\n         */\n        this._state = new _util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__.StateTimeline();\n        /**\n         * The offset values of the ticks\n         */\n        this._tickOffset = new _util_Timeline__WEBPACK_IMPORTED_MODULE_4__.Timeline();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSource.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new _TickSignal__WEBPACK_IMPORTED_MODULE_6__.TickSignal({\n            context: this.context,\n            units: options.units,\n            value: options.frequency,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"frequency\");\n        // set the initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // add the first event\n        this.setTicksAtTime(0, 0);\n    }\n    static getDefaults() {\n        return Object.assign({\n            frequency: 1,\n            units: \"hertz\",\n        }, _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext.getDefaults());\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset The number of ticks to start the source at\n     */\n    start(time, offset) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(offset)) {\n                this.setTicksAtTime(offset, computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        // cancel the previous stop\n        if (this._state.getValueAtTime(computedTime) === \"stopped\") {\n            const event = this._state.get(computedTime);\n            if (event && event.time > 0) {\n                this._tickOffset.cancel(event.time);\n                this._state.cancel(event.time);\n            }\n        }\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this.setTicksAtTime(0, computedTime);\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.\n     * @param time When to clear the events after\n     */\n    cancel(time) {\n        time = this.toSeconds(time);\n        this._state.cancel(time);\n        this._tickOffset.cancel(time);\n        return this;\n    }\n    /**\n     * Get the elapsed ticks at the given time\n     * @param  time  When to get the tick value\n     * @return The number of ticks\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", computedTime);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time: computedTime };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedTicks = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedTicks = offsetEvent.ticks;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedTicks;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked. Returns -1 when stopped.\n     */\n    get ticks() {\n        return this.getTicksAtTime(this.now());\n    }\n    set ticks(t) {\n        this.setTicksAtTime(t, this.now());\n    }\n    /**\n     * The time since ticks=0 that the TickSource has been running. Accounts\n     * for tempo curves\n     */\n    get seconds() {\n        return this.getSecondsAtTime(this.now());\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this.frequency.timeToTicks(s, now);\n        this.setTicksAtTime(ticks, now);\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        time = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", time);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedSeconds = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, time + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedSeconds = offsetEvent.seconds;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedSeconds += e.time - periodStartTime;\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedSeconds;\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        time = this.toSeconds(time);\n        this._tickOffset.cancel(time);\n        this._tickOffset.add({\n            seconds: this.frequency.getDurationOfTicks(ticks, time),\n            ticks,\n            time,\n        });\n        return this;\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     */\n    getStateAtTime(time) {\n        time = this.toSeconds(time);\n        return this._state.getValueAtTime(time);\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        const offset = this._tickOffset.get(before);\n        const event = this._state.get(before);\n        const startTime = Math.max(offset.time, event.time);\n        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;\n        return this.frequency.getTimeOfTick(absoluteTicks);\n    }\n    /**\n     * Invoke the callback event at all scheduled ticks between the\n     * start time and the end time\n     * @param  startTime  The beginning of the search range\n     * @param  endTime    The end of the search range\n     * @param  callback   The callback to invoke with each tick\n     */\n    forEachTickBetween(startTime, endTime, callback) {\n        // only iterate through the sections where it is \"started\"\n        let lastStateEvent = this._state.get(startTime);\n        this._state.forEachBetween(startTime, endTime, event => {\n            if (lastStateEvent && lastStateEvent.state === \"started\" && event.state !== \"started\") {\n                this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);\n            }\n            lastStateEvent = event;\n        });\n        let error = null;\n        if (lastStateEvent && lastStateEvent.state === \"started\") {\n            const maxStartTime = Math.max(lastStateEvent.time, startTime);\n            // figure out the difference between the frequency ticks and the\n            const startTicks = this.frequency.getTicksAtTime(maxStartTime);\n            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);\n            const diff = startTicks - ticksAtStart;\n            let offset = Math.ceil(diff) - diff;\n            // guard against floating point issues\n            offset = (0,_util_Math__WEBPACK_IMPORTED_MODULE_7__.EQ)(offset, 1) ? 0 : offset;\n            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);\n            while (nextTickTime < endTime) {\n                try {\n                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));\n                }\n                catch (e) {\n                    error = e;\n                    break;\n                }\n                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);\n            }\n        }\n        if (error) {\n            throw error;\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._state.dispose();\n        this._tickOffset.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSource.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/TickSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Ticker.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Ticker.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Ticker\": () => (/* binding */ Ticker)\n/* harmony export */ });\n/**\n * A class which provides a reliable callback using either\n * a Web Worker, or if that isn't supported, falls back to setTimeout.\n */\nclass Ticker {\n    constructor(callback, type, updateInterval) {\n        this._callback = callback;\n        this._type = type;\n        this._updateInterval = updateInterval;\n        // create the clock source for the first time\n        this._createClock();\n    }\n    /**\n     * Generate a web worker\n     */\n    _createWorker() {\n        const blob = new Blob([\n            /* javascript */ `\n\t\t\t// the initial timeout time\n\t\t\tlet timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};\n\t\t\t// onmessage callback\n\t\t\tself.onmessage = function(msg){\n\t\t\t\ttimeoutTime = parseInt(msg.data);\n\t\t\t};\n\t\t\t// the tick function which posts a message\n\t\t\t// and schedules a new tick\n\t\t\tfunction tick(){\n\t\t\t\tsetTimeout(tick, timeoutTime);\n\t\t\t\tself.postMessage('tick');\n\t\t\t}\n\t\t\t// call tick initially\n\t\t\ttick();\n\t\t\t`\n        ], { type: \"text/javascript\" });\n        const blobUrl = URL.createObjectURL(blob);\n        const worker = new Worker(blobUrl);\n        worker.onmessage = this._callback.bind(this);\n        this._worker = worker;\n    }\n    /**\n     * Create a timeout loop\n     */\n    _createTimeout() {\n        this._timeout = setTimeout(() => {\n            this._createTimeout();\n            this._callback();\n        }, this._updateInterval * 1000);\n    }\n    /**\n     * Create the clock source.\n     */\n    _createClock() {\n        if (this._type === \"worker\") {\n            try {\n                this._createWorker();\n            }\n            catch (e) {\n                // workers not supported, fallback to timeout\n                this._type = \"timeout\";\n                this._createClock();\n            }\n        }\n        else if (this._type === \"timeout\") {\n            this._createTimeout();\n        }\n    }\n    /**\n     * Clean up the current clock source\n     */\n    _disposeClock() {\n        if (this._timeout) {\n            clearTimeout(this._timeout);\n            this._timeout = 0;\n        }\n        if (this._worker) {\n            this._worker.terminate();\n            this._worker.onmessage = null;\n        }\n    }\n    /**\n     * The rate in seconds the ticker will update\n     */\n    get updateInterval() {\n        return this._updateInterval;\n    }\n    set updateInterval(interval) {\n        this._updateInterval = Math.max(interval, 128 / 44100);\n        if (this._type === \"worker\") {\n            this._worker.postMessage(Math.max(interval * 1000, 1));\n        }\n    }\n    /**\n     * The type of the ticker, either a worker or a timeout\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._disposeClock();\n        this._type = type;\n        this._createClock();\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this._disposeClock();\n    }\n}\n//# sourceMappingURL=Ticker.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/Ticker.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Transport.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Transport.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Transport\": () => (/* binding */ Transport)\n/* harmony export */ });\n/* harmony import */ var _core_type_Time__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _core_util_TimelineValue__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/TimelineValue */ \"./node_modules/tone/build/esm/core/util/TimelineValue.js\");\n/* harmony import */ var _context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../context/ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../util/IntervalTimeline */ \"./node_modules/tone/build/esm/core/util/IntervalTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Clock__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _TransportEvent__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./TransportEvent */ \"./node_modules/tone/build/esm/core/clock/TransportEvent.js\");\n/* harmony import */ var _TransportRepeatEvent__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./TransportRepeatEvent */ \"./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Transport for timing musical events.\n * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n * Transport timing events pass in the exact time of the scheduled event\n * in the argument of the callback function. Pass that time value to the object\n * you're scheduling. <br><br>\n * A single transport is created for you when the library is initialized.\n * <br><br>\n * The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n * called with the time of that event as the argument.\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination();\n * // repeated event every 8th note\n * Tone.Transport.scheduleRepeat((time) => {\n * \t// use the callback time to schedule events\n * \tosc.start(time).stop(time + 0.1);\n * }, \"8n\");\n * // transport must be started before it starts invoking events\n * Tone.Transport.start();\n * @category Core\n */\nclass Transport extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(Transport.getDefaults(), arguments));\n        this.name = \"Transport\";\n        //-------------------------------------\n        // \tLOOPING\n        //-------------------------------------\n        /**\n         * If the transport loops or not.\n         */\n        this._loop = new _core_util_TimelineValue__WEBPACK_IMPORTED_MODULE_1__.TimelineValue(false);\n        /**\n         * The loop start position in ticks\n         */\n        this._loopStart = 0;\n        /**\n         * The loop end position in ticks\n         */\n        this._loopEnd = 0;\n        //-------------------------------------\n        // \tTIMELINE EVENTS\n        //-------------------------------------\n        /**\n         * All the events in an object to keep track by ID\n         */\n        this._scheduledEvents = {};\n        /**\n         * The scheduled events.\n         */\n        this._timeline = new _util_Timeline__WEBPACK_IMPORTED_MODULE_11__.Timeline();\n        /**\n         * Repeated events\n         */\n        this._repeatedEvents = new _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_10__.IntervalTimeline();\n        /**\n         * All of the synced Signals\n         */\n        this._syncedSignals = [];\n        /**\n         * The swing amount\n         */\n        this._swingAmount = 0;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(Transport.getDefaults(), arguments);\n        // CLOCK/TEMPO\n        this._ppq = options.ppq;\n        this._clock = new _Clock__WEBPACK_IMPORTED_MODULE_13__.Clock({\n            callback: this._processTick.bind(this),\n            context: this.context,\n            frequency: 0,\n            units: \"bpm\",\n        });\n        this._bindClockEvents();\n        this.bpm = this._clock.frequency;\n        this._clock.frequency.multiplier = options.ppq;\n        this.bpm.setValueAtTime(options.bpm, 0);\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_9__.readOnly)(this, \"bpm\");\n        this._timeSignature = options.timeSignature;\n        // SWING\n        this._swingTicks = options.ppq / 2; // 8n\n    }\n    static getDefaults() {\n        return Object.assign(_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__.ToneWithContext.getDefaults(), {\n            bpm: 120,\n            loopEnd: \"4m\",\n            loopStart: 0,\n            ppq: 192,\n            swing: 0,\n            swingSubdivision: \"8n\",\n            timeSignature: 4,\n        });\n    }\n    //-------------------------------------\n    // \tTICKS\n    //-------------------------------------\n    /**\n     * called on every tick\n     * @param  tickTime clock relative tick time\n     */\n    _processTick(tickTime, ticks) {\n        // do the loop test\n        if (this._loop.get(tickTime)) {\n            if (ticks >= this._loopEnd) {\n                this.emit(\"loopEnd\", tickTime);\n                this._clock.setTicksAtTime(this._loopStart, tickTime);\n                ticks = this._loopStart;\n                this.emit(\"loopStart\", tickTime, this._clock.getSecondsAtTime(tickTime));\n                this.emit(\"loop\", tickTime);\n            }\n        }\n        // handle swing\n        if (this._swingAmount > 0 &&\n            ticks % this._ppq !== 0 && // not on a downbeat\n            ticks % (this._swingTicks * 2) !== 0) {\n            // add some swing\n            const progress = (ticks % (this._swingTicks * 2)) / (this._swingTicks * 2);\n            const amount = Math.sin((progress) * Math.PI) * this._swingAmount;\n            tickTime += new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;\n        }\n        // invoke the timeline events scheduled on this tick\n        this._timeline.forEachAtTime(ticks, event => event.invoke(tickTime));\n    }\n    //-------------------------------------\n    // \tSCHEDULABLE EVENTS\n    //-------------------------------------\n    /**\n     * Schedule an event along the timeline.\n     * @param callback The callback to be invoked at the time.\n     * @param time The time to invoke the callback at.\n     * @return The id of the event which can be used for canceling the event.\n     * @example\n     * // schedule an event on the 16th measure\n     * Tone.Transport.schedule((time) => {\n     * \t// invoked on measure 16\n     * \tconsole.log(\"measure 16!\");\n     * }, \"16:0:0\");\n     */\n    schedule(callback, time) {\n        const event = new _TransportEvent__WEBPACK_IMPORTED_MODULE_14__.TransportEvent(this, {\n            callback,\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Schedule a repeated event along the timeline. The event will fire\n     * at the `interval` starting at the `startTime` and for the specified\n     * `duration`.\n     * @param  callback   The callback to invoke.\n     * @param  interval   The duration between successive callbacks. Must be a positive number.\n     * @param  startTime  When along the timeline the events should start being invoked.\n     * @param  duration How long the event should repeat.\n     * @return  The ID of the scheduled event. Use this to cancel the event.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // a callback invoked every eighth note after the first measure\n     * Tone.Transport.scheduleRepeat((time) => {\n     * \tosc.start(time).stop(time + 0.1);\n     * }, \"8n\", \"1m\");\n     */\n    scheduleRepeat(callback, interval, startTime, duration = Infinity) {\n        const event = new _TransportRepeatEvent__WEBPACK_IMPORTED_MODULE_15__.TransportRepeatEvent(this, {\n            callback,\n            duration: new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, duration).toTicks(),\n            interval: new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, interval).toTicks(),\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, startTime).toTicks(),\n        });\n        // kick it off if the Transport is started\n        // @ts-ignore\n        return this._addEvent(event, this._repeatedEvents);\n    }\n    /**\n     * Schedule an event that will be removed after it is invoked.\n     * @param callback The callback to invoke once.\n     * @param time The time the callback should be invoked.\n     * @returns The ID of the scheduled event.\n     */\n    scheduleOnce(callback, time) {\n        const event = new _TransportEvent__WEBPACK_IMPORTED_MODULE_14__.TransportEvent(this, {\n            callback,\n            once: true,\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Clear the passed in event id from the timeline\n     * @param eventId The id of the event.\n     */\n    clear(eventId) {\n        if (this._scheduledEvents.hasOwnProperty(eventId)) {\n            const item = this._scheduledEvents[eventId.toString()];\n            item.timeline.remove(item.event);\n            item.event.dispose();\n            delete this._scheduledEvents[eventId.toString()];\n        }\n        return this;\n    }\n    /**\n     * Add an event to the correct timeline. Keep track of the\n     * timeline it was added to.\n     * @returns the event id which was just added\n     */\n    _addEvent(event, timeline) {\n        this._scheduledEvents[event.id.toString()] = {\n            event,\n            timeline,\n        };\n        timeline.add(event);\n        return event.id;\n    }\n    /**\n     * Remove scheduled events from the timeline after\n     * the given time. Repeated events will be removed\n     * if their startTime is after the given time\n     * @param after Clear all events after this time.\n     */\n    cancel(after = 0) {\n        const computedAfter = this.toTicks(after);\n        this._timeline.forEachFrom(computedAfter, event => this.clear(event.id));\n        this._repeatedEvents.forEachFrom(computedAfter, event => this.clear(event.id));\n        return this;\n    }\n    //-------------------------------------\n    // \tSTART/STOP/PAUSE\n    //-------------------------------------\n    /**\n     * Bind start/stop/pause events from the clock and emit them.\n     */\n    _bindClockEvents() {\n        this._clock.on(\"start\", (time, offset) => {\n            offset = new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, offset).toSeconds();\n            this.emit(\"start\", time, offset);\n        });\n        this._clock.on(\"stop\", (time) => {\n            this.emit(\"stop\", time);\n        });\n        this._clock.on(\"pause\", (time) => {\n            this.emit(\"pause\", time);\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\", or \"paused\"\n     */\n    get state() {\n        return this._clock.getStateAtTime(this.now());\n    }\n    /**\n     * Start the transport and all sources synced to the transport.\n     * @param  time The time when the transport should start.\n     * @param  offset The timeline offset to start the transport.\n     * @example\n     * // start the transport in one second starting at beginning of the 5th measure.\n     * Tone.Transport.start(\"+1\", \"4:0:0\");\n     */\n    start(time, offset) {\n        let offsetTicks;\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__.isDefined)(offset)) {\n            offsetTicks = this.toTicks(offset);\n        }\n        // start the clock\n        this._clock.start(time, offsetTicks);\n        return this;\n    }\n    /**\n     * Stop the transport and all sources synced to the transport.\n     * @param time The time when the transport should stop.\n     * @example\n     * Tone.Transport.stop();\n     */\n    stop(time) {\n        this._clock.stop(time);\n        return this;\n    }\n    /**\n     * Pause the transport and all sources synced to the transport.\n     */\n    pause(time) {\n        this._clock.pause(time);\n        return this;\n    }\n    /**\n     * Toggle the current state of the transport. If it is\n     * started, it will stop it, otherwise it will start the Transport.\n     * @param  time The time of the event\n     */\n    toggle(time) {\n        time = this.toSeconds(time);\n        if (this._clock.getStateAtTime(time) !== \"started\") {\n            this.start(time);\n        }\n        else {\n            this.stop(time);\n        }\n        return this;\n    }\n    //-------------------------------------\n    // \tSETTERS/GETTERS\n    //-------------------------------------\n    /**\n     * The time signature as just the numerator over 4.\n     * For example 4/4 would be just 4 and 6/8 would be 3.\n     * @example\n     * // common time\n     * Tone.Transport.timeSignature = 4;\n     * // 7/8\n     * Tone.Transport.timeSignature = [7, 8];\n     * // this will be reduced to a single number\n     * Tone.Transport.timeSignature; // returns 3.5\n     */\n    get timeSignature() {\n        return this._timeSignature;\n    }\n    set timeSignature(timeSig) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__.isArray)(timeSig)) {\n            timeSig = (timeSig[0] / timeSig[1]) * 4;\n        }\n        this._timeSignature = timeSig;\n    }\n    /**\n     * When the Transport.loop = true, this is the starting position of the loop.\n     */\n    get loopStart() {\n        return new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, this._loopStart, \"i\").toSeconds();\n    }\n    set loopStart(startPosition) {\n        this._loopStart = this.toTicks(startPosition);\n    }\n    /**\n     * When the Transport.loop = true, this is the ending position of the loop.\n     */\n    get loopEnd() {\n        return new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, this._loopEnd, \"i\").toSeconds();\n    }\n    set loopEnd(endPosition) {\n        this._loopEnd = this.toTicks(endPosition);\n    }\n    /**\n     * If the transport loops or not.\n     */\n    get loop() {\n        return this._loop.get(this.now());\n    }\n    set loop(loop) {\n        this._loop.set(loop, this.now());\n    }\n    /**\n     * Set the loop start and stop at the same time.\n     * @example\n     * // loop over the first measure\n     * Tone.Transport.setLoopPoints(0, \"1m\");\n     * Tone.Transport.loop = true;\n     */\n    setLoopPoints(startPosition, endPosition) {\n        this.loopStart = startPosition;\n        this.loopEnd = endPosition;\n        return this;\n    }\n    /**\n     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.\n     */\n    get swing() {\n        return this._swingAmount;\n    }\n    set swing(amount) {\n        // scale the values to a normal range\n        this._swingAmount = amount;\n    }\n    /**\n     * Set the subdivision which the swing will be applied to.\n     * The default value is an 8th note. Value must be less\n     * than a quarter note.\n     */\n    get swingSubdivision() {\n        return new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, this._swingTicks).toNotation();\n    }\n    set swingSubdivision(subdivision) {\n        this._swingTicks = this.toTicks(subdivision);\n    }\n    /**\n     * The Transport's position in Bars:Beats:Sixteenths.\n     * Setting the value will jump to that position right away.\n     */\n    get position() {\n        const now = this.now();\n        const ticks = this._clock.getTicksAtTime(now);\n        return new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, ticks).toBarsBeatsSixteenths();\n    }\n    set position(progress) {\n        const ticks = this.toTicks(progress);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's position in seconds\n     * Setting the value will jump to that position right away.\n     */\n    get seconds() {\n        return this._clock.seconds;\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this._clock.frequency.timeToTicks(s, now);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's loop position as a normalized value. Always\n     * returns 0 if the transport if loop is not true.\n     */\n    get progress() {\n        if (this.loop) {\n            const now = this.now();\n            const ticks = this._clock.getTicksAtTime(now);\n            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The transports current tick position.\n     */\n    get ticks() {\n        return this._clock.ticks;\n    }\n    set ticks(t) {\n        if (this._clock.ticks !== t) {\n            const now = this.now();\n            // stop everything synced to the transport\n            if (this.state === \"started\") {\n                const ticks = this._clock.getTicksAtTime(now);\n                // schedule to start on the next tick, #573\n                const remainingTick = this._clock.frequency.getDurationOfTicks(Math.ceil(ticks) - ticks, now);\n                const time = now + remainingTick;\n                this.emit(\"stop\", time);\n                this._clock.setTicksAtTime(t, time);\n                // restart it with the new time\n                this.emit(\"start\", time, this._clock.getSecondsAtTime(time));\n            }\n            else {\n                this._clock.setTicksAtTime(t, now);\n            }\n        }\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return Math.round(this._clock.getTicksAtTime(time));\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._clock.getSecondsAtTime(time);\n    }\n    /**\n     * Pulses Per Quarter note. This is the smallest resolution\n     * the Transport timing supports. This should be set once\n     * on initialization and not set again. Changing this value\n     * after other objects have been created can cause problems.\n     */\n    get PPQ() {\n        return this._clock.frequency.multiplier;\n    }\n    set PPQ(ppq) {\n        this._clock.frequency.multiplier = ppq;\n    }\n    //-------------------------------------\n    // \tSYNCING\n    //-------------------------------------\n    /**\n     * Returns the time aligned to the next subdivision\n     * of the Transport. If the Transport is not started,\n     * it will return 0.\n     * Note: this will not work precisely during tempo ramps.\n     * @param  subdivision  The subdivision to quantize to\n     * @return  The context time of the next subdivision.\n     * @example\n     * // the transport must be started, otherwise returns 0\n     * Tone.Transport.start();\n     * Tone.Transport.nextSubdivision(\"4n\");\n     */\n    nextSubdivision(subdivision) {\n        subdivision = this.toTicks(subdivision);\n        if (this.state !== \"started\") {\n            // if the transport's not started, return 0\n            return 0;\n        }\n        else {\n            const now = this.now();\n            // the remainder of the current ticks and the subdivision\n            const transportPos = this.getTicksAtTime(now);\n            const remainingTicks = subdivision - transportPos % subdivision;\n            return this._clock.nextTickTime(remainingTicks, now);\n        }\n    }\n    /**\n     * Attaches the signal to the tempo control signal so that\n     * any changes in the tempo will change the signal in the same\n     * ratio.\n     *\n     * @param signal\n     * @param ratio Optionally pass in the ratio between the two signals.\n     * \t\t\tOtherwise it will be computed based on their current values.\n     */\n    syncSignal(signal, ratio) {\n        if (!ratio) {\n            // get the sync ratio\n            const now = this.now();\n            if (signal.getValueAtTime(now) !== 0) {\n                const bpm = this.bpm.getValueAtTime(now);\n                const computedFreq = 1 / (60 / bpm / this.PPQ);\n                ratio = signal.getValueAtTime(now) / computedFreq;\n            }\n            else {\n                ratio = 0;\n            }\n        }\n        const ratioSignal = new _context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain(ratio);\n        // @ts-ignore\n        this.bpm.connect(ratioSignal);\n        // @ts-ignore\n        ratioSignal.connect(signal._param);\n        this._syncedSignals.push({\n            initial: signal.value,\n            ratio: ratioSignal,\n            signal,\n        });\n        signal.value = 0;\n        return this;\n    }\n    /**\n     * Unsyncs a previously synced signal from the transport's control.\n     * See Transport.syncSignal.\n     */\n    unsyncSignal(signal) {\n        for (let i = this._syncedSignals.length - 1; i >= 0; i--) {\n            const syncedSignal = this._syncedSignals[i];\n            if (syncedSignal.signal === signal) {\n                syncedSignal.ratio.dispose();\n                syncedSignal.signal.value = syncedSignal.initial;\n                this._syncedSignals.splice(i, 1);\n            }\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._clock.dispose();\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_9__.writable)(this, \"bpm\");\n        this._timeline.dispose();\n        this._repeatedEvents.dispose();\n        return this;\n    }\n}\n_util_Emitter__WEBPACK_IMPORTED_MODULE_8__.Emitter.mixin(Transport);\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.transport = new Transport({ context });\n});\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.transport.dispose();\n});\n//# sourceMappingURL=Transport.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/Transport.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TransportEvent.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TransportEvent.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportEvent\": () => (/* binding */ TransportEvent)\n/* harmony export */ });\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n/**\n * TransportEvent is an internal class used by [[Transport]]\n * to schedule events. Do no invoke this class directly, it is\n * handled from within Tone.Transport.\n */\nclass TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        /**\n         * The unique id of the event\n         */\n        this.id = TransportEvent._eventId++;\n        const options = Object.assign(TransportEvent.getDefaults(), opts);\n        this.transport = transport;\n        this.callback = options.callback;\n        this._once = options.once;\n        this.time = options.time;\n    }\n    static getDefaults() {\n        return {\n            callback: _util_Interface__WEBPACK_IMPORTED_MODULE_0__.noOp,\n            once: false,\n            time: 0,\n        };\n    }\n    /**\n     * Invoke the event callback.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        if (this.callback) {\n            this.callback(time);\n            if (this._once) {\n                this.transport.clear(this.id);\n            }\n        }\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this.callback = undefined;\n        return this;\n    }\n}\n/**\n * Current ID counter\n */\nTransportEvent._eventId = 0;\n//# sourceMappingURL=TransportEvent.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/TransportEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportRepeatEvent\": () => (/* binding */ TransportRepeatEvent)\n/* harmony export */ });\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _TransportEvent__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TransportEvent */ \"./node_modules/tone/build/esm/core/clock/TransportEvent.js\");\n\n\n/**\n * TransportRepeatEvent is an internal class used by Tone.Transport\n * to schedule repeat events. This class should not be instantiated directly.\n */\nclass TransportRepeatEvent extends _TransportEvent__WEBPACK_IMPORTED_MODULE_1__.TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        super(transport, opts);\n        /**\n         * The ID of the current timeline event\n         */\n        this._currentId = -1;\n        /**\n         * The ID of the next timeline event\n         */\n        this._nextId = -1;\n        /**\n         * The time of the next event\n         */\n        this._nextTick = this.time;\n        /**\n         * a reference to the bound start method\n         */\n        this._boundRestart = this._restart.bind(this);\n        const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);\n        this.duration = new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(transport.context, options.duration).valueOf();\n        this._interval = new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(transport.context, options.interval).valueOf();\n        this._nextTick = options.time;\n        this.transport.on(\"start\", this._boundRestart);\n        this.transport.on(\"loopStart\", this._boundRestart);\n        this.context = this.transport.context;\n        this._restart();\n    }\n    static getDefaults() {\n        return Object.assign({}, _TransportEvent__WEBPACK_IMPORTED_MODULE_1__.TransportEvent.getDefaults(), {\n            duration: Infinity,\n            interval: 1,\n            once: false,\n        });\n    }\n    /**\n     * Invoke the callback. Returns the tick time which\n     * the next event should be scheduled at.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        // create more events if necessary\n        this._createEvents(time);\n        // call the super class\n        super.invoke(time);\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _createEvents(time) {\n        // schedule the next event\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {\n            this._nextTick += this._interval;\n            this._currentId = this._nextId;\n            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n        }\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _restart(time) {\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this._nextTick = this.time;\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks > this.time) {\n            this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;\n        }\n        this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n        this._nextTick += this._interval;\n        this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this.transport.off(\"start\", this._boundRestart);\n        this.transport.off(\"loopStart\", this._boundRestart);\n        return this;\n    }\n}\n//# sourceMappingURL=TransportRepeatEvent.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/AudioContext.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/AudioContext.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioContext\": () => (/* binding */ createAudioContext),\n/* harmony export */   \"createAudioWorkletNode\": () => (/* binding */ createAudioWorkletNode),\n/* harmony export */   \"createOfflineAudioContext\": () => (/* binding */ createOfflineAudioContext),\n/* harmony export */   \"hasAudioContext\": () => (/* binding */ hasAudioContext),\n/* harmony export */   \"supported\": () => (/* reexport safe */ standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isSupported),\n/* harmony export */   \"theWindow\": () => (/* binding */ theWindow)\n/* harmony export */ });\n/* harmony import */ var standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! standardized-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/module.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n/**\n * Create a new AudioContext\n */\nfunction createAudioContext(options) {\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioContext(options);\n}\n/**\n * Create a new OfflineAudioContext\n */\nfunction createOfflineAudioContext(channels, length, sampleRate) {\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.OfflineAudioContext(channels, length, sampleRate);\n}\n/**\n * A reference to the window object\n * @hidden\n */\nconst theWindow = typeof self === \"object\" ? self : null;\n/**\n * If the browser has a window object which has an AudioContext\n * @hidden\n */\nconst hasAudioContext = theWindow &&\n    (theWindow.hasOwnProperty(\"AudioContext\") || theWindow.hasOwnProperty(\"webkitAudioContext\"));\nfunction createAudioWorkletNode(context, name, options) {\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_1__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isDefined)(standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioWorkletNode), \"This node only works in a secure context (https or localhost)\");\n    // @ts-ignore\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioWorkletNode(context, name, options);\n}\n/**\n * This promise resolves to a boolean which indicates if the\n * functionality is supported within the currently used browse.\n * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)\n */\n\n//# sourceMappingURL=AudioContext.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/AudioContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/BaseContext.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/BaseContext.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseContext\": () => (/* binding */ BaseContext)\n/* harmony export */ });\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n\nclass BaseContext extends _util_Emitter__WEBPACK_IMPORTED_MODULE_0__.Emitter {\n    constructor() {\n        super(...arguments);\n        this.isOffline = false;\n    }\n    /*\n     * This is a placeholder so that JSON.stringify does not throw an error\n     * This matches what JSON.stringify(audioContext) returns on a native\n     * audioContext instance.\n     */\n    toJSON() {\n        return {};\n    }\n}\n//# sourceMappingURL=BaseContext.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/BaseContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Context.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Context.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Context\": () => (/* binding */ Context)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _clock_Ticker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../clock/Ticker */ \"./node_modules/tone/build/esm/core/clock/Ticker.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _AudioContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _BaseContext__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Wrapper around the native AudioContext.\n * @category Core\n */\nclass Context extends _BaseContext__WEBPACK_IMPORTED_MODULE_7__.BaseContext {\n    constructor() {\n        super();\n        this.name = \"Context\";\n        /**\n         * An object containing all of the constants AudioBufferSourceNodes\n         */\n        this._constants = new Map();\n        /**\n         * All of the setTimeout events.\n         */\n        this._timeouts = new _util_Timeline__WEBPACK_IMPORTED_MODULE_3__.Timeline();\n        /**\n         * The timeout id counter\n         */\n        this._timeoutIds = 0;\n        /**\n         * Private indicator if the context has been initialized\n         */\n        this._initialized = false;\n        /**\n         * Indicates if the context is an OfflineAudioContext or an AudioContext\n         */\n        this.isOffline = false;\n        //--------------------------------------------\n        // AUDIO WORKLET\n        //--------------------------------------------\n        /**\n         * Maps a module name to promise of the addModule method\n         */\n        this._workletModules = new Map();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Context.getDefaults(), arguments, [\n            \"context\",\n        ]);\n        if (options.context) {\n            this._context = options.context;\n        }\n        else {\n            this._context = (0,_AudioContext__WEBPACK_IMPORTED_MODULE_5__.createAudioContext)({\n                latencyHint: options.latencyHint,\n            });\n        }\n        this._ticker = new _clock_Ticker__WEBPACK_IMPORTED_MODULE_0__.Ticker(this.emit.bind(this, \"tick\"), options.clockSource, options.updateInterval);\n        this.on(\"tick\", this._timeoutLoop.bind(this));\n        // fwd events from the context\n        this._context.onstatechange = () => {\n            this.emit(\"statechange\", this.state);\n        };\n        this._setLatencyHint(options.latencyHint);\n        this.lookAhead = options.lookAhead;\n    }\n    static getDefaults() {\n        return {\n            clockSource: \"worker\",\n            latencyHint: \"interactive\",\n            lookAhead: 0.1,\n            updateInterval: 0.05,\n        };\n    }\n    /**\n     * Finish setting up the context. **You usually do not need to do this manually.**\n     */\n    initialize() {\n        if (!this._initialized) {\n            // add any additional modules\n            (0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_6__.initializeContext)(this);\n            this._initialized = true;\n        }\n        return this;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return this._context.createAnalyser();\n    }\n    createOscillator() {\n        return this._context.createOscillator();\n    }\n    createBufferSource() {\n        return this._context.createBufferSource();\n    }\n    createBiquadFilter() {\n        return this._context.createBiquadFilter();\n    }\n    createBuffer(numberOfChannels, length, sampleRate) {\n        return this._context.createBuffer(numberOfChannels, length, sampleRate);\n    }\n    createChannelMerger(numberOfInputs) {\n        return this._context.createChannelMerger(numberOfInputs);\n    }\n    createChannelSplitter(numberOfOutputs) {\n        return this._context.createChannelSplitter(numberOfOutputs);\n    }\n    createConstantSource() {\n        return this._context.createConstantSource();\n    }\n    createConvolver() {\n        return this._context.createConvolver();\n    }\n    createDelay(maxDelayTime) {\n        return this._context.createDelay(maxDelayTime);\n    }\n    createDynamicsCompressor() {\n        return this._context.createDynamicsCompressor();\n    }\n    createGain() {\n        return this._context.createGain();\n    }\n    createIIRFilter(feedForward, feedback) {\n        // @ts-ignore\n        return this._context.createIIRFilter(feedForward, feedback);\n    }\n    createPanner() {\n        return this._context.createPanner();\n    }\n    createPeriodicWave(real, imag, constraints) {\n        return this._context.createPeriodicWave(real, imag, constraints);\n    }\n    createStereoPanner() {\n        return this._context.createStereoPanner();\n    }\n    createWaveShaper() {\n        return this._context.createWaveShaper();\n    }\n    createMediaStreamSource(stream) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamSource(stream);\n    }\n    createMediaElementSource(element) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaElementSource(element);\n    }\n    createMediaStreamDestination() {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamDestination();\n    }\n    decodeAudioData(audioData) {\n        return this._context.decodeAudioData(audioData);\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get currentTime() {\n        return this._context.currentTime;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get state() {\n        return this._context.state;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get sampleRate() {\n        return this._context.sampleRate;\n    }\n    /**\n     * The listener\n     */\n    get listener() {\n        this.initialize();\n        return this._listener;\n    }\n    set listener(l) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The listener cannot be set after initialization.\");\n        this._listener = l;\n    }\n    /**\n     * There is only one Transport per Context. It is created on initialization.\n     */\n    get transport() {\n        this.initialize();\n        return this._transport;\n    }\n    set transport(t) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The transport cannot be set after initialization.\");\n        this._transport = t;\n    }\n    /**\n     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.\n     */\n    get draw() {\n        this.initialize();\n        return this._draw;\n    }\n    set draw(d) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"Draw cannot be set after initialization.\");\n        this._draw = d;\n    }\n    /**\n     * A reference to the Context's destination node.\n     */\n    get destination() {\n        this.initialize();\n        return this._destination;\n    }\n    set destination(d) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The destination cannot be set after initialization.\");\n        this._destination = d;\n    }\n    /**\n     * Create an audio worklet node from a name and options. The module\n     * must first be loaded using [[addAudioWorkletModule]].\n     */\n    createAudioWorkletNode(name, options) {\n        return (0,_AudioContext__WEBPACK_IMPORTED_MODULE_5__.createAudioWorkletNode)(this.rawContext, name, options);\n    }\n    /**\n     * Add an AudioWorkletProcessor module\n     * @param url The url of the module\n     * @param name The name of the module\n     */\n    addAudioWorkletModule(url, name) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.rawContext.audioWorklet), \"AudioWorkletNode is only available in a secure context (https or localhost)\");\n            if (!this._workletModules.has(name)) {\n                this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));\n            }\n            yield this._workletModules.get(name);\n        });\n    }\n    /**\n     * Returns a promise which resolves when all of the worklets have been loaded on this context\n     */\n    workletsAreReady() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            const promises = [];\n            this._workletModules.forEach((promise) => promises.push(promise));\n            yield Promise.all(promises);\n        });\n    }\n    //---------------------------\n    // TICKER\n    //---------------------------\n    /**\n     * How often the interval callback is invoked.\n     * This number corresponds to how responsive the scheduling\n     * can be. context.updateInterval + context.lookAhead gives you the\n     * total latency between scheduling an event and hearing it.\n     */\n    get updateInterval() {\n        return this._ticker.updateInterval;\n    }\n    set updateInterval(interval) {\n        this._ticker.updateInterval = interval;\n    }\n    /**\n     * What the source of the clock is, either \"worker\" (default),\n     * \"timeout\", or \"offline\" (none).\n     */\n    get clockSource() {\n        return this._ticker.type;\n    }\n    set clockSource(type) {\n        this._ticker.type = type;\n    }\n    /**\n     * The type of playback, which affects tradeoffs between audio\n     * output latency and responsiveness.\n     * In addition to setting the value in seconds, the latencyHint also\n     * accepts the strings \"interactive\" (prioritizes low latency),\n     * \"playback\" (prioritizes sustained playback), \"balanced\" (balances\n     * latency and performance).\n     * @example\n     * // prioritize sustained playback\n     * const context = new Tone.Context({ latencyHint: \"playback\" });\n     * // set this context as the global Context\n     * Tone.setContext(context);\n     * // the global context is gettable with Tone.getContext()\n     * console.log(Tone.getContext().latencyHint);\n     */\n    get latencyHint() {\n        return this._latencyHint;\n    }\n    /**\n     * Update the lookAhead and updateInterval based on the latencyHint\n     */\n    _setLatencyHint(hint) {\n        let lookAheadValue = 0;\n        this._latencyHint = hint;\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isString)(hint)) {\n            switch (hint) {\n                case \"interactive\":\n                    lookAheadValue = 0.1;\n                    break;\n                case \"playback\":\n                    lookAheadValue = 0.5;\n                    break;\n                case \"balanced\":\n                    lookAheadValue = 0.25;\n                    break;\n            }\n        }\n        this.lookAhead = lookAheadValue;\n        this.updateInterval = lookAheadValue / 2;\n    }\n    /**\n     * The unwrapped AudioContext or OfflineAudioContext\n     */\n    get rawContext() {\n        return this._context;\n    }\n    /**\n     * The current audio context time plus a short [[lookAhead]].\n     */\n    now() {\n        return this._context.currentTime + this.lookAhead;\n    }\n    /**\n     * The current audio context time without the [[lookAhead]].\n     * In most cases it is better to use [[now]] instead of [[immediate]] since\n     * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,\n     * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]\n     * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.\n     */\n    immediate() {\n        return this._context.currentTime;\n    }\n    /**\n     * Starts the audio context from a suspended state. This is required\n     * to initially start the AudioContext. See [[Tone.start]]\n     */\n    resume() {\n        if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context)) {\n            return this._context.resume();\n        }\n        else {\n            return Promise.resolve();\n        }\n    }\n    /**\n     * Close the context. Once closed, the context can no longer be used and\n     * any AudioNodes created from the context will be silent.\n     */\n    close() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context)) {\n                yield this._context.close();\n            }\n            if (this._initialized) {\n                (0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_6__.closeContext)(this);\n            }\n        });\n    }\n    /**\n     * **Internal** Generate a looped buffer at some constant value.\n     */\n    getConstant(val) {\n        if (this._constants.has(val)) {\n            return this._constants.get(val);\n        }\n        else {\n            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);\n            const arr = buffer.getChannelData(0);\n            for (let i = 0; i < arr.length; i++) {\n                arr[i] = val;\n            }\n            const constant = this._context.createBufferSource();\n            constant.channelCount = 1;\n            constant.channelCountMode = \"explicit\";\n            constant.buffer = buffer;\n            constant.loop = true;\n            constant.start(0);\n            this._constants.set(val, constant);\n            return constant;\n        }\n    }\n    /**\n     * Clean up. Also closes the audio context.\n     */\n    dispose() {\n        super.dispose();\n        this._ticker.dispose();\n        this._timeouts.dispose();\n        Object.keys(this._constants).map((val) => this._constants[val].disconnect());\n        return this;\n    }\n    //---------------------------\n    // TIMEOUTS\n    //---------------------------\n    /**\n     * The private loop which keeps track of the context scheduled timeouts\n     * Is invoked from the clock source\n     */\n    _timeoutLoop() {\n        const now = this.now();\n        let firstEvent = this._timeouts.peek();\n        while (this._timeouts.length && firstEvent && firstEvent.time <= now) {\n            // invoke the callback\n            firstEvent.callback();\n            // shift the first event off\n            this._timeouts.shift();\n            // get the next one\n            firstEvent = this._timeouts.peek();\n        }\n    }\n    /**\n     * A setTimeout which is guaranteed by the clock source.\n     * Also runs in the offline context.\n     * @param  fn       The callback to invoke\n     * @param  timeout  The timeout in seconds\n     * @returns ID to use when invoking Context.clearTimeout\n     */\n    setTimeout(fn, timeout) {\n        this._timeoutIds++;\n        const now = this.now();\n        this._timeouts.add({\n            callback: fn,\n            id: this._timeoutIds,\n            time: now + timeout,\n        });\n        return this._timeoutIds;\n    }\n    /**\n     * Clears a previously scheduled timeout with Tone.context.setTimeout\n     * @param  id  The ID returned from setTimeout\n     */\n    clearTimeout(id) {\n        this._timeouts.forEach((event) => {\n            if (event.id === id) {\n                this._timeouts.remove(event);\n            }\n        });\n        return this;\n    }\n    /**\n     * Clear the function scheduled by [[setInterval]]\n     */\n    clearInterval(id) {\n        return this.clearTimeout(id);\n    }\n    /**\n     * Adds a repeating event to the context's callback clock\n     */\n    setInterval(fn, interval) {\n        const id = ++this._timeoutIds;\n        const intervalFn = () => {\n            const now = this.now();\n            this._timeouts.add({\n                callback: () => {\n                    // invoke the callback\n                    fn();\n                    // invoke the event to repeat it\n                    intervalFn();\n                },\n                id,\n                time: now + interval,\n            });\n        };\n        // kick it off\n        intervalFn();\n        return id;\n    }\n}\n//# sourceMappingURL=Context.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Context.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ContextInitialization.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ContextInitialization.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"closeContext\": () => (/* binding */ closeContext),\n/* harmony export */   \"initializeContext\": () => (/* binding */ initializeContext),\n/* harmony export */   \"onContextClose\": () => (/* binding */ onContextClose),\n/* harmony export */   \"onContextInit\": () => (/* binding */ onContextInit)\n/* harmony export */ });\n//-------------------------------------\n// INITIALIZING NEW CONTEXT\n//-------------------------------------\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyNewContext = [];\n/**\n * Used internally to setup a new Context\n */\nfunction onContextInit(cb) {\n    notifyNewContext.push(cb);\n}\n/**\n * Invoke any classes which need to also be initialized when a new context is created.\n */\nfunction initializeContext(ctx) {\n    // add any additional modules\n    notifyNewContext.forEach(cb => cb(ctx));\n}\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyCloseContext = [];\n/**\n * Used internally to tear down a Context\n */\nfunction onContextClose(cb) {\n    notifyCloseContext.push(cb);\n}\nfunction closeContext(ctx) {\n    // add any additional modules\n    notifyCloseContext.forEach(cb => cb(ctx));\n}\n//# sourceMappingURL=ContextInitialization.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/ContextInitialization.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Delay.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Delay.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Delay\": () => (/* binding */ Delay)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n/**\n * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst delay = new Tone.Delay(0.1).toDestination();\n * \t// connect the signal to both the delay and the destination\n * \tconst pulse = new Tone.PulseOscillator().connect(delay).toDestination();\n * \t// start and stop the pulse\n * \tpulse.start(0).stop(0.01);\n * }, 0.5, 1);\n */\nclass Delay extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]));\n        this.name = \"Delay\";\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]);\n        const maxDelayInSeconds = this.toSeconds(options.maxDelay);\n        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));\n        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);\n        this.delayTime = new _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._delayNode.delayTime,\n            units: \"time\",\n            value: options.delayTime,\n            minValue: 0,\n            maxValue: this.maxDelay,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            delayTime: 0,\n            maxDelay: 1,\n        });\n    }\n    /**\n     * The maximum delay time. This cannot be changed after\n     * the value is passed into the constructor.\n     */\n    get maxDelay() {\n        return this._maxDelay;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._delayNode.disconnect();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Delay.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Delay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Destination.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Destination.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Destination\": () => (/* binding */ Destination)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n/**\n * A single master output which is connected to the\n * AudioDestinationNode (aka your speakers).\n * It provides useful conveniences such as the ability\n * to set the volume and mute the entire application.\n * It also gives you the ability to apply master effects to your application.\n *\n * @example\n * const oscillator = new Tone.Oscillator().start();\n * // the audio will go from the oscillator to the speakers\n * oscillator.connect(Tone.getDestination());\n * // a convenience for connecting to the master output is also provided:\n * oscillator.toDestination();\n * @category Core\n */\nclass Destination extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Destination.getDefaults(), arguments));\n        this.name = \"Destination\";\n        this.input = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({ context: this.context });\n        this.output = new _Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        /**\n         * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.\n         * @example\n         * const osc = new Tone.Oscillator().toDestination();\n         * osc.start();\n         * // ramp the volume down to silent over 10 seconds\n         * Tone.getDestination().volume.rampTo(-Infinity, 10);\n         */\n        this.volume = this.input.volume;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Destination.getDefaults(), arguments);\n        (0,_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(this.input, this.output, this.context.rawContext.destination);\n        this.mute = options.mute;\n        this._internalChannels = [this.input, this.context.rawContext.destination, this.output];\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const oscillator = new Tone.Oscillator().start().toDestination();\n     * setTimeout(() => {\n     * \t// mute the output\n     * \tTone.Destination.mute = true;\n     * }, 1000);\n     */\n    get mute() {\n        return this.input.mute;\n    }\n    set mute(mute) {\n        this.input.mute = mute;\n    }\n    /**\n     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously\n     * chained in the master effects chain.\n     * @param args All arguments will be connected in a row and the Master will be routed through it.\n     * @example\n     * // route all audio through a filter and compressor\n     * const lowpass = new Tone.Filter(800, \"lowpass\");\n     * const compressor = new Tone.Compressor(-18);\n     * Tone.Destination.chain(lowpass, compressor);\n     */\n    chain(...args) {\n        this.input.disconnect();\n        args.unshift(this.input);\n        args.push(this.output);\n        (0,_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(...args);\n        return this;\n    }\n    /**\n     * The maximum number of channels the system can output\n     * @example\n     * console.log(Tone.Destination.maxChannelCount);\n     */\n    get maxChannelCount() {\n        return this.context.rawContext.destination.maxChannelCount;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.destination = new Destination({ context });\n});\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.destination.dispose();\n});\n//# sourceMappingURL=Destination.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Destination.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/DummyContext.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/DummyContext.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DummyContext\": () => (/* binding */ DummyContext)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _BaseContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n\n\nclass DummyContext extends _BaseContext__WEBPACK_IMPORTED_MODULE_0__.BaseContext {\n    constructor() {\n        super(...arguments);\n        this.lookAhead = 0;\n        this.latencyHint = 0;\n        this.isOffline = false;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return {};\n    }\n    createOscillator() {\n        return {};\n    }\n    createBufferSource() {\n        return {};\n    }\n    createBiquadFilter() {\n        return {};\n    }\n    createBuffer(_numberOfChannels, _length, _sampleRate) {\n        return {};\n    }\n    createChannelMerger(_numberOfInputs) {\n        return {};\n    }\n    createChannelSplitter(_numberOfOutputs) {\n        return {};\n    }\n    createConstantSource() {\n        return {};\n    }\n    createConvolver() {\n        return {};\n    }\n    createDelay(_maxDelayTime) {\n        return {};\n    }\n    createDynamicsCompressor() {\n        return {};\n    }\n    createGain() {\n        return {};\n    }\n    createIIRFilter(_feedForward, _feedback) {\n        return {};\n    }\n    createPanner() {\n        return {};\n    }\n    createPeriodicWave(_real, _imag, _constraints) {\n        return {};\n    }\n    createStereoPanner() {\n        return {};\n    }\n    createWaveShaper() {\n        return {};\n    }\n    createMediaStreamSource(_stream) {\n        return {};\n    }\n    createMediaElementSource(_element) {\n        return {};\n    }\n    createMediaStreamDestination() {\n        return {};\n    }\n    decodeAudioData(_audioData) {\n        return Promise.resolve({});\n    }\n    //---------------------------\n    // TONE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAudioWorkletNode(_name, _options) {\n        return {};\n    }\n    get rawContext() {\n        return {};\n    }\n    addAudioWorkletModule(_url, _name) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_1__.__awaiter)(this, void 0, void 0, function* () {\n            return Promise.resolve();\n        });\n    }\n    resume() {\n        return Promise.resolve();\n    }\n    setTimeout(_fn, _timeout) {\n        return 0;\n    }\n    clearTimeout(_id) {\n        return this;\n    }\n    setInterval(_fn, _interval) {\n        return 0;\n    }\n    clearInterval(_id) {\n        return this;\n    }\n    getConstant(_val) {\n        return {};\n    }\n    get currentTime() {\n        return 0;\n    }\n    get state() {\n        return {};\n    }\n    get sampleRate() {\n        return 0;\n    }\n    get listener() {\n        return {};\n    }\n    get transport() {\n        return {};\n    }\n    get draw() {\n        return {};\n    }\n    set draw(_d) { }\n    get destination() {\n        return {};\n    }\n    set destination(_d) { }\n    now() {\n        return 0;\n    }\n    immediate() {\n        return 0;\n    }\n}\n//# sourceMappingURL=DummyContext.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/DummyContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Gain.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Gain.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Gain\": () => (/* binding */ Gain)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n/**\n * A thin wrapper around the Native Web Audio GainNode.\n * The GainNode is a basic building block of the Web Audio\n * API and is useful for routing audio and adjusting gains.\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst gainNode = new Tone.Gain(0).toDestination();\n * \tconst osc = new Tone.Oscillator(30).connect(gainNode).start();\n * \tgainNode.gain.rampTo(1, 0.1);\n * \tgainNode.gain.rampTo(0, 0.4, 0.2);\n * }, 0.7, 1);\n */\nclass Gain extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Gain.getDefaults(), arguments, [\"gain\", \"units\"]));\n        this.name = \"Gain\";\n        /**\n         * The wrapped GainNode.\n         */\n        this._gainNode = this.context.createGain();\n        // input = output\n        this.input = this._gainNode;\n        this.output = this._gainNode;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Gain.getDefaults(), arguments, [\"gain\", \"units\"]);\n        this.gain = new _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._gainNode.gain,\n            units: options.units,\n            value: options.gain,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"gain\");\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            convert: true,\n            gain: 1,\n            units: \"gain\",\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gain.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Gain.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Listener.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Listener.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Listener\": () => (/* binding */ Listener)\n/* harmony export */ });\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n\n\n\n/**\n * Tone.Listener is a thin wrapper around the AudioListener. Listener combined\n * with [[Panner3D]] makes up the Web Audio API's 3D panning system. Panner3D allows you\n * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from\n * a first-person perspective. There is only one listener per audio context.\n */\nclass Listener extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(...arguments);\n        this.name = \"Listener\";\n        this.positionX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionX,\n        });\n        this.positionY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionY,\n        });\n        this.positionZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionZ,\n        });\n        this.forwardX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardX,\n        });\n        this.forwardY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardY,\n        });\n        this.forwardZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardZ,\n        });\n        this.upX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upX,\n        });\n        this.upY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upY,\n        });\n        this.upZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            forwardX: 0,\n            forwardY: 0,\n            forwardZ: -1,\n            upX: 0,\n            upY: 1,\n            upZ: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        this.forwardX.dispose();\n        this.forwardY.dispose();\n        this.forwardZ.dispose();\n        this.upX.dispose();\n        this.upY.dispose();\n        this.upZ.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.listener = new Listener({ context });\n});\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.listener.dispose();\n});\n//# sourceMappingURL=Listener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Listener.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Offline.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Offline.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Offline\": () => (/* binding */ Offline)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _OfflineContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n\n\n\n\n/**\n * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.\n * The OfflineAudioContext is capable of rendering much faster than real time in many cases.\n * The callback function also passes in an offline instance of [[Context]] which can be used\n * to schedule events along the Transport.\n * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.\n * @param  duration     the amount of time to record for.\n * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.\n * @example\n * // render 2 seconds of the oscillator\n * Tone.Offline(() => {\n * \t// only nodes created in this callback will be recorded\n * \tconst oscillator = new Tone.Oscillator().toDestination().start(0);\n * }, 2).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @example\n * // can also schedule events along the Transport\n * // using the passed in Offline Transport\n * Tone.Offline(({ transport }) => {\n * \tconst osc = new Tone.Oscillator().toDestination();\n * \ttransport.schedule(time => {\n * \t\tosc.start(time).stop(time + 0.1);\n * \t}, 1);\n * \t// make sure to start the transport\n * \ttransport.start(0.2);\n * }, 4).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @category Core\n */\nfunction Offline(callback, duration, channels = 2, sampleRate = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().sampleRate) {\n    return (0,tslib__WEBPACK_IMPORTED_MODULE_3__.__awaiter)(this, void 0, void 0, function* () {\n        // set the OfflineAudioContext based on the current context\n        const originalContext = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n        const context = new _OfflineContext__WEBPACK_IMPORTED_MODULE_1__.OfflineContext(channels, duration, sampleRate);\n        (0,_Global__WEBPACK_IMPORTED_MODULE_0__.setContext)(context);\n        // invoke the callback/scheduling\n        yield callback(context);\n        // then render the audio\n        const bufferPromise = context.render();\n        // return the original AudioContext\n        (0,_Global__WEBPACK_IMPORTED_MODULE_0__.setContext)(originalContext);\n        // await the rendering\n        const buffer = yield bufferPromise;\n        // return the audio\n        return new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(buffer);\n    });\n}\n//# sourceMappingURL=Offline.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Offline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/OfflineContext.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/OfflineContext.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OfflineContext\": () => (/* binding */ OfflineContext)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n\n\n\n\n\n/**\n * Wrapper around the OfflineAudioContext\n * @category Core\n * @example\n * // generate a single channel, 0.5 second buffer\n * const context = new Tone.OfflineContext(1, 0.5, 44100);\n * const osc = new Tone.Oscillator({ context });\n * context.render().then(buffer => {\n * \tconsole.log(buffer.numberOfChannels, buffer.duration);\n * });\n */\nclass OfflineContext extends _context_Context__WEBPACK_IMPORTED_MODULE_1__.Context {\n    constructor() {\n        super({\n            clockSource: \"offline\",\n            context: (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n                arguments[0] : (0,_context_AudioContext__WEBPACK_IMPORTED_MODULE_0__.createOfflineAudioContext)(arguments[0], arguments[1] * arguments[2], arguments[2]),\n            lookAhead: 0,\n            updateInterval: (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n                128 / arguments[0].sampleRate : 128 / arguments[2],\n        });\n        this.name = \"OfflineContext\";\n        /**\n         * An artificial clock source\n         */\n        this._currentTime = 0;\n        this.isOffline = true;\n        this._duration = (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n            arguments[0].length / arguments[0].sampleRate : arguments[1];\n    }\n    /**\n     * Override the now method to point to the internal clock time\n     */\n    now() {\n        return this._currentTime;\n    }\n    /**\n     * Same as this.now()\n     */\n    get currentTime() {\n        return this._currentTime;\n    }\n    /**\n     * Render just the clock portion of the audio context.\n     */\n    _renderClock(asynchronous) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_4__.__awaiter)(this, void 0, void 0, function* () {\n            let index = 0;\n            while (this._duration - this._currentTime >= 0) {\n                // invoke all the callbacks on that time\n                this.emit(\"tick\");\n                // increment the clock in block-sized chunks\n                this._currentTime += 128 / this.sampleRate;\n                // yield once a second of audio\n                index++;\n                const yieldEvery = Math.floor(this.sampleRate / 128);\n                if (asynchronous && index % yieldEvery === 0) {\n                    yield new Promise(done => setTimeout(done, 1));\n                }\n            }\n        });\n    }\n    /**\n     * Render the output of the OfflineContext\n     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.\n     */\n    render(asynchronous = true) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_4__.__awaiter)(this, void 0, void 0, function* () {\n            yield this.workletsAreReady();\n            yield this._renderClock(asynchronous);\n            const buffer = yield this._context.startRendering();\n            return new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer(buffer);\n        });\n    }\n    /**\n     * Close the context\n     */\n    close() {\n        return Promise.resolve();\n    }\n}\n//# sourceMappingURL=OfflineContext.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/OfflineContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Param.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Param.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Param\": () => (/* binding */ Param)\n/* harmony export */ });\n/* harmony import */ var _type_Conversions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneWithContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Math__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * Param wraps the native Web Audio's AudioParam to provide\n * additional unit conversion functionality. It also\n * serves as a base-class for classes which have a single,\n * automatable parameter.\n * @category Core\n */\nclass Param extends _ToneWithContext__WEBPACK_IMPORTED_MODULE_5__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]));\n        this.name = \"Param\";\n        this.overridden = false;\n        /**\n         * The minimum output value\n         */\n        this._minOutput = 1e-7;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.param) &&\n            ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioParam)(options.param) || options.param instanceof Param), \"param must be an AudioParam\");\n        while (!(0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioParam)(options.param)) {\n            options.param = options.param._param;\n        }\n        this._swappable = (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.swappable) ? options.swappable : false;\n        if (this._swappable) {\n            this.input = this.context.createGain();\n            // initialize\n            this._param = options.param;\n            this.input.connect(this._param);\n        }\n        else {\n            this._param = this.input = options.param;\n        }\n        this._events = new _util_Timeline__WEBPACK_IMPORTED_MODULE_3__.Timeline(1000);\n        this._initialValue = this._param.defaultValue;\n        this.units = options.units;\n        this.convert = options.convert;\n        this._minValue = options.minValue;\n        this._maxValue = options.maxValue;\n        // if the value is defined, set it immediately\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.value) && options.value !== this._toType(this._initialValue)) {\n            this.setValueAtTime(options.value, 0);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_ToneWithContext__WEBPACK_IMPORTED_MODULE_5__.ToneWithContext.getDefaults(), {\n            convert: true,\n            units: \"number\",\n        });\n    }\n    get value() {\n        const now = this.now();\n        return this.getValueAtTime(now);\n    }\n    set value(value) {\n        this.cancelScheduledValues(this.now());\n        this.setValueAtTime(value, this.now());\n    }\n    get minValue() {\n        // if it's not the default minValue, return it\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this._minValue)) {\n            return this._minValue;\n        }\n        else if (this.units === \"time\" || this.units === \"frequency\" ||\n            this.units === \"normalRange\" || this.units === \"positive\" ||\n            this.units === \"transportTime\" || this.units === \"ticks\" ||\n            this.units === \"bpm\" || this.units === \"hertz\" || this.units === \"samples\") {\n            return 0;\n        }\n        else if (this.units === \"audioRange\") {\n            return -1;\n        }\n        else if (this.units === \"decibels\") {\n            return -Infinity;\n        }\n        else {\n            return this._param.minValue;\n        }\n    }\n    get maxValue() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this._maxValue)) {\n            return this._maxValue;\n        }\n        else if (this.units === \"normalRange\" ||\n            this.units === \"audioRange\") {\n            return 1;\n        }\n        else {\n            return this._param.maxValue;\n        }\n    }\n    /**\n     * Type guard based on the unit name\n     */\n    _is(arg, type) {\n        return this.units === type;\n    }\n    /**\n     * Make sure the value is always in the defined range\n     */\n    _assertRange(value) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.maxValue) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.minValue)) {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(value, this._fromType(this.minValue), this._fromType(this.maxValue));\n        }\n        return value;\n    }\n    /**\n     * Convert the given value from the type specified by Param.units\n     * into the destination value (such as Gain or Frequency).\n     */\n    _fromType(val) {\n        if (this.convert && !this.overridden) {\n            if (this._is(val, \"time\")) {\n                return this.toSeconds(val);\n            }\n            else if (this._is(val, \"decibels\")) {\n                return (0,_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.dbToGain)(val);\n            }\n            else if (this._is(val, \"frequency\")) {\n                return this.toFrequency(val);\n            }\n            else {\n                return val;\n            }\n        }\n        else if (this.overridden) {\n            // if it's overridden, should only schedule 0s\n            return 0;\n        }\n        else {\n            return val;\n        }\n    }\n    /**\n     * Convert the parameters value into the units specified by Param.units.\n     */\n    _toType(val) {\n        if (this.convert && this.units === \"decibels\") {\n            return (0,_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.gainToDb)(val);\n        }\n        else {\n            return val;\n        }\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // all docs are generated from ParamInterface.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        const numericValue = this._fromType(value);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);\n        this._assertRange(numericValue);\n        this.log(this.units, \"setValueAtTime\", value, computedTime);\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: numericValue,\n        });\n        this._param.setValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    getValueAtTime(time) {\n        const computedTime = Math.max(this.toSeconds(time), 0);\n        const after = this._events.getAfter(computedTime);\n        const before = this._events.get(computedTime);\n        let value = this._initialValue;\n        // if it was set by\n        if (before === null) {\n            value = this._initialValue;\n        }\n        else if (before.type === \"setTargetAtTime\" && (after === null || after.type === \"setValueAtTime\")) {\n            const previous = this._events.getBefore(before.time);\n            let previousVal;\n            if (previous === null) {\n                previousVal = this._initialValue;\n            }\n            else {\n                previousVal = previous.value;\n            }\n            if (before.type === \"setTargetAtTime\") {\n                value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);\n            }\n        }\n        else if (after === null) {\n            value = before.value;\n        }\n        else if (after.type === \"linearRampToValueAtTime\" || after.type === \"exponentialRampToValueAtTime\") {\n            let beforeValue = before.value;\n            if (before.type === \"setTargetAtTime\") {\n                const previous = this._events.getBefore(before.time);\n                if (previous === null) {\n                    beforeValue = this._initialValue;\n                }\n                else {\n                    beforeValue = previous.value;\n                }\n            }\n            if (after.type === \"linearRampToValueAtTime\") {\n                value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n            else {\n                value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n        }\n        else {\n            value = before.value;\n        }\n        return this._toType(value);\n    }\n    setRampPoint(time) {\n        time = this.toSeconds(time);\n        let currentVal = this.getValueAtTime(time);\n        this.cancelAndHoldAtTime(time);\n        if (this._fromType(currentVal) === 0) {\n            currentVal = this._toType(this._minOutput);\n        }\n        this.setValueAtTime(currentVal, time);\n        return this;\n    }\n    linearRampToValueAtTime(value, endTime) {\n        const numericValue = this._fromType(value);\n        const computedTime = this.toSeconds(endTime);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        this._assertRange(numericValue);\n        this._events.add({\n            time: computedTime,\n            type: \"linearRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"linearRampToValueAtTime\", value, computedTime);\n        this._param.linearRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, endTime) {\n        let numericValue = this._fromType(value);\n        // the value can't be 0\n        numericValue = (0,_util_Math__WEBPACK_IMPORTED_MODULE_6__.EQ)(numericValue, 0) ? this._minOutput : numericValue;\n        this._assertRange(numericValue);\n        const computedTime = this.toSeconds(endTime);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        // store the event\n        this._events.add({\n            time: computedTime,\n            type: \"exponentialRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"exponentialRampToValueAtTime\", value, computedTime);\n        this._param.exponentialRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialApproachValueAtTime(value, startTime, rampTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        time = this.toSeconds(time);\n        rampTime = this.toSeconds(rampTime);\n        const timeConstant = Math.log(rampTime + 1) / Math.log(200);\n        this.setTargetAtTime(value, time, timeConstant);\n        // at 90% start a linear ramp to the final value\n        this.cancelAndHoldAtTime(time + rampTime * 0.9);\n        this.linearRampToValueAtTime(value, time + rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const numericValue = this._fromType(value);\n        // The value will never be able to approach without timeConstant > 0.\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(timeConstant) && timeConstant > 0, \"timeConstant must be a number greater than 0\");\n        const computedTime = this.toSeconds(startTime);\n        this._assertRange(numericValue);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);\n        this._events.add({\n            constant: timeConstant,\n            time: computedTime,\n            type: \"setTargetAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"setTargetAtTime\", value, computedTime, timeConstant);\n        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling = 1) {\n        duration = this.toSeconds(duration);\n        startTime = this.toSeconds(startTime);\n        const startingValue = this._fromType(values[0]) * scaling;\n        this.setValueAtTime(this._toType(startingValue), startTime);\n        const segTime = duration / (values.length - 1);\n        for (let i = 1; i < values.length; i++) {\n            const numericValue = this._fromType(values[i]) * scaling;\n            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);\n        }\n        return this;\n    }\n    cancelScheduledValues(time) {\n        const computedTime = this.toSeconds(time);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);\n        this._events.cancel(computedTime);\n        this._param.cancelScheduledValues(computedTime);\n        this.log(this.units, \"cancelScheduledValues\", computedTime);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));\n        // remove the schedule events\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);\n        this.log(this.units, \"cancelAndHoldAtTime\", computedTime, \"value=\" + valueAtTime);\n        // if there is an event at the given computedTime\n        // and that even is not a \"set\"\n        const before = this._events.get(computedTime);\n        const after = this._events.getAfter(computedTime);\n        if (before && (0,_util_Math__WEBPACK_IMPORTED_MODULE_6__.EQ)(before.time, computedTime)) {\n            // remove everything after\n            if (after) {\n                this._param.cancelScheduledValues(after.time);\n                this._events.cancel(after.time);\n            }\n            else {\n                this._param.cancelAndHoldAtTime(computedTime);\n                this._events.cancel(computedTime + this.sampleTime);\n            }\n        }\n        else if (after) {\n            this._param.cancelScheduledValues(after.time);\n            // cancel the next event(s)\n            this._events.cancel(after.time);\n            if (after.type === \"linearRampToValueAtTime\") {\n                this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n            else if (after.type === \"exponentialRampToValueAtTime\") {\n                this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n        }\n        // set the value at the given time\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: valueAtTime,\n        });\n        this._param.setValueAtTime(valueAtTime, computedTime);\n        return this;\n    }\n    rampTo(value, rampTime = 0.1, startTime) {\n        if (this.units === \"frequency\" || this.units === \"bpm\" || this.units === \"decibels\") {\n            this.exponentialRampTo(value, rampTime, startTime);\n        }\n        else {\n            this.linearRampTo(value, rampTime, startTime);\n        }\n        return this;\n    }\n    /**\n     * Apply all of the previously scheduled events to the passed in Param or AudioParam.\n     * The applied values will start at the context's current time and schedule\n     * all of the events which are scheduled on this Param onto the passed in param.\n     */\n    apply(param) {\n        const now = this.context.currentTime;\n        // set the param's value at the current time and schedule everything else\n        param.setValueAtTime(this.getValueAtTime(now), now);\n        // if the previous event was a curve, then set the rest of it\n        const previousEvent = this._events.get(now);\n        if (previousEvent && previousEvent.type === \"setTargetAtTime\") {\n            // approx it until the next event with linear ramps\n            const nextEvent = this._events.getAfter(previousEvent.time);\n            // or for 2 seconds if there is no event\n            const endTime = nextEvent ? nextEvent.time : now + 2;\n            const subdivisions = (endTime - now) / 10;\n            for (let i = now; i < endTime; i += subdivisions) {\n                param.linearRampToValueAtTime(this.getValueAtTime(i), i);\n            }\n        }\n        this._events.forEachAfter(this.context.currentTime, event => {\n            if (event.type === \"cancelScheduledValues\") {\n                param.cancelScheduledValues(event.time);\n            }\n            else if (event.type === \"setTargetAtTime\") {\n                param.setTargetAtTime(event.value, event.time, event.constant);\n            }\n            else {\n                param[event.type](event.value, event.time);\n            }\n        });\n        return this;\n    }\n    /**\n     * Replace the Param's internal AudioParam. Will apply scheduled curves\n     * onto the parameter and replace the connections.\n     */\n    setParam(param) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(this._swappable, \"The Param must be assigned as 'swappable' in the constructor\");\n        const input = this.input;\n        input.disconnect(this._param);\n        this.apply(param);\n        this._param = param;\n        input.connect(this._param);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        return this;\n    }\n    get defaultValue() {\n        return this._toType(this._param.defaultValue);\n    }\n    //-------------------------------------\n    // \tAUTOMATION CURVE CALCULATIONS\n    // \tMIT License, copyright (c) 2014 Jordan Santell\n    //-------------------------------------\n    // Calculates the the value along the curve produced by setTargetAtTime\n    _exponentialApproach(t0, v0, v1, timeConstant, t) {\n        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);\n    }\n    // Calculates the the value along the curve produced by linearRampToValueAtTime\n    _linearInterpolate(t0, v0, t1, v1, t) {\n        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));\n    }\n    // Calculates the the value along the curve produced by exponentialRampToValueAtTime\n    _exponentialInterpolate(t0, v0, t1, v1, t) {\n        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));\n    }\n}\n//# sourceMappingURL=Param.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/Param.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioBuffer\": () => (/* binding */ ToneAudioBuffer)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all\n * classes that make requests for audio files such as Tone.Player,\n * Tone.Sampler and Tone.Convolver.\n * @example\n * const buffer = new Tone.ToneAudioBuffer(\"https://tonejs.github.io/audio/casio/A1.mp3\", () => {\n * \tconsole.log(\"loaded\");\n * });\n * @category Core\n */\nclass ToneAudioBuffer extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffer\";\n        /**\n         * Callback when the buffer is loaded.\n         */\n        this.onload = _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneAudioBuffer.getDefaults(), arguments, [\"url\", \"onload\", \"onerror\"]);\n        this.reverse = options.reverse;\n        this.onload = options.onload;\n        if (options.url && (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isAudioBuffer)(options.url) || options.url instanceof ToneAudioBuffer) {\n            this.set(options.url);\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isString)(options.url)) {\n            // initiate the download\n            this.load(options.url).catch(options.onerror);\n        }\n    }\n    static getDefaults() {\n        return {\n            onerror: _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onload: _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            reverse: false,\n        };\n    }\n    /**\n     * The sample rate of the AudioBuffer\n     */\n    get sampleRate() {\n        if (this._buffer) {\n            return this._buffer.sampleRate;\n        }\n        else {\n            return (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().sampleRate;\n        }\n    }\n    /**\n     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.\n     */\n    set(buffer) {\n        if (buffer instanceof ToneAudioBuffer) {\n            // if it's loaded, set it\n            if (buffer.loaded) {\n                this._buffer = buffer.get();\n            }\n            else {\n                // otherwise when it's loaded, invoke it's callback\n                buffer.onload = () => {\n                    this.set(buffer);\n                    this.onload(this);\n                };\n            }\n        }\n        else {\n            this._buffer = buffer;\n        }\n        // reverse it initially\n        if (this._reversed) {\n            this._reverse();\n        }\n        return this;\n    }\n    /**\n     * The audio buffer stored in the object.\n     */\n    get() {\n        return this._buffer;\n    }\n    /**\n     * Makes an fetch request for the selected url then decodes the file as an audio buffer.\n     * Invokes the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     * @returns A Promise which resolves with this ToneAudioBuffer\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const doneLoading = ToneAudioBuffer.load(url).then(audioBuffer => {\n                this.set(audioBuffer);\n                // invoke the onload method\n                this.onload(this);\n            });\n            ToneAudioBuffer.downloads.push(doneLoading);\n            try {\n                yield doneLoading;\n            }\n            finally {\n                // remove the downloaded file\n                const index = ToneAudioBuffer.downloads.indexOf(doneLoading);\n                ToneAudioBuffer.downloads.splice(index, 1);\n            }\n            return this;\n        });\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffer = undefined;\n        return this;\n    }\n    /**\n     * Set the audio buffer from the array.\n     * To create a multichannel AudioBuffer, pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     */\n    fromArray(array) {\n        const isMultidimensional = (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(array) && array[0].length > 0;\n        const channels = isMultidimensional ? array.length : 1;\n        const len = isMultidimensional ? array[0].length : array.length;\n        const context = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n        const buffer = context.createBuffer(channels, len, context.sampleRate);\n        const multiChannelArray = !isMultidimensional && channels === 1 ?\n            [array] : array;\n        for (let c = 0; c < channels; c++) {\n            buffer.copyToChannel(multiChannelArray[c], c);\n        }\n        this._buffer = buffer;\n        return this;\n    }\n    /**\n     * Sums multiple channels into 1 channel\n     * @param chanNum Optionally only copy a single channel from the array.\n     */\n    toMono(chanNum) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(chanNum)) {\n            this.fromArray(this.toArray(chanNum));\n        }\n        else {\n            let outputArray = new Float32Array(this.length);\n            const numChannels = this.numberOfChannels;\n            for (let channel = 0; channel < numChannels; channel++) {\n                const channelArray = this.toArray(channel);\n                for (let i = 0; i < channelArray.length; i++) {\n                    outputArray[i] += channelArray[i];\n                }\n            }\n            // divide by the number of channels\n            outputArray = outputArray.map(sample => sample / numChannels);\n            this.fromArray(outputArray);\n        }\n        return this;\n    }\n    /**\n     * Get the buffer as an array. Single channel buffers will return a 1-dimensional\n     * Float32Array, and multichannel buffers will return multidimensional arrays.\n     * @param channel Optionally only copy a single channel from the array.\n     */\n    toArray(channel) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(channel)) {\n            return this.getChannelData(channel);\n        }\n        else if (this.numberOfChannels === 1) {\n            return this.toArray(0);\n        }\n        else {\n            const ret = [];\n            for (let c = 0; c < this.numberOfChannels; c++) {\n                ret[c] = this.getChannelData(c);\n            }\n            return ret;\n        }\n    }\n    /**\n     * Returns the Float32Array representing the PCM audio data for the specific channel.\n     * @param  channel  The channel number to return\n     * @return The audio as a TypedArray\n     */\n    getChannelData(channel) {\n        if (this._buffer) {\n            return this._buffer.getChannelData(channel);\n        }\n        else {\n            return new Float32Array(0);\n        }\n    }\n    /**\n     * Cut a subsection of the array and return a buffer of the\n     * subsection. Does not modify the original buffer\n     * @param start The time to start the slice\n     * @param end The end time to slice. If none is given will default to the end of the buffer\n     */\n    slice(start, end = this.duration) {\n        const startSamples = Math.floor(start * this.sampleRate);\n        const endSamples = Math.floor(end * this.sampleRate);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(startSamples < endSamples, \"The start time must be less than the end time\");\n        const length = endSamples - startSamples;\n        const retBuffer = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().createBuffer(this.numberOfChannels, length, this.sampleRate);\n        for (let channel = 0; channel < this.numberOfChannels; channel++) {\n            retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);\n        }\n        return new ToneAudioBuffer(retBuffer);\n    }\n    /**\n     * Reverse the buffer.\n     */\n    _reverse() {\n        if (this.loaded) {\n            for (let i = 0; i < this.numberOfChannels; i++) {\n                this.getChannelData(i).reverse();\n            }\n        }\n        return this;\n    }\n    /**\n     * If the buffer is loaded or not\n     */\n    get loaded() {\n        return this.length > 0;\n    }\n    /**\n     * The duration of the buffer in seconds.\n     */\n    get duration() {\n        if (this._buffer) {\n            return this._buffer.duration;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The length of the buffer in samples\n     */\n    get length() {\n        if (this._buffer) {\n            return this._buffer.length;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of discrete audio channels. Returns 0 if no buffer is loaded.\n     */\n    get numberOfChannels() {\n        if (this._buffer) {\n            return this._buffer.numberOfChannels;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * Reverse the buffer.\n     */\n    get reverse() {\n        return this._reversed;\n    }\n    set reverse(rev) {\n        if (this._reversed !== rev) {\n            this._reversed = rev;\n            this._reverse();\n        }\n    }\n    /**\n     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,\n     * pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     * @return A ToneAudioBuffer created from the array\n     */\n    static fromArray(array) {\n        return (new ToneAudioBuffer()).fromArray(array);\n    }\n    /**\n     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer\n     * @param  url The url to load.\n     * @return A promise which resolves to a ToneAudioBuffer\n     */\n    static fromUrl(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const buffer = new ToneAudioBuffer();\n            return yield buffer.load(url);\n        });\n    }\n    /**\n     * Loads a url using fetch and returns the AudioBuffer.\n     */\n    static load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            // test if the url contains multiple extensions\n            const matches = url.match(/\\[([^\\]\\[]+\\|.+)\\]$/);\n            if (matches) {\n                const extensions = matches[1].split(\"|\");\n                let extension = extensions[0];\n                for (const ext of extensions) {\n                    if (ToneAudioBuffer.supportsType(ext)) {\n                        extension = ext;\n                        break;\n                    }\n                }\n                url = url.replace(matches[0], extension);\n            }\n            // make sure there is a slash between the baseUrl and the url\n            const baseUrl = ToneAudioBuffer.baseUrl === \"\" || ToneAudioBuffer.baseUrl.endsWith(\"/\") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + \"/\";\n            const response = yield fetch(baseUrl + url);\n            if (!response.ok) {\n                throw new Error(`could not load url: ${url}`);\n            }\n            const arrayBuffer = yield response.arrayBuffer();\n            const audioBuffer = yield (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().decodeAudioData(arrayBuffer);\n            return audioBuffer;\n        });\n    }\n    /**\n     * Checks a url's extension to see if the current browser can play that file type.\n     * @param url The url/extension to test\n     * @return If the file extension can be played\n     * @static\n     * @example\n     * Tone.ToneAudioBuffer.supportsType(\"wav\"); // returns true\n     * Tone.ToneAudioBuffer.supportsType(\"path/to/file.wav\"); // returns true\n     */\n    static supportsType(url) {\n        const extensions = url.split(\".\");\n        const extension = extensions[extensions.length - 1];\n        const response = document.createElement(\"audio\").canPlayType(\"audio/\" + extension);\n        return response !== \"\";\n    }\n    /**\n     * Returns a Promise which resolves when all of the buffers have loaded\n     */\n    static loaded() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            // this makes sure that the function is always async\n            yield Promise.resolve();\n            while (ToneAudioBuffer.downloads.length) {\n                yield ToneAudioBuffer.downloads[0];\n            }\n        });\n    }\n}\n//-------------------------------------\n// STATIC METHODS\n//-------------------------------------\n/**\n * A path which is prefixed before every url.\n */\nToneAudioBuffer.baseUrl = \"\";\n/**\n * All of the downloads\n */\nToneAudioBuffer.downloads = [];\n//# sourceMappingURL=ToneAudioBuffer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioBuffers\": () => (/* binding */ ToneAudioBuffers)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n/**\n * A data structure for holding multiple buffers in a Map-like datastructure.\n *\n * @example\n * const pianoSamples = new Tone.ToneAudioBuffers({\n * \tA1: \"https://tonejs.github.io/audio/casio/A1.mp3\",\n * \tA2: \"https://tonejs.github.io/audio/casio/A2.mp3\",\n * }, () => {\n * \tconst player = new Tone.Player().toDestination();\n * \t// play one of the samples when they all load\n * \tplayer.buffer = pianoSamples.get(\"A2\");\n * \tplayer.start();\n * });\n * @example\n * // To pass in additional parameters in the second parameter\n * const buffers = new Tone.ToneAudioBuffers({\n * \t urls: {\n * \t\t A1: \"A1.mp3\",\n * \t\t A2: \"A2.mp3\",\n * \t },\n * \t onload: () => console.log(\"loaded\"),\n * \t baseUrl: \"https://tonejs.github.io/audio/casio/\"\n * });\n * @category Core\n */\nclass ToneAudioBuffers extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffers\";\n        /**\n         * All of the buffers\n         */\n        this._buffers = new Map();\n        /**\n         * Keep track of the number of loaded buffers\n         */\n        this._loadingCount = 0;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ToneAudioBuffers.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        this.baseUrl = options.baseUrl;\n        // add each one\n        Object.keys(options.urls).forEach(name => {\n            this._loadingCount++;\n            const url = options.urls[name];\n            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);\n        });\n    }\n    static getDefaults() {\n        return {\n            baseUrl: \"\",\n            onerror: _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            onload: _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            urls: {},\n        };\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param  name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name.toString());\n    }\n    /**\n     * Get a buffer by name. If an array was loaded,\n     * then use the array index.\n     * @param  name  The key or index of the buffer.\n     */\n    get(name) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);\n        return this._buffers.get(name.toString());\n    }\n    /**\n     * A buffer was loaded. decrement the counter.\n     */\n    _bufferLoaded(callback) {\n        this._loadingCount--;\n        if (this._loadingCount === 0 && callback) {\n            callback();\n        }\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return Array.from(this._buffers).every(([_, buffer]) => buffer.loaded);\n    }\n    /**\n     * Add a buffer by name and url to the Buffers\n     * @param  name      A unique name to give the buffer\n     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     * @param  onerror  Invoked if the buffer can't be loaded\n     */\n    add(name, url, callback = _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp, onerror = _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isString)(url)) {\n            this._buffers.set(name.toString(), new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__.ToneAudioBuffer(this.baseUrl + url, callback, onerror));\n        }\n        else {\n            this._buffers.set(name.toString(), new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__.ToneAudioBuffer(url, callback, onerror));\n        }\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._buffers.forEach(buffer => buffer.dispose());\n        this._buffers.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioBuffers.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioNode.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioNode.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioNode\": () => (/* binding */ ToneAudioNode),\n/* harmony export */   \"connect\": () => (/* binding */ connect),\n/* harmony export */   \"connectSeries\": () => (/* binding */ connectSeries),\n/* harmony export */   \"disconnect\": () => (/* binding */ disconnect)\n/* harmony export */ });\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Param__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _ToneWithContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * ToneAudioNode is the base class for classes which process audio.\n */\nclass ToneAudioNode extends _ToneWithContext__WEBPACK_IMPORTED_MODULE_3__.ToneWithContext {\n    constructor() {\n        super(...arguments);\n        /**\n         * The name of the class\n         */\n        this.name = \"ToneAudioNode\";\n        /**\n         * List all of the node that must be set to match the ChannelProperties\n         */\n        this._internalChannels = [];\n    }\n    /**\n     * The number of inputs feeding into the AudioNode.\n     * For source nodes, this will be 0.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfInputs);\n     */\n    get numberOfInputs() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.input)) {\n            if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(this.input) || this.input instanceof _Param__WEBPACK_IMPORTED_MODULE_2__.Param) {\n                return 1;\n            }\n            else {\n                return this.input.numberOfInputs;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of outputs of the AudioNode.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfOutputs);\n     */\n    get numberOfOutputs() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.output)) {\n            return this.output.numberOfOutputs;\n        }\n        else {\n            return 0;\n        }\n    }\n    //-------------------------------------\n    // AUDIO PROPERTIES\n    //-------------------------------------\n    /**\n     * Used to decide which nodes to get/set properties on\n     */\n    _isAudioNode(node) {\n        return (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(node) && (node instanceof ToneAudioNode || (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(node));\n    }\n    /**\n     * Get all of the audio nodes (either internal or input/output) which together\n     * make up how the class node responds to channel input/output\n     */\n    _getInternalNodes() {\n        const nodeList = this._internalChannels.slice(0);\n        if (this._isAudioNode(this.input)) {\n            nodeList.push(this.input);\n        }\n        if (this._isAudioNode(this.output)) {\n            if (this.input !== this.output) {\n                nodeList.push(this.output);\n            }\n        }\n        return nodeList;\n    }\n    /**\n     * Set the audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     * @param options\n     */\n    _setChannelProperties(options) {\n        const nodeList = this._getInternalNodes();\n        nodeList.forEach(node => {\n            node.channelCount = options.channelCount;\n            node.channelCountMode = options.channelCountMode;\n            node.channelInterpretation = options.channelInterpretation;\n        });\n    }\n    /**\n     * Get the current audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     */\n    _getChannelProperties() {\n        const nodeList = this._getInternalNodes();\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(nodeList.length > 0, \"ToneAudioNode does not have any internal nodes\");\n        // use the first node to get properties\n        // they should all be the same\n        const node = nodeList[0];\n        return {\n            channelCount: node.channelCount,\n            channelCountMode: node.channelCountMode,\n            channelInterpretation: node.channelInterpretation,\n        };\n    }\n    /**\n     * channelCount is the number of channels used when up-mixing and down-mixing\n     * connections to any inputs to the node. The default value is 2 except for\n     * specific nodes where its value is specially determined.\n     */\n    get channelCount() {\n        return this._getChannelProperties().channelCount;\n    }\n    set channelCount(channelCount) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCount }));\n    }\n    /**\n     * channelCountMode determines how channels will be counted when up-mixing and\n     * down-mixing connections to any inputs to the node.\n     * The default value is \"max\". This attribute has no effect for nodes with no inputs.\n     * * \"max\" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.\n     * * \"clamped-max\" - computedNumberOfChannels is determined as for \"max\" and then clamped to a maximum value of the given channelCount.\n     * * \"explicit\" - computedNumberOfChannels is the exact value as specified by the channelCount.\n     */\n    get channelCountMode() {\n        return this._getChannelProperties().channelCountMode;\n    }\n    set channelCountMode(channelCountMode) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCountMode }));\n    }\n    /**\n     * channelInterpretation determines how individual channels will be treated\n     * when up-mixing and down-mixing connections to any inputs to the node.\n     * The default value is \"speakers\".\n     */\n    get channelInterpretation() {\n        return this._getChannelProperties().channelInterpretation;\n    }\n    set channelInterpretation(channelInterpretation) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelInterpretation }));\n    }\n    //-------------------------------------\n    // CONNECTIONS\n    //-------------------------------------\n    /**\n     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode\n     * @param destination The output to connect to\n     * @param outputNum The output to connect from\n     * @param inputNum The input to connect to\n     */\n    connect(destination, outputNum = 0, inputNum = 0) {\n        connect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * @example\n     * const osc = new Tone.Oscillator(\"C2\").start();\n     * osc.toDestination();\n     */\n    toDestination() {\n        this.connect(this.context.destination);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * See [[toDestination]]\n     * @deprecated\n     */\n    toMaster() {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.warn)(\"toMaster() has been renamed toDestination()\");\n        return this.toDestination();\n    }\n    /**\n     * disconnect the output\n     */\n    disconnect(destination, outputNum = 0, inputNum = 0) {\n        disconnect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output of this node to the rest of the nodes in series.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3\");\n     * player.autostart = true;\n     * const filter = new Tone.AutoFilter(4).start();\n     * const distortion = new Tone.Distortion(0.5);\n     * // connect the player to the filter, distortion and then to the master output\n     * player.chain(filter, distortion, Tone.Destination);\n     */\n    chain(...nodes) {\n        connectSeries(this, ...nodes);\n        return this;\n    }\n    /**\n     * connect the output of this node to the rest of the nodes in parallel.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3\");\n     * player.autostart = true;\n     * const pitchShift = new Tone.PitchShift(4).toDestination();\n     * const filter = new Tone.Filter(\"G5\").toDestination();\n     * // connect a node to the pitch shift and filter in parallel\n     * player.fan(pitchShift, filter);\n     */\n    fan(...nodes) {\n        nodes.forEach(node => this.connect(node));\n        return this;\n    }\n    /**\n     * Dispose and disconnect\n     */\n    dispose() {\n        super.dispose();\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.input)) {\n            if (this.input instanceof ToneAudioNode) {\n                this.input.dispose();\n            }\n            else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(this.input)) {\n                this.input.disconnect();\n            }\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.output)) {\n            if (this.output instanceof ToneAudioNode) {\n                this.output.dispose();\n            }\n            else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(this.output)) {\n                this.output.disconnect();\n            }\n        }\n        this._internalChannels = [];\n        return this;\n    }\n}\n//-------------------------------------\n// CONNECTIONS\n//-------------------------------------\n/**\n * connect together all of the arguments in series\n * @param nodes\n */\nfunction connectSeries(...nodes) {\n    const first = nodes.shift();\n    nodes.reduce((prev, current) => {\n        if (prev instanceof ToneAudioNode) {\n            prev.connect(current);\n        }\n        else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(prev)) {\n            connect(prev, current);\n        }\n        return current;\n    }, first);\n}\n/**\n * Connect two nodes together so that signal flows from the\n * first node to the second. Optionally specify the input and output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nfunction connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode), \"Cannot connect from undefined node\");\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode), \"Cannot connect to undefined node\");\n    if (dstNode instanceof ToneAudioNode || (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(dstNode)) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(dstNode.numberOfInputs > 0, \"Cannot connect to node with no inputs\");\n    }\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(srcNode.numberOfOutputs > 0, \"Cannot connect from node with no outputs\");\n    // resolve the input of the dstNode\n    while ((dstNode instanceof ToneAudioNode || dstNode instanceof _Param__WEBPACK_IMPORTED_MODULE_2__.Param)) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode.input)) {\n            dstNode = dstNode.input;\n        }\n    }\n    while (srcNode instanceof ToneAudioNode) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    // make the connection\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(dstNode)) {\n        srcNode.connect(dstNode, outputNumber);\n    }\n    else {\n        srcNode.connect(dstNode, outputNumber, inputNumber);\n    }\n}\n/**\n * Disconnect a node from all nodes or optionally include a destination node and input/output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nfunction disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    // resolve the destination node\n    if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode)) {\n        while (dstNode instanceof ToneAudioNode) {\n            dstNode = dstNode.input;\n        }\n    }\n    // resolve the src node\n    while (!((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(srcNode))) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber);\n    }\n    else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber, inputNumber);\n    }\n    else {\n        srcNode.disconnect();\n    }\n}\n//# sourceMappingURL=ToneAudioNode.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/ToneAudioNode.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneWithContext.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneWithContext.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneWithContext\": () => (/* binding */ ToneWithContext)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _type_Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _type_Time__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * The Base class for all nodes that have an AudioContext.\n */\nclass ToneWithContext extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    constructor() {\n        super();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.optionsFromArguments)(ToneWithContext.getDefaults(), arguments, [\"context\"]);\n        if (this.defaultContext) {\n            this.context = this.defaultContext;\n        }\n        else {\n            this.context = options.context;\n        }\n    }\n    static getDefaults() {\n        return {\n            context: (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(),\n        };\n    }\n    /**\n     * Return the current time of the Context clock plus the lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.now());\n     * }, 100);\n     */\n    now() {\n        return this.context.currentTime + this.context.lookAhead;\n    }\n    /**\n     * Return the current time of the Context clock without any lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.immediate());\n     * }, 100);\n     */\n    immediate() {\n        return this.context.currentTime;\n    }\n    /**\n     * The duration in seconds of one sample.\n     * @example\n     * console.log(Tone.Transport.sampleTime);\n     */\n    get sampleTime() {\n        return 1 / this.context.sampleRate;\n    }\n    /**\n     * The number of seconds of 1 processing block (128 samples)\n     * @example\n     * console.log(Tone.Destination.blockTime);\n     */\n    get blockTime() {\n        return 128 / this.context.sampleRate;\n    }\n    /**\n     * Convert the incoming time to seconds.\n     * This is calculated against the current [[Tone.Transport]] bpm\n     * @example\n     * const gain = new Tone.Gain();\n     * setInterval(() => console.log(gain.toSeconds(\"4n\")), 100);\n     * // ramp the tempo to 60 bpm over 30 seconds\n     * Tone.getTransport().bpm.rampTo(60, 30);\n     */\n    toSeconds(time) {\n        return new _type_Time__WEBPACK_IMPORTED_MODULE_3__.TimeClass(this.context, time).toSeconds();\n    }\n    /**\n     * Convert the input to a frequency number\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toFrequency(\"4n\"));\n     */\n    toFrequency(freq) {\n        return new _type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, freq).toFrequency();\n    }\n    /**\n     * Convert the input time into ticks\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toTicks(\"4n\"));\n     */\n    toTicks(time) {\n        return new _type_TransportTime__WEBPACK_IMPORTED_MODULE_4__.TransportTimeClass(this.context, time).toTicks();\n    }\n    //-------------------------------------\n    // \tGET/SET\n    //-------------------------------------\n    /**\n     * Get a subset of the properties which are in the partial props\n     */\n    _getPartialProperties(props) {\n        const options = this.get();\n        // remove attributes from the prop that are not in the partial\n        Object.keys(options).forEach(name => {\n            if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isUndef)(props[name])) {\n                delete options[name];\n            }\n        });\n        return options;\n    }\n    /**\n     * Get the object's attributes.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.get());\n     */\n    get() {\n        const defaults = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.getDefaultsFromInstance)(this);\n        Object.keys(defaults).forEach(attribute => {\n            if (Reflect.has(this, attribute)) {\n                const member = this[attribute];\n                if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member.value) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member.setValueAtTime)) {\n                    defaults[attribute] = member.value;\n                }\n                else if (member instanceof ToneWithContext) {\n                    defaults[attribute] = member._getPartialProperties(defaults[attribute]);\n                    // otherwise make sure it's a serializable type\n                }\n                else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isArray)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isString)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isBoolean)(member)) {\n                    defaults[attribute] = member;\n                }\n                else {\n                    // remove all undefined and unserializable attributes\n                    delete defaults[attribute];\n                }\n            }\n        });\n        return defaults;\n    }\n    /**\n     * Set multiple properties at once with an object.\n     * @example\n     * const filter = new Tone.Filter().toDestination();\n     * // set values using an object\n     * filter.set({\n     * \tfrequency: \"C6\",\n     * \ttype: \"highpass\"\n     * });\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3\").connect(filter);\n     * player.autostart = true;\n     */\n    set(props) {\n        Object.keys(props).forEach(attribute => {\n            if (Reflect.has(this, attribute) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute])) {\n                if (this[attribute] && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute].value) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute].setValueAtTime)) {\n                    // small optimization\n                    if (this[attribute].value !== props[attribute]) {\n                        this[attribute].value = props[attribute];\n                    }\n                }\n                else if (this[attribute] instanceof ToneWithContext) {\n                    this[attribute].set(props[attribute]);\n                }\n                else {\n                    this[attribute] = props[attribute];\n                }\n            }\n        });\n        return this;\n    }\n}\n//# sourceMappingURL=ToneWithContext.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/context/ToneWithContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/index.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/core/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _context_BaseContext__WEBPACK_IMPORTED_MODULE_2__.BaseContext),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _clock_Clock__WEBPACK_IMPORTED_MODULE_0__.Clock),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _context_Context__WEBPACK_IMPORTED_MODULE_1__.Context),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _util_Emitter__WEBPACK_IMPORTED_MODULE_17__.Emitter),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _type_Frequency__WEBPACK_IMPORTED_MODULE_11__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _type_Frequency__WEBPACK_IMPORTED_MODULE_11__.FrequencyClass),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _context_Gain__WEBPACK_IMPORTED_MODULE_4__.Gain),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_18__.IntervalTimeline),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _type_Midi__WEBPACK_IMPORTED_MODULE_12__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _type_Midi__WEBPACK_IMPORTED_MODULE_12__.MidiClass),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _context_Offline__WEBPACK_IMPORTED_MODULE_5__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _context_OfflineContext__WEBPACK_IMPORTED_MODULE_6__.OfflineContext),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _context_Param__WEBPACK_IMPORTED_MODULE_7__.Param),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _util_StateTimeline__WEBPACK_IMPORTED_MODULE_19__.StateTimeline),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _type_Ticks__WEBPACK_IMPORTED_MODULE_14__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _type_Ticks__WEBPACK_IMPORTED_MODULE_14__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _type_Time__WEBPACK_IMPORTED_MODULE_13__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _type_Time__WEBPACK_IMPORTED_MODULE_13__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _util_Timeline__WEBPACK_IMPORTED_MODULE_20__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_8__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_9__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.ToneAudioNode),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__.TransportTimeClass),\n/* harmony export */   \"Unit\": () => (/* reexport module object */ _type_Units__WEBPACK_IMPORTED_MODULE_24__),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.connectSeries),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport module object */ _util_Debug__WEBPACK_IMPORTED_MODULE_25__),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _util_Defaults__WEBPACK_IMPORTED_MODULE_23__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.gainToDb),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isUndef),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.mtof),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _util_Defaults__WEBPACK_IMPORTED_MODULE_23__.optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _clock_Clock__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./clock/Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _context_BaseContext__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./context/BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n/* harmony import */ var _context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _context_Gain__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _context_Offline__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./context/Offline */ \"./node_modules/tone/build/esm/core/context/Offline.js\");\n/* harmony import */ var _context_OfflineContext__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _type_Frequency__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _type_Midi__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./type/Midi */ \"./node_modules/tone/build/esm/core/type/Midi.js\");\n/* harmony import */ var _type_Time__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Draw__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./util/Draw */ \"./node_modules/tone/build/esm/core/util/Draw.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./util/IntervalTimeline */ \"./node_modules/tone/build/esm/core/util/IntervalTimeline.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _type_Conversions__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _type_Units__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./type/Units */ \"./node_modules/tone/build/esm/core/type/Units.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n// export * from \"./clock/Transport\";\n\n\n\n// export * from \"./context/Destination\";\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// get the units and export them under the \"Unit\" namespace\n\n\n// export the debug stuff as Debug\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Conversions.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Conversions.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"dbToGain\": () => (/* binding */ dbToGain),\n/* harmony export */   \"equalPowerScale\": () => (/* binding */ equalPowerScale),\n/* harmony export */   \"ftom\": () => (/* binding */ ftom),\n/* harmony export */   \"ftomf\": () => (/* binding */ ftomf),\n/* harmony export */   \"gainToDb\": () => (/* binding */ gainToDb),\n/* harmony export */   \"getA4\": () => (/* binding */ getA4),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* binding */ intervalToFrequencyRatio),\n/* harmony export */   \"mtof\": () => (/* binding */ mtof),\n/* harmony export */   \"setA4\": () => (/* binding */ setA4)\n/* harmony export */ });\n/**\n * Equal power gain scale. Good for cross-fading.\n * @param  percent (0-1)\n */\nfunction equalPowerScale(percent) {\n    const piFactor = 0.5 * Math.PI;\n    return Math.sin(percent * piFactor);\n}\n/**\n * Convert decibels into gain.\n */\nfunction dbToGain(db) {\n    return Math.pow(10, db / 20);\n}\n/**\n * Convert gain to decibels.\n */\nfunction gainToDb(gain) {\n    return 20 * (Math.log(gain) / Math.LN10);\n}\n/**\n * Convert an interval (in semitones) to a frequency ratio.\n * @param interval the number of semitones above the base note\n * @example\n * Tone.intervalToFrequencyRatio(0); // 1\n * Tone.intervalToFrequencyRatio(12); // 2\n * Tone.intervalToFrequencyRatio(-12); // 0.5\n */\nfunction intervalToFrequencyRatio(interval) {\n    return Math.pow(2, (interval / 12));\n}\n/**\n * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n * to generate all the other pitch values from notes. A4's values in Hertz.\n */\nlet A4 = 440;\nfunction getA4() {\n    return A4;\n}\nfunction setA4(freq) {\n    A4 = freq;\n}\n/**\n * Convert a frequency value to a MIDI note.\n * @param frequency The value to frequency value to convert.\n * @example\n * Tone.ftom(440); // returns 69\n */\nfunction ftom(frequency) {\n    return Math.round(ftomf(frequency));\n}\n/**\n * Convert a frequency to a floating point midi value\n */\nfunction ftomf(frequency) {\n    return 69 + 12 * Math.log2(frequency / A4);\n}\n/**\n * Convert a MIDI note to frequency value.\n * @param  midi The midi number to convert.\n * @return The corresponding frequency value\n * @example\n * Tone.mtof(69); // 440\n */\nfunction mtof(midi) {\n    return A4 * Math.pow(2, (midi - 69) / 12);\n}\n//# sourceMappingURL=Conversions.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Conversions.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Frequency.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Frequency.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Frequency\": () => (/* binding */ Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* binding */ FrequencyClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _Time__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n\n\n\n\n/**\n * Frequency is a primitive type for encoding Frequency values.\n * Eventually all time values are evaluated to hertz using the `valueOf` method.\n * @example\n * Tone.Frequency(\"C3\"); // 261\n * Tone.Frequency(38, \"midi\");\n * Tone.Frequency(\"C3\").transpose(4);\n * @category Unit\n */\nclass FrequencyClass extends _Time__WEBPACK_IMPORTED_MODULE_2__.TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Frequency\";\n        this.defaultUnits = \"hz\";\n    }\n    /**\n     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n     * to generate all the other pitch values from notes. A4's values in Hertz.\n     */\n    static get A4() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.getA4)();\n    }\n    static set A4(freq) {\n        (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.setA4)(freq);\n    }\n    //-------------------------------------\n    // \tAUGMENT BASE EXPRESSIONS\n    //-------------------------------------\n    _getExpressions() {\n        return Object.assign({}, super._getExpressions(), {\n            midi: {\n                regexp: /^(\\d+(?:\\.\\d+)?midi)/,\n                method(value) {\n                    if (this.defaultUnits === \"midi\") {\n                        return value;\n                    }\n                    else {\n                        return FrequencyClass.mtof(value);\n                    }\n                },\n            },\n            note: {\n                regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,\n                method(pitch, octave) {\n                    const index = noteToScaleIndex[pitch.toLowerCase()];\n                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;\n                    if (this.defaultUnits === \"midi\") {\n                        return noteNumber;\n                    }\n                    else {\n                        return FrequencyClass.mtof(noteNumber);\n                    }\n                },\n            },\n            tr: {\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,\n                method(m, q, s) {\n                    let total = 1;\n                    if (m && m !== \"0\") {\n                        total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n            },\n        });\n    }\n    //-------------------------------------\n    // \tEXPRESSIONS\n    //-------------------------------------\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return  A new transposed frequency\n     * @example\n     * Tone.Frequency(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new FrequencyClass(this.context, this.valueOf() * (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio)(interval));\n    }\n    /**\n     * Takes an array of semitone intervals and returns\n     * an array of frequencies transposed by those intervals.\n     * @return  Returns an array of Frequencies\n     * @example\n     * Tone.Frequency(\"A4\").harmonize([0, 3, 7]); // [\"A4\", \"C5\", \"E5\"]\n     */\n    harmonize(intervals) {\n        return intervals.map(interval => {\n            return this.transpose(interval);\n        });\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Frequency(\"C4\").toMidi(); // 60\n     */\n    toMidi() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(this.valueOf());\n    }\n    /**\n     * Return the value of the frequency in Scientific Pitch Notation\n     * @example\n     * Tone.Frequency(69, \"midi\").toNote(); // \"A4\"\n     */\n    toNote() {\n        const freq = this.toFrequency();\n        const log = Math.log2(freq / FrequencyClass.A4);\n        let noteNumber = Math.round(12 * log) + 57;\n        const octave = Math.floor(noteNumber / 12);\n        if (octave < 0) {\n            noteNumber += -12 * octave;\n        }\n        const noteName = scaleIndexToNote[noteNumber % 12];\n        return noteName + octave.toString();\n    }\n    /**\n     * Return the duration of one cycle in seconds.\n     */\n    toSeconds() {\n        return 1 / super.toSeconds();\n    }\n    /**\n     * Return the duration of one cycle in ticks\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.floor(quarters * this._getPPQ());\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS HELPERS\n    //-------------------------------------\n    /**\n     * With no arguments, return 0\n     */\n    _noArg() {\n        return 0;\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return freq;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return 1 / ((ticks * 60) / (this._getBpm() * this._getPPQ()));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return 1 / super._beatsToUnits(beats);\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return 1 / seconds;\n    }\n    /**\n     * Convert a MIDI note to frequency value.\n     * @param  midi The midi number to convert.\n     * @return The corresponding frequency value\n     */\n    static mtof(midi) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.mtof)(midi);\n    }\n    /**\n     * Convert a frequency value to a MIDI note.\n     * @param frequency The value to frequency value to convert.\n     */\n    static ftom(frequency) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(frequency);\n    }\n}\n//-------------------------------------\n// \tFREQUENCY CONVERSIONS\n//-------------------------------------\n/**\n * Note to scale index.\n * @hidden\n */\nconst noteToScaleIndex = {\n    cbb: -2, cb: -1, c: 0, \"c#\": 1, cx: 2,\n    dbb: 0, db: 1, d: 2, \"d#\": 3, dx: 4,\n    ebb: 2, eb: 3, e: 4, \"e#\": 5, ex: 6,\n    fbb: 3, fb: 4, f: 5, \"f#\": 6, fx: 7,\n    gbb: 5, gb: 6, g: 7, \"g#\": 8, gx: 9,\n    abb: 7, ab: 8, a: 9, \"a#\": 10, ax: 11,\n    bbb: 9, bb: 10, b: 11, \"b#\": 12, bx: 13,\n};\n/**\n * scale index to note (sharps)\n * @hidden\n */\nconst scaleIndexToNote = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"];\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n * @example\n * const midi = Tone.Frequency(\"C3\").toMidi();\n * console.log(midi);\n * @example\n * const hertz = Tone.Frequency(38, \"midi\").toFrequency();\n * console.log(hertz);\n */\nfunction Frequency(value, units) {\n    return new FrequencyClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Frequency.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Frequency.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Midi.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Midi.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Midi\": () => (/* binding */ Midi),\n/* harmony export */   \"MidiClass\": () => (/* binding */ MidiClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n\n\n\n/**\n * Midi is a primitive type for encoding Time values.\n * Midi can be constructed with or without the `new` keyword. Midi can be passed\n * into the parameter of any method which takes time as an argument.\n * @category Unit\n */\nclass MidiClass extends _Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"MidiClass\";\n        this.defaultUnits = \"midi\";\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._frequencyToUnits(freq));\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._ticksToUnits(ticks));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._beatsToUnits(beats));\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._secondsToUnits(seconds));\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toMidi(); // 60\n     */\n    toMidi() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toFrequency(); // 261.6255653005986\n     */\n    toFrequency() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.mtof)(this.toMidi());\n    }\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return A new transposed MidiClass\n     * @example\n     * Tone.Midi(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new MidiClass(this.context, this.toMidi() + interval);\n    }\n}\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n */\nfunction Midi(value, units) {\n    return new MidiClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Midi.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Midi.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/NoteUnits.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/NoteUnits.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// this file contains all of the valid note names for all pitches between C-4 and C11\n\n//# sourceMappingURL=NoteUnits.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/NoteUnits.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Ticks.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Ticks.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Ticks\": () => (/* binding */ Ticks),\n/* harmony export */   \"TicksClass\": () => (/* binding */ TicksClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _TransportTime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n\n\n/**\n * Ticks is a primitive type for encoding Time values.\n * Ticks can be constructed with or without the `new` keyword. Ticks can be passed\n * into the parameter of any method which takes time as an argument.\n * @example\n * const t = Tone.Ticks(\"4n\"); // a quarter note as ticks\n * @category Unit\n */\nclass TicksClass extends _TransportTime__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Ticks\";\n        this.defaultUnits = \"i\";\n    }\n    /**\n     * Get the current time in the given units\n     */\n    _now() {\n        return this.context.transport.ticks;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return this._getPPQ() * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return ticks;\n    }\n    /**\n     * Return the time in ticks\n     */\n    toTicks() {\n        return this.valueOf();\n    }\n    /**\n     * Return the time in seconds\n     */\n    toSeconds() {\n        return (this.valueOf() / this._getPPQ()) * (60 / this._getBpm());\n    }\n}\n/**\n * Convert a time representation to ticks\n * @category Unit\n */\nfunction Ticks(value, units) {\n    return new TicksClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Ticks.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Ticks.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Time.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Time.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Time\": () => (/* binding */ Time),\n/* harmony export */   \"TimeClass\": () => (/* binding */ TimeClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _TimeBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TimeBase */ \"./node_modules/tone/build/esm/core/type/TimeBase.js\");\n\n\n\n/**\n * TimeClass is a primitive type for encoding and decoding Time values.\n * TimeClass can be passed into the parameter of any method which takes time as an argument.\n * @param  val    The time value.\n * @param  units  The units of the value.\n * @example\n * const time = Tone.Time(\"4n\"); // a quarter note\n * @category Unit\n */\nclass TimeClass extends _TimeBase__WEBPACK_IMPORTED_MODULE_2__.TimeBaseClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TimeClass\";\n    }\n    _getExpressions() {\n        return Object.assign(super._getExpressions(), {\n            now: {\n                method: (capture) => {\n                    return this._now() + new this.constructor(this.context, capture).valueOf();\n                },\n                regexp: /^\\+(.+)/,\n            },\n            quantize: {\n                method: (capture) => {\n                    const quantTo = new TimeClass(this.context, capture).valueOf();\n                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));\n                },\n                regexp: /^@(.+)/,\n            },\n        });\n    }\n    /**\n     * Quantize the time by the given subdivision. Optionally add a\n     * percentage which will move the time value towards the ideal\n     * quantized value by that percentage.\n     * @param  subdiv    The subdivision to quantize to\n     * @param  percent  Move the time value towards the quantized value by a percentage.\n     * @example\n     * Tone.Time(21).quantize(2); // returns 22\n     * Tone.Time(0.6).quantize(\"4n\", 0.5); // returns 0.55\n     */\n    quantize(subdiv, percent = 1) {\n        const subdivision = new this.constructor(this.context, subdiv).valueOf();\n        const value = this.valueOf();\n        const multiple = Math.round(value / subdivision);\n        const ideal = multiple * subdivision;\n        const diff = ideal - value;\n        return value + diff * percent;\n    }\n    //-------------------------------------\n    // CONVERSIONS\n    //-------------------------------------\n    /**\n     * Convert a Time to Notation. The notation values are will be the\n     * closest representation between 1m to 128th note.\n     * @return {Notation}\n     * @example\n     * // if the Transport is at 120bpm:\n     * Tone.Time(2).toNotation(); // returns \"1m\"\n     */\n    toNotation() {\n        const time = this.toSeconds();\n        const testNotations = [\"1m\"];\n        for (let power = 1; power < 9; power++) {\n            const subdiv = Math.pow(2, power);\n            testNotations.push(subdiv + \"n.\");\n            testNotations.push(subdiv + \"n\");\n            testNotations.push(subdiv + \"t\");\n        }\n        testNotations.push(\"0\");\n        // find the closets notation representation\n        let closest = testNotations[0];\n        let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();\n        testNotations.forEach(notation => {\n            const notationSeconds = new TimeClass(this.context, notation).toSeconds();\n            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {\n                closest = notation;\n                closestSeconds = notationSeconds;\n            }\n        });\n        return closest;\n    }\n    /**\n     * Return the time encoded as Bars:Beats:Sixteenths.\n     */\n    toBarsBeatsSixteenths() {\n        const quarterTime = this._beatsToUnits(1);\n        let quarters = this.valueOf() / quarterTime;\n        quarters = parseFloat(quarters.toFixed(4));\n        const measures = Math.floor(quarters / this._getTimeSignature());\n        let sixteenths = (quarters % 1) * 4;\n        quarters = Math.floor(quarters) % this._getTimeSignature();\n        const sixteenthString = sixteenths.toString();\n        if (sixteenthString.length > 3) {\n            // the additional parseFloat removes insignificant trailing zeroes\n            sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));\n        }\n        const progress = [measures, quarters, sixteenths];\n        return progress.join(\":\");\n    }\n    /**\n     * Return the time in ticks.\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.round(quarters * this._getPPQ());\n    }\n    /**\n     * Return the time in seconds.\n     */\n    toSeconds() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value as a midi note.\n     */\n    toMidi() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(this.toFrequency());\n    }\n    _now() {\n        return this.context.now();\n    }\n}\n/**\n * Create a TimeClass from a time string or number. The time is computed against the\n * global Tone.Context. To use a specific context, use [[TimeClass]]\n * @param value A value which represents time\n * @param units The value's units if they can't be inferred by the value.\n * @category Unit\n * @example\n * const time = Tone.Time(\"4n\").toSeconds();\n * console.log(time);\n * @example\n * const note = Tone.Time(1).toNotation();\n * console.log(note);\n * @example\n * const freq = Tone.Time(0.5).toFrequency();\n * console.log(freq);\n */\nfunction Time(value, units) {\n    return new TimeClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Time.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Time.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/TimeBase.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/TimeBase.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TimeBaseClass\": () => (/* binding */ TimeBaseClass)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * TimeBase is a flexible encoding of time which can be evaluated to and from a string.\n */\nclass TimeBaseClass extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    /**\n     * @param context The context associated with the time value. Used to compute\n     * Transport and context-relative timing.\n     * @param  value  The time value as a number, string or object\n     * @param  units  Unit values\n     */\n    constructor(context, value, units) {\n        super();\n        /**\n         * The default units\n         */\n        this.defaultUnits = \"s\";\n        this._val = value;\n        this._units = units;\n        this.context = context;\n        this._expressions = this._getExpressions();\n    }\n    /**\n     * All of the time encoding expressions\n     */\n    _getExpressions() {\n        return {\n            hz: {\n                method: (value) => {\n                    return this._frequencyToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)hz$/i,\n            },\n            i: {\n                method: (value) => {\n                    return this._ticksToUnits(parseInt(value, 10));\n                },\n                regexp: /^(\\d+)i$/i,\n            },\n            m: {\n                method: (value) => {\n                    return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());\n                },\n                regexp: /^(\\d+)m$/i,\n            },\n            n: {\n                method: (value, dot) => {\n                    const numericValue = parseInt(value, 10);\n                    const scalar = dot === \".\" ? 1.5 : 1;\n                    if (numericValue === 1) {\n                        return this._beatsToUnits(this._getTimeSignature()) * scalar;\n                    }\n                    else {\n                        return this._beatsToUnits(4 / numericValue) * scalar;\n                    }\n                },\n                regexp: /^(\\d+)n(\\.?)$/i,\n            },\n            number: {\n                method: (value) => {\n                    return this._expressions[this.defaultUnits].method.call(this, value);\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)$/,\n            },\n            s: {\n                method: (value) => {\n                    return this._secondsToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)s$/,\n            },\n            samples: {\n                method: (value) => {\n                    return parseInt(value, 10) / this.context.sampleRate;\n                },\n                regexp: /^(\\d+)samples$/,\n            },\n            t: {\n                method: (value) => {\n                    const numericValue = parseInt(value, 10);\n                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));\n                },\n                regexp: /^(\\d+)t$/i,\n            },\n            tr: {\n                method: (m, q, s) => {\n                    let total = 0;\n                    if (m && m !== \"0\") {\n                        total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?$/,\n            },\n        };\n    }\n    //-------------------------------------\n    // \tVALUE OF\n    //-------------------------------------\n    /**\n     * Evaluate the time value. Returns the time in seconds.\n     */\n    valueOf() {\n        if (this._val instanceof TimeBaseClass) {\n            this.fromType(this._val);\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._val)) {\n            return this._noArg();\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isString)(this._val) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._units)) {\n            for (const units in this._expressions) {\n                if (this._expressions[units].regexp.test(this._val.trim())) {\n                    this._units = units;\n                    break;\n                }\n            }\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(this._val)) {\n            let total = 0;\n            for (const typeName in this._val) {\n                if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this._val[typeName])) {\n                    const quantity = this._val[typeName];\n                    // @ts-ignore\n                    const time = (new this.constructor(this.context, typeName)).valueOf() * quantity;\n                    total += time;\n                }\n            }\n            return total;\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this._units)) {\n            const expr = this._expressions[this._units];\n            const matching = this._val.toString().trim().match(expr.regexp);\n            if (matching) {\n                return expr.method.apply(this, matching.slice(1));\n            }\n            else {\n                return expr.method.call(this, this._val);\n            }\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isString)(this._val)) {\n            return parseFloat(this._val);\n        }\n        else {\n            return this._val;\n        }\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return 1 / freq;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return (60 / this._getBpm()) * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return seconds;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return (ticks * (this._beatsToUnits(1)) / this._getPPQ());\n    }\n    /**\n     * With no arguments, return 'now'\n     */\n    _noArg() {\n        return this._now();\n    }\n    //-------------------------------------\n    // \tTEMPO CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the bpm\n     */\n    _getBpm() {\n        return this.context.transport.bpm.value;\n    }\n    /**\n     * Return the timeSignature\n     */\n    _getTimeSignature() {\n        return this.context.transport.timeSignature;\n    }\n    /**\n     * Return the PPQ or 192 if Transport is not available\n     */\n    _getPPQ() {\n        return this.context.transport.PPQ;\n    }\n    //-------------------------------------\n    // \tCONVERSION INTERFACE\n    //-------------------------------------\n    /**\n     * Coerce a time type into this units type.\n     * @param type Any time type units\n     */\n    fromType(type) {\n        this._units = undefined;\n        switch (this.defaultUnits) {\n            case \"s\":\n                this._val = type.toSeconds();\n                break;\n            case \"i\":\n                this._val = type.toTicks();\n                break;\n            case \"hz\":\n                this._val = type.toFrequency();\n                break;\n            case \"midi\":\n                this._val = type.toMidi();\n                break;\n        }\n        return this;\n    }\n    /**\n     * Return the value in hertz\n     */\n    toFrequency() {\n        return 1 / this.toSeconds();\n    }\n    /**\n     * Return the time in samples\n     */\n    toSamples() {\n        return this.toSeconds() * this.context.sampleRate;\n    }\n    /**\n     * Return the time in milliseconds.\n     */\n    toMilliseconds() {\n        return this.toSeconds() * 1000;\n    }\n}\n//# sourceMappingURL=TimeBase.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/TimeBase.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/TransportTime.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/TransportTime.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportTime\": () => (/* binding */ TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* binding */ TransportTimeClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Time__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n\n\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to Tone.Time, but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nclass TransportTimeClass extends _Time__WEBPACK_IMPORTED_MODULE_1__.TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TransportTime\";\n    }\n    /**\n     * Return the current time in whichever context is relevant\n     */\n    _now() {\n        return this.context.transport.seconds;\n    }\n}\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to [[Time]], but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nfunction TransportTime(value, units) {\n    return new TransportTimeClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=TransportTime.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/TransportTime.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Units.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Units.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _NoteUnits__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./NoteUnits */ \"./node_modules/tone/build/esm/core/type/NoteUnits.js\");\n\n//# sourceMappingURL=Units.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/type/Units.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioBuffer\": () => (/* binding */ isAudioBuffer),\n/* harmony export */   \"isAudioContext\": () => (/* binding */ isAudioContext),\n/* harmony export */   \"isAudioNode\": () => (/* binding */ isAudioNode),\n/* harmony export */   \"isAudioParam\": () => (/* binding */ isAudioParam),\n/* harmony export */   \"isOfflineAudioContext\": () => (/* binding */ isOfflineAudioContext)\n/* harmony export */ });\n/* harmony import */ var standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! standardized-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/module.js\");\n\n/**\n * Test if the given value is an instanceof AudioParam\n */\nfunction isAudioParam(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioParam)(arg);\n}\n/**\n * Test if the given value is an instanceof AudioNode\n */\nfunction isAudioNode(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioNode)(arg);\n}\n/**\n * Test if the arg is instanceof an OfflineAudioContext\n */\nfunction isOfflineAudioContext(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyOfflineAudioContext)(arg);\n}\n/**\n * Test if the arg is an instanceof AudioContext\n */\nfunction isAudioContext(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioContext)(arg);\n}\n/**\n * Test if the arg is instanceof an AudioBuffer\n */\nfunction isAudioBuffer(arg) {\n    return arg instanceof AudioBuffer;\n}\n//# sourceMappingURL=AdvancedTypeCheck.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Debug.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Debug.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assert\": () => (/* binding */ assert),\n/* harmony export */   \"assertContextRunning\": () => (/* binding */ assertContextRunning),\n/* harmony export */   \"assertRange\": () => (/* binding */ assertRange),\n/* harmony export */   \"log\": () => (/* binding */ log),\n/* harmony export */   \"setLogger\": () => (/* binding */ setLogger),\n/* harmony export */   \"warn\": () => (/* binding */ warn)\n/* harmony export */ });\n/**\n * Assert that the statement is true, otherwise invoke the error.\n * @param statement\n * @param error The message which is passed into an Error\n */\nfunction assert(statement, error) {\n    if (!statement) {\n        throw new Error(error);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nfunction assertRange(value, gte, lte = Infinity) {\n    if (!(gte <= value && value <= lte)) {\n        throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nfunction assertContextRunning(context) {\n    // add a warning if the context is not started\n    if (!context.isOffline && context.state !== \"running\") {\n        warn(\"The AudioContext is \\\"suspended\\\". Invoke Tone.start() from a user action to start the audio.\");\n    }\n}\n/**\n * The default logger is the console\n */\nlet defaultLogger = console;\n/**\n * Set the logging interface\n */\nfunction setLogger(logger) {\n    defaultLogger = logger;\n}\n/**\n * Log anything\n */\nfunction log(...args) {\n    defaultLogger.log(...args);\n}\n/**\n * Warn anything\n */\nfunction warn(...args) {\n    defaultLogger.warn(...args);\n}\n//# sourceMappingURL=Debug.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Debug.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Decorator.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Decorator.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"range\": () => (/* binding */ range),\n/* harmony export */   \"timeRange\": () => (/* binding */ timeRange)\n/* harmony export */ });\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n/**\n * Assert that the number is in the given range.\n */\nfunction range(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                (0,_Debug__WEBPACK_IMPORTED_MODULE_0__.assertRange)(newValue, min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n/**\n * Convert the time to seconds and assert that the time is in between the two\n * values when being set.\n */\nfunction timeRange(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                (0,_Debug__WEBPACK_IMPORTED_MODULE_0__.assertRange)(this.toSeconds(newValue), min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n//# sourceMappingURL=Decorator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Decorator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Defaults.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Defaults.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deepEquals\": () => (/* binding */ deepEquals),\n/* harmony export */   \"deepMerge\": () => (/* binding */ deepMerge),\n/* harmony export */   \"defaultArg\": () => (/* binding */ defaultArg),\n/* harmony export */   \"getDefaultsFromInstance\": () => (/* binding */ getDefaultsFromInstance),\n/* harmony export */   \"omitFromObject\": () => (/* binding */ omitFromObject),\n/* harmony export */   \"optionsFromArguments\": () => (/* binding */ optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * Some objects should not be merged\n */\nfunction noCopy(key, arg) {\n    return key === \"value\" || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(arg) || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(arg) || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioBuffer)(arg);\n}\nfunction deepMerge(target, ...sources) {\n    if (!sources.length) {\n        return target;\n    }\n    const source = sources.shift();\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(target) && (0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(source)) {\n        for (const key in source) {\n            if (noCopy(key, source[key])) {\n                target[key] = source[key];\n            }\n            else if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(source[key])) {\n                if (!target[key]) {\n                    Object.assign(target, { [key]: {} });\n                }\n                deepMerge(target[key], source[key]);\n            }\n            else {\n                Object.assign(target, { [key]: source[key] });\n            }\n        }\n    }\n    // @ts-ignore\n    return deepMerge(target, ...sources);\n}\n/**\n * Returns true if the two arrays have the same value for each of the elements\n */\nfunction deepEquals(arrayA, arrayB) {\n    return arrayA.length === arrayB.length && arrayA.every((element, index) => arrayB[index] === element);\n}\n/**\n * Convert an args array into an object.\n */\nfunction optionsFromArguments(defaults, argsArray, keys = [], objKey) {\n    const opts = {};\n    const args = Array.from(argsArray);\n    // if the first argument is an object and has an object key\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(args[0]) && objKey && !Reflect.has(args[0], objKey)) {\n        // if it's not part of the defaults\n        const partOfDefaults = Object.keys(args[0]).some(key => Reflect.has(defaults, key));\n        if (!partOfDefaults) {\n            // merge that key\n            deepMerge(opts, { [objKey]: args[0] });\n            // remove the obj key from the keys\n            keys.splice(keys.indexOf(objKey), 1);\n            // shift the first argument off\n            args.shift();\n        }\n    }\n    if (args.length === 1 && (0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(args[0])) {\n        deepMerge(opts, args[0]);\n    }\n    else {\n        for (let i = 0; i < keys.length; i++) {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(args[i])) {\n                opts[keys[i]] = args[i];\n            }\n        }\n    }\n    return deepMerge(defaults, opts);\n}\n/**\n * Return this instances default values by calling Constructor.getDefaults()\n */\nfunction getDefaultsFromInstance(instance) {\n    return instance.constructor.getDefaults();\n}\n/**\n * Returns the fallback if the given object is undefined.\n * Take an array of arguments and return a formatted options object.\n */\nfunction defaultArg(given, fallback) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(given)) {\n        return fallback;\n    }\n    else {\n        return given;\n    }\n}\n/**\n * Remove all of the properties belonging to omit from obj.\n */\nfunction omitFromObject(obj, omit) {\n    omit.forEach(prop => {\n        if (Reflect.has(obj, prop)) {\n            delete obj[prop];\n        }\n    });\n    return obj;\n}\n//# sourceMappingURL=Defaults.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Defaults.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Draw.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Draw.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Draw\": () => (/* binding */ Draw)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../context/ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n\n\n\n/**\n * Draw is useful for synchronizing visuals and audio events.\n * Callbacks from Tone.Transport or any of the Tone.Event classes\n * always happen _before_ the scheduled time and are not synchronized\n * to the animation frame so they are not good for triggering tightly\n * synchronized visuals and sound. Draw makes it easy to schedule\n * callbacks using the AudioContext time and uses requestAnimationFrame.\n * @example\n * Tone.Transport.schedule((time) => {\n * \t// use the time argument to schedule a callback with Draw\n * \tTone.Draw.schedule(() => {\n * \t\t// do drawing or DOM manipulation here\n * \t\tconsole.log(time);\n * \t}, time);\n * }, \"+0.5\");\n * Tone.Transport.start();\n * @category Core\n */\nclass Draw extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super(...arguments);\n        this.name = \"Draw\";\n        /**\n         * The duration after which events are not invoked.\n         */\n        this.expiration = 0.25;\n        /**\n         * The amount of time before the scheduled time\n         * that the callback can be invoked. Default is\n         * half the time of an animation frame (0.008 seconds).\n         */\n        this.anticipation = 0.008;\n        /**\n         * All of the events.\n         */\n        this._events = new _Timeline__WEBPACK_IMPORTED_MODULE_1__.Timeline();\n        /**\n         * The draw loop\n         */\n        this._boundDrawLoop = this._drawLoop.bind(this);\n        /**\n         * The animation frame id\n         */\n        this._animationFrame = -1;\n    }\n    /**\n     * Schedule a function at the given time to be invoked\n     * on the nearest animation frame.\n     * @param  callback  Callback is invoked at the given time.\n     * @param  time      The time relative to the AudioContext time to invoke the callback.\n     * @example\n     * Tone.Transport.scheduleRepeat(time => {\n     * \tTone.Draw.schedule(() => console.log(time), time);\n     * }, 1);\n     * Tone.Transport.start();\n     */\n    schedule(callback, time) {\n        this._events.add({\n            callback,\n            time: this.toSeconds(time),\n        });\n        // start the draw loop on the first event\n        if (this._events.length === 1) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n        return this;\n    }\n    /**\n     * Cancel events scheduled after the given time\n     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.\n     */\n    cancel(after) {\n        this._events.cancel(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * The draw loop\n     */\n    _drawLoop() {\n        const now = this.context.currentTime;\n        while (this._events.length && this._events.peek().time - this.anticipation <= now) {\n            const event = this._events.shift();\n            if (event && now - event.time <= this.expiration) {\n                event.callback();\n            }\n        }\n        if (this._events.length > 0) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        cancelAnimationFrame(this._animationFrame);\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.draw = new Draw({ context });\n});\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.draw.dispose();\n});\n//# sourceMappingURL=Draw.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Draw.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Emitter.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Emitter.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Emitter\": () => (/* binding */ Emitter)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * Emitter gives classes which extend it\n * the ability to listen for and emit events.\n * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n * MIT (c) 2011 Jerome Etienne.\n * @category Core\n */\nclass Emitter extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"Emitter\";\n    }\n    /**\n     * Bind a callback to a specific event.\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    on(event, callback) {\n        // split the event\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._events)) {\n                this._events = {};\n            }\n            if (!this._events.hasOwnProperty(eventName)) {\n                this._events[eventName] = [];\n            }\n            this._events[eventName].push(callback);\n        });\n        return this;\n    }\n    /**\n     * Bind a callback which is only invoked once\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    once(event, callback) {\n        const boundCallback = (...args) => {\n            // invoke the callback\n            callback(...args);\n            // remove the event\n            this.off(event, boundCallback);\n        };\n        this.on(event, boundCallback);\n        return this;\n    }\n    /**\n     * Remove the event listener.\n     * @param  event     The event to stop listening to.\n     * @param  callback  The callback which was bound to the event with Emitter.on.\n     *                   If no callback is given, all callbacks events are removed.\n     */\n    off(event, callback) {\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._events)) {\n                this._events = {};\n            }\n            if (this._events.hasOwnProperty(event)) {\n                if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(callback)) {\n                    this._events[event] = [];\n                }\n                else {\n                    const eventList = this._events[event];\n                    for (let i = eventList.length - 1; i >= 0; i--) {\n                        if (eventList[i] === callback) {\n                            eventList.splice(i, 1);\n                        }\n                    }\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Invoke all of the callbacks bound to the event\n     * with any arguments passed in.\n     * @param  event  The name of the event.\n     * @param args The arguments to pass to the functions listening.\n     */\n    emit(event, ...args) {\n        if (this._events) {\n            if (this._events.hasOwnProperty(event)) {\n                const eventList = this._events[event].slice(0);\n                for (let i = 0, len = eventList.length; i < len; i++) {\n                    eventList[i].apply(this, args);\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * Add Emitter functions (on/off/emit) to the object\n     */\n    static mixin(constr) {\n        // instance._events = {};\n        [\"on\", \"once\", \"off\", \"emit\"].forEach(name => {\n            const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);\n            Object.defineProperty(constr.prototype, name, property);\n        });\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._events = undefined;\n        return this;\n    }\n}\n//# sourceMappingURL=Emitter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Emitter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Interface.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Interface.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"noOp\": () => (/* binding */ noOp),\n/* harmony export */   \"readOnly\": () => (/* binding */ readOnly),\n/* harmony export */   \"writable\": () => (/* binding */ writable)\n/* harmony export */ });\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n/**\n * Make the property not writable using `defineProperty`. Internal use only.\n */\nfunction readOnly(target, property) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_0__.isArray)(property)) {\n        property.forEach(str => readOnly(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            enumerable: true,\n            writable: false,\n        });\n    }\n}\n/**\n * Make an attribute writeable. Internal use only.\n */\nfunction writable(target, property) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_0__.isArray)(property)) {\n        property.forEach(str => writable(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            writable: true,\n        });\n    }\n}\nconst noOp = () => {\n    // no operation here!\n};\n//# sourceMappingURL=Interface.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Interface.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/IntervalTimeline.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/IntervalTimeline.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntervalTimeline\": () => (/* binding */ IntervalTimeline)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n/**\n * Similar to Tone.Timeline, but all events represent\n * intervals with both \"time\" and \"duration\" times. The\n * events are placed in a tree structure optimized\n * for querying an intersection point with the timeline\n * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n * to represent the data.\n */\nclass IntervalTimeline extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"IntervalTimeline\";\n        /**\n         * The root node of the inteval tree\n         */\n        this._root = null;\n        /**\n         * Keep track of the length of the timeline.\n         */\n        this._length = 0;\n    }\n    /**\n     * The event to add to the timeline. All events must\n     * have a time and duration value\n     * @param  event  The event to add to the timeline\n     */\n    add(event) {\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(event.time), \"Events must have a time property\");\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(event.duration), \"Events must have a duration parameter\");\n        event.time = event.time.valueOf();\n        let node = new IntervalNode(event.time, event.time + event.duration, event);\n        if (this._root === null) {\n            this._root = node;\n        }\n        else {\n            this._root.insert(node);\n        }\n        this._length++;\n        // Restructure tree to be balanced\n        while (node !== null) {\n            node.updateHeight();\n            node.updateMax();\n            this._rebalance(node);\n            node = node.parent;\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  event  The event to remove from the timeline\n     */\n    remove(event) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(event.time, results);\n            for (const node of results) {\n                if (node.event === event) {\n                    this._removeNode(node);\n                    this._length--;\n                    break;\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of items in the timeline.\n     * @readOnly\n     */\n    get length() {\n        return this._length;\n    }\n    /**\n     * Remove events whose time time is after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        this.forEachFrom(after, event => this.remove(event));\n        return this;\n    }\n    /**\n     * Set the root node as the given node\n     */\n    _setRoot(node) {\n        this._root = node;\n        if (this._root !== null) {\n            this._root.parent = null;\n        }\n    }\n    /**\n     * Replace the references to the node in the node's parent\n     * with the replacement node.\n     */\n    _replaceNodeInParent(node, replacement) {\n        if (node.parent !== null) {\n            if (node.isLeftChild()) {\n                node.parent.left = replacement;\n            }\n            else {\n                node.parent.right = replacement;\n            }\n            this._rebalance(node.parent);\n        }\n        else {\n            this._setRoot(replacement);\n        }\n    }\n    /**\n     * Remove the node from the tree and replace it with\n     * a successor which follows the schema.\n     */\n    _removeNode(node) {\n        if (node.left === null && node.right === null) {\n            this._replaceNodeInParent(node, null);\n        }\n        else if (node.right === null) {\n            this._replaceNodeInParent(node, node.left);\n        }\n        else if (node.left === null) {\n            this._replaceNodeInParent(node, node.right);\n        }\n        else {\n            const balance = node.getBalance();\n            let replacement;\n            let temp = null;\n            if (balance > 0) {\n                if (node.left.right === null) {\n                    replacement = node.left;\n                    replacement.right = node.right;\n                    temp = replacement;\n                }\n                else {\n                    replacement = node.left.right;\n                    while (replacement.right !== null) {\n                        replacement = replacement.right;\n                    }\n                    if (replacement.parent) {\n                        replacement.parent.right = replacement.left;\n                        temp = replacement.parent;\n                        replacement.left = node.left;\n                        replacement.right = node.right;\n                    }\n                }\n            }\n            else if (node.right.left === null) {\n                replacement = node.right;\n                replacement.left = node.left;\n                temp = replacement;\n            }\n            else {\n                replacement = node.right.left;\n                while (replacement.left !== null) {\n                    replacement = replacement.left;\n                }\n                if (replacement.parent) {\n                    replacement.parent.left = replacement.right;\n                    temp = replacement.parent;\n                    replacement.left = node.left;\n                    replacement.right = node.right;\n                }\n            }\n            if (node.parent !== null) {\n                if (node.isLeftChild()) {\n                    node.parent.left = replacement;\n                }\n                else {\n                    node.parent.right = replacement;\n                }\n            }\n            else {\n                this._setRoot(replacement);\n            }\n            if (temp) {\n                this._rebalance(temp);\n            }\n        }\n        node.dispose();\n    }\n    /**\n     * Rotate the tree to the left\n     */\n    _rotateLeft(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.right the new root of this sub tree (instead of node)\n        const pivotNode = node.right;\n        if (pivotNode) {\n            node.right = pivotNode.left;\n            pivotNode.left = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Rotate the tree to the right\n     */\n    _rotateRight(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.left the new root of this sub tree (instead of node)\n        const pivotNode = node.left;\n        if (pivotNode) {\n            node.left = pivotNode.right;\n            pivotNode.right = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Balance the BST\n     */\n    _rebalance(node) {\n        const balance = node.getBalance();\n        if (balance > 1 && node.left) {\n            if (node.left.getBalance() < 0) {\n                this._rotateLeft(node.left);\n            }\n            else {\n                this._rotateRight(node);\n            }\n        }\n        else if (balance < -1 && node.right) {\n            if (node.right.getBalance() > 0) {\n                this._rotateRight(node.right);\n            }\n            else {\n                this._rotateLeft(node);\n            }\n        }\n    }\n    /**\n     * Get an event whose time and duration span the give time. Will\n     * return the match whose \"time\" value is closest to the given time.\n     * @return  The event which spans the desired time\n     */\n    get(time) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            if (results.length > 0) {\n                let max = results[0];\n                for (let i = 1; i < results.length; i++) {\n                    if (results[i].low > max.low) {\n                        max = results[i];\n                    }\n                }\n                return max.event;\n            }\n        }\n        return null;\n    }\n    /**\n     * Iterate over everything in the timeline.\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        if (this._root !== null) {\n            const allNodes = [];\n            this._root.traverse(node => allNodes.push(node));\n            allNodes.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the given time\n     * overlaps with the time and duration time of the event.\n     * @param  time The time to check if items are overlapping\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the time is greater\n     * than or equal to the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.searchAfter(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        if (this._root !== null) {\n            this._root.traverse(node => node.dispose());\n        }\n        this._root = null;\n        return this;\n    }\n}\n//-------------------------------------\n// \tINTERVAL NODE HELPER\n//-------------------------------------\n/**\n * Represents a node in the binary search tree, with the addition\n * of a \"high\" value which keeps track of the highest value of\n * its children.\n * References:\n * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/\n * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf\n * @param low\n * @param high\n */\nclass IntervalNode {\n    constructor(low, high, event) {\n        // the nodes to the left\n        this._left = null;\n        // the nodes to the right\n        this._right = null;\n        // the parent node\n        this.parent = null;\n        // the number of child nodes\n        this.height = 0;\n        this.event = event;\n        // the low value\n        this.low = low;\n        // the high value\n        this.high = high;\n        // the high value for this and all child nodes\n        this.max = this.high;\n    }\n    /**\n     * Insert a node into the correct spot in the tree\n     */\n    insert(node) {\n        if (node.low <= this.low) {\n            if (this.left === null) {\n                this.left = node;\n            }\n            else {\n                this.left.insert(node);\n            }\n        }\n        else if (this.right === null) {\n            this.right = node;\n        }\n        else {\n            this.right.insert(node);\n        }\n    }\n    /**\n     * Search the tree for nodes which overlap\n     * with the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    search(point, results) {\n        // If p is to the right of the rightmost point of any interval\n        // in this node and all children, there won't be any matches.\n        if (point > this.max) {\n            return;\n        }\n        // Search left children\n        if (this.left !== null) {\n            this.left.search(point, results);\n        }\n        // Check this node\n        if (this.low <= point && this.high > point) {\n            results.push(this);\n        }\n        // If p is to the left of the time of this interval,\n        // then it can't be in any child to the right.\n        if (this.low > point) {\n            return;\n        }\n        // Search right children\n        if (this.right !== null) {\n            this.right.search(point, results);\n        }\n    }\n    /**\n     * Search the tree for nodes which are less\n     * than the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    searchAfter(point, results) {\n        // Check this node\n        if (this.low >= point) {\n            results.push(this);\n            if (this.left !== null) {\n                this.left.searchAfter(point, results);\n            }\n        }\n        // search the right side\n        if (this.right !== null) {\n            this.right.searchAfter(point, results);\n        }\n    }\n    /**\n     * Invoke the callback on this element and both it's branches\n     * @param  {Function}  callback\n     */\n    traverse(callback) {\n        callback(this);\n        if (this.left !== null) {\n            this.left.traverse(callback);\n        }\n        if (this.right !== null) {\n            this.right.traverse(callback);\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateHeight() {\n        if (this.left !== null && this.right !== null) {\n            this.height = Math.max(this.left.height, this.right.height) + 1;\n        }\n        else if (this.right !== null) {\n            this.height = this.right.height + 1;\n        }\n        else if (this.left !== null) {\n            this.height = this.left.height + 1;\n        }\n        else {\n            this.height = 0;\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateMax() {\n        this.max = this.high;\n        if (this.left !== null) {\n            this.max = Math.max(this.max, this.left.max);\n        }\n        if (this.right !== null) {\n            this.max = Math.max(this.max, this.right.max);\n        }\n    }\n    /**\n     * The balance is how the leafs are distributed on the node\n     * @return  Negative numbers are balanced to the right\n     */\n    getBalance() {\n        let balance = 0;\n        if (this.left !== null && this.right !== null) {\n            balance = this.left.height - this.right.height;\n        }\n        else if (this.left !== null) {\n            balance = this.left.height + 1;\n        }\n        else if (this.right !== null) {\n            balance = -(this.right.height + 1);\n        }\n        return balance;\n    }\n    /**\n     * @returns true if this node is the left child of its parent\n     */\n    isLeftChild() {\n        return this.parent !== null && this.parent.left === this;\n    }\n    /**\n     * get/set the left node\n     */\n    get left() {\n        return this._left;\n    }\n    set left(node) {\n        this._left = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * get/set the right node\n     */\n    get right() {\n        return this._right;\n    }\n    set right(node) {\n        this._right = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * null out references.\n     */\n    dispose() {\n        this.parent = null;\n        this._left = null;\n        this._right = null;\n        this.event = null;\n    }\n}\n//# sourceMappingURL=IntervalTimeline.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/IntervalTimeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Math.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Math.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EQ\": () => (/* binding */ EQ),\n/* harmony export */   \"GT\": () => (/* binding */ GT),\n/* harmony export */   \"GTE\": () => (/* binding */ GTE),\n/* harmony export */   \"LT\": () => (/* binding */ LT),\n/* harmony export */   \"clamp\": () => (/* binding */ clamp)\n/* harmony export */ });\n/**\n * The threshold for correctness for operators. Less than one sample even\n * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).\n */\nconst EPSILON = 1e-6;\n/**\n * Test if A is greater than B\n */\nfunction GT(a, b) {\n    return a > b + EPSILON;\n}\n/**\n * Test if A is greater than or equal to B\n */\nfunction GTE(a, b) {\n    return GT(a, b) || EQ(a, b);\n}\n/**\n * Test if A is less than B\n */\nfunction LT(a, b) {\n    return a + EPSILON < b;\n}\n/**\n * Test if A is less than B\n */\nfunction EQ(a, b) {\n    return Math.abs(a - b) < EPSILON;\n}\n/**\n * Clamp the value within the given range\n */\nfunction clamp(value, min, max) {\n    return Math.max(Math.min(value, max), min);\n}\n//# sourceMappingURL=Math.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Math.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/StateTimeline.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/StateTimeline.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StateTimeline\": () => (/* binding */ StateTimeline)\n/* harmony export */ });\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n/**\n * A Timeline State. Provides the methods: `setStateAtTime(\"state\", time)` and `getValueAtTime(time)`\n * @param initial The initial state of the StateTimeline.  Defaults to `undefined`\n */\nclass StateTimeline extends _Timeline__WEBPACK_IMPORTED_MODULE_0__.Timeline {\n    constructor(initial = \"stopped\") {\n        super();\n        this.name = \"StateTimeline\";\n        this._initial = initial;\n        this.setStateAtTime(this._initial, 0);\n    }\n    /**\n     * Returns the scheduled state scheduled before or at\n     * the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     */\n    getValueAtTime(time) {\n        const event = this.get(time);\n        if (event !== null) {\n            return event.state;\n        }\n        else {\n            return this._initial;\n        }\n    }\n    /**\n     * Add a state to the timeline.\n     * @param  state The name of the state to set.\n     * @param  time  The time to query.\n     * @param options Any additional options that are needed in the timeline.\n     */\n    setStateAtTime(state, time, options) {\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_1__.assertRange)(time, 0);\n        this.add(Object.assign({}, options, {\n            state,\n            time,\n        }));\n        return this;\n    }\n    /**\n     * Return the event before the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check before\n     * @return  The event with the given state before the time\n     */\n    getLastState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        for (let i = index; i >= 0; i--) {\n            const event = this._timeline[i];\n            if (event.state === state) {\n                return event;\n            }\n        }\n    }\n    /**\n     * Return the event after the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check from\n     * @return  The event with the given state after the time\n     */\n    getNextState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        if (index !== -1) {\n            for (let i = index; i < this._timeline.length; i++) {\n                const event = this._timeline[i];\n                if (event.state === state) {\n                    return event;\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=StateTimeline.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/StateTimeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Timeline.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Timeline.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Timeline\": () => (/* binding */ Timeline)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Math__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n/**\n * A Timeline class for scheduling and maintaining state\n * along a timeline. All events must have a \"time\" property.\n * Internally, events are stored in time order for fast\n * retrieval.\n */\nclass Timeline extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super();\n        this.name = \"Timeline\";\n        /**\n         * The array of scheduled timeline events\n         */\n        this._timeline = [];\n        const options = (0,_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Timeline.getDefaults(), arguments, [\"memory\"]);\n        this.memory = options.memory;\n        this.increasing = options.increasing;\n    }\n    static getDefaults() {\n        return {\n            memory: Infinity,\n            increasing: false,\n        };\n    }\n    /**\n     * The number of items in the timeline.\n     */\n    get length() {\n        return this._timeline.length;\n    }\n    /**\n     * Insert an event object onto the timeline. Events must have a \"time\" attribute.\n     * @param event  The event object to insert into the timeline.\n     */\n    add(event) {\n        // the event needs to have a time attribute\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(Reflect.has(event, \"time\"), \"Timeline: events must have a time attribute\");\n        event.time = event.time.valueOf();\n        if (this.increasing && this.length) {\n            const lastValue = this._timeline[this.length - 1];\n            (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GTE)(event.time, lastValue.time), \"The time must be greater than or equal to the last scheduled time\");\n            this._timeline.push(event);\n        }\n        else {\n            const index = this._search(event.time);\n            this._timeline.splice(index + 1, 0, event);\n        }\n        // if the length is more than the memory, remove the previous ones\n        if (this.length > this.memory) {\n            const diff = this.length - this.memory;\n            this._timeline.splice(0, diff);\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  {Object}  event  The event object to remove from the list.\n     * @returns {Timeline} this\n     */\n    remove(event) {\n        const index = this._timeline.indexOf(event);\n        if (index !== -1) {\n            this._timeline.splice(index, 1);\n        }\n        return this;\n    }\n    /**\n     * Get the nearest event whose time is less than or equal to the given time.\n     * @param  time  The time to query.\n     */\n    get(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index !== -1) {\n            return this._timeline[index];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Return the first event in the timeline without removing it\n     * @returns {Object} The first event object\n     */\n    peek() {\n        return this._timeline[0];\n    }\n    /**\n     * Return the first event in the timeline and remove it\n     */\n    shift() {\n        return this._timeline.shift();\n    }\n    /**\n     * Get the event which is scheduled after the given time.\n     * @param  time  The time to query.\n     */\n    getAfter(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index + 1 < this._timeline.length) {\n            return this._timeline[index + 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Get the event before the event at the given time.\n     * @param  time  The time to query.\n     */\n    getBefore(time) {\n        const len = this._timeline.length;\n        // if it's after the last item, return the last item\n        if (len > 0 && this._timeline[len - 1].time < time) {\n            return this._timeline[len - 1];\n        }\n        const index = this._search(time);\n        if (index - 1 >= 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Cancel events at and after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        if (this._timeline.length > 1) {\n            let index = this._search(after);\n            if (index >= 0) {\n                if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[index].time, after)) {\n                    // get the first item with that time\n                    for (let i = index; i >= 0; i--) {\n                        if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[i].time, after)) {\n                            index = i;\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                    this._timeline = this._timeline.slice(0, index);\n                }\n                else {\n                    this._timeline = this._timeline.slice(0, index + 1);\n                }\n            }\n            else {\n                this._timeline = [];\n            }\n        }\n        else if (this._timeline.length === 1) {\n            // the first item's time\n            if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GTE)(this._timeline[0].time, after)) {\n                this._timeline = [];\n            }\n        }\n        return this;\n    }\n    /**\n     * Cancel events before or equal to the given time.\n     * @param  time  The time to cancel before.\n     */\n    cancelBefore(time) {\n        const index = this._search(time);\n        if (index >= 0) {\n            this._timeline = this._timeline.slice(index + 1);\n        }\n        return this;\n    }\n    /**\n     * Returns the previous event if there is one. null otherwise\n     * @param  event The event to find the previous one of\n     * @return The event right before the given event\n     */\n    previousEvent(event) {\n        const index = this._timeline.indexOf(event);\n        if (index > 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Does a binary search on the timeline array and returns the\n     * nearest event index whose time is after or equal to the given time.\n     * If a time is searched before the first index in the timeline, -1 is returned.\n     * If the time is after the end, the index of the last item is returned.\n     */\n    _search(time, param = \"time\") {\n        if (this._timeline.length === 0) {\n            return -1;\n        }\n        let beginning = 0;\n        const len = this._timeline.length;\n        let end = len;\n        if (len > 0 && this._timeline[len - 1][param] <= time) {\n            return len - 1;\n        }\n        while (beginning < end) {\n            // calculate the midpoint for roughly equal partition\n            let midPoint = Math.floor(beginning + (end - beginning) / 2);\n            const event = this._timeline[midPoint];\n            const nextEvent = this._timeline[midPoint + 1];\n            if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(event[param], time)) {\n                // choose the last one that has the same time\n                for (let i = midPoint; i < this._timeline.length; i++) {\n                    const testEvent = this._timeline[i];\n                    if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(testEvent[param], time)) {\n                        midPoint = i;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                return midPoint;\n            }\n            else if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.LT)(event[param], time) && (0,_Math__WEBPACK_IMPORTED_MODULE_3__.GT)(nextEvent[param], time)) {\n                return midPoint;\n            }\n            else if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GT)(event[param], time)) {\n                // search lower\n                end = midPoint;\n            }\n            else {\n                // search upper\n                beginning = midPoint + 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Internal iterator. Applies extra safety checks for\n     * removing items from the array.\n     */\n    _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {\n        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);\n    }\n    /**\n     * Iterate over everything in the array\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        this._iterate(callback);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or before the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBefore(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array after the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAfter(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const lowerBound = this._search(time);\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array between the startTime and endTime.\n     * The timerange is inclusive of the startTime, but exclusive of the endTime.\n     * range = [startTime, endTime).\n     * @param  startTime The time to check if items are before\n     * @param  endTime The end of the test interval.\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBetween(startTime, endTime, callback) {\n        let lowerBound = this._search(startTime);\n        let upperBound = this._search(endTime);\n        if (lowerBound !== -1 && upperBound !== -1) {\n            if (this._timeline[lowerBound].time !== startTime) {\n                lowerBound += 1;\n            }\n            // exclusive of the end time\n            if (this._timeline[upperBound].time === endTime) {\n                upperBound -= 1;\n            }\n            this._iterate(callback, lowerBound, upperBound);\n        }\n        else if (lowerBound === -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or after the given time. Similar to\n     * forEachAfter, but includes the item(s) at the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        let lowerBound = this._search(time);\n        // work backwards until the event time is less than time\n        while (lowerBound >= 0 && this._timeline[lowerBound].time >= time) {\n            lowerBound--;\n        }\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at the given time\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1 && (0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[upperBound].time, time)) {\n            let lowerBound = upperBound;\n            for (let i = upperBound; i >= 0; i--) {\n                if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[i].time, time)) {\n                    lowerBound = i;\n                }\n                else {\n                    break;\n                }\n            }\n            this._iterate(event => {\n                callback(event);\n            }, lowerBound, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._timeline = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Timeline.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/Timeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/TimelineValue.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/TimelineValue.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TimelineValue\": () => (/* binding */ TimelineValue)\n/* harmony export */ });\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n\n\n/**\n * Represents a single value which is gettable and settable in a timed way\n */\nclass TimelineValue extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    /**\n     * @param initialValue The value to return if there is no scheduled values\n     */\n    constructor(initialValue) {\n        super();\n        this.name = \"TimelineValue\";\n        /**\n         * The timeline which stores the values\n         */\n        this._timeline = new _Timeline__WEBPACK_IMPORTED_MODULE_0__.Timeline({ memory: 10 });\n        this._initialValue = initialValue;\n    }\n    /**\n     * Set the value at the given time\n     */\n    set(value, time) {\n        this._timeline.add({\n            value, time\n        });\n        return this;\n    }\n    /**\n     * Get the value at the given time\n     */\n    get(time) {\n        const event = this._timeline.get(time);\n        if (event) {\n            return event.value;\n        }\n        else {\n            return this._initialValue;\n        }\n    }\n}\n//# sourceMappingURL=TimelineValue.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/TimelineValue.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/TypeCheck.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/TypeCheck.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isArray\": () => (/* binding */ isArray),\n/* harmony export */   \"isBoolean\": () => (/* binding */ isBoolean),\n/* harmony export */   \"isDefined\": () => (/* binding */ isDefined),\n/* harmony export */   \"isFunction\": () => (/* binding */ isFunction),\n/* harmony export */   \"isNote\": () => (/* binding */ isNote),\n/* harmony export */   \"isNumber\": () => (/* binding */ isNumber),\n/* harmony export */   \"isObject\": () => (/* binding */ isObject),\n/* harmony export */   \"isString\": () => (/* binding */ isString),\n/* harmony export */   \"isUndef\": () => (/* binding */ isUndef)\n/* harmony export */ });\n/**\n * Test if the arg is undefined\n */\nfunction isUndef(arg) {\n    return typeof arg === \"undefined\";\n}\n/**\n * Test if the arg is not undefined\n */\nfunction isDefined(arg) {\n    return !isUndef(arg);\n}\n/**\n * Test if the arg is a function\n */\nfunction isFunction(arg) {\n    return typeof arg === \"function\";\n}\n/**\n * Test if the argument is a number.\n */\nfunction isNumber(arg) {\n    return (typeof arg === \"number\");\n}\n/**\n * Test if the given argument is an object literal (i.e. `{}`);\n */\nfunction isObject(arg) {\n    return (Object.prototype.toString.call(arg) === \"[object Object]\" && arg.constructor === Object);\n}\n/**\n * Test if the argument is a boolean.\n */\nfunction isBoolean(arg) {\n    return (typeof arg === \"boolean\");\n}\n/**\n * Test if the argument is an Array\n */\nfunction isArray(arg) {\n    return (Array.isArray(arg));\n}\n/**\n * Test if the argument is a string.\n */\nfunction isString(arg) {\n    return (typeof arg === \"string\");\n}\n/**\n * Test if the argument is in the form of a note in scientific pitch notation.\n * e.g. \"C4\"\n */\nfunction isNote(arg) {\n    return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);\n}\n//# sourceMappingURL=TypeCheck.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/util/TypeCheck.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\nconst delayLine = /* javascript */ `\n\t/**\n\t * A multichannel buffer for use within an AudioWorkletProcessor as a delay line\n\t */\n\tclass DelayLine {\n\t\t\n\t\tconstructor(size, channels) {\n\t\t\tthis.buffer = [];\n\t\t\tthis.writeHead = []\n\t\t\tthis.size = size;\n\n\t\t\t// create the empty channels\n\t\t\tfor (let i = 0; i < channels; i++) {\n\t\t\t\tthis.buffer[i] = new Float32Array(this.size);\n\t\t\t\tthis.writeHead[i] = 0;\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Push a value onto the end\n\t\t * @param channel number\n\t\t * @param value number\n\t\t */\n\t\tpush(channel, value) {\n\t\t\tthis.writeHead[channel] += 1;\n\t\t\tif (this.writeHead[channel] > this.size) {\n\t\t\t\tthis.writeHead[channel] = 0;\n\t\t\t}\n\t\t\tthis.buffer[channel][this.writeHead[channel]] = value;\n\t\t}\n\n\t\t/**\n\t\t * Get the recorded value of the channel given the delay\n\t\t * @param channel number\n\t\t * @param delay number delay samples\n\t\t */\n\t\tget(channel, delay) {\n\t\t\tlet readHead = this.writeHead[channel] - Math.floor(delay);\n\t\t\tif (readHead < 0) {\n\t\t\t\treadHead += this.size;\n\t\t\t}\n\t\t\treturn this.buffer[channel][readHead];\n\t\t}\n\t}\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__.addToWorklet)(delayLine);\n//# sourceMappingURL=DelayLine.worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"singleIOProcess\": () => (/* binding */ singleIOProcess)\n/* harmony export */ });\n/* harmony import */ var _ToneAudioWorkletProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneAudioWorkletProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js\");\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\nconst singleIOProcess = /* javascript */ `\n\t/**\n\t * Abstract class for a single input/output processor. \n\t * has a 'generate' function which processes one sample at a time\n\t */\n\tclass SingleIOProcessor extends ToneAudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(Object.assign(options, {\n\t\t\t\tnumberOfInputs: 1,\n\t\t\t\tnumberOfOutputs: 1\n\t\t\t}));\n\t\t\t/**\n\t\t\t * Holds the name of the parameter and a single value of that\n\t\t\t * parameter at the current sample\n\t\t\t * @type { [name: string]: number }\n\t\t\t */\n\t\t\tthis.params = {}\n\t\t}\n\n\t\t/**\n\t\t * Generate an output sample from the input sample and parameters\n\t\t * @abstract\n\t\t * @param input number\n\t\t * @param channel number\n\t\t * @param parameters { [name: string]: number }\n\t\t * @returns number\n\t\t */\n\t\tgenerate(){}\n\n\t\t/**\n\t\t * Update the private params object with the \n\t\t * values of the parameters at the given index\n\t\t * @param parameters { [name: string]: Float32Array },\n\t\t * @param index number\n\t\t */\n\t\tupdateParams(parameters, index) {\n\t\t\tfor (const paramName in parameters) {\n\t\t\t\tconst param = parameters[paramName];\n\t\t\t\tif (param.length > 1) {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][index];\n\t\t\t\t} else {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][0];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Process a single frame of the audio\n\t\t * @param inputs Float32Array[][]\n\t\t * @param outputs Float32Array[][]\n\t\t */\n\t\tprocess(inputs, outputs, parameters) {\n\t\t\tconst input = inputs[0];\n\t\t\tconst output = outputs[0];\n\t\t\t// get the parameter values\n\t\t\tconst channelCount = Math.max(input && input.length || 0, output.length);\n\t\t\tfor (let sample = 0; sample < this.blockSize; sample++) {\n\t\t\t\tthis.updateParams(parameters, sample);\n\t\t\t\tfor (let channel = 0; channel < channelCount; channel++) {\n\t\t\t\t\tconst inputSample = input && input.length ? input[channel][sample] : 0;\n\t\t\t\t\toutput[channel][sample] = this.generate(inputSample, channel, this.params);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn !this.disposed;\n\t\t}\n\t};\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__.addToWorklet)(singleIOProcess);\n//# sourceMappingURL=SingleIOProcessor.worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioWorklet\": () => (/* binding */ ToneAudioWorklet)\n/* harmony export */ });\n/* harmony import */ var _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\n\nclass ToneAudioWorklet extends _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"ToneAudioWorklet\";\n        /**\n         * The constructor options for the node\n         */\n        this.workletOptions = {};\n        /**\n         * Callback which is invoked when there is an error in the processing\n         */\n        this.onprocessorerror = _util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp;\n        const blobUrl = URL.createObjectURL(new Blob([(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__.getWorkletGlobalScope)()], { type: \"text/javascript\" }));\n        const name = this._audioWorkletName();\n        this._dummyGain = this.context.createGain();\n        this._dummyParam = this._dummyGain.gain;\n        // Register the processor\n        this.context.addAudioWorkletModule(blobUrl, name).then(() => {\n            // create the worklet when it's read\n            if (!this.disposed) {\n                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);\n                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);\n                this.onReady(this._worklet);\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dummyGain.disconnect();\n        if (this._worklet) {\n            this._worklet.port.postMessage(\"dispose\");\n            this._worklet.disconnect();\n        }\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioWorklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\nconst toneAudioWorkletProcessor = /* javascript */ `\n\t/**\n\t * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. \n\t */\n\tclass ToneAudioWorkletProcessor extends AudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\t\n\t\t\tsuper(options);\n\t\t\t/**\n\t\t\t * If the processor was disposed or not. Keep alive until it's disposed.\n\t\t\t */\n\t\t\tthis.disposed = false;\n\t\t   \t/** \n\t\t\t * The number of samples in the processing block\n\t\t\t */\n\t\t\tthis.blockSize = 128;\n\t\t\t/**\n\t\t\t * the sample rate\n\t\t\t */\n\t\t\tthis.sampleRate = sampleRate;\n\n\t\t\tthis.port.onmessage = (event) => {\n\t\t\t\t// when it receives a dispose \n\t\t\t\tif (event.data === \"dispose\") {\n\t\t\t\t\tthis.disposed = true;\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t}\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__.addToWorklet)(toneAudioWorkletProcessor);\n//# sourceMappingURL=ToneAudioWorkletProcessor.worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addToWorklet\": () => (/* binding */ addToWorklet),\n/* harmony export */   \"getWorkletGlobalScope\": () => (/* binding */ getWorkletGlobalScope),\n/* harmony export */   \"registerProcessor\": () => (/* binding */ registerProcessor)\n/* harmony export */ });\n/**\n * All of the classes or functions which are loaded into the AudioWorkletGlobalScope\n */\nconst workletContext = new Set();\n/**\n * Add a class to the AudioWorkletGlobalScope\n */\nfunction addToWorklet(classOrFunction) {\n    workletContext.add(classOrFunction);\n}\n/**\n * Register a processor in the AudioWorkletGlobalScope with the given name\n */\nfunction registerProcessor(name, classDesc) {\n    const processor = /* javascript */ `registerProcessor(\"${name}\", ${classDesc})`;\n    workletContext.add(processor);\n}\n/**\n * Get all of the modules which have been registered to the AudioWorkletGlobalScope\n */\nfunction getWorkletGlobalScope() {\n    return Array.from(workletContext).join(\"\\n\");\n}\n//# sourceMappingURL=WorkletGlobalScope.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoFilter.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoFilter.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoFilter\": () => (/* binding */ AutoFilter)\n/* harmony export */ });\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _LFOEffect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LFOEffect */ \"./node_modules/tone/build/esm/effect/LFOEffect.js\");\n\n\n\n/**\n * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n * Setting the LFO rate and depth allows for control over the filter modulation rate\n * and depth.\n *\n * @example\n * // create an autofilter and start it's LFO\n * const autoFilter = new Tone.AutoFilter(\"4n\").toDestination().start();\n * // route an oscillator through the filter and start it\n * const oscillator = new Tone.Oscillator().connect(autoFilter).start();\n * @category Effect\n */\nclass AutoFilter extends _LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]));\n        this.name = \"AutoFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]);\n        this.filter = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_0__.Filter(Object.assign(options.filter, {\n            context: this.context,\n        }));\n        // connections\n        this.connectEffect(this.filter);\n        this._lfo.connect(this.filter.frequency);\n        this.octaves = options.octaves;\n        this.baseFrequency = options.baseFrequency;\n    }\n    static getDefaults() {\n        return Object.assign(_LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect.getDefaults(), {\n            baseFrequency: 200,\n            octaves: 2.6,\n            filter: {\n                type: \"lowpass\",\n                rolloff: -12,\n                Q: 1,\n            }\n        });\n    }\n    /**\n     * The minimum value of the filter's cutoff frequency.\n     */\n    get baseFrequency() {\n        return this._lfo.min;\n    }\n    set baseFrequency(freq) {\n        this._lfo.min = this.toFrequency(freq);\n        // and set the max\n        this.octaves = this._octaves;\n    }\n    /**\n     * The maximum value of the filter's cutoff frequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(oct) {\n        this._octaves = oct;\n        this._lfo.max = this._lfo.min * Math.pow(2, oct);\n    }\n    dispose() {\n        super.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoFilter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/AutoFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoPanner.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoPanner.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoPanner\": () => (/* binding */ AutoPanner)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Panner__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _LFOEffect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LFOEffect */ \"./node_modules/tone/build/esm/effect/LFOEffect.js\");\n\n\n\n/**\n * AutoPanner is a [[Panner]] with an [[LFO]] connected to the pan amount.\n * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).\n *\n * @example\n * // create an autopanner and start it\n * const autoPanner = new Tone.AutoPanner(\"4n\").toDestination().start();\n * // route an oscillator through the panner and start it\n * const oscillator = new Tone.Oscillator().connect(autoPanner).start();\n * @category Effect\n */\nclass AutoPanner extends _LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoPanner.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"AutoPanner\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoPanner.getDefaults(), arguments, [\"frequency\"]);\n        this._panner = new _component_channel_Panner__WEBPACK_IMPORTED_MODULE_0__.Panner({\n            context: this.context,\n            channelCount: options.channelCount\n        });\n        // connections\n        this.connectEffect(this._panner);\n        this._lfo.connect(this._panner.pan);\n        this._lfo.min = -1;\n        this._lfo.max = 1;\n    }\n    static getDefaults() {\n        return Object.assign(_LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect.getDefaults(), {\n            channelCount: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoPanner.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/AutoPanner.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoWah.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoWah.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoWah\": () => (/* binding */ AutoWah)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _component_analysis_Follower__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _signal_ScaleExp__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/ScaleExp */ \"./node_modules/tone/build/esm/signal/ScaleExp.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n\n\n/**\n * AutoWah connects a [[Follower]] to a [[Filter]].\n * The frequency of the filter, follows the input amplitude curve.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).\n *\n * @example\n * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();\n * // initialize the synth and connect to autowah\n * const synth = new Tone.Synth().connect(autoWah);\n * // Q value influences the effect of the wah - default is 2\n * autoWah.Q.value = 6;\n * // more audible on higher notes\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Effect\n */\nclass AutoWah extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]));\n        this.name = \"AutoWah\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]);\n        this._follower = new _component_analysis_Follower__WEBPACK_IMPORTED_MODULE_2__.Follower({\n            context: this.context,\n            smoothing: options.follower,\n        });\n        this._sweepRange = new _signal_ScaleExp__WEBPACK_IMPORTED_MODULE_6__.ScaleExp({\n            context: this.context,\n            min: 0,\n            max: 1,\n            exponent: 0.5,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this._inputBoost = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_4__.Gain({ context: this.context });\n        this._bandpass = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            context: this.context,\n            rolloff: -48,\n            frequency: 0,\n            Q: options.Q,\n        });\n        this._peaking = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            context: this.context,\n            type: \"peaking\"\n        });\n        this._peaking.gain.value = options.gain;\n        this.gain = this._peaking.gain;\n        this.Q = this._bandpass.Q;\n        // the control signal path\n        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);\n        this._sweepRange.connect(this._bandpass.frequency);\n        this._sweepRange.connect(this._peaking.frequency);\n        // the filtered path\n        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);\n        // set the initial value\n        this._setSweepRange();\n        this.sensitivity = options.sensitivity;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_7__.readOnly)(this, [\"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            baseFrequency: 100,\n            octaves: 6,\n            sensitivity: 0,\n            Q: 2,\n            gain: 2,\n            follower: 0.2,\n        });\n    }\n    /**\n     * The number of octaves that the filter will sweep above the baseFrequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        this._setSweepRange();\n    }\n    /**\n     * The follower's smoothing time\n     */\n    get follower() {\n        return this._follower.smoothing;\n    }\n    set follower(follower) {\n        this._follower.smoothing = follower;\n    }\n    /**\n     * The base frequency from which the sweep will start from.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(baseFreq) {\n        this._baseFrequency = this.toFrequency(baseFreq);\n        this._setSweepRange();\n    }\n    /**\n     * The sensitivity to control how responsive to the input signal the filter is.\n     */\n    get sensitivity() {\n        return (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.gainToDb)(1 / this._inputBoost.gain.value);\n    }\n    set sensitivity(sensitivity) {\n        this._inputBoost.gain.value = 1 / (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(sensitivity);\n    }\n    /**\n     * sets the sweep range of the scaler\n     */\n    _setSweepRange() {\n        this._sweepRange.min = this._baseFrequency;\n        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);\n    }\n    dispose() {\n        super.dispose();\n        this._follower.dispose();\n        this._sweepRange.dispose();\n        this._bandpass.dispose();\n        this._peaking.dispose();\n        this._inputBoost.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoWah.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/AutoWah.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/BitCrusher.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/BitCrusher.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BitCrusher\": () => (/* binding */ BitCrusher)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/worklet/ToneAudioWorklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _BitCrusher_worklet__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./BitCrusher.worklet */ \"./node_modules/tone/build/esm/effect/BitCrusher.worklet.js\");\n\n\n\n\n\n\n\n/**\n * BitCrusher down-samples the incoming signal to a different bit depth.\n * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing\n * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).\n * @example\n * // initialize crusher and route a synth through it\n * const crusher = new Tone.BitCrusher(4).toDestination();\n * const synth = new Tone.Synth().connect(crusher);\n * synth.triggerAttackRelease(\"C2\", 2);\n *\n * @category Effect\n */\nclass BitCrusher extends _Effect__WEBPACK_IMPORTED_MODULE_1__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusher.getDefaults(), arguments, [\"bits\"]));\n        this.name = \"BitCrusher\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusher.getDefaults(), arguments, [\"bits\"]);\n        this._bitCrusherWorklet = new BitCrusherWorklet({\n            context: this.context,\n            bits: options.bits,\n        });\n        // connect it up\n        this.connectEffect(this._bitCrusherWorklet);\n        this.bits = this._bitCrusherWorklet.bits;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_1__.Effect.getDefaults(), {\n            bits: 4,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._bitCrusherWorklet.dispose();\n        return this;\n    }\n}\n/**\n * Internal class which creates an AudioWorklet to do the bit crushing\n */\nclass BitCrusherWorklet extends _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__.ToneAudioWorklet {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusherWorklet.getDefaults(), arguments));\n        this.name = \"BitCrusherWorklet\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusherWorklet.getDefaults(), arguments);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.bits = new _core_context_Param__WEBPACK_IMPORTED_MODULE_5__.Param({\n            context: this.context,\n            value: options.bits,\n            units: \"positive\",\n            minValue: 1,\n            maxValue: 16,\n            param: this._dummyParam,\n            swappable: true,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__.ToneAudioWorklet.getDefaults(), {\n            bits: 12,\n        });\n    }\n    _audioWorkletName() {\n        return _BitCrusher_worklet__WEBPACK_IMPORTED_MODULE_6__.workletName;\n    }\n    onReady(node) {\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(this.input, node, this.output);\n        const bits = node.parameters.get(\"bits\");\n        this.bits.setParam(bits);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.bits.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=BitCrusher.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/BitCrusher.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/BitCrusher.worklet.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/BitCrusher.worklet.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"bitCrusherWorklet\": () => (/* binding */ bitCrusherWorklet),\n/* harmony export */   \"workletName\": () => (/* binding */ workletName)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_SingleIOProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/worklet/SingleIOProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js\");\n/* harmony import */ var _core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/worklet/WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\nconst workletName = \"bit-crusher\";\nconst bitCrusherWorklet = /* javascript */ `\n\tclass BitCrusherWorklet extends SingleIOProcessor {\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"bits\",\n\t\t\t\tdefaultValue: 12,\n\t\t\t\tminValue: 1,\n\t\t\t\tmaxValue: 16,\n\t\t\t\tautomationRate: 'k-rate'\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, _channel, parameters) {\n\t\t\tconst step = Math.pow(0.5, parameters.bits - 1);\n\t\t\tconst val = step * Math.floor(input / step + 0.5);\n\t\t\treturn val;\n\t\t}\n\t}\n`;\n(0,_core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__.registerProcessor)(workletName, bitCrusherWorklet);\n//# sourceMappingURL=BitCrusher.worklet.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/BitCrusher.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Chebyshev.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Chebyshev.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Chebyshev\": () => (/* binding */ Chebyshev)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n\n/**\n * Chebyshev is a waveshaper which is good\n * for making different types of distortion sounds.\n * Note that odd orders sound very different from even ones,\n * and order = 1 is no change.\n * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).\n * @example\n * // create a new cheby\n * const cheby = new Tone.Chebyshev(50).toDestination();\n * // create a monosynth connected to our cheby\n * const synth = new Tone.MonoSynth().connect(cheby);\n * synth.triggerAttackRelease(\"C2\", 0.4);\n * @category Effect\n */\nclass Chebyshev extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chebyshev.getDefaults(), arguments, [\"order\"]));\n        this.name = \"Chebyshev\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chebyshev.getDefaults(), arguments, [\"order\"]);\n        this._shaper = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_2__.WaveShaper({\n            context: this.context,\n            length: 4096\n        });\n        this._order = options.order;\n        this.connectEffect(this._shaper);\n        this.order = options.order;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            order: 1,\n            oversample: \"none\"\n        });\n    }\n    /**\n     * get the coefficient for that degree\n     * @param  x the x value\n     * @param  degree\n     * @param  memo memoize the computed value. this speeds up computation greatly.\n     */\n    _getCoefficient(x, degree, memo) {\n        if (memo.has(degree)) {\n            return memo.get(degree);\n        }\n        else if (degree === 0) {\n            memo.set(degree, 0);\n        }\n        else if (degree === 1) {\n            memo.set(degree, x);\n        }\n        else {\n            memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));\n        }\n        return memo.get(degree);\n    }\n    /**\n     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming\n     * signal through a Tone.WaveShaper. The equations are in the form:\n     * ```\n     * order 2: 2x^2 + 1\n     * order 3: 4x^3 + 3x\n     * ```\n     * @min 1\n     * @max 100\n     */\n    get order() {\n        return this._order;\n    }\n    set order(order) {\n        this._order = order;\n        this._shaper.setMap((x => {\n            return this._getCoefficient(x, order, new Map());\n        }));\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chebyshev.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Chebyshev.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Chorus.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Chorus.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Chorus\": () => (/* binding */ Chorus)\n/* harmony export */ });\n/* harmony import */ var _effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/StereoFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Chorus is a stereo chorus effect composed of a left and right delay with an [[LFO]] applied to the delayTime of each channel.\n * When [[feedback]] is set to a value larger than 0, you also get Flanger-type effects.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n * Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).\n *\n * @example\n * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();\n * const synth = new Tone.PolySynth().connect(chorus);\n * synth.triggerAttackRelease([\"C3\", \"E3\", \"G3\"], \"8n\");\n *\n * @category Effect\n */\nclass Chorus extends _effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]));\n        this.name = \"Chorus\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]);\n        this._depth = options.depth;\n        this._delayTime = options.delayTime / 1000;\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180\n        });\n        this._delayNodeL = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({ context: this.context });\n        this._delayNodeR = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({ context: this.context });\n        this.frequency = this._lfoL.frequency;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\"]);\n        // have one LFO frequency control the other\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // connections\n        this.connectEffectLeft(this._delayNodeL);\n        this.connectEffectRight(this._delayNodeR);\n        // lfo setup\n        this._lfoL.connect(this._delayNodeL.delayTime);\n        this._lfoR.connect(this._delayNodeR.delayTime);\n        // set the initial values\n        this.depth = this._depth;\n        this.type = options.type;\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(_effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect.getDefaults(), {\n            frequency: 1.5,\n            delayTime: 3.5,\n            depth: 0.7,\n            type: \"sine\",\n            spread: 180,\n            feedback: 0,\n            wet: 0.5,\n        });\n    }\n    /**\n     * The depth of the effect. A depth of 1 makes the delayTime\n     * modulate between 0 and 2*delayTime (centered around the delayTime).\n     */\n    get depth() {\n        return this._depth;\n    }\n    set depth(depth) {\n        this._depth = depth;\n        const deviation = this._delayTime * depth;\n        this._lfoL.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoL.max = this._delayTime + deviation;\n        this._lfoR.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoR.max = this._delayTime + deviation;\n    }\n    /**\n     * The delayTime in milliseconds of the chorus. A larger delayTime\n     * will give a more pronounced effect. Nominal range a delayTime\n     * is between 2 and 20ms.\n     */\n    get delayTime() {\n        return this._delayTime * 1000;\n    }\n    set delayTime(delayTime) {\n        this._delayTime = delayTime / 1000;\n        this.depth = this._depth;\n    }\n    /**\n     * The oscillator type of the LFO.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase;\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._delayNodeL.dispose();\n        this._delayNodeR.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chorus.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Chorus.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Distortion.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Distortion.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Distortion\": () => (/* binding */ Distortion)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n\n\n\n/**\n * A simple distortion effect using Tone.WaveShaper.\n * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).\n *\n * @example\n * const dist = new Tone.Distortion(0.8).toDestination();\n * const fm = new Tone.FMSynth().connect(dist);\n * fm.triggerAttackRelease(\"A1\", \"8n\");\n * @category Effect\n */\nclass Distortion extends _Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Distortion.getDefaults(), arguments, [\"distortion\"]));\n        this.name = \"Distortion\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Distortion.getDefaults(), arguments, [\"distortion\"]);\n        this._shaper = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            length: 4096,\n        });\n        this._distortion = options.distortion;\n        this.connectEffect(this._shaper);\n        this.distortion = options.distortion;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            distortion: 0.4,\n            oversample: \"none\",\n        });\n    }\n    /**\n     * The amount of distortion. Nominal range is between 0 and 1.\n     */\n    get distortion() {\n        return this._distortion;\n    }\n    set distortion(amount) {\n        this._distortion = amount;\n        const k = amount * 100;\n        const deg = Math.PI / 180;\n        this._shaper.setMap((x) => {\n            if (Math.abs(x) < 0.001) {\n                // should output 0 when input is 0\n                return 0;\n            }\n            else {\n                return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));\n            }\n        });\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Distortion.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Distortion.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Effect.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Effect.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Effect\": () => (/* binding */ Effect)\n/* harmony export */ });\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Effect is the base class for effects. Connect the effect between\n * the effectSend and effectReturn GainNodes, then control the amount of\n * effect which goes to the output using the wet control.\n */\nclass Effect extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"Effect\";\n        /**\n         * the drywet knob to control the amount of effect\n         */\n        this._dryWet = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_0__.CrossFade({ context: this.context });\n        /**\n         * The wet control is how much of the effected\n         * will pass through to the output. 1 = 100% effected\n         * signal, 0 = 100% dry signal.\n         */\n        this.wet = this._dryWet.fade;\n        /**\n         * connect the effectSend to the input of hte effect\n         */\n        this.effectSend = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * connect the output of the effect to the effectReturn\n         */\n        this.effectReturn = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * The effect input node\n         */\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * The effect output\n         */\n        this.output = this._dryWet;\n        // connections\n        this.input.fan(this._dryWet.a, this.effectSend);\n        this.effectReturn.connect(this._dryWet.b);\n        this.wet.setValueAtTime(options.wet, 0);\n        this._internalChannels = [this.effectReturn, this.effectSend];\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"wet\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    /**\n     * chains the effect in between the effectSend and effectReturn\n     */\n    connectEffect(effect) {\n        // add it to the internal channels\n        this._internalChannels.push(effect);\n        this.effectSend.chain(effect, this.effectReturn);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this.effectSend.dispose();\n        this.effectReturn.dispose();\n        this.wet.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Effect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Effect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FeedbackDelay.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FeedbackDelay.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackDelay\": () => (/* binding */ FeedbackDelay)\n/* harmony export */ });\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FeedbackEffect */ \"./node_modules/tone/build/esm/effect/FeedbackEffect.js\");\n\n\n\n\n/**\n * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.\n *\n * @param delayTime The delay applied to the incoming signal.\n * @param feedback The amount of the effected signal which is fed back through the delay.\n * @example\n * const feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toDestination();\n * const tom = new Tone.MembraneSynth({\n * \toctaves: 4,\n * \tpitchDecay: 0.1\n * }).connect(feedbackDelay);\n * tom.triggerAttackRelease(\"A2\", \"32n\");\n * @category Effect\n */\nclass FeedbackDelay extends _FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__.FeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"FeedbackDelay\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._delayNode = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_0__.Delay({\n            context: this.context,\n            delayTime: options.delayTime,\n            maxDelay: options.maxDelay,\n        });\n        this.delayTime = this._delayNode.delayTime;\n        // connect it up\n        this.connectEffect(this._delayNode);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(_FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__.FeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackDelay.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/FeedbackDelay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FeedbackEffect.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FeedbackEffect.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackEffect\": () => (/* binding */ FeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n\n\n\n/**\n * FeedbackEffect provides a loop between an audio source and its own output.\n * This is a base-class for feedback effects.\n */\nclass FeedbackEffect extends _Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"FeedbackEffect\";\n        this._feedbackGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.feedback,\n            units: \"normalRange\",\n        });\n        this.feedback = this._feedbackGain.gain;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"feedback\");\n        // the feedback loop\n        this.effectReturn.chain(this._feedbackGain, this.effectSend);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            feedback: 0.125,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._feedbackGain.dispose();\n        this.feedback.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/FeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Freeverb.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Freeverb.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Freeverb\": () => (/* binding */ Freeverb)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n\n\n\n\n\n/**\n * An array of comb filter delay values from Freeverb implementation\n */\nconst combFilterTunings = [1557 / 44100, 1617 / 44100, 1491 / 44100, 1422 / 44100, 1277 / 44100, 1356 / 44100, 1188 / 44100, 1116 / 44100];\n/**\n * An array of allpass filter frequency values from Freeverb implementation\n */\nconst allpassFilterFrequencies = [225, 556, 441, 341];\n/**\n * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).\n * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].\n * @example\n * const freeverb = new Tone.Freeverb().toDestination();\n * freeverb.dampening = 1000;\n * // routing synth through the reverb\n * const synth = new Tone.NoiseSynth().connect(freeverb);\n * synth.triggerAttackRelease(0.05);\n * @category Effect\n */\nclass Freeverb extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]));\n        this.name = \"Freeverb\";\n        /**\n         * the comb filters\n         */\n        this._combFilters = [];\n        /**\n         * the allpass filters on the left\n         */\n        this._allpassFiltersL = [];\n        /**\n         * the allpass filters on the right\n         */\n        this._allpassFiltersR = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]);\n        this.roomSize = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        // make the allpass filters on the right\n        this._allpassFiltersL = allpassFilterFrequencies.map(freq => {\n            const allpassL = this.context.createBiquadFilter();\n            allpassL.type = \"allpass\";\n            allpassL.frequency.value = freq;\n            return allpassL;\n        });\n        // make the allpass filters on the left\n        this._allpassFiltersR = allpassFilterFrequencies.map(freq => {\n            const allpassR = this.context.createBiquadFilter();\n            allpassR.type = \"allpass\";\n            allpassR.frequency.value = freq;\n            return allpassR;\n        });\n        // make the comb filters\n        this._combFilters = combFilterTunings.map((delayTime, index) => {\n            const lfpf = new _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_4__.LowpassCombFilter({\n                context: this.context,\n                dampening: options.dampening,\n                delayTime,\n            });\n            if (index < combFilterTunings.length / 2) {\n                this.connectEffectLeft(lfpf, ...this._allpassFiltersL);\n            }\n            else {\n                this.connectEffectRight(lfpf, ...this._allpassFiltersR);\n            }\n            this.roomSize.connect(lfpf.resonance);\n            return lfpf;\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            roomSize: 0.7,\n            dampening: 3000\n        });\n    }\n    /**\n     * The amount of dampening of the reverberant signal.\n     */\n    get dampening() {\n        return this._combFilters[0].dampening;\n    }\n    set dampening(d) {\n        this._combFilters.forEach(c => c.dampening = d);\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFiltersL.forEach(al => al.disconnect());\n        this._allpassFiltersR.forEach(ar => ar.disconnect());\n        this._combFilters.forEach(cf => cf.dispose());\n        this.roomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Freeverb.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Freeverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FrequencyShifter.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FrequencyShifter.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FrequencyShifter\": () => (/* binding */ FrequencyShifter)\n/* harmony export */ });\n/* harmony import */ var _component_filter_PhaseShiftAllpass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/PhaseShiftAllpass */ \"./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _effect_Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Negate__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../signal/Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _source_oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/oscillator/Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _source_oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../source/oscillator/ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n\n\n\n\n\n\n\n\n\n/**\n * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.\n * The amount can be changed at audio rate and the effect is applied in real time.\n * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.\n * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,\n * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.\n * The algorithm will produces some aliasing towards the high end, especially if your source material\n * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling\n * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might\n * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.\n * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/\n *\n * @example\n * const input = new Tone.Oscillator(230, \"sawtooth\").start();\n * const shift = new Tone.FrequencyShifter(42).toDestination();\n * input.connect(shift);\n * @category Effect\n */\nclass FrequencyShifter extends _effect_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"FrequencyShifter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_6__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n            minValue: -this.context.sampleRate / 2,\n            maxValue: this.context.sampleRate / 2,\n        });\n        this._sine = new _source_oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_8__.ToneOscillatorNode({\n            context: this.context,\n            type: \"sine\",\n        });\n        this._cosine = new _source_oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_7__.Oscillator({\n            context: this.context,\n            phase: -90,\n            type: \"sine\",\n        });\n        this._sineMultiply = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({ context: this.context });\n        this._cosineMultiply = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({ context: this.context });\n        this._negate = new _signal_Negate__WEBPACK_IMPORTED_MODULE_5__.Negate({ context: this.context });\n        this._add = new _signal_Add__WEBPACK_IMPORTED_MODULE_3__.Add({ context: this.context });\n        this._phaseShifter = new _component_filter_PhaseShiftAllpass__WEBPACK_IMPORTED_MODULE_0__.PhaseShiftAllpass({ context: this.context });\n        this.effectSend.connect(this._phaseShifter);\n        // connect the carrier frequency signal to the two oscillators\n        this.frequency.fan(this._sine.frequency, this._cosine.frequency);\n        this._phaseShifter.offset90.connect(this._cosineMultiply);\n        this._cosine.connect(this._cosineMultiply.factor);\n        this._phaseShifter.connect(this._sineMultiply);\n        this._sine.connect(this._sineMultiply.factor);\n        this._sineMultiply.connect(this._negate);\n        this._cosineMultiply.connect(this._add);\n        this._negate.connect(this._add.addend);\n        this._add.connect(this.effectReturn);\n        // start the oscillators at the same time\n        const now = this.immediate();\n        this._sine.start(now);\n        this._cosine.start(now);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            frequency: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this._add.dispose();\n        this._cosine.dispose();\n        this._cosineMultiply.dispose();\n        this._negate.dispose();\n        this._phaseShifter.dispose();\n        this._sine.dispose();\n        this._sineMultiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyShifter.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/FrequencyShifter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/JCReverb.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/JCReverb.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"JCReverb\": () => (/* binding */ JCReverb)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _component_filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/filter/FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * an array of the comb filter delay time values\n */\nconst combFilterDelayTimes = [1687 / 25000, 1601 / 25000, 2053 / 25000, 2251 / 25000];\n/**\n * the resonances of each of the comb filters\n */\nconst combFilterResonances = [0.773, 0.802, 0.753, 0.733];\n/**\n * the allpass filter frequencies\n */\nconst allpassFilterFreqs = [347, 113, 37];\n/**\n * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n * tuned by John Chowning in 1970.\n * It is made up of three allpass filters and four [[FeedbackCombFilter]].\n * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].\n * @example\n * const reverb = new Tone.JCReverb(0.4).toDestination();\n * const delay = new Tone.FeedbackDelay(0.5);\n * // connecting the synth to reverb through delay\n * const synth = new Tone.DuoSynth().chain(delay, reverb);\n * synth.triggerAttackRelease(\"A4\", \"8n\");\n *\n * @category Effect\n */\nclass JCReverb extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(JCReverb.getDefaults(), arguments, [\"roomSize\"]));\n        this.name = \"JCReverb\";\n        /**\n         * a series of allpass filters\n         */\n        this._allpassFilters = [];\n        /**\n         * parallel feedback comb filters\n         */\n        this._feedbackCombFilters = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(JCReverb.getDefaults(), arguments, [\"roomSize\"]);\n        this.roomSize = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        this._scaleRoomSize = new _signal_Scale__WEBPACK_IMPORTED_MODULE_2__.Scale({\n            context: this.context,\n            min: -0.733,\n            max: 0.197,\n        });\n        // make the allpass filters\n        this._allpassFilters = allpassFilterFreqs.map(freq => {\n            const allpass = this.context.createBiquadFilter();\n            allpass.type = \"allpass\";\n            allpass.frequency.value = freq;\n            return allpass;\n        });\n        // and the comb filters\n        this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index) => {\n            const fbcf = new _component_filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_4__.FeedbackCombFilter({\n                context: this.context,\n                delayTime,\n            });\n            this._scaleRoomSize.connect(fbcf.resonance);\n            fbcf.resonance.value = combFilterResonances[index];\n            if (index < combFilterDelayTimes.length / 2) {\n                this.connectEffectLeft(...this._allpassFilters, fbcf);\n            }\n            else {\n                this.connectEffectRight(...this._allpassFilters, fbcf);\n            }\n            return fbcf;\n        });\n        // chain the allpass filters together\n        this.roomSize.connect(this._scaleRoomSize);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            roomSize: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFilters.forEach(apf => apf.disconnect());\n        this._feedbackCombFilters.forEach(fbcf => fbcf.dispose());\n        this.roomSize.dispose();\n        this._scaleRoomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=JCReverb.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/JCReverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/LFOEffect.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/LFOEffect.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LFOEffect\": () => (/* binding */ LFOEffect)\n/* harmony export */ });\n/* harmony import */ var _effect_Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n/**\n * Base class for LFO-based effects.\n */\nclass LFOEffect extends _effect_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"LFOEffect\";\n        this._lfo = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            amplitude: options.depth,\n        });\n        this.depth = this._lfo.amplitude;\n        this.frequency = this._lfo.frequency;\n        this.type = options.type;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"frequency\", \"depth\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            frequency: 1,\n            type: \"sine\",\n            depth: 1,\n        });\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfo.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfo.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfo.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfo.unsync();\n        return this;\n    }\n    /**\n     * The type of the LFO's oscillator: See [[Oscillator.type]]\n     * @example\n     * const autoFilter = new Tone.AutoFilter().start().toDestination();\n     * const noise = new Tone.Noise().start().connect(autoFilter);\n     * autoFilter.type = \"square\";\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFOEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/LFOEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/MidSideEffect.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/MidSideEffect.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideEffect\": () => (/* binding */ MidSideEffect)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _component_channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _component_channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n\n\n\n/**\n * Mid/Side processing separates the the 'mid' signal\n * (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels)\n * and effects them separately before being recombined.\n * Applies a Mid/Side seperation and recombination.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * This is a base-class for Mid/Side Effects.\n * @category Effect\n */\nclass MidSideEffect extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"MidSideEffect\";\n        this._midSideMerge = new _component_channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_2__.MidSideMerge({ context: this.context });\n        this._midSideSplit = new _component_channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_1__.MidSideSplit({ context: this.context });\n        this._midSend = this._midSideSplit.mid;\n        this._sideSend = this._midSideSplit.side;\n        this._midReturn = this._midSideMerge.mid;\n        this._sideReturn = this._midSideMerge.side;\n        // the connections\n        this.effectSend.connect(this._midSideSplit);\n        this._midSideMerge.connect(this.effectReturn);\n    }\n    /**\n     * Connect the mid chain of the effect\n     */\n    connectEffectMid(...nodes) {\n        this._midSend.chain(...nodes, this._midReturn);\n    }\n    /**\n     * Connect the side chain of the effect\n     */\n    connectEffectSide(...nodes) {\n        this._sideSend.chain(...nodes, this._sideReturn);\n    }\n    dispose() {\n        super.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        this._midSend.dispose();\n        this._sideSend.dispose();\n        this._midReturn.dispose();\n        this._sideReturn.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/MidSideEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Phaser.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Phaser.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Phaser\": () => (/* binding */ Phaser)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Phaser is a phaser effect. Phasers work by changing the phase\n * of different frequency components of an incoming signal. Read more on\n * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).\n * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).\n * @example\n * const phaser = new Tone.Phaser({\n * \tfrequency: 15,\n * \toctaves: 5,\n * \tbaseFrequency: 1000\n * }).toDestination();\n * const synth = new Tone.FMSynth().connect(phaser);\n * synth.triggerAttackRelease(\"E3\", \"2n\");\n * @category Effect\n */\nclass Phaser extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]));\n        this.name = \"Phaser\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]);\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.Q,\n            units: \"positive\",\n        });\n        this._filtersL = this._makeFilters(options.stages, this._lfoL);\n        this._filtersR = this._makeFilters(options.stages, this._lfoR);\n        this.frequency = this._lfoL.frequency;\n        this.frequency.value = options.frequency;\n        // connect them up\n        this.connectEffectLeft(...this._filtersL);\n        this.connectEffectRight(...this._filtersR);\n        // control the frequency with one LFO\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // set the options\n        this.baseFrequency = options.baseFrequency;\n        this.octaves = options.octaves;\n        // start the lfo\n        this._lfoL.start();\n        this._lfoR.start();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            frequency: 0.5,\n            octaves: 3,\n            stages: 10,\n            Q: 10,\n            baseFrequency: 350,\n        });\n    }\n    _makeFilters(stages, connectToFreq) {\n        const filters = [];\n        // make all the filters\n        for (let i = 0; i < stages; i++) {\n            const filter = this.context.createBiquadFilter();\n            filter.type = \"allpass\";\n            this.Q.connect(filter.Q);\n            connectToFreq.connect(filter.frequency);\n            filters.push(filter);\n        }\n        return filters;\n    }\n    /**\n     * The number of octaves the phase goes above the baseFrequency\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        const max = this._baseFrequency * Math.pow(2, octaves);\n        this._lfoL.max = max;\n        this._lfoR.max = max;\n    }\n    /**\n     * The the base frequency of the filters.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(freq) {\n        this._baseFrequency = this.toFrequency(freq);\n        this._lfoL.min = this._baseFrequency;\n        this._lfoR.min = this._baseFrequency;\n        this.octaves = this._octaves;\n    }\n    dispose() {\n        super.dispose();\n        this.Q.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._filtersL.forEach(f => f.disconnect());\n        this._filtersR.forEach(f => f.disconnect());\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Phaser.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Phaser.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/PingPongDelay.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/PingPongDelay.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PingPongDelay\": () => (/* binding */ PingPongDelay)\n/* harmony export */ });\n/* harmony import */ var _StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoXFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * PingPongDelay is a feedback delay effect where the echo is heard\n * first in one channel and next in the opposite channel. In a stereo\n * system these are the right and left channels.\n * PingPongDelay in more simplified terms is two Tone.FeedbackDelays\n * with independent delay values. Each delay is routed to one channel\n * (left or right), and the channel triggered second will always\n * trigger at the same interval after the first.\n * @example\n * const pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toDestination();\n * const drum = new Tone.MembraneSynth().connect(pingPong);\n * drum.triggerAttackRelease(\"C4\", \"32n\");\n * @category Effect\n */\nclass PingPongDelay extends _StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoXFeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"PingPongDelay\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._leftDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay,\n        });\n        this._rightDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this._rightPreDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this.delayTime = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"time\",\n            value: options.delayTime,\n        });\n        // connect it up\n        this.connectEffectLeft(this._leftDelay);\n        this.connectEffectRight(this._rightPreDelay, this._rightDelay);\n        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);\n        // rearranged the feedback to be after the rightPreDelay\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._rightDelay);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"delayTime\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoXFeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._leftDelay.dispose();\n        this._rightDelay.dispose();\n        this._rightPreDelay.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PingPongDelay.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/PingPongDelay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/PitchShift.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/PitchShift.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PitchShift\": () => (/* binding */ PitchShift)\n/* harmony export */ });\n/* harmony import */ var _FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FeedbackEffect */ \"./node_modules/tone/build/esm/effect/FeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n\n\n\n\n\n\n\n\n/**\n * PitchShift does near-realtime pitch shifting to the incoming signal.\n * The effect is achieved by speeding up or slowing down the delayTime\n * of a DelayNode using a sawtooth wave.\n * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).\n * @category Effect\n */\nclass PitchShift extends _FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.FeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PitchShift.getDefaults(), arguments, [\"pitch\"]));\n        this.name = \"PitchShift\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PitchShift.getDefaults(), arguments, [\"pitch\"]);\n        this._frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({ context: this.context });\n        this._delayA = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoA = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\"\n        }).connect(this._delayA.delayTime);\n        this._delayB = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoB = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\",\n            phase: 180\n        }).connect(this._delayB.delayTime);\n        this._crossFade = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_4__.CrossFade({ context: this.context });\n        this._crossFadeLFO = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 1,\n            type: \"triangle\",\n            phase: 90\n        }).connect(this._crossFade.fade);\n        this._feedbackDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            delayTime: options.delayTime,\n            context: this.context,\n        });\n        this.delayTime = this._feedbackDelay.delayTime;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_6__.readOnly)(this, \"delayTime\");\n        this._pitch = options.pitch;\n        this._windowSize = options.windowSize;\n        // connect the two delay lines up\n        this._delayA.connect(this._crossFade.a);\n        this._delayB.connect(this._crossFade.b);\n        // connect the frequency\n        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);\n        // route the input\n        this.effectSend.fan(this._delayA, this._delayB);\n        this._crossFade.chain(this._feedbackDelay, this.effectReturn);\n        // start the LFOs at the same time\n        const now = this.now();\n        this._lfoA.start(now);\n        this._lfoB.start(now);\n        this._crossFadeLFO.start(now);\n        // set the initial value\n        this.windowSize = this._windowSize;\n    }\n    static getDefaults() {\n        return Object.assign(_FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.FeedbackEffect.getDefaults(), {\n            pitch: 0,\n            windowSize: 0.1,\n            delayTime: 0,\n            feedback: 0\n        });\n    }\n    /**\n     * Repitch the incoming signal by some interval (measured in semi-tones).\n     * @example\n     * const pitchShift = new Tone.PitchShift().toDestination();\n     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();\n     * pitchShift.pitch = -12; // down one octave\n     * pitchShift.pitch = 7; // up a fifth\n     */\n    get pitch() {\n        return this._pitch;\n    }\n    set pitch(interval) {\n        this._pitch = interval;\n        let factor = 0;\n        if (interval < 0) {\n            this._lfoA.min = 0;\n            this._lfoA.max = this._windowSize;\n            this._lfoB.min = 0;\n            this._lfoB.max = this._windowSize;\n            factor = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__.intervalToFrequencyRatio)(interval - 1) + 1;\n        }\n        else {\n            this._lfoA.min = this._windowSize;\n            this._lfoA.max = 0;\n            this._lfoB.min = this._windowSize;\n            this._lfoB.max = 0;\n            factor = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__.intervalToFrequencyRatio)(interval) - 1;\n        }\n        this._frequency.value = factor * (1.2 / this._windowSize);\n    }\n    /**\n     * The window size corresponds roughly to the sample length in a looping sampler.\n     * Smaller values are desirable for a less noticeable delay time of the pitch shifted\n     * signal, but larger values will result in smoother pitch shifting for larger intervals.\n     * A nominal range of 0.03 to 0.1 is recommended.\n     */\n    get windowSize() {\n        return this._windowSize;\n    }\n    set windowSize(size) {\n        this._windowSize = this.toSeconds(size);\n        this.pitch = this._pitch;\n    }\n    dispose() {\n        super.dispose();\n        this._frequency.dispose();\n        this._delayA.dispose();\n        this._delayB.dispose();\n        this._lfoA.dispose();\n        this._lfoB.dispose();\n        this._crossFade.dispose();\n        this._crossFadeLFO.dispose();\n        this._feedbackDelay.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PitchShift.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/PitchShift.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Reverb.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Reverb.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Reverb\": () => (/* binding */ Reverb)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Simple convolution created with decaying noise.\n * Generates an Impulse Response Buffer\n * with Tone.Offline then feeds the IR into ConvolverNode.\n * The impulse response generation is async, so you have\n * to wait until [[ready]] resolves before it will make a sound.\n *\n * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).\n * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.\n *\n * @category Effect\n */\nclass Reverb extends _Effect__WEBPACK_IMPORTED_MODULE_4__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Reverb.getDefaults(), arguments, [\"decay\"]));\n        this.name = \"Reverb\";\n        /**\n         * Convolver node\n         */\n        this._convolver = this.context.createConvolver();\n        /**\n         * Resolves when the reverb buffer is generated. Whenever either [[decay]]\n         * or [[preDelay]] are set, you have to wait until [[ready]] resolves\n         * before the IR is generated with the latest values.\n         */\n        this.ready = Promise.resolve();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Reverb.getDefaults(), arguments, [\"decay\"]);\n        this._decay = options.decay;\n        this._preDelay = options.preDelay;\n        this.generate();\n        this.connectEffect(this._convolver);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_4__.Effect.getDefaults(), {\n            decay: 1.5,\n            preDelay: 0.01,\n        });\n    }\n    /**\n     * The duration of the reverb.\n     */\n    get decay() {\n        return this._decay;\n    }\n    set decay(time) {\n        time = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(time, 0.001);\n        this._decay = time;\n        this.generate();\n    }\n    /**\n     * The amount of time before the reverb is fully ramped in.\n     */\n    get preDelay() {\n        return this._preDelay;\n    }\n    set preDelay(time) {\n        time = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(time, 0);\n        this._preDelay = time;\n        this.generate();\n    }\n    /**\n     * Generate the Impulse Response. Returns a promise while the IR is being generated.\n     * @return Promise which returns this object.\n     */\n    generate() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            const previousReady = this.ready;\n            // create a noise burst which decays over the duration in each channel\n            const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_5__.OfflineContext(2, this._decay + this._preDelay, this.context.sampleRate);\n            const noiseL = new _source_Noise__WEBPACK_IMPORTED_MODULE_3__.Noise({ context });\n            const noiseR = new _source_Noise__WEBPACK_IMPORTED_MODULE_3__.Noise({ context });\n            const merge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_0__.Merge({ context });\n            noiseL.connect(merge, 0, 0);\n            noiseR.connect(merge, 0, 1);\n            const gainNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context }).toDestination();\n            merge.connect(gainNode);\n            noiseL.start(0);\n            noiseR.start(0);\n            // predelay\n            gainNode.gain.setValueAtTime(0, 0);\n            gainNode.gain.setValueAtTime(1, this._preDelay);\n            // decay\n            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);\n            // render the buffer\n            const renderPromise = context.render();\n            this.ready = renderPromise.then(_core_util_Interface__WEBPACK_IMPORTED_MODULE_6__.noOp);\n            // wait for the previous `ready` to resolve\n            yield previousReady;\n            // set the buffer\n            this._convolver.buffer = (yield renderPromise).get();\n            return this;\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Reverb.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Reverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoEffect.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoEffect.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoEffect\": () => (/* binding */ StereoEffect)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _component_channel_Split__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Base class for Stereo effects.\n */\nclass StereoEffect extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"StereoEffect\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        // force mono sources to be stereo\n        this.input.channelCount = 2;\n        this.input.channelCountMode = \"explicit\";\n        this._dryWet = this.output = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_1__.CrossFade({\n            context: this.context,\n            fade: options.wet\n        });\n        this.wet = this._dryWet.fade;\n        this._split = new _component_channel_Split__WEBPACK_IMPORTED_MODULE_2__.Split({ context: this.context, channels: 2 });\n        this._merge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_4__.Merge({ context: this.context, channels: 2 });\n        // connections\n        this.input.connect(this._split);\n        // dry wet connections\n        this.input.connect(this._dryWet.a);\n        this._merge.connect(this._dryWet.b);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"wet\"]);\n    }\n    /**\n     * Connect the left part of the effect\n     */\n    connectEffectLeft(...nodes) {\n        this._split.connect(nodes[0], 0, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(...nodes);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(nodes[nodes.length - 1], this._merge, 0, 0);\n    }\n    /**\n     * Connect the right part of the effect\n     */\n    connectEffectRight(...nodes) {\n        this._split.connect(nodes[0], 1, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(...nodes);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(nodes[nodes.length - 1], this._merge, 0, 1);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this._split.dispose();\n        this._merge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/StereoEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoFeedbackEffect\": () => (/* binding */ StereoFeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _component_channel_Split__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n\n\n\n\n\n\n/**\n * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.\n */\nclass StereoFeedbackEffect extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor(options) {\n        super(options);\n        this.feedback = new _signal_Signal__WEBPACK_IMPORTED_MODULE_1__.Signal({\n            context: this.context,\n            value: options.feedback,\n            units: \"normalRange\"\n        });\n        this._feedbackL = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._feedbackR = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._feedbackSplit = new _component_channel_Split__WEBPACK_IMPORTED_MODULE_4__.Split({ context: this.context, channels: 2 });\n        this._feedbackMerge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_5__.Merge({ context: this.context, channels: 2 });\n        this._merge.connect(this._feedbackSplit);\n        this._feedbackMerge.connect(this._split);\n        // the left output connected to the left input\n        this._feedbackSplit.connect(this._feedbackL, 0, 0);\n        this._feedbackL.connect(this._feedbackMerge, 0, 0);\n        // the right output connected to the right input\n        this._feedbackSplit.connect(this._feedbackR, 1, 0);\n        this._feedbackR.connect(this._feedbackMerge, 0, 1);\n        // the feedback control\n        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"feedback\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            feedback: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.feedback.dispose();\n        this._feedbackL.dispose();\n        this._feedbackR.dispose();\n        this._feedbackSplit.dispose();\n        this._feedbackMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoFeedbackEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoWidener.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoWidener.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoWidener\": () => (/* binding */ StereoWidener)\n/* harmony export */ });\n/* harmony import */ var _effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/MidSideEffect */ \"./node_modules/tone/build/esm/effect/MidSideEffect.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n\n\n/**\n * Applies a width factor to the mid/side seperation.\n * 0 is all mid and 1 is all side.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * ```\n * Mid *= 2*(1-width)<br>\n * Side *= 2*width\n * ```\n * @category Effect\n */\nclass StereoWidener extends _effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__.MidSideEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(StereoWidener.getDefaults(), arguments, [\"width\"]));\n        this.name = \"StereoWidener\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(StereoWidener.getDefaults(), arguments, [\"width\"]);\n        this.width = new _signal_Signal__WEBPACK_IMPORTED_MODULE_1__.Signal({\n            context: this.context,\n            value: options.width,\n            units: \"normalRange\",\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"width\"]);\n        this._twoTimesWidthMid = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._twoTimesWidthSide = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._midMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({ context: this.context });\n        this._twoTimesWidthMid.connect(this._midMult.factor);\n        this.connectEffectMid(this._midMult);\n        this._oneMinusWidth = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_3__.Subtract({ context: this.context });\n        this._oneMinusWidth.connect(this._twoTimesWidthMid);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_6__.connect)(this.context.getConstant(1), this._oneMinusWidth);\n        this.width.connect(this._oneMinusWidth.subtrahend);\n        this._sideMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({ context: this.context });\n        this.width.connect(this._twoTimesWidthSide);\n        this._twoTimesWidthSide.connect(this._sideMult.factor);\n        this.connectEffectSide(this._sideMult);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__.MidSideEffect.getDefaults(), {\n            width: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.width.dispose();\n        this._midMult.dispose();\n        this._sideMult.dispose();\n        this._twoTimesWidthMid.dispose();\n        this._twoTimesWidthSide.dispose();\n        this._oneMinusWidth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoWidener.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/StereoWidener.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoXFeedbackEffect\": () => (/* binding */ StereoXFeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n/**\n * Just like a [[StereoFeedbackEffect]], but the feedback is routed from left to right\n * and right to left instead of on the same channel.\n * ```\n * +--------------------------------+ feedbackL <-----------------------------------+\n * |                                                                                |\n * +-->                          +----->        +---->                          +-----+\n *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |\n * +-->                          +----->        +---->                          +---+ |\n * |                                                                                  |\n * +--------------------------------+ feedbackR <-------------------------------------+\n * ```\n */\nclass StereoXFeedbackEffect extends _StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect {\n    constructor(options) {\n        super(options);\n        // the left output connected to the right input\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._feedbackMerge, 0, 1);\n        // the left output connected to the right input\n        this._feedbackR.disconnect();\n        this._feedbackR.connect(this._feedbackMerge, 0, 0);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"feedback\"]);\n    }\n}\n//# sourceMappingURL=StereoXFeedbackEffect.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Tremolo.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Tremolo.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Tremolo\": () => (/* binding */ Tremolo)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Tremolo modulates the amplitude of an incoming signal using an [[LFO]].\n * The effect is a stereo effect where the modulation phase is inverted in each channel.\n *\n * @example\n * // create a tremolo and start it's LFO\n * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();\n * // route an oscillator through the tremolo and start it\n * const oscillator = new Tone.Oscillator().connect(tremolo).start();\n *\n * @category Effect\n */\nclass Tremolo extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Tremolo\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._amplitudeL = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._amplitudeR = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.frequency,\n            units: \"frequency\",\n        });\n        this.depth = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.depth,\n            units: \"normalRange\",\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"frequency\", \"depth\"]);\n        this.connectEffectLeft(this._amplitudeL);\n        this.connectEffectRight(this._amplitudeR);\n        this._lfoL.connect(this._amplitudeL.gain);\n        this._lfoR.connect(this._amplitudeR.gain);\n        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);\n        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            frequency: 10,\n            type: \"sine\",\n            depth: 0.5,\n            spread: 180,\n        });\n    }\n    /**\n     * Start the tremolo.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the tremolo.\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the effect to the transport.\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * The oscillator type.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase; // 180\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._amplitudeL.dispose();\n        this._amplitudeR.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Tremolo.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Tremolo.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Vibrato.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Vibrato.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Vibrato\": () => (/* binding */ Vibrato)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n * modulates the delayTime of the delay, causing the pitch to rise and fall.\n * @category Effect\n */\nclass Vibrato extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Vibrato\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._delayNode = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            context: this.context,\n            delayTime: 0,\n            maxDelay: options.maxDelay,\n        });\n        this._lfo = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 0,\n            max: options.maxDelay,\n            frequency: options.frequency,\n            phase: -90 // offse the phase so the resting position is in the center\n        }).start().connect(this._delayNode.delayTime);\n        this.frequency = this._lfo.frequency;\n        this.depth = this._lfo.amplitude;\n        this.depth.value = options.depth;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"depth\"]);\n        this.effectSend.chain(this._delayNode, this.effectReturn);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            maxDelay: 0.005,\n            frequency: 5,\n            depth: 0.1,\n            type: \"sine\"\n        });\n    }\n    /**\n     * Type of oscillator attached to the Vibrato.\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Vibrato.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/Vibrato.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _AutoFilter__WEBPACK_IMPORTED_MODULE_0__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _AutoPanner__WEBPACK_IMPORTED_MODULE_1__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _AutoWah__WEBPACK_IMPORTED_MODULE_2__.AutoWah),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _BitCrusher__WEBPACK_IMPORTED_MODULE_3__.BitCrusher),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _Chebyshev__WEBPACK_IMPORTED_MODULE_4__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _Chorus__WEBPACK_IMPORTED_MODULE_5__.Chorus),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _Distortion__WEBPACK_IMPORTED_MODULE_6__.Distortion),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _FeedbackDelay__WEBPACK_IMPORTED_MODULE_7__.FeedbackDelay),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _Freeverb__WEBPACK_IMPORTED_MODULE_9__.Freeverb),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _FrequencyShifter__WEBPACK_IMPORTED_MODULE_8__.FrequencyShifter),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _JCReverb__WEBPACK_IMPORTED_MODULE_10__.JCReverb),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _Phaser__WEBPACK_IMPORTED_MODULE_13__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _PingPongDelay__WEBPACK_IMPORTED_MODULE_11__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _PitchShift__WEBPACK_IMPORTED_MODULE_12__.PitchShift),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _Reverb__WEBPACK_IMPORTED_MODULE_14__.Reverb),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _StereoWidener__WEBPACK_IMPORTED_MODULE_15__.StereoWidener),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _Tremolo__WEBPACK_IMPORTED_MODULE_16__.Tremolo),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _Vibrato__WEBPACK_IMPORTED_MODULE_17__.Vibrato)\n/* harmony export */ });\n/* harmony import */ var _AutoFilter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AutoFilter */ \"./node_modules/tone/build/esm/effect/AutoFilter.js\");\n/* harmony import */ var _AutoPanner__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AutoPanner */ \"./node_modules/tone/build/esm/effect/AutoPanner.js\");\n/* harmony import */ var _AutoWah__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AutoWah */ \"./node_modules/tone/build/esm/effect/AutoWah.js\");\n/* harmony import */ var _BitCrusher__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./BitCrusher */ \"./node_modules/tone/build/esm/effect/BitCrusher.js\");\n/* harmony import */ var _Chebyshev__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Chebyshev */ \"./node_modules/tone/build/esm/effect/Chebyshev.js\");\n/* harmony import */ var _Chorus__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Chorus */ \"./node_modules/tone/build/esm/effect/Chorus.js\");\n/* harmony import */ var _Distortion__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Distortion */ \"./node_modules/tone/build/esm/effect/Distortion.js\");\n/* harmony import */ var _FeedbackDelay__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./FeedbackDelay */ \"./node_modules/tone/build/esm/effect/FeedbackDelay.js\");\n/* harmony import */ var _FrequencyShifter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./FrequencyShifter */ \"./node_modules/tone/build/esm/effect/FrequencyShifter.js\");\n/* harmony import */ var _Freeverb__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Freeverb */ \"./node_modules/tone/build/esm/effect/Freeverb.js\");\n/* harmony import */ var _JCReverb__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JCReverb */ \"./node_modules/tone/build/esm/effect/JCReverb.js\");\n/* harmony import */ var _PingPongDelay__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./PingPongDelay */ \"./node_modules/tone/build/esm/effect/PingPongDelay.js\");\n/* harmony import */ var _PitchShift__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./PitchShift */ \"./node_modules/tone/build/esm/effect/PitchShift.js\");\n/* harmony import */ var _Phaser__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Phaser */ \"./node_modules/tone/build/esm/effect/Phaser.js\");\n/* harmony import */ var _Reverb__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Reverb */ \"./node_modules/tone/build/esm/effect/Reverb.js\");\n/* harmony import */ var _StereoWidener__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./StereoWidener */ \"./node_modules/tone/build/esm/effect/StereoWidener.js\");\n/* harmony import */ var _Tremolo__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Tremolo */ \"./node_modules/tone/build/esm/effect/Tremolo.js\");\n/* harmony import */ var _Vibrato__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Vibrato */ \"./node_modules/tone/build/esm/effect/Vibrato.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/effect/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Loop.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Loop.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Loop\": () => (/* binding */ Loop)\n/* harmony export */ });\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n/* harmony import */ var _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Loop creates a looped callback at the\n * specified interval. The callback can be\n * started, stopped and scheduled along\n * the Transport's timeline.\n * @example\n * const loop = new Tone.Loop((time) => {\n * \t// triggered every eighth note.\n * \tconsole.log(time);\n * }, \"8n\").start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Loop extends _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]));\n        this.name = \"Loop\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]);\n        this._event = new _ToneEvent__WEBPACK_IMPORTED_MODULE_0__.ToneEvent({\n            context: this.context,\n            callback: this._tick.bind(this),\n            loop: true,\n            loopEnd: options.interval,\n            playbackRate: options.playbackRate,\n            probability: options.probability\n        });\n        this.callback = options.callback;\n        // set the iterations\n        this.iterations = options.iterations;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext.getDefaults(), {\n            interval: \"4n\",\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n            playbackRate: 1,\n            iterations: Infinity,\n            probability: 1,\n            mute: false,\n            humanize: false\n        });\n    }\n    /**\n     * Start the loop at the specified time along the Transport's timeline.\n     * @param  time  When to start the Loop.\n     */\n    start(time) {\n        this._event.start(time);\n        return this;\n    }\n    /**\n     * Stop the loop at the given time.\n     * @param  time  When to stop the Loop.\n     */\n    stop(time) {\n        this._event.stop(time);\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        this._event.cancel(time);\n        return this;\n    }\n    /**\n     * Internal function called when the notes should be called\n     * @param time  The time the event occurs\n     */\n    _tick(time) {\n        this.callback(time);\n    }\n    /**\n     * The state of the Loop, either started or stopped.\n     */\n    get state() {\n        return this._event.state;\n    }\n    /**\n     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.\n     */\n    get progress() {\n        return this._event.progress;\n    }\n    /**\n     * The time between successive callbacks.\n     * @example\n     * const loop = new Tone.Loop();\n     * loop.interval = \"8n\"; // loop every 8n\n     */\n    get interval() {\n        return this._event.loopEnd;\n    }\n    set interval(interval) {\n        this._event.loopEnd = interval;\n    }\n    /**\n     * The playback rate of the loop. The normal playback rate is 1 (no change).\n     * A `playbackRate` of 2 would be twice as fast.\n     */\n    get playbackRate() {\n        return this._event.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._event.playbackRate = rate;\n    }\n    /**\n     * Random variation +/-0.01s to the scheduled time.\n     * Or give it a time value which it will randomize by.\n     */\n    get humanize() {\n        return this._event.humanize;\n    }\n    set humanize(variation) {\n        this._event.humanize = variation;\n    }\n    /**\n     * The probably of the callback being invoked.\n     */\n    get probability() {\n        return this._event.probability;\n    }\n    set probability(prob) {\n        this._event.probability = prob;\n    }\n    /**\n     * Muting the Loop means that no callbacks are invoked.\n     */\n    get mute() {\n        return this._event.mute;\n    }\n    set mute(mute) {\n        this._event.mute = mute;\n    }\n    /**\n     * The number of iterations of the loop. The default value is `Infinity` (loop forever).\n     */\n    get iterations() {\n        if (this._event.loop === true) {\n            return Infinity;\n        }\n        else {\n            return this._event.loop;\n        }\n    }\n    set iterations(iters) {\n        if (iters === Infinity) {\n            this._event.loop = true;\n        }\n        else {\n            this._event.loop = iters;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._event.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Loop.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/Loop.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Part.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Part.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Part\": () => (/* binding */ Part)\n/* harmony export */ });\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n\n/**\n * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.\n *\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const part = new Tone.Part(((time, note) => {\n * \t// the notes given as the second element in the array\n * \t// will be passed in as the second argument\n * \tsynth.triggerAttackRelease(note, \"8n\", time);\n * }), [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]);\n * Tone.Transport.start();\n * @example\n * const synth = new Tone.Synth().toDestination();\n * // use an array of objects as long as the object has a \"time\" attribute\n * const part = new Tone.Part(((time, value) => {\n * \t// the value is an object which contains both the note and the velocity\n * \tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n * }), [{ time: 0, note: \"C3\", velocity: 0.9 },\n * \t{ time: \"0:2\", note: \"C4\", velocity: 0.5 }\n * ]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Part extends _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Part.getDefaults(), arguments, [\"callback\", \"events\"]));\n        this.name = \"Part\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__.StateTimeline(\"stopped\");\n        /**\n         * The events that belong to this part\n         */\n        this._events = new Set();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Part.getDefaults(), arguments, [\"callback\", \"events\"]);\n        // make sure things are assigned in the right order\n        this._state.increasing = true;\n        // add the events\n        options.events.forEach(event => {\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isArray)(event)) {\n                this.add(event[0], event[1]);\n            }\n            else {\n                this.add(event);\n            }\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent.getDefaults(), {\n            events: [],\n        });\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset from the start of the part to begin playing at.\n     */\n    start(time, offset) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) !== \"started\") {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, this._loop ? this._loopStart : 0);\n            if (this._loop) {\n                offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, this._loopStart);\n            }\n            else {\n                offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, 0);\n            }\n            const computedOffset = this.toTicks(offset);\n            this._state.add({\n                id: -1,\n                offset: computedOffset,\n                state: \"started\",\n                time: ticks,\n            });\n            this._forEach(event => {\n                this._startNote(event, ticks, computedOffset);\n            });\n        }\n        return this;\n    }\n    /**\n     * Start the event in the given event at the correct time given\n     * the ticks and offset and looping.\n     * @param  event\n     * @param  ticks\n     * @param  offset\n     */\n    _startNote(event, ticks, offset) {\n        ticks -= offset;\n        if (this._loop) {\n            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {\n                if (event.startOffset < offset) {\n                    // start it on the next loop\n                    ticks += this._getLoopDuration();\n                }\n                event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n            }\n            else if (event.startOffset < this._loopStart && event.startOffset >= offset) {\n                event.loop = false;\n                event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n            }\n        }\n        else if (event.startOffset >= offset) {\n            event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n        }\n    }\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n        this._forEach(event => {\n            event.startOffset += this._startOffset;\n        });\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        const ticks = this.toTicks(time);\n        this._state.cancel(ticks);\n        this._state.setStateAtTime(\"stopped\", ticks);\n        this._forEach(event => {\n            event.stop(time);\n        });\n        return this;\n    }\n    /**\n     * Get/Set an Event's value at the given time.\n     * If a value is passed in and no event exists at\n     * the given time, one will be created with that value.\n     * If two events are at the same time, the first one will\n     * be returned.\n     * @example\n     * const part = new Tone.Part();\n     * part.at(\"1m\"); // returns the part at the first measure\n     * part.at(\"2m\", \"C2\"); // set the value at \"2m\" to C2.\n     * // if an event didn't exist at that time, it will be created.\n     * @param time The time of the event to get or set.\n     * @param value If a value is passed in, the value of the event at the given time will be set to it.\n     */\n    at(time, value) {\n        const timeInTicks = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass(this.context, time).toTicks();\n        const tickTime = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, 1).toSeconds();\n        const iterator = this._events.values();\n        let result = iterator.next();\n        while (!result.done) {\n            const event = result.value;\n            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value)) {\n                    event.value = value;\n                }\n                return event;\n            }\n            result = iterator.next();\n        }\n        // if there was no event at that time, create one\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value)) {\n            this.add(time, value);\n            // return the new event\n            return this.at(time);\n        }\n        else {\n            return null;\n        }\n    }\n    add(time, value) {\n        // extract the parameters\n        if (time instanceof Object && Reflect.has(time, \"time\")) {\n            value = time;\n            time = value.time;\n        }\n        const ticks = this.toTicks(time);\n        let event;\n        if (value instanceof _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent) {\n            event = value;\n            event.callback = this._tick.bind(this);\n        }\n        else {\n            event = new _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent({\n                callback: this._tick.bind(this),\n                context: this.context,\n                value,\n            });\n        }\n        // the start offset\n        event.startOffset = ticks;\n        // initialize the values\n        event.set({\n            humanize: this.humanize,\n            loop: this.loop,\n            loopEnd: this.loopEnd,\n            loopStart: this.loopStart,\n            playbackRate: this.playbackRate,\n            probability: this.probability,\n        });\n        this._events.add(event);\n        // start the note if it should be played right now\n        this._restartEvent(event);\n        return this;\n    }\n    /**\n     * Restart the given event\n     */\n    _restartEvent(event) {\n        this._state.forEach((stateEvent) => {\n            if (stateEvent.state === \"started\") {\n                this._startNote(event, stateEvent.time, stateEvent.offset);\n            }\n            else {\n                // stop the note\n                event.stop(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, stateEvent.time));\n            }\n        });\n    }\n    remove(time, value) {\n        // extract the parameters\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isObject)(time) && time.hasOwnProperty(\"time\")) {\n            value = time;\n            time = value.time;\n        }\n        time = this.toTicks(time);\n        this._events.forEach(event => {\n            if (event.startOffset === time) {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isUndef)(value) || ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value) && event.value === value)) {\n                    this._events.delete(event);\n                    event.dispose();\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Remove all of the notes from the group.\n     */\n    clear() {\n        this._forEach(event => event.dispose());\n        this._events.clear();\n        return this;\n    }\n    /**\n     * Cancel scheduled state change events: i.e. \"start\" and \"stop\".\n     * @param after The time after which to cancel the scheduled events.\n     */\n    cancel(after) {\n        this._forEach(event => event.cancel(after));\n        this._state.cancel(this.toTicks(after));\n        return this;\n    }\n    /**\n     * Iterate over all of the events\n     */\n    _forEach(callback) {\n        if (this._events) {\n            this._events.forEach(event => {\n                if (event instanceof Part) {\n                    event._forEach(callback);\n                }\n                else {\n                    callback(event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Set the attribute of all of the events\n     * @param  attr  the attribute to set\n     * @param  value      The value to set it to\n     */\n    _setAll(attr, value) {\n        this._forEach(event => {\n            event[attr] = value;\n        });\n    }\n    /**\n     * Internal tick method\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time, value) {\n        if (!this.mute) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * Determine if the event should be currently looping\n     * given the loop boundries of this Part.\n     * @param  event  The event to test\n     */\n    _testLoopBoundries(event) {\n        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) {\n            event.cancel(0);\n        }\n        else if (event.state === \"stopped\") {\n            // reschedule it if it's stopped\n            this._restartEvent(event);\n        }\n    }\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n        this._setAll(\"probability\", prob);\n    }\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n        this._setAll(\"humanize\", variation);\n    }\n    /**\n     * If the part should loop or not\n     * between Part.loopStart and\n     * Part.loopEnd. If set to true,\n     * the part will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     * @example\n     * const part = new Tone.Part();\n     * // loop the part 8 times\n     * part.loop = 8;\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._forEach(event => {\n            event.loopStart = this.loopStart;\n            event.loopEnd = this.loopEnd;\n            event.loop = loop;\n            this._testLoopBoundries(event);\n        });\n    }\n    /**\n     * The loopEnd point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopEnd() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopEnd = loopEnd;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The loopStart point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopStart() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopStart = this.loopStart;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The playback rate of the part\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._setAll(\"playbackRate\", rate);\n    }\n    /**\n     * The number of scheduled notes in the part.\n     */\n    get length() {\n        return this._events.size;\n    }\n    dispose() {\n        super.dispose();\n        this.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=Part.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/Part.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Pattern.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Pattern.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Pattern\": () => (/* binding */ Pattern)\n/* harmony export */ });\n/* harmony import */ var _Loop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Loop */ \"./node_modules/tone/build/esm/event/Loop.js\");\n/* harmony import */ var _PatternGenerator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./PatternGenerator */ \"./node_modules/tone/build/esm/event/PatternGenerator.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Pattern arpeggiates between the given notes\n * in a number of patterns.\n * @example\n * const pattern = new Tone.Pattern((time, note) => {\n * \t// the order of the notes passed in depends on the pattern\n * }, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n * @category Event\n */\nclass Pattern extends _Loop__WEBPACK_IMPORTED_MODULE_0__.Loop {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]));\n        this.name = \"Pattern\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]);\n        this.callback = options.callback;\n        this._values = options.values;\n        this._pattern = (0,_PatternGenerator__WEBPACK_IMPORTED_MODULE_1__.PatternGenerator)(options.values, options.pattern);\n        this._type = options.pattern;\n    }\n    static getDefaults() {\n        return Object.assign(_Loop__WEBPACK_IMPORTED_MODULE_0__.Loop.getDefaults(), {\n            pattern: \"up\",\n            values: [],\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n        });\n    }\n    /**\n     * Internal function called when the notes should be called\n     */\n    _tick(time) {\n        const value = this._pattern.next();\n        this._value = value.value;\n        this.callback(time, this._value);\n    }\n    /**\n     * The array of events.\n     */\n    get values() {\n        return this._values;\n    }\n    set values(val) {\n        this._values = val;\n        // reset the pattern\n        this.pattern = this._type;\n    }\n    /**\n     * The current value of the pattern.\n     */\n    get value() {\n        return this._value;\n    }\n    /**\n     * The pattern type. See Tone.CtrlPattern for the full list of patterns.\n     */\n    get pattern() {\n        return this._type;\n    }\n    set pattern(pattern) {\n        this._type = pattern;\n        this._pattern = (0,_PatternGenerator__WEBPACK_IMPORTED_MODULE_1__.PatternGenerator)(this._values, this._type);\n    }\n}\n//# sourceMappingURL=Pattern.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/Pattern.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/PatternGenerator.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/event/PatternGenerator.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PatternGenerator\": () => (/* binding */ PatternGenerator)\n/* harmony export */ });\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n/**\n * Start at the first value and go up to the last\n */\nfunction* upPatternGen(values) {\n    let index = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index++;\n    }\n}\n/**\n * Start at the last value and go down to 0\n */\nfunction* downPatternGen(values) {\n    let index = values.length - 1;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index--;\n    }\n}\n/**\n * Infinitely yield the generator\n */\nfunction* infiniteGen(values, gen) {\n    while (true) {\n        yield* gen(values);\n    }\n}\n/**\n * Make sure that the index is in the given range\n */\nfunction clampToArraySize(index, values) {\n    return (0,_core_util_Math__WEBPACK_IMPORTED_MODULE_1__.clamp)(index, 0, values.length - 1);\n}\n/**\n * Alternate between two generators\n */\nfunction* alternatingGenerator(values, directionUp) {\n    let index = directionUp ? 0 : values.length - 1;\n    while (true) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        if (directionUp) {\n            index++;\n            if (index >= values.length - 1) {\n                directionUp = false;\n            }\n        }\n        else {\n            index--;\n            if (index <= 0) {\n                directionUp = true;\n            }\n        }\n    }\n}\n/**\n * Starting from the bottom move up 2, down 1\n */\nfunction* jumpUp(values) {\n    let index = 0;\n    let stepIndex = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? 2 : -1);\n    }\n}\n/**\n * Starting from the top move down 2, up 1\n */\nfunction* jumpDown(values) {\n    let index = values.length - 1;\n    let stepIndex = 0;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? -2 : 1);\n    }\n}\n/**\n * Choose a random index each time\n */\nfunction* randomGen(values) {\n    while (true) {\n        const randomIndex = Math.floor(Math.random() * values.length);\n        yield values[randomIndex];\n    }\n}\n/**\n * Randomly go through all of the values once before choosing a new random order\n */\nfunction* randomOnce(values) {\n    // create an array of indices\n    const copy = [];\n    for (let i = 0; i < values.length; i++) {\n        copy.push(i);\n    }\n    while (copy.length > 0) {\n        // random choose an index, and then remove it so it's not chosen again\n        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);\n        const index = clampToArraySize(randVal[0], values);\n        yield values[index];\n    }\n}\n/**\n * Randomly choose to walk up or down 1 index in the values array\n */\nfunction* randomWalk(values) {\n    // randomly choose a starting index in the values array\n    let index = Math.floor(Math.random() * values.length);\n    while (true) {\n        if (index === 0) {\n            index++; // at bottom of array, so force upward step\n        }\n        else if (index === values.length - 1) {\n            index--; // at top of array, so force downward step\n        }\n        else if (Math.random() < 0.5) { // else choose random downward or upward step\n            index--;\n        }\n        else {\n            index++;\n        }\n        yield values[index];\n    }\n}\n/**\n * PatternGenerator returns a generator which will iterate over the given array\n * of values and yield the items according to the passed in pattern\n * @param values An array of values to iterate over\n * @param pattern The name of the pattern use when iterating over\n * @param index Where to start in the offset of the values array\n */\nfunction* PatternGenerator(values, pattern = \"up\", index = 0) {\n    // safeguards\n    (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_0__.assert)(values.length > 0, \"The array must have more than one value in it\");\n    switch (pattern) {\n        case \"up\":\n            yield* infiniteGen(values, upPatternGen);\n        case \"down\":\n            yield* infiniteGen(values, downPatternGen);\n        case \"upDown\":\n            yield* alternatingGenerator(values, true);\n        case \"downUp\":\n            yield* alternatingGenerator(values, false);\n        case \"alternateUp\":\n            yield* infiniteGen(values, jumpUp);\n        case \"alternateDown\":\n            yield* infiniteGen(values, jumpDown);\n        case \"random\":\n            yield* randomGen(values);\n        case \"randomOnce\":\n            yield* infiniteGen(values, randomOnce);\n        case \"randomWalk\":\n            yield* randomWalk(values);\n    }\n}\n//# sourceMappingURL=PatternGenerator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/PatternGenerator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Sequence.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Sequence.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Sequence\": () => (/* binding */ Sequence)\n/* harmony export */ });\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Part__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Part */ \"./node_modules/tone/build/esm/event/Part.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n/**\n * A sequence is an alternate notation of a part. Instead\n * of passing in an array of [time, event] pairs, pass\n * in an array of events which will be spaced at the\n * given subdivision. Sub-arrays will subdivide that beat\n * by the number of items are in the array.\n * Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const seq = new Tone.Sequence((time, note) => {\n * \tsynth.triggerAttackRelease(note, 0.1, time);\n * \t// subdivisions are given as subarrays\n * }, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Sequence extends _ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]));\n        this.name = \"Sequence\";\n        /**\n         * The object responsible for scheduling all of the events\n         */\n        this._part = new _Part__WEBPACK_IMPORTED_MODULE_3__.Part({\n            callback: this._seqCallback.bind(this),\n            context: this.context,\n        });\n        /**\n         * private reference to all of the sequence proxies\n         */\n        this._events = [];\n        /**\n         * The proxied array\n         */\n        this._eventsArray = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]);\n        this._subdivision = this.toTicks(options.subdivision);\n        this.events = options.events;\n        // set all of the values\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.playbackRate = options.playbackRate;\n        this.probability = options.probability;\n        this.humanize = options.humanize;\n        this.mute = options.mute;\n        this.playbackRate = options.playbackRate;\n    }\n    static getDefaults() {\n        return Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent.getDefaults(), [\"value\"]), {\n            events: [],\n            loop: true,\n            loopEnd: 0,\n            loopStart: 0,\n            subdivision: \"8n\",\n        });\n    }\n    /**\n     * The internal callback for when an event is invoked\n     */\n    _seqCallback(time, value) {\n        if (value !== null) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * The sequence\n     */\n    get events() {\n        return this._events;\n    }\n    set events(s) {\n        this.clear();\n        this._eventsArray = s;\n        this._events = this._createSequence(this._eventsArray);\n        this._eventsUpdated();\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset index to start at\n     */\n    start(time, offset) {\n        this._part.start(time, offset ? this._indexTime(offset) : offset);\n        return this;\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        this._part.stop(time);\n        return this;\n    }\n    /**\n     * The subdivision of the sequence. This can only be\n     * set in the constructor. The subdivision is the\n     * interval between successive steps.\n     */\n    get subdivision() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._subdivision).toSeconds();\n    }\n    /**\n     * Create a sequence proxy which can be monitored to create subsequences\n     */\n    _createSequence(array) {\n        return new Proxy(array, {\n            get: (target, property) => {\n                // property is index in this case\n                return target[property];\n            },\n            set: (target, property, value) => {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(property) && isFinite(parseInt(property, 10))) {\n                    if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(value)) {\n                        target[property] = this._createSequence(value);\n                    }\n                    else {\n                        target[property] = value;\n                    }\n                }\n                else {\n                    target[property] = value;\n                }\n                this._eventsUpdated();\n                // return true to accept the changes\n                return true;\n            },\n        });\n    }\n    /**\n     * When the sequence has changed, all of the events need to be recreated\n     */\n    _eventsUpdated() {\n        this._part.clear();\n        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);\n        // update the loopEnd\n        this.loopEnd = this.loopEnd;\n    }\n    /**\n     * reschedule all of the events that need to be rescheduled\n     */\n    _rescheduleSequence(sequence, subdivision, startOffset) {\n        sequence.forEach((value, index) => {\n            const eventOffset = index * (subdivision) + startOffset;\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(value)) {\n                this._rescheduleSequence(value, subdivision / value.length, eventOffset);\n            }\n            else {\n                const startTime = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, eventOffset, \"i\").toSeconds();\n                this._part.add(startTime, value);\n            }\n        });\n    }\n    /**\n     * Get the time of the index given the Sequence's subdivision\n     * @param  index\n     * @return The time of that index\n     */\n    _indexTime(index) {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, index * (this._subdivision) + this.startOffset).toSeconds();\n    }\n    /**\n     * Clear all of the events\n     */\n    clear() {\n        this._part.clear();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._part.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // PROXY CALLS\n    //-------------------------------------\n    get loop() {\n        return this._part.loop;\n    }\n    set loop(l) {\n        this._part.loop = l;\n    }\n    /**\n     * The index at which the sequence should start looping\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(index) {\n        this._loopStart = index;\n        this._part.loopStart = this._indexTime(index);\n    }\n    /**\n     * The index at which the sequence should end looping\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(index) {\n        this._loopEnd = index;\n        if (index === 0) {\n            this._part.loopEnd = this._indexTime(this._eventsArray.length);\n        }\n        else {\n            this._part.loopEnd = this._indexTime(index);\n        }\n    }\n    get startOffset() {\n        return this._part.startOffset;\n    }\n    set startOffset(start) {\n        this._part.startOffset = start;\n    }\n    get playbackRate() {\n        return this._part.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._part.playbackRate = rate;\n    }\n    get probability() {\n        return this._part.probability;\n    }\n    set probability(prob) {\n        this._part.probability = prob;\n    }\n    get progress() {\n        return this._part.progress;\n    }\n    get humanize() {\n        return this._part.humanize;\n    }\n    set humanize(variation) {\n        this._part.humanize = variation;\n    }\n    /**\n     * The number of scheduled events\n     */\n    get length() {\n        return this._part.length;\n    }\n}\n//# sourceMappingURL=Sequence.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/Sequence.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/ToneEvent.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/event/ToneEvent.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneEvent\": () => (/* binding */ ToneEvent)\n/* harmony export */ });\n/* harmony import */ var _core_clock_Transport__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/clock/Transport */ \"./node_modules/tone/build/esm/core/clock/Transport.js\");\n/* harmony import */ var _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable\n * callback for a single or repeatable events along the timeline.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * const chordEvent = new Tone.ToneEvent(((time, chord) => {\n * \t// the chord as well as the exact time of the event\n * \t// are passed in as arguments to the callback function\n * \tsynth.triggerAttackRelease(chord, 0.5, time);\n * }), [\"D4\", \"E4\", \"F4\"]);\n * // start the chord at the beginning of the transport timeline\n * chordEvent.start();\n * // loop it every measure for 8 measures\n * chordEvent.loop = 8;\n * chordEvent.loopEnd = \"1m\";\n * @category Event\n */\nclass ToneEvent extends _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]));\n        this.name = \"ToneEvent\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_5__.StateTimeline(\"stopped\");\n        /**\n         * A delay time from when the event is scheduled to start\n         */\n        this._startOffset = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]);\n        this._loop = options.loop;\n        this.callback = options.callback;\n        this.value = options.value;\n        this._loopStart = this.toTicks(options.loopStart);\n        this._loopEnd = this.toTicks(options.loopEnd);\n        this._playbackRate = options.playbackRate;\n        this._probability = options.probability;\n        this._humanize = options.humanize;\n        this.mute = options.mute;\n        this._playbackRate = options.playbackRate;\n        this._state.increasing = true;\n        // schedule the events for the first time\n        this._rescheduleEvents();\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext.getDefaults(), {\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            humanize: false,\n            loop: false,\n            loopEnd: \"1m\",\n            loopStart: 0,\n            mute: false,\n            playbackRate: 1,\n            probability: 1,\n            value: null,\n        });\n    }\n    /**\n     * Reschedule all of the events along the timeline\n     * with the updated values.\n     * @param after Only reschedules events after the given time.\n     */\n    _rescheduleEvents(after = -1) {\n        // if no argument is given, schedules all of the events\n        this._state.forEachFrom(after, event => {\n            let duration;\n            if (event.state === \"started\") {\n                if (event.id !== -1) {\n                    this.context.transport.clear(event.id);\n                }\n                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);\n                if (this._loop === true || (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(this._loop) && this._loop > 1) {\n                    duration = Infinity;\n                    if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(this._loop)) {\n                        duration = (this._loop) * this._getLoopDuration();\n                    }\n                    const nextEvent = this._state.getAfter(startTick);\n                    if (nextEvent !== null) {\n                        duration = Math.min(duration, nextEvent.time - startTick);\n                    }\n                    if (duration !== Infinity) {\n                        // schedule a stop since it's finite duration\n                        this._state.setStateAtTime(\"stopped\", startTick + duration + 1, { id: -1 });\n                        duration = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, duration);\n                    }\n                    const interval = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._getLoopDuration());\n                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, startTick), duration);\n                }\n                else {\n                    event.id = this.context.transport.schedule(this._tick.bind(this), new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, startTick));\n                }\n            }\n        });\n    }\n    /**\n     * Returns the playback state of the note, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.context.transport.ticks);\n    }\n    /**\n     * The start from the scheduled start time.\n     */\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n    }\n    /**\n     * The probability of the notes being triggered.\n     */\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n    }\n    /**\n     * If set to true, will apply small random variation\n     * to the callback time. If the value is given as a time, it will randomize\n     * by that amount.\n     * @example\n     * const event = new Tone.ToneEvent();\n     * event.humanize = true;\n     */\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n    }\n    /**\n     * Start the note at the given time.\n     * @param  time  When the event should start.\n     */\n    start(time) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"stopped\") {\n            this._state.add({\n                id: -1,\n                state: \"started\",\n                time: ticks,\n            });\n            this._rescheduleEvents(ticks);\n        }\n        return this;\n    }\n    /**\n     * Stop the Event at the given time.\n     * @param  time  When the event should stop.\n     */\n    stop(time) {\n        this.cancel(time);\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"started\") {\n            this._state.setStateAtTime(\"stopped\", ticks, { id: -1 });\n            const previousEvent = this._state.getBefore(ticks);\n            let reschedulTime = ticks;\n            if (previousEvent !== null) {\n                reschedulTime = previousEvent.time;\n            }\n            this._rescheduleEvents(reschedulTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        time = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(time, -Infinity);\n        const ticks = this.toTicks(time);\n        this._state.forEachFrom(ticks, event => {\n            this.context.transport.clear(event.id);\n        });\n        this._state.cancel(ticks);\n        return this;\n    }\n    /**\n     * The callback function invoker. Also\n     * checks if the Event is done playing\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time) {\n        const ticks = this.context.transport.getTicksAtTime(time);\n        if (!this.mute && this._state.getValueAtTime(ticks) === \"started\") {\n            if (this.probability < 1 && Math.random() > this.probability) {\n                return;\n            }\n            if (this.humanize) {\n                let variation = 0.02;\n                if (!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isBoolean)(this.humanize)) {\n                    variation = this.toSeconds(this.humanize);\n                }\n                time += (Math.random() * 2 - 1) * variation;\n            }\n            this.callback(time, this.value);\n        }\n    }\n    /**\n     * Get the duration of the loop.\n     */\n    _getLoopDuration() {\n        return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);\n    }\n    /**\n     * If the note should loop or not\n     * between ToneEvent.loopStart and\n     * ToneEvent.loopEnd. If set to true,\n     * the event will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._rescheduleEvents();\n    }\n    /**\n     * The playback rate of the note. Defaults to 1.\n     * @example\n     * const note = new Tone.ToneEvent();\n     * note.loop = true;\n     * // repeat the note twice as fast\n     * note.playbackRate = 2;\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._rescheduleEvents();\n    }\n    /**\n     * The loopEnd point is the time the event will loop\n     * if ToneEvent.loop is true.\n     */\n    get loopEnd() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The time when the loop should start.\n     */\n    get loopStart() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The current progress of the loop interval.\n     * Returns 0 if the event is not started yet or\n     * it is not set to loop.\n     */\n    get progress() {\n        if (this._loop) {\n            const ticks = this.context.transport.ticks;\n            const lastEvent = this._state.get(ticks);\n            if (lastEvent !== null && lastEvent.state === \"started\") {\n                const loopDuration = this._getLoopDuration();\n                const progress = (ticks - lastEvent.time) % loopDuration;\n                return progress / loopDuration;\n            }\n            else {\n                return 0;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this.cancel();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneEvent.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/ToneEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/index.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/event/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _Loop__WEBPACK_IMPORTED_MODULE_0__.Loop),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _Part__WEBPACK_IMPORTED_MODULE_1__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _Pattern__WEBPACK_IMPORTED_MODULE_2__.Pattern),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _Sequence__WEBPACK_IMPORTED_MODULE_3__.Sequence),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent)\n/* harmony export */ });\n/* harmony import */ var _Loop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Loop */ \"./node_modules/tone/build/esm/event/Loop.js\");\n/* harmony import */ var _Part__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Part */ \"./node_modules/tone/build/esm/event/Part.js\");\n/* harmony import */ var _Pattern__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Pattern */ \"./node_modules/tone/build/esm/event/Pattern.js\");\n/* harmony import */ var _Sequence__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Sequence */ \"./node_modules/tone/build/esm/event/Sequence.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/event/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/index.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/build/esm/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AMOscillator),\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AMSynth),\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Add),\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Analyser),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AudioToGain),\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoWah),\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BaseContext),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BiquadFilter),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BitCrusher),\n/* harmony export */   \"Buffer\": () => (/* binding */ Buffer),\n/* harmony export */   \"BufferSource\": () => (/* binding */ BufferSource),\n/* harmony export */   \"Buffers\": () => (/* binding */ Buffers),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Channel),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Chorus),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Clock),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Compressor),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Context),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.DCMeter),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Delay),\n/* harmony export */   \"Destination\": () => (/* binding */ Destination),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Distortion),\n/* harmony export */   \"Draw\": () => (/* binding */ Draw),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.DuoSynth),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.EQ3),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Emitter),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FFT),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FMOscillator),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FMSynth),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FatOscillator),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FeedbackCombFilter),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FeedbackDelay),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Follower),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Freeverb),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyClass),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyEnvelope),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyShifter),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Gain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GainToAudio),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Gate),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GrainPlayer),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GreaterThanZero),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.IntervalTimeline),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.JCReverb),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.LFO),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Limiter),\n/* harmony export */   \"Listener\": () => (/* binding */ Listener),\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Loop),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.LowpassCombFilter),\n/* harmony export */   \"Master\": () => (/* binding */ Master),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MembraneSynth),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Merge),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MetalSynth),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideSplit),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidiClass),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Mono),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MonoSynth),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MultibandSplit),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Negate),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Noise),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.NoiseSynth),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OfflineContext),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OmniOscillator),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OnePoleFilter),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PWMOscillator),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Panner3D),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Param),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Pattern),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PitchShift),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Players),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PolySynth),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Pow),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PulseOscillator),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Recorder),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Reverb),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Sampler),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ScaleExp),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Sequence),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Signal),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Split),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.StateTimeline),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.StereoWidener),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.SyncedSignal),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Synth),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneBufferSource),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneEvent),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneOscillatorNode),\n/* harmony export */   \"Transport\": () => (/* binding */ Transport),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Tremolo),\n/* harmony export */   \"Unit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Unit),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.UserMedia),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Vibrato),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Volume),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.WaveShaper),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Waveform),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Zero),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connectSeries),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connectSignal),\n/* harmony export */   \"context\": () => (/* binding */ context),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.debug),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.gainToDb),\n/* harmony export */   \"getContext\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext),\n/* harmony export */   \"getDestination\": () => (/* binding */ getDestination),\n/* harmony export */   \"getDraw\": () => (/* binding */ getDraw),\n/* harmony export */   \"getListener\": () => (/* binding */ getListener),\n/* harmony export */   \"getTransport\": () => (/* binding */ getTransport),\n/* harmony export */   \"immediate\": () => (/* binding */ immediate),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isUndef),\n/* harmony export */   \"loaded\": () => (/* binding */ loaded),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.mtof),\n/* harmony export */   \"now\": () => (/* binding */ now),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments),\n/* harmony export */   \"setContext\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.setContext),\n/* harmony export */   \"start\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.start),\n/* harmony export */   \"supported\": () => (/* reexport safe */ _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_4__.supported),\n/* harmony export */   \"version\": () => (/* reexport safe */ _version__WEBPACK_IMPORTED_MODULE_2__.version)\n/* harmony export */ });\n/* harmony import */ var _core_Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core/Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./classes */ \"./node_modules/tone/build/esm/classes.js\");\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./core/context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./source/buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n\n\n\n\n\n\n\n/**\n * The current audio context time of the global [[Context]].\n * See [[Context.now]]\n * @category Core\n */\nfunction now() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().now();\n}\n/**\n * The current audio context time of the global [[Context]] without the [[Context.lookAhead]]\n * See [[Context.immediate]]\n * @category Core\n */\nfunction immediate() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().immediate();\n}\n/**\n * The Transport object belonging to the global Tone.js Context.\n * See [[Transport]]\n * @category Core\n */\nconst Transport = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().transport;\n/**\n * The Transport object belonging to the global Tone.js Context.\n * See [[Transport]]\n * @category Core\n */\nfunction getTransport() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().transport;\n}\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * See [[Destination]]\n * @category Core\n */\nconst Destination = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n/**\n * @deprecated Use [[Destination]]\n */\nconst Master = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * See [[Destination]]\n * @category Core\n */\nfunction getDestination() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n}\n/**\n * The [[Listener]] belonging to the global Tone.js Context.\n * @category Core\n */\nconst Listener = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().listener;\n/**\n * The [[Listener]] belonging to the global Tone.js Context.\n * @category Core\n */\nfunction getListener() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().listener;\n}\n/**\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * See [[Draw]]\n * @category Core\n */\nconst Draw = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().draw;\n/**\n * Get the singleton attached to the global context.\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * See [[Draw]]\n * @category Core\n */\nfunction getDraw() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().draw;\n}\n/**\n * A reference to the global context\n * See [[Context]]\n */\nconst context = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n/**\n * Promise which resolves when all of the loading promises are resolved.\n * Alias for static [[ToneAudioBuffer.loaded]] method.\n * @category Core\n */\nfunction loaded() {\n    return _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer.loaded();\n}\n// this fills in name changes from 13.x to 14.x\n\n\nconst Buffer = _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer;\nconst Buffers = _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_5__.ToneAudioBuffers;\nconst BufferSource = _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_6__.ToneBufferSource;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/AMSynth.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/AMSynth.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMSynth\": () => (/* binding */ AMSynth)\n/* harmony export */ });\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ModulationSynth */ \"./node_modules/tone/build/esm/instrument/ModulationSynth.js\");\n\n\n\n/**\n * AMSynth uses the output of one Tone.Synth to modulate the\n * amplitude of another Tone.Synth. The harmonicity (the ratio between\n * the two signals) affects the timbre of the output signal greatly.\n * Read more about Amplitude Modulation Synthesis on\n * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n *\n * @example\n * const synth = new Tone.AMSynth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"4n\");\n *\n * @category Instrument\n */\nclass AMSynth extends _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMSynth.getDefaults(), arguments));\n        this.name = \"AMSynth\";\n        this._modulationScale = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_0__.AudioToGain({\n            context: this.context,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n    }\n    dispose() {\n        super.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/AMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/DuoSynth.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/DuoSynth.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DuoSynth\": () => (/* binding */ DuoSynth)\n/* harmony export */ });\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _MonoSynth__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MonoSynth */ \"./node_modules/tone/build/esm/instrument/MonoSynth.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n\n/**\n * DuoSynth is a monophonic synth composed of two [[MonoSynths]] run in parallel with control over the\n * frequency ratio between the two voices and vibrato effect.\n * @example\n * const duoSynth = new Tone.DuoSynth().toDestination();\n * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n * @category Instrument\n */\nclass DuoSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(DuoSynth.getDefaults(), arguments));\n        this.name = \"DuoSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(DuoSynth.getDefaults(), arguments);\n        this.voice0 = new _MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth(Object.assign(options.voice0, {\n            context: this.context,\n            onsilence: () => this.onsilence(this)\n        }));\n        this.voice1 = new _MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth(Object.assign(options.voice1, {\n            context: this.context,\n        }));\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this._vibrato = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_4__.LFO({\n            frequency: options.vibratoRate,\n            context: this.context,\n            min: -50,\n            max: 50\n        });\n        // start the vibrato immediately\n        this._vibrato.start();\n        this.vibratoRate = this._vibrato.frequency;\n        this._vibratoGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({\n            context: this.context,\n            units: \"normalRange\",\n            gain: options.vibratoAmount\n        });\n        this.vibratoAmount = this._vibratoGain.gain;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: 440\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune\n        });\n        // control the two voices frequency\n        this.frequency.connect(this.voice0.frequency);\n        this.frequency.chain(this.harmonicity, this.voice1.frequency);\n        this._vibrato.connect(this._vibratoGain);\n        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);\n        this.detune.fan(this.voice0.detune, this.voice1.detune);\n        this.voice0.connect(this.output);\n        this.voice1.connect(this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"voice0\", \"voice1\", \"frequency\", \"vibratoAmount\", \"vibratoRate\"]);\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults(), {\n            vibratoAmount: 0.5,\n            vibratoRate: 5,\n            harmonicity: 1.5,\n            voice0: (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.omitFromObject)(_MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth.getDefaults(), Object.keys(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n            voice1: (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.omitFromObject)(_MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth.getDefaults(), Object.keys(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeRelease(time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.voice0.dispose();\n        this.voice1.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._vibrato.dispose();\n        this.vibratoRate.dispose();\n        this._vibratoGain.dispose();\n        this.harmonicity.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=DuoSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/DuoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/FMSynth.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/FMSynth.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FMSynth\": () => (/* binding */ FMSynth)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ModulationSynth */ \"./node_modules/tone/build/esm/instrument/ModulationSynth.js\");\n\n\n\n/**\n * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n * the frequency of a second Tone.Synth. A lot of spectral content\n * can be explored using the modulationIndex parameter. Read more about\n * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n *\n * @example\n * const fmSynth = new Tone.FMSynth().toDestination();\n * fmSynth.triggerAttackRelease(\"C5\", \"4n\");\n *\n * @category Instrument\n */\nclass FMSynth extends _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FMSynth.getDefaults(), arguments));\n        this.name = \"FMSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FMSynth.getDefaults(), arguments);\n        this.modulationIndex = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: options.modulationIndex,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth.getDefaults(), {\n            modulationIndex: 10,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/FMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Instrument.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Instrument.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Instrument\": () => (/* binding */ Instrument)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Base-class for all instruments\n */\nclass Instrument extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Instrument.getDefaults(), arguments));\n        /**\n         * Keep track of all events scheduled to the transport\n         * when the instrument is 'synced'\n         */\n        this._scheduledEvents = [];\n        /**\n         * If the instrument is currently synced\n         */\n        this._synced = false;\n        this._original_triggerAttack = this.triggerAttack;\n        this._original_triggerRelease = this.triggerRelease;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Instrument.getDefaults(), arguments);\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"volume\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            volume: 0,\n        });\n    }\n    /**\n     * Sync the instrument to the Transport. All subsequent calls of\n     * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.\n     * @example\n     * const fmSynth = new Tone.FMSynth().toDestination();\n     * fmSynth.volume.value = -6;\n     * fmSynth.sync();\n     * // schedule 3 notes when the transport first starts\n     * fmSynth.triggerAttackRelease(\"C4\", \"8n\", 0);\n     * fmSynth.triggerAttackRelease(\"E4\", \"8n\", \"8n\");\n     * fmSynth.triggerAttackRelease(\"G4\", \"8n\", \"4n\");\n     * // start the transport to hear the notes\n     * Tone.Transport.start();\n     */\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 0);\n        }\n        return this;\n    }\n    /**\n     * set _sync\n     */\n    _syncState() {\n        let changed = false;\n        if (!this._synced) {\n            this._synced = true;\n            changed = true;\n        }\n        return changed;\n    }\n    /**\n     * Wrap the given method so that it can be synchronized\n     * @param method Which method to wrap and sync\n     * @param  timePosition What position the time argument appears in\n     */\n    _syncMethod(method, timePosition) {\n        const originalMethod = this[\"_original_\" + method] = this[method];\n        this[method] = (...args) => {\n            const time = args[timePosition];\n            const id = this.context.transport.schedule((t) => {\n                args[timePosition] = t;\n                originalMethod.apply(this, args);\n            }, time);\n            this._scheduledEvents.push(id);\n        };\n    }\n    /**\n     * Unsync the instrument from the Transport\n     */\n    unsync() {\n        this._scheduledEvents.forEach(id => this.context.transport.clear(id));\n        this._scheduledEvents = [];\n        if (this._synced) {\n            this._synced = false;\n            this.triggerAttack = this._original_triggerAttack;\n            this.triggerRelease = this._original_triggerRelease;\n        }\n        return this;\n    }\n    /**\n     * Trigger the attack and then the release after the duration.\n     * @param  note     The note to trigger.\n     * @param  duration How long the note should be held for before\n     *                         triggering the release. This value must be greater than 0.\n     * @param time  When the note should be triggered.\n     * @param  velocity The velocity the note should be triggered at.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger \"C4\" for the duration of an 8th note\n     * synth.triggerAttackRelease(\"C4\", \"8n\");\n     */\n    triggerAttackRelease(note, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        const computedDuration = this.toSeconds(duration);\n        this.triggerAttack(note, computedTime, velocity);\n        this.triggerRelease(computedTime + computedDuration);\n        return this;\n    }\n    /**\n     * clean up\n     * @returns {Instrument} this\n     */\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.unsync();\n        this._scheduledEvents = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Instrument.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/Instrument.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MembraneSynth.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MembraneSynth.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MembraneSynth\": () => (/* binding */ MembraneSynth)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n/**\n * MembraneSynth makes kick and tom sounds using a single oscillator\n * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n * is routed through a Tone.AmplitudeEnvelope to the output. The drum\n * quality of the sound comes from the frequency envelope applied\n * during MembraneSynth.triggerAttack(note). The frequency envelope\n * starts at <code>note * .octaves</code> and ramps to <code>note</code>\n * over the duration of <code>.pitchDecay</code>.\n * @example\n * const synth = new Tone.MembraneSynth().toDestination();\n * synth.triggerAttackRelease(\"C2\", \"8n\");\n * @category Instrument\n */\nclass MembraneSynth extends _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MembraneSynth.getDefaults(), arguments));\n        this.name = \"MembraneSynth\";\n        /**\n         * Portamento is ignored in this synth. use pitch decay instead.\n         */\n        this.portamento = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MembraneSynth.getDefaults(), arguments);\n        this.pitchDecay = options.pitchDecay;\n        this.octaves = options.octaves;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"oscillator\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_3__.Monophonic.getDefaults(), _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth.getDefaults(), {\n            envelope: {\n                attack: 0.001,\n                attackCurve: \"exponential\",\n                decay: 0.4,\n                release: 1.4,\n                sustain: 0.01,\n            },\n            octaves: 10,\n            oscillator: {\n                type: \"sine\",\n            },\n            pitchDecay: 0.05,\n        });\n    }\n    setNote(note, time) {\n        const seconds = this.toSeconds(time);\n        const hertz = this.toFrequency(note instanceof _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass ? note.toFrequency() : note);\n        const maxNote = hertz * this.octaves;\n        this.oscillator.frequency.setValueAtTime(maxNote, seconds);\n        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_6__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__.range)(0)\n], MembraneSynth.prototype, \"octaves\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_6__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__.timeRange)(0)\n], MembraneSynth.prototype, \"pitchDecay\", void 0);\n//# sourceMappingURL=MembraneSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/MembraneSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MetalSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MetalSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MetalSynth\": () => (/* binding */ MetalSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _source_oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../source/oscillator/FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Inharmonic ratio of frequencies based on the Roland TR-808\n * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model\n */\nconst inharmRatios = [1.0, 1.483, 1.932, 2.546, 2.630, 3.897];\n/**\n * A highly inharmonic and spectrally complex source with a highpass filter\n * and amplitude envelope which is good for making metallophone sounds.\n * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n * Inspiration from [Sound on Sound](https://shorturl.at/rSZ12).\n * @category Instrument\n */\nclass MetalSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_10__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(MetalSynth.getDefaults(), arguments));\n        this.name = \"MetalSynth\";\n        /**\n         * The array of FMOscillators\n         */\n        this._oscillators = [];\n        /**\n         * The frequency multipliers\n         */\n        this._freqMultipliers = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(MetalSynth.getDefaults(), arguments);\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_8__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_8__.Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this._amplitude = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({\n            context: this.context,\n            gain: 0,\n        }).connect(this.output);\n        this._highpass = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            // Q: -3.0102999566398125,\n            Q: 0,\n            context: this.context,\n            type: \"highpass\",\n        }).connect(this._amplitude);\n        for (let i = 0; i < inharmRatios.length; i++) {\n            const osc = new _source_oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_9__.FMOscillator({\n                context: this.context,\n                harmonicity: options.harmonicity,\n                modulationIndex: options.modulationIndex,\n                modulationType: \"square\",\n                onstop: i === 0 ? () => this.onsilence(this) : _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n                type: \"square\",\n            });\n            osc.connect(this._highpass);\n            this._oscillators[i] = osc;\n            const mult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply({\n                context: this.context,\n                value: inharmRatios[i],\n            });\n            this._freqMultipliers[i] = mult;\n            this.frequency.chain(mult, osc.frequency);\n            this.detune.connect(osc.detune);\n        }\n        this._filterFreqScaler = new _signal_Scale__WEBPACK_IMPORTED_MODULE_7__.Scale({\n            context: this.context,\n            max: 7000,\n            min: this.toFrequency(options.resonance),\n        });\n        this.envelope = new _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__.Envelope({\n            attack: options.envelope.attack,\n            attackCurve: \"linear\",\n            context: this.context,\n            decay: options.envelope.decay,\n            release: options.envelope.release,\n            sustain: 0,\n        });\n        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);\n        this.envelope.connect(this._amplitude.gain);\n        // set the octaves\n        this._octaves = options.octaves;\n        this.octaves = options.octaves;\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_10__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults())), {\n                attack: 0.001,\n                decay: 1.4,\n                release: 0.2,\n            }),\n            harmonicity: 5.1,\n            modulationIndex: 32,\n            octaves: 1.5,\n            resonance: 4000,\n        });\n    }\n    /**\n     * Trigger the attack.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity that the envelope should be triggered at.\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this._oscillators.forEach(osc => osc.start(time));\n        if (this.envelope.sustain === 0) {\n            this._oscillators.forEach(osc => {\n                osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n            });\n        }\n        return this;\n    }\n    /**\n     * Trigger the release of the envelope.\n     * @param time When the release should be triggered.\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this._oscillators.forEach(osc => osc.stop(time + this.toSeconds(this.envelope.release)));\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * The modulationIndex of the oscillators which make up the source.\n     * see [[FMOscillator.modulationIndex]]\n     * @min 1\n     * @max 100\n     */\n    get modulationIndex() {\n        return this._oscillators[0].modulationIndex.value;\n    }\n    set modulationIndex(val) {\n        this._oscillators.forEach(osc => (osc.modulationIndex.value = val));\n    }\n    /**\n     * The harmonicity of the oscillators which make up the source.\n     * see Tone.FMOscillator.harmonicity\n     * @min 0.1\n     * @max 10\n     */\n    get harmonicity() {\n        return this._oscillators[0].harmonicity.value;\n    }\n    set harmonicity(val) {\n        this._oscillators.forEach(osc => (osc.harmonicity.value = val));\n    }\n    /**\n     * The lower level of the highpass filter which is attached to the envelope.\n     * This value should be between [0, 7000]\n     * @min 0\n     * @max 7000\n     */\n    get resonance() {\n        return this._filterFreqScaler.min;\n    }\n    set resonance(val) {\n        this._filterFreqScaler.min = this.toFrequency(val);\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the \"resonance\" frequency\n     * that the filter ramps during the attack/decay envelope\n     * @min 0\n     * @max 8\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(val) {\n        this._octaves = val;\n        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);\n    }\n    dispose() {\n        super.dispose();\n        this._oscillators.forEach(osc => osc.dispose());\n        this._freqMultipliers.forEach(freqMult => freqMult.dispose());\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._filterFreqScaler.dispose();\n        this._amplitude.dispose();\n        this.envelope.dispose();\n        this._highpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MetalSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/MetalSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/ModulationSynth.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/ModulationSynth.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ModulationSynth\": () => (/* binding */ ModulationSynth)\n/* harmony export */ });\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Base class for both AM and FM synths\n */\nclass ModulationSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.optionsFromArguments)(ModulationSynth.getDefaults(), arguments));\n        this.name = \"ModulationSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.optionsFromArguments)(ModulationSynth.getDefaults(), arguments);\n        this._carrier = new _Synth__WEBPACK_IMPORTED_MODULE_8__.Synth({\n            context: this.context,\n            oscillator: options.oscillator,\n            envelope: options.envelope,\n            onsilence: () => this.onsilence(this),\n            volume: -10,\n        });\n        this._modulator = new _Synth__WEBPACK_IMPORTED_MODULE_8__.Synth({\n            context: this.context,\n            oscillator: options.modulation,\n            envelope: options.modulationEnvelope,\n            volume: -10,\n        });\n        this.oscillator = this._carrier.oscillator;\n        this.envelope = this._carrier.envelope;\n        this.modulation = this._modulator.oscillator;\n        this.modulationEnvelope = this._modulator.envelope;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal({\n            context: this.context,\n            value: options.detune,\n            units: \"cents\"\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: options.harmonicity,\n            minValue: 0,\n        });\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_9__.readOnly)(this, [\"frequency\", \"harmonicity\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic.getDefaults(), {\n            harmonicity: 3,\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), [\n                ...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"sine\"\n            }),\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                attack: 0.01,\n                decay: 0.01,\n                sustain: 1,\n                release: 0.5\n            }),\n            modulation: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), [\n                ...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"square\"\n            }),\n            modulationEnvelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                attack: 0.5,\n                decay: 0.0,\n                sustain: 1,\n                release: 0.5\n            })\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeRelease(time);\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._modulationNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ModulationSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/ModulationSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MonoSynth.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MonoSynth.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MonoSynth\": () => (/* binding */ MonoSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../component/envelope/FrequencyEnvelope */ \"./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.\n * The amplitude of the Oscillator and the cutoff frequency of the\n * Filter are controlled by Envelopes.\n * <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">\n * @example\n * const synth = new Tone.MonoSynth({\n * \toscillator: {\n * \t\ttype: \"square\"\n * \t},\n * \tenvelope: {\n * \t\tattack: 0.1\n * \t}\n * }).toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nclass MonoSynth extends _instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(MonoSynth.getDefaults(), arguments));\n        this.name = \"MonoSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(MonoSynth.getDefaults(), arguments);\n        this.oscillator = new _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator(Object.assign(options.oscillator, {\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.filter = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__.Filter(Object.assign(options.filter, { context: this.context }));\n        this.filterEnvelope = new _component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__.FrequencyEnvelope(Object.assign(options.filterEnvelope, { context: this.context }));\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign(options.envelope, { context: this.context }));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.filter, this.envelope, this.output);\n        // connect the filter envelope\n        this.filterEnvelope.connect(this.filter.frequency);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"oscillator\", \"frequency\", \"detune\", \"filter\", \"filterEnvelope\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.9,\n            }),\n            filter: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__.Filter.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                Q: 1,\n                rolloff: -12,\n                type: \"lowpass\",\n            }),\n            filterEnvelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__.FrequencyEnvelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                attack: 0.6,\n                baseFrequency: 200,\n                decay: 0.2,\n                exponent: 2,\n                octaves: 3,\n                release: 2,\n                sustain: 0.5,\n            }),\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults())), {\n                type: \"sawtooth\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this.filterEnvelope.triggerAttack(time);\n        this.oscillator.start(time);\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.filterEnvelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        this.filterEnvelope.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MonoSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/MonoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Monophonic.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Monophonic.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Monophonic\": () => (/* binding */ Monophonic)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n/**\n * Abstract base class for other monophonic instruments to extend.\n */\nclass Monophonic extends _instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Monophonic.getDefaults(), arguments));\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Monophonic.getDefaults(), arguments);\n        this.portamento = options.portamento;\n        this.onsilence = options.onsilence;\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            detune: 0,\n            onsilence: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            portamento: 0,\n        });\n    }\n    /**\n     * Trigger the attack of the note optionally with a given velocity.\n     * @param  note The note to trigger.\n     * @param  time When the note should start.\n     * @param  velocity The velocity scaler determines how \"loud\" the note will be triggered.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger the note a half second from now at half velocity\n     * synth.triggerAttack(\"C4\", \"+0.5\", 0.5);\n     */\n    triggerAttack(note, time, velocity = 1) {\n        this.log(\"triggerAttack\", note, time, velocity);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeAttack(seconds, velocity);\n        this.setNote(note, seconds);\n        return this;\n    }\n    /**\n     * Trigger the release portion of the envelope\n     * @param  time If no time is given, the release happens immediatly\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // trigger the release a second from now\n     * synth.triggerRelease(\"+1\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeRelease(seconds);\n        return this;\n    }\n    /**\n     * Set the note at the given time. If no time is given, the note\n     * will set immediately.\n     * @param note The note to change to.\n     * @param  time The time when the note should be set.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // change to F#6 in one quarter note from now.\n     * synth.setNote(\"F#6\", \"+4n\");\n     */\n    setNote(note, time) {\n        const computedTime = this.toSeconds(time);\n        const computedFrequency = note instanceof _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass ? note.toFrequency() : note;\n        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {\n            const portTime = this.toSeconds(this.portamento);\n            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);\n        }\n        else {\n            this.frequency.setValueAtTime(computedFrequency, computedTime);\n        }\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_5__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_4__.timeRange)(0)\n], Monophonic.prototype, \"portamento\", void 0);\n//# sourceMappingURL=Monophonic.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/Monophonic.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/NoiseSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/NoiseSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoiseSynth\": () => (/* binding */ NoiseSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n\n\n\n\n\n\n\n/**\n * Tone.NoiseSynth is composed of [[Noise]] through an [[AmplitudeEnvelope]].\n * ```\n * +-------+   +-------------------+\n * | Noise +>--> AmplitudeEnvelope +>--> Output\n * +-------+   +-------------------+\n * ```\n * @example\n * const noiseSynth = new Tone.NoiseSynth().toDestination();\n * noiseSynth.triggerAttackRelease(\"8n\", 0.05);\n * @category Instrument\n */\nclass NoiseSynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(NoiseSynth.getDefaults(), arguments));\n        this.name = \"NoiseSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(NoiseSynth.getDefaults(), arguments);\n        this.noise = new _source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise(Object.assign({\n            context: this.context,\n        }, options.noise));\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the noise to the output\n        this.noise.chain(this.envelope, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_5__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                decay: 0.1,\n                sustain: 0.0,\n            }),\n            noise: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise.getDefaults(), Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults())), {\n                type: \"white\",\n            }),\n        });\n    }\n    /**\n     * Start the attack portion of the envelopes. Unlike other\n     * instruments, Tone.NoiseSynth doesn't have a note.\n     * @example\n     * const noiseSynth = new Tone.NoiseSynth().toDestination();\n     * noiseSynth.triggerAttack();\n     */\n    triggerAttack(time, velocity = 1) {\n        time = this.toSeconds(time);\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        // start the noise\n        this.noise.start(time);\n        if (this.envelope.sustain === 0) {\n            this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n        }\n        return this;\n    }\n    /**\n     * Start the release portion of the envelopes.\n     */\n    triggerRelease(time) {\n        time = this.toSeconds(time);\n        this.envelope.triggerRelease(time);\n        this.noise.stop(time + this.toSeconds(this.envelope.release));\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 0);\n            this._syncMethod(\"triggerRelease\", 0);\n        }\n        return this;\n    }\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        duration = this.toSeconds(duration);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + duration);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.noise.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=NoiseSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/NoiseSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/PluckSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/PluckSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PluckSynth\": () => (/* binding */ PluckSynth)\n/* harmony export */ });\n/* harmony import */ var _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n\n\n\n\n\n/**\n * Karplus-String string synthesis.\n * @example\n * const plucky = new Tone.PluckSynth().toDestination();\n * plucky.triggerAttack(\"C4\", \"+0.5\");\n * plucky.triggerAttack(\"C3\", \"+1\");\n * plucky.triggerAttack(\"C2\", \"+1.5\");\n * plucky.triggerAttack(\"C1\", \"+2\");\n * @category Instrument\n */\nclass PluckSynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PluckSynth.getDefaults(), arguments));\n        this.name = \"PluckSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PluckSynth.getDefaults(), arguments);\n        this._noise = new _source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise({\n            context: this.context,\n            type: \"pink\"\n        });\n        this.attackNoise = options.attackNoise;\n        this._lfcf = new _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_0__.LowpassCombFilter({\n            context: this.context,\n            dampening: options.dampening,\n            resonance: options.resonance,\n        });\n        this.resonance = options.resonance;\n        this.release = options.release;\n        this._noise.connect(this._lfcf);\n        this._lfcf.connect(this.output);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            attackNoise: 1,\n            dampening: 4000,\n            resonance: 0.7,\n            release: 1,\n        });\n    }\n    /**\n     * The dampening control. i.e. the lowpass filter frequency of the comb filter\n     * @min 0\n     * @max 7000\n     */\n    get dampening() {\n        return this._lfcf.dampening;\n    }\n    set dampening(fq) {\n        this._lfcf.dampening = fq;\n    }\n    triggerAttack(note, time) {\n        const freq = this.toFrequency(note);\n        time = this.toSeconds(time);\n        const delayAmount = 1 / freq;\n        this._lfcf.delayTime.setValueAtTime(delayAmount, time);\n        this._noise.start(time);\n        this._noise.stop(time + delayAmount * this.attackNoise);\n        this._lfcf.resonance.cancelScheduledValues(time);\n        this._lfcf.resonance.setValueAtTime(this.resonance, time);\n        return this;\n    }\n    /**\n     * Ramp down the [[resonance]] to 0 over the duration of the release time.\n     */\n    triggerRelease(time) {\n        this._lfcf.resonance.linearRampTo(0, this.release, time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._noise.dispose();\n        this._lfcf.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PluckSynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/PluckSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/PolySynth.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/PolySynth.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PolySynth\": () => (/* binding */ PolySynth)\n/* harmony export */ });\n/* harmony import */ var _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Midi */ \"./node_modules/tone/build/esm/core/type/Midi.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n/**\n * PolySynth handles voice creation and allocation for any\n * instruments passed in as the second paramter. PolySynth is\n * not a synthesizer by itself, it merely manages voices of\n * one of the other types of synths, allowing any of the\n * monophonic synthesizers to be polyphonic.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * // set the attributes across all the voices using 'set'\n * synth.set({ detune: -1200 });\n * // play a chord\n * synth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], 1);\n * @category Instrument\n */\nclass PolySynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]));\n        this.name = \"PolySynth\";\n        /**\n         * The voices which are not currently in use\n         */\n        this._availableVoices = [];\n        /**\n         * The currently active voices\n         */\n        this._activeVoices = [];\n        /**\n         * All of the allocated voices for this synth.\n         */\n        this._voices = [];\n        /**\n         * The GC timeout. Held so that it could be cancelled when the node is disposed.\n         */\n        this._gcTimeout = -1;\n        /**\n         * A moving average of the number of active voices\n         */\n        this._averageActiveVoices = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]);\n        // check against the old API (pre 14.3.0)\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(options.voice), \"DEPRECATED: The polyphony count is no longer the first argument.\");\n        const defaults = options.voice.getDefaults();\n        this.options = Object.assign(defaults, options.options);\n        this.voice = options.voice;\n        this.maxPolyphony = options.maxPolyphony;\n        // create the first voice\n        this._dummyVoice = this._getNextAvailableVoice();\n        // remove it from the voices list\n        const index = this._voices.indexOf(this._dummyVoice);\n        this._voices.splice(index, 1);\n        // kick off the GC interval\n        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);\n    }\n    static getDefaults() {\n        return Object.assign(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            maxPolyphony: 32,\n            options: {},\n            voice: _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth,\n        });\n    }\n    /**\n     * The number of active voices.\n     */\n    get activeVoices() {\n        return this._activeVoices.length;\n    }\n    /**\n     * Invoked when the source is done making sound, so that it can be\n     * readded to the pool of available voices\n     */\n    _makeVoiceAvailable(voice) {\n        this._availableVoices.push(voice);\n        // remove the midi note from 'active voices'\n        const activeVoiceIndex = this._activeVoices.findIndex((e) => e.voice === voice);\n        this._activeVoices.splice(activeVoiceIndex, 1);\n    }\n    /**\n     * Get an available voice from the pool of available voices.\n     * If one is not available and the maxPolyphony limit is reached,\n     * steal a voice, otherwise return null.\n     */\n    _getNextAvailableVoice() {\n        // if there are available voices, return the first one\n        if (this._availableVoices.length) {\n            return this._availableVoices.shift();\n        }\n        else if (this._voices.length < this.maxPolyphony) {\n            // otherwise if there is still more maxPolyphony, make a new voice\n            const voice = new this.voice(Object.assign(this.options, {\n                context: this.context,\n                onsilence: this._makeVoiceAvailable.bind(this),\n            }));\n            voice.connect(this.output);\n            this._voices.push(voice);\n            return voice;\n        }\n        else {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.warn)(\"Max polyphony exceeded. Note dropped.\");\n        }\n    }\n    /**\n     * Occasionally check if there are any allocated voices which can be cleaned up.\n     */\n    _collectGarbage() {\n        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);\n        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {\n            // take off an available note\n            const firstAvail = this._availableVoices.shift();\n            const index = this._voices.indexOf(firstAvail);\n            this._voices.splice(index, 1);\n            if (!this.context.isOffline) {\n                firstAvail.dispose();\n            }\n        }\n    }\n    /**\n     * Internal method which triggers the attack\n     */\n    _triggerAttack(notes, time, velocity) {\n        notes.forEach(note => {\n            const midiNote = new _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__.MidiClass(this.context, note).toMidi();\n            const voice = this._getNextAvailableVoice();\n            if (voice) {\n                voice.triggerAttack(note, time, velocity);\n                this._activeVoices.push({\n                    midi: midiNote, voice, released: false,\n                });\n                this.log(\"triggerAttack\", note, time);\n            }\n        });\n    }\n    /**\n     * Internal method which triggers the release\n     */\n    _triggerRelease(notes, time) {\n        notes.forEach(note => {\n            const midiNote = new _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__.MidiClass(this.context, note).toMidi();\n            const event = this._activeVoices.find(({ midi, released }) => midi === midiNote && !released);\n            if (event) {\n                // trigger release on that note\n                event.voice.triggerRelease(time);\n                // mark it as released\n                event.released = true;\n                this.log(\"triggerRelease\", note, time);\n            }\n        });\n    }\n    /**\n     * Schedule the attack/release events. If the time is in the future, then it should set a timeout\n     * to wait for just-in-time scheduling\n     */\n    _scheduleEvent(type, notes, time, velocity) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(!this.disposed, \"Synth was already disposed\");\n        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout\n        if (time <= this.now()) {\n            // do it immediately\n            if (type === \"attack\") {\n                this._triggerAttack(notes, time, velocity);\n            }\n            else {\n                this._triggerRelease(notes, time);\n            }\n        }\n        else {\n            // schedule it to start in the future\n            this.context.setTimeout(() => {\n                this._scheduleEvent(type, notes, time, velocity);\n            }, time - this.now());\n        }\n    }\n    /**\n     * Trigger the attack portion of the note\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  The start time of the note.\n     * @param velocity The velocity of the note.\n     * @example\n     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();\n     * // trigger a chord immediately with a velocity of 0.2\n     * synth.triggerAttack([\"Ab3\", \"C4\", \"F5\"], Tone.now(), 0.2);\n     */\n    triggerAttack(notes, time, velocity) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"attack\", notes, computedTime, velocity);\n        return this;\n    }\n    /**\n     * Trigger the release of the note. Unlike monophonic instruments,\n     * a note (or array of notes) needs to be passed in as the first argument.\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  When the release will be triggered.\n     * @example\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * poly.triggerAttack([\"Ab3\", \"C4\", \"F5\"]);\n     * // trigger the release of the given notes.\n     * poly.triggerRelease([\"Ab3\", \"C4\"], \"+1\");\n     * poly.triggerRelease(\"F5\", \"+3\");\n     */\n    triggerRelease(notes, time) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"release\", notes, computedTime);\n        return this;\n    }\n    /**\n     * Trigger the attack and release after the specified duration\n     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.\n     * @param  duration the duration of the note\n     * @param  time  if no time is given, defaults to now\n     * @param  velocity the velocity of the attack (0-1)\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * // can pass in an array of durations as well\n     * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"Bb4\", \"D5\"], [4, 3, 2, 1]);\n     */\n    triggerAttackRelease(notes, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(duration)) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(notes), \"If the duration is an array, the notes must also be an array\");\n            notes = notes;\n            for (let i = 0; i < notes.length; i++) {\n                const d = duration[Math.min(i, duration.length - 1)];\n                const durationSeconds = this.toSeconds(d);\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(durationSeconds > 0, \"The duration must be greater than 0\");\n                this.triggerRelease(notes[i], computedTime + durationSeconds);\n            }\n        }\n        else {\n            const durationSeconds = this.toSeconds(duration);\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(durationSeconds > 0, \"The duration must be greater than 0\");\n            this.triggerRelease(notes, computedTime + durationSeconds);\n        }\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 1);\n        }\n        return this;\n    }\n    /**\n     * Set a member/attribute of the voices\n     * @example\n     * const poly = new Tone.PolySynth().toDestination();\n     * // set all of the voices using an options object for the synth type\n     * poly.set({\n     * \tenvelope: {\n     * \t\tattack: 0.25\n     * \t}\n     * });\n     * poly.triggerAttackRelease(\"Bb3\", 0.2);\n     */\n    set(options) {\n        // remove options which are controlled by the PolySynth\n        const sanitizedOptions = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(options, [\"onsilence\", \"context\"]);\n        // store all of the options\n        this.options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(this.options, sanitizedOptions);\n        this._voices.forEach(voice => voice.set(sanitizedOptions));\n        this._dummyVoice.set(sanitizedOptions);\n        return this;\n    }\n    get() {\n        return this._dummyVoice.get();\n    }\n    /**\n     * Trigger the release portion of all the currently active voices immediately.\n     * Useful for silencing the synth.\n     */\n    releaseAll(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeVoices.forEach(({ voice }) => {\n            voice.triggerRelease(computedTime);\n        });\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dummyVoice.dispose();\n        this._voices.forEach(v => v.dispose());\n        this._activeVoices = [];\n        this._availableVoices = [];\n        this.context.clearInterval(this._gcTimeout);\n        return this;\n    }\n}\n//# sourceMappingURL=PolySynth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/PolySynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Sampler.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Sampler.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Sampler\": () => (/* binding */ Sampler)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Pass in an object which maps the note's pitch or midi value to the url,\n * then you can trigger the attack and release of that note like other instruments.\n * By automatically repitching the samples, it is possible to play pitches which\n * were not explicitly included which can save loading time.\n *\n * For sample or buffer playback where repitching is not necessary,\n * use [[Player]].\n * @example\n * const sampler = new Tone.Sampler({\n * \turls: {\n * \t\tA1: \"A1.mp3\",\n * \t\tA2: \"A2.mp3\",\n * \t},\n * \tbaseUrl: \"https://tonejs.github.io/audio/casio/\",\n * \tonload: () => {\n * \t\tsampler.triggerAttackRelease([\"C1\", \"E1\", \"G1\", \"B1\"], 0.5);\n * \t}\n * }).toDestination();\n * @category Instrument\n */\nclass Sampler extends _instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\"));\n        this.name = \"Sampler\";\n        /**\n         * The object of all currently playing BufferSources\n         */\n        this._activeSources = new Map();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        const urlMap = {};\n        Object.keys(options.urls).forEach((note) => {\n            const noteNumber = parseInt(note, 10);\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)\n                || ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(noteNumber) && isFinite(noteNumber)), `url key is neither a note or midi pitch: ${note}`);\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)) {\n                // convert the note name to MIDI\n                const mid = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n                urlMap[mid] = options.urls[note];\n            }\n            else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(noteNumber) && isFinite(noteNumber)) {\n                // otherwise if it's numbers assume it's midi\n                urlMap[noteNumber] = options.urls[noteNumber];\n            }\n        });\n        this._buffers = new _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffers({\n            urls: urlMap,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror,\n        });\n        this.attack = options.attack;\n        this.release = options.release;\n        this.curve = options.curve;\n        // invoke the callback if it's already loaded\n        if (this._buffers.loaded) {\n            // invoke onload deferred\n            Promise.resolve().then(options.onload);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__.Instrument.getDefaults(), {\n            attack: 0,\n            baseUrl: \"\",\n            curve: \"exponential\",\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            release: 0.1,\n            urls: {},\n        });\n    }\n    /**\n     * Returns the difference in steps between the given midi note at the closets sample.\n     */\n    _findClosest(midi) {\n        // searches within 8 octaves of the given midi note\n        const MAX_INTERVAL = 96;\n        let interval = 0;\n        while (interval < MAX_INTERVAL) {\n            // check above and below\n            if (this._buffers.has(midi + interval)) {\n                return -interval;\n            }\n            else if (this._buffers.has(midi - interval)) {\n                return interval;\n            }\n            interval++;\n        }\n        throw new Error(`No available buffers for note: ${midi}`);\n    }\n    /**\n     * @param  notes\tThe note to play, or an array of notes.\n     * @param  time     When to play the note\n     * @param  velocity The velocity to play the sample back.\n     */\n    triggerAttack(notes, time, velocity = 1) {\n        this.log(\"triggerAttack\", notes, time, velocity);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midiFloat = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftomf)(new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toFrequency());\n            const midi = Math.round(midiFloat);\n            const remainder = midiFloat - midi;\n            // find the closest note pitch\n            const difference = this._findClosest(midi);\n            const closestNote = midi - difference;\n            const buffer = this._buffers.get(closestNote);\n            const playbackRate = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio)(difference + remainder);\n            // play that note\n            const source = new _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_7__.ToneBufferSource({\n                url: buffer,\n                context: this.context,\n                curve: this.curve,\n                fadeIn: this.attack,\n                fadeOut: this.release,\n                playbackRate,\n            }).connect(this.output);\n            source.start(time, 0, buffer.duration / playbackRate, velocity);\n            // add it to the active sources\n            if (!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(this._activeSources.get(midi))) {\n                this._activeSources.set(midi, []);\n            }\n            this._activeSources.get(midi).push(source);\n            // remove it when it's done\n            source.onended = () => {\n                if (this._activeSources && this._activeSources.has(midi)) {\n                    const sources = this._activeSources.get(midi);\n                    const index = sources.indexOf(source);\n                    if (index !== -1) {\n                        sources.splice(index, 1);\n                    }\n                }\n            };\n        });\n        return this;\n    }\n    /**\n     * @param  notes\tThe note to release, or an array of notes.\n     * @param  time     \tWhen to release the note.\n     */\n    triggerRelease(notes, time) {\n        this.log(\"triggerRelease\", notes, time);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midi = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n            // find the note\n            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {\n                const sources = this._activeSources.get(midi);\n                time = this.toSeconds(time);\n                sources.forEach(source => {\n                    source.stop(time);\n                });\n                this._activeSources.set(midi, []);\n            }\n        });\n        return this;\n    }\n    /**\n     * Release all currently active notes.\n     * @param  time     \tWhen to release the notes.\n     */\n    releaseAll(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(sources => {\n            while (sources.length) {\n                const source = sources.shift();\n                source.stop(computedTime);\n            }\n        });\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 1);\n        }\n        return this;\n    }\n    /**\n     * Invoke the attack phase, then after the duration, invoke the release.\n     * @param  notes\tThe note to play and release, or an array of notes.\n     * @param  duration The time the note should be held\n     * @param  time     When to start the attack\n     * @param  velocity The velocity of the attack\n     */\n    triggerAttackRelease(notes, duration, time, velocity = 1) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(duration)) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(notes), \"notes must be an array when duration is array\");\n            notes.forEach((note, index) => {\n                const d = duration[Math.min(index, duration.length - 1)];\n                this.triggerRelease(note, computedTime + this.toSeconds(d));\n            });\n        }\n        else {\n            this.triggerRelease(notes, computedTime + this.toSeconds(duration));\n        }\n        return this;\n    }\n    /**\n     * Add a note to the sampler.\n     * @param  note      The buffer's pitch.\n     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     */\n    add(note, url, callback) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note) || isFinite(note), `note must be a pitch or midi: ${note}`);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)) {\n            // convert the note name to MIDI\n            const mid = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n            this._buffers.add(mid, url, callback);\n        }\n        else {\n            // otherwise if it's numbers assume it's midi\n            this._buffers.add(note, url, callback);\n        }\n        return this;\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffers.dispose();\n        this._activeSources.forEach(sources => {\n            sources.forEach(source => source.dispose());\n        });\n        this._activeSources.clear();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_10__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__.timeRange)(0)\n], Sampler.prototype, \"attack\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_10__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__.timeRange)(0)\n], Sampler.prototype, \"release\", void 0);\n//# sourceMappingURL=Sampler.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/Sampler.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Synth.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Synth.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Synth\": () => (/* binding */ Synth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n\n\n\n\n\n\n\n\n/**\n * Synth is composed simply of a [[OmniOscillator]] routed through an [[AmplitudeEnvelope]].\n * ```\n * +----------------+   +-------------------+\n * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output\n * +----------------+   +-------------------+\n * ```\n * @example\n * const synth = new Tone.Synth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nclass Synth extends _Monophonic__WEBPACK_IMPORTED_MODULE_7__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Synth.getDefaults(), arguments));\n        this.name = \"Synth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Synth.getDefaults(), arguments);\n        this.oscillator = new _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__.OmniOscillator(Object.assign({\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }, options.oscillator));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.envelope, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"oscillator\", \"frequency\", \"detune\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Monophonic__WEBPACK_IMPORTED_MODULE_7__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.3,\n            }),\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__.OmniOscillator.getDefaults(), [...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults()), \"frequency\", \"detune\"]), {\n                type: \"triangle\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        this.oscillator.start(time);\n        // if there is no release portion, stop the oscillator\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Synth.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/Synth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _AMSynth__WEBPACK_IMPORTED_MODULE_0__.AMSynth),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _DuoSynth__WEBPACK_IMPORTED_MODULE_1__.DuoSynth),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _FMSynth__WEBPACK_IMPORTED_MODULE_2__.FMSynth),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _MembraneSynth__WEBPACK_IMPORTED_MODULE_4__.MembraneSynth),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _MetalSynth__WEBPACK_IMPORTED_MODULE_3__.MetalSynth),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _MonoSynth__WEBPACK_IMPORTED_MODULE_5__.MonoSynth),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _NoiseSynth__WEBPACK_IMPORTED_MODULE_6__.NoiseSynth),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _PluckSynth__WEBPACK_IMPORTED_MODULE_7__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _PolySynth__WEBPACK_IMPORTED_MODULE_8__.PolySynth),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _Sampler__WEBPACK_IMPORTED_MODULE_9__.Sampler),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _Synth__WEBPACK_IMPORTED_MODULE_10__.Synth)\n/* harmony export */ });\n/* harmony import */ var _AMSynth__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AMSynth */ \"./node_modules/tone/build/esm/instrument/AMSynth.js\");\n/* harmony import */ var _DuoSynth__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DuoSynth */ \"./node_modules/tone/build/esm/instrument/DuoSynth.js\");\n/* harmony import */ var _FMSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FMSynth */ \"./node_modules/tone/build/esm/instrument/FMSynth.js\");\n/* harmony import */ var _MetalSynth__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./MetalSynth */ \"./node_modules/tone/build/esm/instrument/MetalSynth.js\");\n/* harmony import */ var _MembraneSynth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./MembraneSynth */ \"./node_modules/tone/build/esm/instrument/MembraneSynth.js\");\n/* harmony import */ var _MonoSynth__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./MonoSynth */ \"./node_modules/tone/build/esm/instrument/MonoSynth.js\");\n/* harmony import */ var _NoiseSynth__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./NoiseSynth */ \"./node_modules/tone/build/esm/instrument/NoiseSynth.js\");\n/* harmony import */ var _PluckSynth__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./PluckSynth */ \"./node_modules/tone/build/esm/instrument/PluckSynth.js\");\n/* harmony import */ var _PolySynth__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./PolySynth */ \"./node_modules/tone/build/esm/instrument/PolySynth.js\");\n/* harmony import */ var _Sampler__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Sampler */ \"./node_modules/tone/build/esm/instrument/Sampler.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/instrument/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Abs.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Abs.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Abs\": () => (/* binding */ Abs)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * Return the absolute value of an incoming signal.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst abs = new Tone.Abs().toDestination();\n * \tconst signal = new Tone.Signal(1);\n * \tsignal.rampTo(-1, 0.5);\n * \tsignal.connect(abs);\n * }, 0.5, 1);\n * @category Signal\n */\nclass Abs extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Abs\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._abs = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: val => {\n                if (Math.abs(val) < 0.001) {\n                    return 0;\n                }\n                else {\n                    return Math.abs(val);\n                }\n            },\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._abs;\n        /**\n         * The output range [0, 1]\n         */\n        this.output = this._abs;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Abs.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Abs.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Add.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Add.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Add\": () => (/* binding */ Add)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n/**\n * Add a signal and a number or two signals. When no value is\n * passed into the constructor, Tone.Add will sum input and `addend`\n * If a value is passed into the constructor, the it will be added to the input.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst add = new Tone.Add(2).toDestination();\n * \tadd.addend.setValueAtTime(1, 0.2);\n * \tconst signal = new Tone.Signal(2);\n * \t// add a signal and a scalar\n * \tsignal.connect(add);\n * \tsignal.setValueAtTime(1, 0.1);\n * }, 0.5, 1);\n * @category Signal\n */\nclass Add extends _Signal__WEBPACK_IMPORTED_MODULE_3__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Add.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Add\";\n        /**\n         * the summing node\n         */\n        this._sum = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * The value which is added to the input signal\n         */\n        this.addend = this._param;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(this._constantSource, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Add.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Add.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/AudioToGain.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/AudioToGain.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioToGain\": () => (/* binding */ AudioToGain)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].\n * See [[GainToAudio]].\n * @category Signal\n */\nclass AudioToGain extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"AudioToGain\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: x => (x + 1) / 2,\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The GainRange output [0, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AudioToGain.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/AudioToGain.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GainToAudio.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GainToAudio.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GainToAudio\": () => (/* binding */ GainToAudio)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].\n * See [[AudioToGain]].\n * @category Signal\n */\nclass GainToAudio extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"GainToAudio\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: x => Math.abs(x) * 2 - 1,\n        });\n        /**\n         * The NormalRange input [0, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The AudioRange output [-1, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GainToAudio.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/GainToAudio.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GreaterThan.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GreaterThan.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GreaterThan\": () => (/* binding */ GreaterThan)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Subtract__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _GreaterThanZero__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./GreaterThanZero */ \"./node_modules/tone/build/esm/signal/GreaterThanZero.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Output 1 if the signal is greater than the value, otherwise outputs 0.\n * can compare two signals or a signal and a number.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst gt = new Tone.GreaterThan(2).toDestination();\n * \tconst sig = new Tone.Signal(4).connect(gt);\n * }, 0.1, 1);\n * @category Signal\n */\nclass GreaterThan extends _Signal__WEBPACK_IMPORTED_MODULE_2__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(GreaterThan.getDefaults(), arguments, [\"value\"])));\n        this.name = \"GreaterThan\";\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(GreaterThan.getDefaults(), arguments, [\"value\"]);\n        this._subtract = this.input = new _Subtract__WEBPACK_IMPORTED_MODULE_1__.Subtract({\n            context: this.context,\n            value: options.value\n        });\n        this._gtz = this.output = new _GreaterThanZero__WEBPACK_IMPORTED_MODULE_3__.GreaterThanZero({ context: this.context });\n        this.comparator = this._param = this._subtract.subtrahend;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, \"comparator\");\n        // connect\n        this._subtract.connect(this._gtz);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._gtz.dispose();\n        this._subtract.dispose();\n        this.comparator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThan.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/GreaterThan.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GreaterThanZero.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GreaterThanZero.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GreaterThanZero\": () => (/* binding */ GreaterThanZero)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n/**\n * GreaterThanZero outputs 1 when the input is strictly greater than zero\n * @example\n * return Tone.Offline(() => {\n * \tconst gt0 = new Tone.GreaterThanZero().toDestination();\n * \tconst sig = new Tone.Signal(0.5).connect(gt0);\n * \tsig.setValueAtTime(-1, 0.05);\n * }, 0.1, 1);\n * @category Signal\n */\nclass GreaterThanZero extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GreaterThanZero.getDefaults(), arguments)));\n        this.name = \"GreaterThanZero\";\n        this._thresh = this.output = new _WaveShaper__WEBPACK_IMPORTED_MODULE_2__.WaveShaper({\n            context: this.context,\n            length: 127,\n            mapping: (val) => {\n                if (val <= 0) {\n                    return 0;\n                }\n                else {\n                    return 1;\n                }\n            },\n        });\n        this._scale = this.input = new _Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: 10000\n        });\n        // connections\n        this._scale.connect(this._thresh);\n    }\n    dispose() {\n        super.dispose();\n        this._scale.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThanZero.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/GreaterThanZero.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Multiply.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Multiply.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Multiply\": () => (/* binding */ Multiply)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n/**\n * Multiply two incoming signals. Or, if a number is given in the constructor,\n * multiplies the incoming signal by that value.\n *\n * @example\n * // multiply two signals\n * const mult = new Tone.Multiply();\n * const sigA = new Tone.Signal(3);\n * const sigB = new Tone.Signal(4);\n * sigA.connect(mult);\n * sigB.connect(mult.factor);\n * // output of mult is 12.\n * @example\n * // multiply a signal and a number\n * const mult = new Tone.Multiply(10);\n * const sig = new Tone.Signal(2).connect(mult);\n * // the output of mult is 20.\n * @category Signal\n */\nclass Multiply extends _Signal__WEBPACK_IMPORTED_MODULE_2__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Multiply.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Multiply\";\n        /**\n         * Indicates if the value should be overridden on connection\n         */\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Multiply.getDefaults(), arguments, [\"value\"]);\n        this._mult = this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this.factor = this._param = this._mult.gain;\n        this.factor.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Multiply.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Multiply.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Negate.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Negate.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Negate\": () => (/* binding */ Negate)\n/* harmony export */ });\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n/**\n * Negate the incoming signal. i.e. an input signal of 10 will output -10\n *\n * @example\n * const neg = new Tone.Negate();\n * const sig = new Tone.Signal(-2).connect(neg);\n * // output of neg is positive 2.\n * @category Signal\n */\nclass Negate extends _SignalOperator__WEBPACK_IMPORTED_MODULE_1__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Negate\";\n        /**\n         * negation is done by multiplying by -1\n         */\n        this._multiply = new _Multiply__WEBPACK_IMPORTED_MODULE_0__.Multiply({\n            context: this.context,\n            value: -1,\n        });\n        /**\n         * The input and output are equal to the multiply node\n         */\n        this.input = this._multiply;\n        this.output = this._multiply;\n    }\n    /**\n     * clean up\n     * @returns {Negate} this\n     */\n    dispose() {\n        super.dispose();\n        this._multiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Negate.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Negate.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Pow.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Pow.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Pow\": () => (/* binding */ Pow)\n/* harmony export */ });\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n/**\n * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]\n *\n * @example\n * const pow = new Tone.Pow(2);\n * const sig = new Tone.Signal(0.5).connect(pow);\n * // output of pow is 0.25.\n * @category Signal\n */\nclass Pow extends _SignalOperator__WEBPACK_IMPORTED_MODULE_2__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Pow.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Pow\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Pow.getDefaults(), arguments, [\"value\"]);\n        this._exponentScaler = this.input = this.output = new _WaveShaper__WEBPACK_IMPORTED_MODULE_0__.WaveShaper({\n            context: this.context,\n            mapping: this._expFunc(options.value),\n            length: 8192,\n        });\n        this._exponent = options.value;\n    }\n    static getDefaults() {\n        return Object.assign(_SignalOperator__WEBPACK_IMPORTED_MODULE_2__.SignalOperator.getDefaults(), {\n            value: 1,\n        });\n    }\n    /**\n     * the function which maps the waveshaper\n     * @param exponent exponent value\n     */\n    _expFunc(exponent) {\n        return (val) => {\n            return Math.pow(Math.abs(val), exponent);\n        };\n    }\n    /**\n     * The value of the exponent.\n     */\n    get value() {\n        return this._exponent;\n    }\n    set value(exponent) {\n        this._exponent = exponent;\n        this._exponentScaler.setMap(this._expFunc(this._exponent));\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._exponentScaler.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Pow.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Pow.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Scale.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Scale.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Scale\": () => (/* binding */ Scale)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Add__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n/**\n * Performs a linear scaling on an input signal.\n * Scales a NormalRange input to between\n * outputMin and outputMax.\n *\n * @example\n * const scale = new Tone.Scale(50, 100);\n * const signal = new Tone.Signal(0.5).connect(scale);\n * // the output of scale equals 75\n * @category Signal\n */\nclass Scale extends _SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Scale.getDefaults(), arguments, [\"min\", \"max\"])));\n        this.name = \"Scale\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Scale.getDefaults(), arguments, [\"min\", \"max\"]);\n        this._mult = this.input = new _Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: options.max - options.min,\n        });\n        this._add = this.output = new _Add__WEBPACK_IMPORTED_MODULE_1__.Add({\n            context: this.context,\n            value: options.min,\n        });\n        this._min = options.min;\n        this._max = options.max;\n        this.input.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator.getDefaults(), {\n            max: 1,\n            min: 0,\n        });\n    }\n    /**\n     * The minimum output value. This number is output when the value input value is 0.\n     */\n    get min() {\n        return this._min;\n    }\n    set min(min) {\n        this._min = min;\n        this._setRange();\n    }\n    /**\n     * The maximum output value. This number is output when the value input value is 1.\n     */\n    get max() {\n        return this._max;\n    }\n    set max(max) {\n        this._max = max;\n        this._setRange();\n    }\n    /**\n     * set the values\n     */\n    _setRange() {\n        this._add.value = this._min;\n        this._mult.value = this._max - this._min;\n    }\n    dispose() {\n        super.dispose();\n        this._add.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Scale.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Scale.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/ScaleExp.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/ScaleExp.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ScaleExp\": () => (/* binding */ ScaleExp)\n/* harmony export */ });\n/* harmony import */ var _Scale__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Pow__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n\n\n\n/**\n * Performs an exponential scaling on an input signal.\n * Scales a NormalRange value [0,1] exponentially\n * to the output range of outputMin to outputMax.\n * @example\n * const scaleExp = new Tone.ScaleExp(0, 100, 2);\n * const signal = new Tone.Signal(0.5).connect(scaleExp);\n * @category Signal\n */\nclass ScaleExp extends _Scale__WEBPACK_IMPORTED_MODULE_0__.Scale {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"])));\n        this.name = \"ScaleExp\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"]);\n        this.input = this._exp = new _Pow__WEBPACK_IMPORTED_MODULE_2__.Pow({\n            context: this.context,\n            value: options.exponent,\n        });\n        this._exp.connect(this._mult);\n    }\n    static getDefaults() {\n        return Object.assign(_Scale__WEBPACK_IMPORTED_MODULE_0__.Scale.getDefaults(), {\n            exponent: 1,\n        });\n    }\n    /**\n     * Instead of interpolating linearly between the [[min]] and\n     * [[max]] values, setting the exponent will interpolate between\n     * the two values with an exponential curve.\n     */\n    get exponent() {\n        return this._exp.value;\n    }\n    set exponent(exp) {\n        this._exp.value = exp;\n    }\n    dispose() {\n        super.dispose();\n        this._exp.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ScaleExp.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/ScaleExp.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Signal.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Signal.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Signal\": () => (/* binding */ Signal),\n/* harmony export */   \"connectSignal\": () => (/* binding */ connectSignal)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ToneConstantSource__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneConstantSource */ \"./node_modules/tone/build/esm/signal/ToneConstantSource.js\");\n\n\n\n\n\n\n/**\n * A signal is an audio-rate value. Tone.Signal is a core component of the library.\n * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n * has all of the methods available to native Web Audio\n * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n * as well as additional conveniences. Read more about working with signals\n * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // a scheduleable signal which can be connected to control an AudioParam or another Signal\n * const signal = new Tone.Signal({\n * \tvalue: \"C4\",\n * \tunits: \"frequency\"\n * }).connect(osc.frequency);\n * // the scheduled ramp controls the connected signal\n * signal.rampTo(\"C2\", 4, \"+0.5\");\n * @category Signal\n */\nclass Signal extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"Signal\";\n        /**\n         * Indicates if the value should be overridden on connection.\n         */\n        this.override = true;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this.output = this._constantSource = new _ToneConstantSource__WEBPACK_IMPORTED_MODULE_4__.ToneConstantSource({\n            context: this.context,\n            convert: options.convert,\n            offset: options.value,\n            units: options.units,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this._constantSource.start(0);\n        this.input = this._param = this._constantSource.offset;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            convert: true,\n            units: \"number\",\n            value: 0,\n        });\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        // start it only when connected to something\n        connectSignal(this, destination, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        this._constantSource.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // just a proxy for the ConstantSourceNode's offset AudioParam\n    // all docs are generated from AbstractParam.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        this._param.setValueAtTime(value, time);\n        return this;\n    }\n    getValueAtTime(time) {\n        return this._param.getValueAtTime(time);\n    }\n    setRampPoint(time) {\n        this._param.setRampPoint(time);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        this._param.linearRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        this._param.exponentialRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        this._param.exponentialRampTo(value, rampTime, startTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        this._param.linearRampTo(value, rampTime, startTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        this._param.targetRampTo(value, rampTime, startTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        this._param.exponentialApproachValueAtTime(value, time, rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        this._param.setTargetAtTime(value, startTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        this._param.setValueCurveAtTime(values, startTime, duration, scaling);\n        return this;\n    }\n    cancelScheduledValues(time) {\n        this._param.cancelScheduledValues(time);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        this._param.cancelAndHoldAtTime(time);\n        return this;\n    }\n    rampTo(value, rampTime, startTime) {\n        this._param.rampTo(value, rampTime, startTime);\n        return this;\n    }\n    get value() {\n        return this._param.value;\n    }\n    set value(value) {\n        this._param.value = value;\n    }\n    get convert() {\n        return this._param.convert;\n    }\n    set convert(convert) {\n        this._param.convert = convert;\n    }\n    get units() {\n        return this._param.units;\n    }\n    get overridden() {\n        return this._param.overridden;\n    }\n    set overridden(overridden) {\n        this._param.overridden = overridden;\n    }\n    get maxValue() {\n        return this._param.maxValue;\n    }\n    get minValue() {\n        return this._param.minValue;\n    }\n    /**\n     * See [[Param.apply]].\n     */\n    apply(param) {\n        this._param.apply(param);\n        return this;\n    }\n}\n/**\n * When connecting from a signal, it's necessary to zero out the node destination\n * node if that node is also a signal. If the destination is not 0, then the values\n * will be summed. This method insures that the output of the destination signal will\n * be the same as the source signal, making the destination signal a pass through node.\n * @param signal The output signal to connect from\n * @param destination the destination to connect to\n * @param outputNum the optional output number\n * @param inputNum the input number\n */\nfunction connectSignal(signal, destination, outputNum, inputNum) {\n    if (destination instanceof _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param || (0,_core_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isAudioParam)(destination) ||\n        (destination instanceof Signal && destination.override)) {\n        // cancel changes\n        destination.cancelScheduledValues(0);\n        // reset the value\n        destination.setValueAtTime(0, 0);\n        // mark the value as overridden\n        if (destination instanceof Signal) {\n            destination.overridden = true;\n        }\n    }\n    (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(signal, destination, outputNum, inputNum);\n}\n//# sourceMappingURL=Signal.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Signal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/SignalOperator.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/SignalOperator.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SignalOperator\": () => (/* binding */ SignalOperator)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n/**\n * A signal operator has an input and output and modifies the signal.\n */\nclass SignalOperator extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(SignalOperator.getDefaults(), arguments, [\"context\"])));\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        (0,_Signal__WEBPACK_IMPORTED_MODULE_2__.connectSignal)(this, destination, outputNum, inputNum);\n        return this;\n    }\n}\n//# sourceMappingURL=SignalOperator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/SignalOperator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Subtract.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Subtract.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Subtract\": () => (/* binding */ Subtract)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Negate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n\n/**\n * Subtract the signal connected to the input is subtracted from the signal connected\n * The subtrahend.\n *\n * @example\n * // subtract a scalar from a signal\n * const sub = new Tone.Subtract(1);\n * const sig = new Tone.Signal(4).connect(sub);\n * // the output of sub is 3.\n * @example\n * // subtract two signals\n * const sub = new Tone.Subtract();\n * const sigA = new Tone.Signal(10);\n * const sigB = new Tone.Signal(2.5);\n * sigA.connect(sub);\n * sigB.connect(sub.subtrahend);\n * // output of sub is 7.5\n * @category Signal\n */\nclass Subtract extends _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Subtract.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Subtract\";\n        /**\n         * the summing node\n         */\n        this._sum = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * Negate the input of the second input before connecting it to the summing node.\n         */\n        this._neg = new _signal_Negate__WEBPACK_IMPORTED_MODULE_3__.Negate({ context: this.context });\n        /**\n         * The value which is subtracted from the main signal\n         */\n        this.subtrahend = this._param;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(this._constantSource, this._neg, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(_signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._neg.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Subtract.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Subtract.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/SyncedSignal.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/SyncedSignal.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SyncedSignal\": () => (/* binding */ SyncedSignal)\n/* harmony export */ });\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _ToneConstantSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneConstantSource */ \"./node_modules/tone/build/esm/signal/ToneConstantSource.js\");\n\n\n\n\n/**\n * Adds the ability to synchronize the signal to the [[Transport]]\n */\nclass SyncedSignal extends _Signal__WEBPACK_IMPORTED_MODULE_0__.Signal {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"SyncedSignal\";\n        /**\n         * Don't override when something is connected to the input\n         */\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this._lastVal = options.value;\n        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), \"1i\");\n        this._syncedCallback = this._anchorValue.bind(this);\n        this.context.transport.on(\"start\", this._syncedCallback);\n        this.context.transport.on(\"pause\", this._syncedCallback);\n        this.context.transport.on(\"stop\", this._syncedCallback);\n        // disconnect the constant source from the output and replace it with another one\n        this._constantSource.disconnect();\n        this._constantSource.stop(0);\n        // create a new one\n        this._constantSource = this.output = new _ToneConstantSource__WEBPACK_IMPORTED_MODULE_3__.ToneConstantSource({\n            context: this.context,\n            offset: options.value,\n            units: options.units,\n        }).start(0);\n        this.setValueAtTime(options.value, 0);\n    }\n    /**\n     * Callback which is invoked every tick.\n     */\n    _onTick(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        // approximate ramp curves with linear ramps\n        if (this._lastVal !== val) {\n            this._lastVal = val;\n            this._constantSource.offset.setValueAtTime(val, time);\n        }\n    }\n    /**\n     * Anchor the value at the start and stop of the Transport\n     */\n    _anchorValue(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        this._lastVal = val;\n        this._constantSource.offset.cancelAndHoldAtTime(time);\n        this._constantSource.offset.setValueAtTime(val, time);\n    }\n    getValueAtTime(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        return super.getValueAtTime(computedTime);\n    }\n    setValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.setValueAtTime(value, computedTime);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.linearRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.exponentialRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.setTargetAtTime(value, computedTime, timeConstant);\n        return this;\n    }\n    cancelScheduledValues(startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.cancelScheduledValues(computedTime);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        duration = this.toSeconds(duration);\n        super.setValueCurveAtTime(values, computedTime, duration, scaling);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.cancelAndHoldAtTime(computedTime);\n        return this;\n    }\n    setRampPoint(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.setRampPoint(computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.exponentialRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.linearRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.targetRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.context.transport.clear(this._synced);\n        this.context.transport.off(\"start\", this._syncedCallback);\n        this.context.transport.off(\"pause\", this._syncedCallback);\n        this.context.transport.off(\"stop\", this._syncedCallback);\n        this._constantSource.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=SyncedSignal.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/SyncedSignal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/ToneConstantSource.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/ToneConstantSource.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneConstantSource\": () => (/* binding */ ToneConstantSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n\n\n\n\n/**\n * Wrapper around the native fire-and-forget ConstantSource.\n * Adds the ability to reschedule the stop method.\n * @category Signal\n */\nclass ToneConstantSource extends _source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneConstantSource.getDefaults(), arguments, [\"offset\"]));\n        this.name = \"ToneConstantSource\";\n        /**\n         * The signal generator\n         */\n        this._source = this.context.createConstantSource();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneConstantSource.getDefaults(), arguments, [\"offset\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._source, this._gainNode);\n        this.offset = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._source.offset,\n            units: options.units,\n            value: options.offset,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource.getDefaults(), {\n            convert: true,\n            offset: 1,\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the source node at the given time\n     * @param  time When to start the source\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._source.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._source.stop(time);\n    }\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._source.disconnect();\n        this.offset.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneConstantSource.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/ToneConstantSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/WaveShaper.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/WaveShaper.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WaveShaper\": () => (/* binding */ WaveShaper)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n\n/**\n * Wraps the native Web Audio API\n * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // multiply the output of the signal by 2 using the waveshaper's function\n * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);\n * const signal = new Tone.Signal(440).connect(timesTwo);\n * @category Signal\n */\nclass WaveShaper extends _SignalOperator__WEBPACK_IMPORTED_MODULE_4__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"])));\n        this.name = \"WaveShaper\";\n        /**\n         * the waveshaper node\n         */\n        this._shaper = this.context.createWaveShaper();\n        /**\n         * The input to the waveshaper node.\n         */\n        this.input = this._shaper;\n        /**\n         * The output from the waveshaper node\n         */\n        this.output = this._shaper;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"]);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isArray)(options.mapping) || options.mapping instanceof Float32Array) {\n            this.curve = Float32Array.from(options.mapping);\n        }\n        else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isFunction)(options.mapping)) {\n            this.setMap(options.mapping, options.length);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal.getDefaults(), {\n            length: 1024,\n        });\n    }\n    /**\n     * Uses a mapping function to set the value of the curve.\n     * @param mapping The function used to define the values.\n     *                The mapping function take two arguments:\n     *                the first is the value at the current position\n     *                which goes from -1 to 1 over the number of elements\n     *                in the curve array. The second argument is the array position.\n     * @example\n     * const shaper = new Tone.WaveShaper();\n     * // map the input signal from [-1, 1] to [0, 10]\n     * shaper.setMap((val, index) => (val + 1) * 5);\n     */\n    setMap(mapping, length = 1024) {\n        const array = new Float32Array(length);\n        for (let i = 0, len = length; i < len; i++) {\n            const normalized = (i / (len - 1)) * 2 - 1;\n            array[i] = mapping(normalized, i);\n        }\n        this.curve = array;\n        return this;\n    }\n    /**\n     * The array to set as the waveshaper curve. For linear curves\n     * array length does not make much difference, but for complex curves\n     * longer arrays will provide smoother interpolation.\n     */\n    get curve() {\n        return this._shaper.curve;\n    }\n    set curve(mapping) {\n        this._shaper.curve = mapping;\n    }\n    /**\n     * Specifies what type of oversampling (if any) should be used when\n     * applying the shaping curve. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        const isOverSampleType = [\"none\", \"2x\", \"4x\"].some(str => str.includes(oversampling));\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(isOverSampleType, \"oversampling must be either 'none', '2x', or '4x'\");\n        this._shaper.oversample = oversampling;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._shaper.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=WaveShaper.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/WaveShaper.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Zero.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Zero.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Zero\": () => (/* binding */ Zero)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n/**\n * Tone.Zero outputs 0's at audio-rate. The reason this has to be\n * it's own class is that many browsers optimize out Tone.Signal\n * with a value of 0 and will not process nodes further down the graph.\n * @category Signal\n */\nclass Zero extends _SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Zero.getDefaults(), arguments)));\n        this.name = \"Zero\";\n        /**\n         * The gain node which connects the constant source to the output\n         */\n        this._gain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * Only outputs 0\n         */\n        this.output = this._gain;\n        /**\n         * no input node\n         */\n        this.input = undefined;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this.context.getConstant(0), this._gain);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.disconnect)(this.context.getConstant(0), this._gain);\n        return this;\n    }\n}\n//# sourceMappingURL=Zero.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/Zero.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _Abs__WEBPACK_IMPORTED_MODULE_1__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _Add__WEBPACK_IMPORTED_MODULE_0__.Add),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _AudioToGain__WEBPACK_IMPORTED_MODULE_2__.AudioToGain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _GainToAudio__WEBPACK_IMPORTED_MODULE_3__.GainToAudio),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _GreaterThan__WEBPACK_IMPORTED_MODULE_4__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _GreaterThanZero__WEBPACK_IMPORTED_MODULE_5__.GreaterThanZero),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _Negate__WEBPACK_IMPORTED_MODULE_7__.Negate),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _Pow__WEBPACK_IMPORTED_MODULE_8__.Pow),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _Scale__WEBPACK_IMPORTED_MODULE_10__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _ScaleExp__WEBPACK_IMPORTED_MODULE_11__.ScaleExp),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _Signal__WEBPACK_IMPORTED_MODULE_9__.Signal),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _Subtract__WEBPACK_IMPORTED_MODULE_12__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _SyncedSignal__WEBPACK_IMPORTED_MODULE_13__.SyncedSignal),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _WaveShaper__WEBPACK_IMPORTED_MODULE_14__.WaveShaper),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _Zero__WEBPACK_IMPORTED_MODULE_15__.Zero),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _Signal__WEBPACK_IMPORTED_MODULE_9__.connectSignal)\n/* harmony export */ });\n/* harmony import */ var _Add__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _Abs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Abs */ \"./node_modules/tone/build/esm/signal/Abs.js\");\n/* harmony import */ var _AudioToGain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _GainToAudio__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./GainToAudio */ \"./node_modules/tone/build/esm/signal/GainToAudio.js\");\n/* harmony import */ var _GreaterThan__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./GreaterThan */ \"./node_modules/tone/build/esm/signal/GreaterThan.js\");\n/* harmony import */ var _GreaterThanZero__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./GreaterThanZero */ \"./node_modules/tone/build/esm/signal/GreaterThanZero.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Negate__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _Pow__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Scale__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _ScaleExp__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ScaleExp */ \"./node_modules/tone/build/esm/signal/ScaleExp.js\");\n/* harmony import */ var _Subtract__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _SyncedSignal__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SyncedSignal */ \"./node_modules/tone/build/esm/signal/SyncedSignal.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Zero__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./Zero */ \"./node_modules/tone/build/esm/signal/Zero.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/signal/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/Noise.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/source/Noise.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Noise\": () => (/* binding */ Noise)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n\n\n\n\n\n/**\n * Noise is a noise generator. It uses looped noise buffers to save on performance.\n * Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).\n *\n * @example\n * // initialize the noise and start\n * const noise = new Tone.Noise(\"pink\").start();\n * // make an autofilter to shape the noise\n * const autoFilter = new Tone.AutoFilter({\n * \tfrequency: \"8n\",\n * \tbaseFrequency: 200,\n * \toctaves: 8\n * }).toDestination().start();\n * // connect the noise\n * noise.connect(autoFilter);\n * // start the autofilter LFO\n * autoFilter.start();\n * @category Source\n */\nclass Noise extends _source_Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Noise.getDefaults(), arguments, [\"type\"]));\n        this.name = \"Noise\";\n        /**\n         * Private reference to the source\n         */\n        this._source = null;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Noise.getDefaults(), arguments, [\"type\"]);\n        this._playbackRate = options.playbackRate;\n        this.type = options.type;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_source_Source__WEBPACK_IMPORTED_MODULE_3__.Source.getDefaults(), {\n            fadeIn: 0,\n            fadeOut: 0,\n            playbackRate: 1,\n            type: \"white\",\n        });\n    }\n    /**\n     * The type of the noise. Can be \"white\", \"brown\", or \"pink\".\n     * @example\n     * const noise = new Tone.Noise().toDestination().start();\n     * noise.type = \"brown\";\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(type in _noiseBuffers, \"Noise: invalid type: \" + type);\n        if (this._type !== type) {\n            this._type = type;\n            // if it's playing, stop and restart it\n            if (this.state === \"started\") {\n                const now = this.now();\n                this._stop(now);\n                this._start(now);\n            }\n        }\n    }\n    /**\n     * The playback rate of the noise. Affects\n     * the \"frequency\" of the noise.\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        if (this._source) {\n            this._source.playbackRate.value = rate;\n        }\n    }\n    /**\n     * internal start method\n     */\n    _start(time) {\n        const buffer = _noiseBuffers[this._type];\n        this._source = new _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_4__.ToneBufferSource({\n            url: buffer,\n            context: this.context,\n            fadeIn: this._fadeIn,\n            fadeOut: this._fadeOut,\n            loop: true,\n            onended: () => this.onstop(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));\n    }\n    /**\n     * internal stop method\n     */\n    _stop(time) {\n        if (this._source) {\n            this._source.stop(this.toSeconds(time));\n            this._source = null;\n        }\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(time) {\n        this._fadeIn = time;\n        if (this._source) {\n            this._source.fadeIn = this._fadeIn;\n        }\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(time) {\n        this._fadeOut = time;\n        if (this._source) {\n            this._source.fadeOut = this._fadeOut;\n        }\n    }\n    _restart(time) {\n        // TODO could be optimized by cancelling the buffer source 'stop'\n        this._stop(time);\n        this._start(time);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this._source) {\n            this._source.disconnect();\n        }\n        return this;\n    }\n}\n//--------------------\n// THE NOISE BUFFERS\n//--------------------\n// Noise buffer stats\nconst BUFFER_LENGTH = 44100 * 5;\nconst NUM_CHANNELS = 2;\n/**\n * Cache the noise buffers\n */\nconst _noiseCache = {\n    brown: null,\n    pink: null,\n    white: null,\n};\n/**\n * The noise arrays. Generated on initialization.\n * borrowed heavily from https://github.com/zacharydenton/noise.js\n * (c) 2013 Zach Denton (MIT)\n */\nconst _noiseBuffers = {\n    get brown() {\n        if (!_noiseCache.brown) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let lastOut = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    channel[i] = (lastOut + (0.02 * white)) / 1.02;\n                    lastOut = channel[i];\n                    channel[i] *= 3.5; // (roughly) compensate for gain\n                }\n            }\n            _noiseCache.brown = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.brown;\n    },\n    get pink() {\n        if (!_noiseCache.pink) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let b0, b1, b2, b3, b4, b5, b6;\n                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    b0 = 0.99886 * b0 + white * 0.0555179;\n                    b1 = 0.99332 * b1 + white * 0.0750759;\n                    b2 = 0.96900 * b2 + white * 0.1538520;\n                    b3 = 0.86650 * b3 + white * 0.3104856;\n                    b4 = 0.55000 * b4 + white * 0.5329522;\n                    b5 = -0.7616 * b5 - white * 0.0168980;\n                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;\n                    channel[i] *= 0.11; // (roughly) compensate for gain\n                    b6 = white * 0.115926;\n                }\n            }\n            _noiseCache.pink = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.pink;\n    },\n    get white() {\n        if (!_noiseCache.white) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    channel[i] = Math.random() * 2 - 1;\n                }\n            }\n            _noiseCache.white = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.white;\n    },\n};\n//# sourceMappingURL=Noise.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/Noise.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/OneShotSource.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/OneShotSource.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OneShotSource\": () => (/* binding */ OneShotSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n/**\n * Base class for fire-and-forget nodes\n */\nclass OneShotSource extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * The callback to invoke after the\n         * source is done playing.\n         */\n        this.onended = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp;\n        /**\n         * The start time\n         */\n        this._startTime = -1;\n        /**\n         * The stop time\n         */\n        this._stopTime = -1;\n        /**\n         * The id of the timeout\n         */\n        this._timeout = -1;\n        /**\n         * The public output node\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output gain node.\n         */\n        this._gainNode = this.output;\n        /**\n         * Get the playback state at the given time\n         */\n        this.getStateAtTime = function (time) {\n            const computedTime = this.toSeconds(time);\n            if (this._startTime !== -1 &&\n                computedTime >= this._startTime &&\n                (this._stopTime === -1 || computedTime <= this._stopTime)) {\n                return \"started\";\n            }\n            else {\n                return \"stopped\";\n            }\n        };\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n        this._curve = options.curve;\n        this.onended = options.onended;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            curve: \"linear\",\n            fadeIn: 0,\n            fadeOut: 0,\n            onended: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n        });\n    }\n    /**\n     * Start the source at the given time\n     * @param  time When to start the source\n     */\n    _startGain(time, gain = 1) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime === -1, \"Source cannot be started more than once\");\n        // apply a fade in envelope\n        const fadeInTime = this.toSeconds(this._fadeIn);\n        // record the start time\n        this._startTime = time + fadeInTime;\n        this._startTime = Math.max(this._startTime, this.context.currentTime);\n        // schedule the envelope\n        if (fadeInTime > 0) {\n            this._gainNode.gain.setValueAtTime(0, time);\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);\n            }\n            else {\n                this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);\n            }\n        }\n        else {\n            this._gainNode.gain.setValueAtTime(gain, time);\n        }\n        return this;\n    }\n    /**\n     * Stop the source node at the given time.\n     * @param time When to stop the source\n     */\n    stop(time) {\n        this.log(\"stop\", time);\n        this._stopGain(this.toSeconds(time));\n        return this;\n    }\n    /**\n     * Stop the source at the given time\n     * @param  time When to stop the source\n     */\n    _stopGain(time) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime !== -1, \"'start' must be called before 'stop'\");\n        // cancel the previous stop\n        this.cancelStop();\n        // the fadeOut time\n        const fadeOutTime = this.toSeconds(this._fadeOut);\n        // schedule the stop callback\n        this._stopTime = this.toSeconds(time) + fadeOutTime;\n        this._stopTime = Math.max(this._stopTime, this.context.currentTime);\n        if (fadeOutTime > 0) {\n            // start the fade out curve at the given time\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampTo(0, fadeOutTime, time);\n            }\n            else {\n                this._gainNode.gain.targetRampTo(0, fadeOutTime, time);\n            }\n        }\n        else {\n            // stop any ongoing ramps, and set the value to 0\n            this._gainNode.gain.cancelAndHoldAtTime(time);\n            this._gainNode.gain.setValueAtTime(0, time);\n        }\n        this.context.clearTimeout(this._timeout);\n        this._timeout = this.context.setTimeout(() => {\n            // allow additional time for the exponential curve to fully decay\n            const additionalTail = this._curve === \"exponential\" ? fadeOutTime * 2 : 0;\n            this._stopSource(this.now() + additionalTail);\n            this._onended();\n        }, this._stopTime - this.context.currentTime);\n        return this;\n    }\n    /**\n     * Invoke the onended callback\n     */\n    _onended() {\n        if (this.onended !== _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n            this.onended(this);\n            // overwrite onended to make sure it only is called once\n            this.onended = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp;\n            // dispose when it's ended to free up for garbage collection only in the online context\n            if (!this.context.isOffline) {\n                const disposeCallback = () => this.dispose();\n                // @ts-ignore\n                if (typeof window.requestIdleCallback !== \"undefined\") {\n                    // @ts-ignore\n                    window.requestIdleCallback(disposeCallback);\n                }\n                else {\n                    setTimeout(disposeCallback, 1000);\n                }\n            }\n        }\n    }\n    /**\n     * Get the playback state at the current time\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Cancel a scheduled stop event\n     */\n    cancelStop() {\n        this.log(\"cancelStop\");\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime !== -1, \"Source is not started\");\n        // cancel the stop envelope\n        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);\n        this.context.clearTimeout(this._timeout);\n        this._stopTime = -1;\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OneShotSource.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/OneShotSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/Source.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/source/Source.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Source\": () => (/* binding */ Source)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_Destination__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Destination */ \"./node_modules/tone/build/esm/core/context/Destination.js\");\n/* harmony import */ var _core_clock_Transport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/clock/Transport */ \"./node_modules/tone/build/esm/core/clock/Transport.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Base class for sources.\n * start/stop of this.context.transport.\n *\n * ```\n * // Multiple state change events can be chained together,\n * // but must be set in the correct order and with ascending times\n * // OK\n * state.start().stop(\"+0.2\");\n * // OK\n * state.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n * // BAD\n * state.stop(\"+0.2\").start();\n * // BAD\n * state.start(\"+0.3\").stop(\"+0.2\");\n * ```\n */\nclass Source extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * Sources have no inputs\n         */\n        this.input = undefined;\n        /**\n         * Keep track of the scheduled state.\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_6__.StateTimeline(\"stopped\");\n        /**\n         * The synced `start` callback function from the transport\n         */\n        this._synced = false;\n        /**\n         * Keep track of all of the scheduled event ids\n         */\n        this._scheduled = [];\n        /**\n         * Placeholder functions for syncing/unsyncing to transport\n         */\n        this._syncedStart = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this._syncedStop = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this._state.memory = 100;\n        this._state.increasing = true;\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            mute: options.mute,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, \"volume\");\n        this.onstop = options.onstop;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            onstop: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            volume: 0,\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/ahntone_c3.mp3\", () => {\n     * \tplayer.start();\n     * \tconsole.log(player.state);\n     * }).toDestination();\n     */\n    get state() {\n        if (this._synced) {\n            if (this.context.transport.state === \"started\") {\n                return this._state.getValueAtTime(this.context.transport.seconds);\n            }\n            else {\n                return \"stopped\";\n            }\n        }\n        else {\n            return this._state.getValueAtTime(this.now());\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // mute the output\n     * osc.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * Ensure that the scheduled time is not before the current time.\n     * Should only be used when scheduled unsynced.\n     */\n    _clampToCurrentTime(time) {\n        if (this._synced) {\n            return time;\n        }\n        else {\n            return Math.max(time, this.context.currentTime);\n        }\n    }\n    /**\n     * Start the source at the specified time. If no time is given,\n     * start the source now.\n     * @param  time When the source should be started.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start(\"+0.5\"); // starts the source 0.5 seconds from now\n     */\n    start(time, offset, duration) {\n        let computedTime = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        // if it's started, stop it and restart it\n        if (!this._synced && this._state.getValueAtTime(computedTime) === \"started\") {\n            // time should be strictly greater than the previous start time\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_9__.GT)(computedTime, this._state.get(computedTime).time), \"Start time must be strictly greater than previous start time\");\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            this.log(\"restart\", computedTime);\n            this.restart(computedTime, offset, duration);\n        }\n        else {\n            this.log(\"start\", computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            if (this._synced) {\n                // add the offset time to the event\n                const event = this._state.get(computedTime);\n                if (event) {\n                    event.offset = this.toSeconds((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.defaultArg)(offset, 0));\n                    event.duration = duration ? this.toSeconds(duration) : undefined;\n                }\n                const sched = this.context.transport.schedule(t => {\n                    this._start(t, offset, duration);\n                }, computedTime);\n                this._scheduled.push(sched);\n                // if the transport is already started\n                // and the time is greater than where the transport is\n                if (this.context.transport.state === \"started\" &&\n                    this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) {\n                    this._syncedStart(this.now(), this.context.transport.seconds);\n                }\n            }\n            else {\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assertContextRunning)(this.context);\n                this._start(computedTime, offset, duration);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the source at the specified time. If no time is given,\n     * stop the source now.\n     * @param  time When the source should be stopped.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start();\n     * source.stop(\"+0.5\"); // stops the source 0.5 seconds from now\n     */\n    stop(time) {\n        let computedTime = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        if (this._state.getValueAtTime(computedTime) === \"started\" || (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isDefined)(this._state.getNextState(\"started\", computedTime))) {\n            this.log(\"stop\", computedTime);\n            if (!this._synced) {\n                this._stop(computedTime);\n            }\n            else {\n                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);\n                this._scheduled.push(sched);\n            }\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"stopped\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Restart the source.\n     */\n    restart(time, offset, duration) {\n        time = this.toSeconds(time);\n        if (this._state.getValueAtTime(time) === \"started\") {\n            this._state.cancel(time);\n            this._restart(time, offset, duration);\n        }\n        return this;\n    }\n    /**\n     * Sync the source to the Transport so that all subsequent\n     * calls to `start` and `stop` are synced to the TransportTime\n     * instead of the AudioContext time.\n     *\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline\n     * osc.sync().start(0).stop(0.3);\n     * // start the transport.\n     * Tone.Transport.start();\n     * // set it to loop once a second\n     * Tone.Transport.loop = true;\n     * Tone.Transport.loopEnd = 1;\n     */\n    sync() {\n        if (!this._synced) {\n            this._synced = true;\n            this._syncedStart = (time, offset) => {\n                if (offset > 0) {\n                    // get the playback state at that time\n                    const stateEvent = this._state.get(offset);\n                    // listen for start events which may occur in the middle of the sync'ed time\n                    if (stateEvent && stateEvent.state === \"started\" && stateEvent.time !== offset) {\n                        // get the offset\n                        const startOffset = offset - this.toSeconds(stateEvent.time);\n                        let duration;\n                        if (stateEvent.duration) {\n                            duration = this.toSeconds(stateEvent.duration) - startOffset;\n                        }\n                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);\n                    }\n                }\n            };\n            this._syncedStop = time => {\n                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));\n                if (this._state.getValueAtTime(seconds) === \"started\") {\n                    this._stop(time);\n                }\n            };\n            this.context.transport.on(\"start\", this._syncedStart);\n            this.context.transport.on(\"loopStart\", this._syncedStart);\n            this.context.transport.on(\"stop\", this._syncedStop);\n            this.context.transport.on(\"pause\", this._syncedStop);\n            this.context.transport.on(\"loopEnd\", this._syncedStop);\n        }\n        return this;\n    }\n    /**\n     * Unsync the source to the Transport. See Source.sync\n     */\n    unsync() {\n        if (this._synced) {\n            this.context.transport.off(\"stop\", this._syncedStop);\n            this.context.transport.off(\"pause\", this._syncedStop);\n            this.context.transport.off(\"loopEnd\", this._syncedStop);\n            this.context.transport.off(\"start\", this._syncedStart);\n            this.context.transport.off(\"loopStart\", this._syncedStart);\n        }\n        this._synced = false;\n        // clear all of the scheduled ids\n        this._scheduled.forEach(id => this.context.transport.clear(id));\n        this._scheduled = [];\n        this._state.cancel(0);\n        // stop it also\n        this._stop(0);\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.onstop = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this.unsync();\n        this._volume.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Source.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/Source.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/UserMedia.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/source/UserMedia.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"UserMedia\": () => (/* binding */ UserMedia)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.\n * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n * to see which browsers are supported. Access to an external input\n * is limited to secure (HTTPS) connections.\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia().connect(meter);\n * mic.open().then(() => {\n * \t// promise resolves when input is available\n * \tconsole.log(\"mic open\");\n * \t// print the incoming mic levels in decibels\n * \tsetInterval(() => console.log(meter.getValue()), 100);\n * }).catch(e => {\n * \t// promise is rejected when the user doesn't have or allow mic access\n * \tconsole.log(\"mic not open\");\n * });\n * @category Source\n */\nclass UserMedia extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(UserMedia.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"UserMedia\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(UserMedia.getDefaults(), arguments, [\"volume\"]);\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_1__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, \"volume\");\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0\n        });\n    }\n    /**\n     * Open the media stream. If a string is passed in, it is assumed\n     * to be the label or id of the stream, if a number is passed in,\n     * it is the input number of the stream.\n     * @param  labelOrId The label or id of the audio input media device.\n     *                   With no argument, the default stream is opened.\n     * @return The promise is resolved when the stream is open.\n     */\n    open(labelOrId) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_6__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(UserMedia.supported, \"UserMedia is not supported\");\n            // close the previous stream\n            if (this.state === \"started\") {\n                this.close();\n            }\n            const devices = yield UserMedia.enumerateDevices();\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(labelOrId)) {\n                this._device = devices[labelOrId];\n            }\n            else {\n                this._device = devices.find((device) => {\n                    return device.label === labelOrId || device.deviceId === labelOrId;\n                });\n                // didn't find a matching device\n                if (!this._device && devices.length > 0) {\n                    this._device = devices[0];\n                }\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(this._device), `No matching device ${labelOrId}`);\n            }\n            // do getUserMedia\n            const constraints = {\n                audio: {\n                    echoCancellation: false,\n                    sampleRate: this.context.sampleRate,\n                    noiseSuppression: false,\n                    mozNoiseSuppression: false,\n                }\n            };\n            if (this._device) {\n                // @ts-ignore\n                constraints.audio.deviceId = this._device.deviceId;\n            }\n            const stream = yield navigator.mediaDevices.getUserMedia(constraints);\n            // start a new source only if the previous one is closed\n            if (!this._stream) {\n                this._stream = stream;\n                // Wrap a MediaStreamSourceNode around the live input stream.\n                const mediaStreamNode = this.context.createMediaStreamSource(stream);\n                // Connect the MediaStreamSourceNode to a gate gain node\n                (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(mediaStreamNode, this.output);\n                this._mediaStream = mediaStreamNode;\n            }\n            return this;\n        });\n    }\n    /**\n     * Close the media stream\n     */\n    close() {\n        if (this._stream && this._mediaStream) {\n            this._stream.getAudioTracks().forEach((track) => {\n                track.stop();\n            });\n            this._stream = undefined;\n            // remove the old media stream\n            this._mediaStream.disconnect();\n            this._mediaStream = undefined;\n        }\n        this._device = undefined;\n        return this;\n    }\n    /**\n     * Returns a promise which resolves with the list of audio input devices available.\n     * @return The promise that is resolved with the devices\n     * @example\n     * Tone.UserMedia.enumerateDevices().then((devices) => {\n     * \t// print the device labels\n     * \tconsole.log(devices.map(device => device.label));\n     * });\n     */\n    static enumerateDevices() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_6__.__awaiter)(this, void 0, void 0, function* () {\n            const allDevices = yield navigator.mediaDevices.enumerateDevices();\n            return allDevices.filter(device => {\n                return device.kind === \"audioinput\";\n            });\n        });\n    }\n    /**\n     * Returns the playback state of the source, \"started\" when the microphone is open\n     * and \"stopped\" when the mic is closed.\n     */\n    get state() {\n        return this._stream && this._stream.active ? \"started\" : \"stopped\";\n    }\n    /**\n     * Returns an identifier for the represented device that is\n     * persisted across sessions. It is un-guessable by other applications and\n     * unique to the origin of the calling application. It is reset when the\n     * user clears cookies (for Private Browsing, a different identifier is\n     * used that is not persisted across sessions). Returns undefined when the\n     * device is not open.\n     */\n    get deviceId() {\n        if (this._device) {\n            return this._device.deviceId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a group identifier. Two devices have the\n     * same group identifier if they belong to the same physical device.\n     * Returns null  when the device is not open.\n     */\n    get groupId() {\n        if (this._device) {\n            return this._device.groupId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a label describing this device (for example \"Built-in Microphone\").\n     * Returns undefined when the device is not open or label is not available\n     * because of permissions.\n     */\n    get label() {\n        if (this._device) {\n            return this._device.label;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const mic = new Tone.UserMedia();\n     * mic.open().then(() => {\n     * \t// promise resolves when input is available\n     * });\n     * // mute the output\n     * mic.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this.close();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n    /**\n     * If getUserMedia is supported by the browser.\n     */\n    static get supported() {\n        return (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(navigator.mediaDevices) &&\n            (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(navigator.mediaDevices.getUserMedia);\n    }\n}\n//# sourceMappingURL=UserMedia.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/UserMedia.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/GrainPlayer.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/GrainPlayer.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GrainPlayer\": () => (/* binding */ GrainPlayer)\n/* harmony export */ });\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_clock_Clock__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/clock/Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n * amount of time each small chunk of audio is played for and the overlap is the\n * amount of crossfading transition time between successive grains.\n * @category Source\n */\nclass GrainPlayer extends _Source__WEBPACK_IMPORTED_MODULE_0__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"GrainPlayer\";\n        /**\n         * Internal loopStart value\n         */\n        this._loopStart = 0;\n        /**\n         * Internal loopStart value\n         */\n        this._loopEnd = 0;\n        /**\n         * All of the currently playing BufferSources\n         */\n        this._activeSources = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this.buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer({\n            onload: options.onload,\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this._clock = new _core_clock_Clock__WEBPACK_IMPORTED_MODULE_4__.Clock({\n            context: this.context,\n            callback: this._tick.bind(this),\n            frequency: 1 / options.grainSize\n        });\n        this._playbackRate = options.playbackRate;\n        this._grainSize = options.grainSize;\n        this._overlap = options.overlap;\n        this.detune = options.detune;\n        // setup\n        this.overlap = options.overlap;\n        this.loop = options.loop;\n        this.playbackRate = options.playbackRate;\n        this.grainSize = options.grainSize;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.reverse = options.reverse;\n        this._clock.on(\"stop\", this._onstop.bind(this));\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_0__.Source.getDefaults(), {\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n            overlap: 0.1,\n            grainSize: 0.2,\n            playbackRate: 1,\n            detune: 0,\n            loop: false,\n            loopStart: 0,\n            loopEnd: 0,\n            reverse: false\n        });\n    }\n    /**\n     * Internal start method\n     */\n    _start(time, offset, duration) {\n        offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, 0);\n        offset = this.toSeconds(offset);\n        time = this.toSeconds(time);\n        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);\n        this._clock.start(time, offset / grainSize);\n        if (duration) {\n            this.stop(time + this.toSeconds(duration));\n        }\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Internal stop method\n     */\n    _stop(time) {\n        this._clock.stop(time);\n    }\n    /**\n     * Invoked when the clock is stopped\n     */\n    _onstop(time) {\n        // stop the players\n        this._activeSources.forEach((source) => {\n            source.fadeOut = 0;\n            source.stop(time);\n        });\n        this.onstop(this);\n    }\n    /**\n     * Invoked on each clock tick. scheduled a new grain at this time.\n     */\n    _tick(time) {\n        // check if it should stop looping\n        const ticks = this._clock.getTicksAtTime(time);\n        const offset = ticks * this._grainSize;\n        this.log(\"offset\", offset);\n        if (!this.loop && offset > this.buffer.duration) {\n            this.stop(time);\n            return;\n        }\n        // at the beginning of the file, the fade in should be 0\n        const fadeIn = offset < this._overlap ? 0 : this._overlap;\n        // create a buffer source\n        const source = new _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__.ToneBufferSource({\n            context: this.context,\n            url: this.buffer,\n            fadeIn: fadeIn,\n            fadeOut: this._overlap,\n            loop: this.loop,\n            loopStart: this._loopStart,\n            loopEnd: this._loopEnd,\n            // compute the playbackRate based on the detune\n            playbackRate: (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_6__.intervalToFrequencyRatio)(this.detune / 100)\n        }).connect(this.output);\n        source.start(time, this._grainSize * ticks);\n        source.stop(time + this._grainSize / this.playbackRate);\n        // add it to the active sources\n        this._activeSources.push(source);\n        // remove it when it's done\n        source.onended = () => {\n            const index = this._activeSources.indexOf(source);\n            if (index !== -1) {\n                this._activeSources.splice(index, 1);\n            }\n        };\n    }\n    /**\n     * The playback rate of the sample\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(rate, 0.001);\n        this._playbackRate = rate;\n        this.grainSize = this._grainSize;\n    }\n    /**\n     * The loop start time.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(time) {\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopStart = this.toSeconds(time);\n    }\n    /**\n     * The loop end time.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(time) {\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopEnd = this.toSeconds(time);\n    }\n    /**\n     * The direction the buffer should play in\n     */\n    get reverse() {\n        return this.buffer.reverse;\n    }\n    set reverse(rev) {\n        this.buffer.reverse = rev;\n    }\n    /**\n     * The size of each chunk of audio that the\n     * buffer is chopped into and played back at.\n     */\n    get grainSize() {\n        return this._grainSize;\n    }\n    set grainSize(size) {\n        this._grainSize = this.toSeconds(size);\n        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());\n    }\n    /**\n     * The duration of the cross-fade between successive grains.\n     */\n    get overlap() {\n        return this._overlap;\n    }\n    set overlap(time) {\n        const computedTime = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(computedTime, 0);\n        this._overlap = computedTime;\n    }\n    /**\n     * If all the buffer is loaded\n     */\n    get loaded() {\n        return this.buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        this.buffer.dispose();\n        this._clock.dispose();\n        this._activeSources.forEach((source) => source.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=GrainPlayer.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/buffer/GrainPlayer.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/Player.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/Player.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Player\": () => (/* binding */ Player)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Player is an audio file player with start, loop, and stop functions.\n * @example\n * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gong_1.mp3\").toDestination();\n * // play as soon as the buffer is loaded\n * player.autostart = true;\n * @category Source\n */\nclass Player extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Player.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Player\";\n        /**\n         * All of the active buffer source nodes\n         */\n        this._activeSources = new Set();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Player.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer({\n            onload: this._onload.bind(this, options.onload),\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this.autostart = options.autostart;\n        this._loop = options.loop;\n        this._loopStart = options.loopStart;\n        this._loopEnd = options.loopEnd;\n        this._playbackRate = options.playbackRate;\n        this.fadeIn = options.fadeIn;\n        this.fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_4__.Source.getDefaults(), {\n            autostart: false,\n            fadeIn: 0,\n            fadeOut: 0,\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            playbackRate: 1,\n            reverse: false,\n        });\n    }\n    /**\n     * Load the audio file as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * Note: this does not need to be called if a url\n     * was passed in to the constructor. Only use this\n     * if you want to manually load a new url.\n     * @param url The url of the buffer to load. Filetype support depends on the browser.\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            yield this._buffer.load(url);\n            this._onload();\n            return this;\n        });\n    }\n    /**\n     * Internal callback when the buffer is loaded.\n     */\n    _onload(callback = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n        callback();\n        if (this.autostart) {\n            this.start();\n        }\n    }\n    /**\n     * Internal callback when the buffer is done playing.\n     */\n    _onSourceEnd(source) {\n        // invoke the onstop function\n        this.onstop(this);\n        // delete the source from the active sources\n        this._activeSources.delete(source);\n        if (this._activeSources.size === 0 && !this._synced &&\n            this._state.getValueAtTime(this.now()) === \"started\") {\n            // remove the 'implicitEnd' event and replace with an explicit end\n            this._state.cancel(this.now());\n            this._state.setStateAtTime(\"stopped\", this.now());\n        }\n    }\n    /**\n     * Play the buffer at the given startTime. Optionally add an offset\n     * and/or duration which will play the buffer from a position\n     * within the buffer for the given duration.\n     *\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     */\n    start(time, offset, duration) {\n        super.start(time, offset, duration);\n        return this;\n    }\n    /**\n     * Internal start method\n     */\n    _start(startTime, offset, duration) {\n        // if it's a loop the default offset is the loopStart point\n        if (this._loop) {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(offset, this._loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(offset, 0);\n        }\n        // compute the values in seconds\n        const computedOffset = this.toSeconds(offset);\n        // compute the duration which is either the passed in duration of the buffer.duration - offset\n        const origDuration = duration;\n        duration = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(duration, Math.max(this._buffer.duration - computedOffset, 0));\n        let computedDuration = this.toSeconds(duration);\n        // scale it by the playback rate\n        computedDuration = computedDuration / this._playbackRate;\n        // get the start time\n        startTime = this.toSeconds(startTime);\n        // make the source\n        const source = new _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__.ToneBufferSource({\n            url: this._buffer,\n            context: this.context,\n            fadeIn: this.fadeIn,\n            fadeOut: this.fadeOut,\n            loop: this._loop,\n            loopEnd: this._loopEnd,\n            loopStart: this._loopStart,\n            onended: this._onSourceEnd.bind(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        // set the looping properties\n        if (!this._loop && !this._synced) {\n            // cancel the previous stop\n            this._state.cancel(startTime + computedDuration);\n            // if it's not looping, set the state change at the end of the sample\n            this._state.setStateAtTime(\"stopped\", startTime + computedDuration, {\n                implicitEnd: true,\n            });\n        }\n        // add it to the array of active sources\n        this._activeSources.add(source);\n        // start it\n        if (this._loop && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isUndef)(origDuration)) {\n            source.start(startTime, computedOffset);\n        }\n        else {\n            // subtract the fade out time\n            source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));\n        }\n    }\n    /**\n     * Stop playback.\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(source => source.stop(computedTime));\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Seek to a specific time in the player's buffer. If the\n     * source is no longer playing at that time, it will stop.\n     * @param offset The time to seek to.\n     * @param when The time for the seek event to occur.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3\", () => {\n     * \tplayer.start();\n     * \t// seek to the offset in 1 second from now\n     * \tplayer.seek(0.4, \"+1\");\n     * }).toDestination();\n     */\n    seek(offset, when) {\n        const computedTime = this.toSeconds(when);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            const computedOffset = this.toSeconds(offset);\n            // if it's currently playing, stop it\n            this._stop(computedTime);\n            // restart it at the given time\n            this._start(computedTime, computedOffset);\n        }\n        return this;\n    }\n    /**\n     * Set the loop start and end. Will only loop if loop is set to true.\n     * @param loopStart The loop start time\n     * @param loopEnd The loop end time\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3\").toDestination();\n     * // loop between the given points\n     * player.setLoopPoints(0.2, 0.3);\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    setLoopPoints(loopStart, loopEnd) {\n        this.loopStart = loopStart;\n        this.loopEnd = loopEnd;\n        return this;\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(loopStart) {\n        this._loopStart = loopStart;\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(this.toSeconds(loopStart), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopStart = loopStart;\n        });\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = loopEnd;\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(this.toSeconds(loopEnd), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopEnd = loopEnd;\n        });\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/breakbeat.mp3\").toDestination();\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        // if no change, do nothing\n        if (this._loop === loop) {\n            return;\n        }\n        this._loop = loop;\n        // set the loop of all of the sources\n        this._activeSources.forEach(source => {\n            source.loop = loop;\n        });\n        if (loop) {\n            // remove the next stopEvent\n            const stopEvent = this._state.getNextState(\"stopped\", this.now());\n            if (stopEvent) {\n                this._state.cancel(stopEvent.time);\n            }\n        }\n    }\n    /**\n     * Normal speed is 1. The pitch will change with the playback rate.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3\").toDestination();\n     * // play at 1/4 speed\n     * player.playbackRate = 0.25;\n     * // play as soon as the buffer is loaded\n     * player.autostart = true;\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        const now = this.now();\n        // cancel the stop event since it's at a different time now\n        const stopEvent = this._state.getNextState(\"stopped\", now);\n        if (stopEvent && stopEvent.implicitEnd) {\n            this._state.cancel(stopEvent.time);\n            this._activeSources.forEach(source => source.cancelStop());\n        }\n        // set all the sources\n        this._activeSources.forEach(source => {\n            source.playbackRate.setValueAtTime(rate, now);\n        });\n    }\n    /**\n     * If the buffer should be reversed\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/chime_1.mp3\").toDestination();\n     * player.autostart = true;\n     * player.reverse = true;\n     */\n    get reverse() {\n        return this._buffer.reverse;\n    }\n    set reverse(rev) {\n        this._buffer.reverse = rev;\n    }\n    /**\n     * If the buffer is loaded\n     */\n    get loaded() {\n        return this._buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        // disconnect all of the players\n        this._activeSources.forEach(source => source.dispose());\n        this._activeSources.clear();\n        this._buffer.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_8__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__.timeRange)(0)\n], Player.prototype, \"fadeIn\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_8__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__.timeRange)(0)\n], Player.prototype, \"fadeOut\", void 0);\n//# sourceMappingURL=Player.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/buffer/Player.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/Players.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/Players.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Players\": () => (/* binding */ Players)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Player__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Player */ \"./node_modules/tone/build/esm/source/buffer/Player.js\");\n\n\n\n\n\n\n\n\n/**\n * Players combines multiple [[Player]] objects.\n * @category Source\n */\nclass Players extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\"));\n        this.name = \"Players\";\n        /**\n         * Players has no input.\n         */\n        this.input = undefined;\n        /**\n         * The container of all of the players\n         */\n        this._players = new Map();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\");\n        /**\n         * The output volume node\n         */\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, \"volume\");\n        this._buffers = new _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffers({\n            urls: options.urls,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror\n        });\n        // mute initially\n        this.mute = options.mute;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults(), {\n            baseUrl: \"\",\n            fadeIn: 0,\n            fadeOut: 0,\n            mute: false,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            urls: {},\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * The fadeIn time of the envelope applied to the source.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(fadeIn) {\n        this._fadeIn = fadeIn;\n        this._players.forEach(player => {\n            player.fadeIn = fadeIn;\n        });\n    }\n    /**\n     * The fadeOut time of the each of the sources.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(fadeOut) {\n        this._fadeOut = fadeOut;\n        this._players.forEach(player => {\n            player.fadeOut = fadeOut;\n        });\n    }\n    /**\n     * The state of the players object. Returns \"started\" if any of the players are playing.\n     */\n    get state() {\n        const playing = Array.from(this._players).some(([_, player]) => player.state === \"started\");\n        return playing ? \"started\" : \"stopped\";\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name);\n    }\n    /**\n     * Get a player by name.\n     * @param  name  The players name as defined in the constructor object or `add` method.\n     */\n    player(name) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(this.has(name), `No Player with the name ${name} exists on this object`);\n        if (!this._players.has(name)) {\n            const player = new _Player__WEBPACK_IMPORTED_MODULE_7__.Player({\n                context: this.context,\n                fadeIn: this._fadeIn,\n                fadeOut: this._fadeOut,\n                url: this._buffers.get(name),\n            }).connect(this.output);\n            this._players.set(name, player);\n        }\n        return this._players.get(name);\n    }\n    /**\n     * If all the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Add a player by name and url to the Players\n     * @param  name A unique name to give the player\n     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.\n     * @param callback  The callback to invoke when the url is loaded.\n     */\n    add(name, url, callback) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(!this._buffers.has(name), \"A buffer with that name already exists on this object\");\n        this._buffers.add(name, url, callback);\n        return this;\n    }\n    /**\n     * Stop all of the players at the given time\n     * @param time The time to stop all of the players.\n     */\n    stopAll(time) {\n        this._players.forEach(player => player.stop(time));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        this._players.forEach(player => player.dispose());\n        this._buffers.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Players.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/buffer/Players.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneBufferSource\": () => (/* binding */ ToneBufferSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _OneShotSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Wrapper around the native BufferSourceNode.\n * @category Source\n */\nclass ToneBufferSource extends _OneShotSource__WEBPACK_IMPORTED_MODULE_7__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"ToneBufferSource\";\n        /**\n         * The oscillator\n         */\n        this._source = this.context.createBufferSource();\n        this._internalChannels = [this._source];\n        /**\n         * indicators if the source has started/stopped\n         */\n        this._sourceStarted = false;\n        this._sourceStopped = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._source, this._gainNode);\n        this._source.onended = () => this._stopSource();\n        /**\n         * The playbackRate of the buffer\n         */\n        this.playbackRate = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._source.playbackRate,\n            units: \"positive\",\n            value: options.playbackRate,\n        });\n        // set some values initially\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(options.url, options.onload, options.onerror);\n        this._internalChannels.push(this._source);\n    }\n    static getDefaults() {\n        return Object.assign(_OneShotSource__WEBPACK_IMPORTED_MODULE_7__.OneShotSource.getDefaults(), {\n            url: new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(),\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            playbackRate: 1,\n        });\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(t) {\n        this._fadeIn = t;\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(t) {\n        this._fadeOut = t;\n    }\n    /**\n     * The curve applied to the fades, either \"linear\" or \"exponential\"\n     */\n    get curve() {\n        return this._curve;\n    }\n    set curve(t) {\n        this._curve = t;\n    }\n    /**\n     * Start the buffer\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     * @param  gain  The gain to play the buffer back at.\n     */\n    start(time, offset, duration, gain = 1) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(this.buffer.loaded, \"buffer is either not set or not loaded\");\n        const computedTime = this.toSeconds(time);\n        // apply the gain envelope\n        this._startGain(computedTime, gain);\n        // if it's a loop the default offset is the loopstart point\n        if (this.loop) {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, this.loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, 0);\n        }\n        // make sure the offset is not less than 0\n        let computedOffset = Math.max(this.toSeconds(offset), 0);\n        // start the buffer source\n        if (this.loop) {\n            // modify the offset if it's greater than the loop time\n            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n            const loopStart = this.toSeconds(this.loopStart);\n            const loopDuration = loopEnd - loopStart;\n            // move the offset back\n            if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.GTE)(computedOffset, loopEnd)) {\n                computedOffset = ((computedOffset - loopStart) % loopDuration) + loopStart;\n            }\n            // when the offset is very close to the duration, set it to 0\n            if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.EQ)(computedOffset, this.buffer.duration)) {\n                computedOffset = 0;\n            }\n        }\n        // this.buffer.loaded would have return false if the AudioBuffer was undefined\n        this._source.buffer = this.buffer.get();\n        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n        if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.LT)(computedOffset, this.buffer.duration)) {\n            this._sourceStarted = true;\n            this._source.start(computedTime, computedOffset);\n        }\n        // if a duration is given, schedule a stop\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(duration)) {\n            let computedDur = this.toSeconds(duration);\n            // make sure it's never negative\n            computedDur = Math.max(computedDur, 0);\n            this.stop(computedTime + computedDur);\n        }\n        return this;\n    }\n    _stopSource(time) {\n        if (!this._sourceStopped && this._sourceStarted) {\n            this._sourceStopped = true;\n            this._source.stop(this.toSeconds(time));\n            this._onended();\n        }\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._source.loopStart;\n    }\n    set loopStart(loopStart) {\n        this._source.loopStart = this.toSeconds(loopStart);\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._source.loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._source.loopEnd = this.toSeconds(loopEnd);\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     */\n    get loop() {\n        return this._source.loop;\n    }\n    set loop(loop) {\n        this._source.loop = loop;\n        if (this._sourceStarted) {\n            this.cancelStop();\n        }\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._source.onended = null;\n        this._source.disconnect();\n        this._buffer.dispose();\n        this.playbackRate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneBufferSource.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/source/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _oscillator_AMOscillator__WEBPACK_IMPORTED_MODULE_3__.AMOscillator),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_4__.FMOscillator),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _oscillator_FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _buffer_GrainPlayer__WEBPACK_IMPORTED_MODULE_14__.GrainPlayer),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _oscillator_LFO__WEBPACK_IMPORTED_MODULE_10__.LFO),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _Noise__WEBPACK_IMPORTED_MODULE_0__.Noise),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_8__.OmniOscillator),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_2__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _oscillator_PWMOscillator__WEBPACK_IMPORTED_MODULE_7__.PWMOscillator),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _buffer_Player__WEBPACK_IMPORTED_MODULE_12__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _buffer_Players__WEBPACK_IMPORTED_MODULE_13__.Players),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _oscillator_PulseOscillator__WEBPACK_IMPORTED_MODULE_5__.PulseOscillator),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_11__.ToneBufferSource),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_9__.ToneOscillatorNode),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _UserMedia__WEBPACK_IMPORTED_MODULE_1__.UserMedia)\n/* harmony export */ });\n/* harmony import */ var _Noise__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _UserMedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./UserMedia */ \"./node_modules/tone/build/esm/source/UserMedia.js\");\n/* harmony import */ var _oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./oscillator/Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _oscillator_AMOscillator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./oscillator/AMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/AMOscillator.js\");\n/* harmony import */ var _oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./oscillator/FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _oscillator_PulseOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./oscillator/PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n/* harmony import */ var _oscillator_FatOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./oscillator/FatOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FatOscillator.js\");\n/* harmony import */ var _oscillator_PWMOscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./oscillator/PWMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js\");\n/* harmony import */ var _oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./oscillator/ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n/* harmony import */ var _oscillator_LFO__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _buffer_Player__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./buffer/Player */ \"./node_modules/tone/build/esm/source/buffer/Player.js\");\n/* harmony import */ var _buffer_Players__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./buffer/Players */ \"./node_modules/tone/build/esm/source/buffer/Players.js\");\n/* harmony import */ var _buffer_GrainPlayer__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./buffer/GrainPlayer */ \"./node_modules/tone/build/esm/source/buffer/GrainPlayer.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/AMOscillator.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/AMOscillator.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* binding */ AMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * An amplitude modulated oscillator node. It is implemented with\n * two oscillators, one which modulators the other's amplitude\n * through a gain node.\n * ```\n *    +-------------+       +----------+\n *    | Carrier Osc +>------> GainNode |\n *    +-------------+       |          +--->Output\n *                      +---> gain     |\n * +---------------+    |   +----------+\n * | Modulator Osc +>---+\n * +---------------+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst amOsc = new Tone.AMOscillator(30, \"sine\", \"square\").toDestination().start();\n * }, 0.2, 1);\n * @category Source\n */\nclass AMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"AMOscillator\";\n        /**\n         * convert the -1,1 output to 0,1\n         */\n        this._modulationScale = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_3__.AudioToGain({ context: this.context });\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.frequency = this._carrier.frequency,\n            this.detune = this._carrier.detune;\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        // connections\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n    }\n    /**\n     * The type of the carrier oscillator\n     */\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/AMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/FMOscillator.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/FMOscillator.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FMOscillator\": () => (/* binding */ FMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * FMOscillator implements a frequency modulation synthesis\n * ```\n *                                              +-------------+\n * +---------------+        +-------------+     | Carrier Osc |\n * | Modulator Osc +>-------> GainNode    |     |             +--->Output\n * +---------------+        |             +>----> frequency   |\n *                       +--> gain        |     +-------------+\n *                       |  +-------------+\n * +-----------------+   |\n * | modulationIndex +>--+\n * +-----------------+\n * ```\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst fmOsc = new Tone.FMOscillator({\n * \t\tfrequency: 200,\n * \t\ttype: \"square\",\n * \t\tmodulationType: \"triangle\",\n * \t\tharmonicity: 0.2,\n * \t\tmodulationIndex: 3\n * \t}).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass FMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"FMOscillator\";\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: 0,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.detune = this._carrier.detune;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this.modulationIndex = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.modulationIndex,\n        });\n        // connections\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n        this.detune.connect(this._modulator.detune);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"modulationIndex\", \"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationIndex: 2,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n        return this;\n    }\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/FMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/FatOscillator.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/FatOscillator.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FatOscillator\": () => (/* binding */ FatOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * FatOscillator is an array of oscillators with detune spread between the oscillators\n * @example\n * const fatOsc = new Tone.FatOscillator(\"Ab3\", \"sawtooth\", 40).toDestination().start();\n * @category Source\n */\nclass FatOscillator extends _Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]));\n        this.name = \"FatOscillator\";\n        /**\n         * The array of oscillators\n         */\n        this._oscillators = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this._spread = options.spread;\n        this._type = options.type;\n        this._phase = options.phase;\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        // set the count initially\n        this.count = options.count;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator.getDefaults(), {\n            count: 3,\n            spread: 20,\n            type: \"sawtooth\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.start(time));\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.stop(time));\n    }\n    _restart(time) {\n        this._forEach(osc => osc.restart(time));\n    }\n    /**\n     * Iterate over all of the oscillators\n     */\n    _forEach(iterator) {\n        for (let i = 0; i < this._oscillators.length; i++) {\n            iterator(this._oscillators[i], i);\n        }\n    }\n    /**\n     * The type of the oscillator\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        this._forEach(osc => osc.type = type);\n    }\n    /**\n     * The detune spread between the oscillators. If \"count\" is\n     * set to 3 oscillators and the \"spread\" is set to 40,\n     * the three oscillators would be detuned like this: [-20, 0, 20]\n     * for a total detune spread of 40 cents.\n     * @example\n     * const fatOsc = new Tone.FatOscillator().toDestination().start();\n     * fatOsc.spread = 70;\n     */\n    get spread() {\n        return this._spread;\n    }\n    set spread(spread) {\n        this._spread = spread;\n        if (this._oscillators.length > 1) {\n            const start = -spread / 2;\n            const step = spread / (this._oscillators.length - 1);\n            this._forEach((osc, i) => osc.detune.value = start + step * i);\n        }\n    }\n    /**\n     * The number of detuned oscillators. Must be an integer greater than 1.\n     * @example\n     * const fatOsc = new Tone.FatOscillator(\"C#3\", \"sawtooth\").toDestination().start();\n     * // use 4 sawtooth oscillators\n     * fatOsc.count = 4;\n     */\n    get count() {\n        return this._oscillators.length;\n    }\n    set count(count) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(count, 1);\n        if (this._oscillators.length !== count) {\n            // dispose the previous oscillators\n            this._forEach(osc => osc.dispose());\n            this._oscillators = [];\n            for (let i = 0; i < count; i++) {\n                const osc = new _Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator({\n                    context: this.context,\n                    volume: -6 - count * 1.1,\n                    type: this._type,\n                    phase: this._phase + (i / count) * 360,\n                    partialCount: this._partialCount,\n                    onstop: i === 0 ? () => this.onstop(this) : _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n                });\n                if (this.type === \"custom\") {\n                    osc.partials = this._partials;\n                }\n                this.frequency.connect(osc.frequency);\n                this.detune.connect(osc.detune);\n                osc.detune.overridden = false;\n                osc.connect(this.output);\n                this._oscillators[i] = osc;\n            }\n            // set the spread\n            this.spread = this._spread;\n            if (this.state === \"started\") {\n                this._forEach(osc => osc.start());\n            }\n        }\n    }\n    get phase() {\n        return this._phase;\n    }\n    set phase(phase) {\n        this._phase = phase;\n        this._forEach((osc, i) => osc.phase = this._phase + (i / this.count) * 360);\n    }\n    get baseType() {\n        return this._oscillators[0].baseType;\n    }\n    set baseType(baseType) {\n        this._forEach(osc => osc.baseType = baseType);\n        this._type = this._oscillators[0].type;\n    }\n    get partials() {\n        return this._oscillators[0].partials;\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this._type = \"custom\";\n            this._forEach(osc => osc.partials = partials);\n        }\n    }\n    get partialCount() {\n        return this._oscillators[0].partialCount;\n    }\n    set partialCount(partialCount) {\n        this._partialCount = partialCount;\n        this._forEach(osc => osc.partialCount = partialCount);\n        this._type = this._oscillators[0].type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._forEach(osc => osc.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=FatOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/FatOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/LFO.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/LFO.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LFO\": () => (/* binding */ LFO)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Zero__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../signal/Zero */ \"./node_modules/tone/build/esm/signal/Zero.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * LFO stands for low frequency oscillator. LFO produces an output signal\n * which can be attached to an AudioParam or Tone.Signal\n * in order to modulate that parameter with an oscillator. The LFO can\n * also be synced to the transport to start/stop and change when the tempo changes.\n * @example\n * return Tone.Offline(() => {\n * \tconst lfo = new Tone.LFO(\"4n\", 400, 4000).start().toDestination();\n * }, 0.5, 1);\n * @category Source\n */\nclass LFO extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]));\n        this.name = \"LFO\";\n        /**\n         * The value that the LFO outputs when it's stopped\n         */\n        this._stoppedValue = 0;\n        /**\n         * A private placeholder for the units\n         */\n        this._units = \"number\";\n        /**\n         * If the input value is converted using the [[units]]\n         */\n        this.convert = true;\n        /**\n         * Private methods borrowed from Param\n         */\n        // @ts-ignore\n        this._fromType = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._fromType;\n        // @ts-ignore\n        this._toType = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._toType;\n        // @ts-ignore\n        this._is = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._is;\n        // @ts-ignore\n        this._clampValue = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._clampValue;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]);\n        this._oscillator = new _Oscillator__WEBPACK_IMPORTED_MODULE_9__.Oscillator(options);\n        this.frequency = this._oscillator.frequency;\n        this._amplitudeGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.amplitude,\n            units: \"normalRange\",\n        });\n        this.amplitude = this._amplitudeGain.gain;\n        this._stoppedSignal = new _signal_Signal__WEBPACK_IMPORTED_MODULE_7__.Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: 0,\n        });\n        this._zeros = new _signal_Zero__WEBPACK_IMPORTED_MODULE_8__.Zero({ context: this.context });\n        this._a2g = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_5__.AudioToGain({ context: this.context });\n        this._scaler = this.output = new _signal_Scale__WEBPACK_IMPORTED_MODULE_6__.Scale({\n            context: this.context,\n            max: options.max,\n            min: options.min,\n        });\n        this.units = options.units;\n        this.min = options.min;\n        this.max = options.max;\n        // connect it up\n        this._oscillator.chain(this._amplitudeGain, this._a2g, this._scaler);\n        this._zeros.connect(this._a2g);\n        this._stoppedSignal.connect(this._a2g);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"amplitude\", \"frequency\"]);\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_9__.Oscillator.getDefaults(), {\n            amplitude: 1,\n            frequency: \"4n\",\n            max: 1,\n            min: 0,\n            type: \"sine\",\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the LFO.\n     * @param time The time the LFO will start\n     */\n    start(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(0, time);\n        this._oscillator.start(time);\n        return this;\n    }\n    /**\n     * Stop the LFO.\n     * @param  time The time the LFO will stop\n     */\n    stop(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);\n        this._oscillator.stop(time);\n        return this;\n    }\n    /**\n     * Sync the start/stop/pause to the transport\n     * and the frequency to the bpm of the transport\n     * @example\n     * const lfo = new Tone.LFO(\"8n\");\n     * lfo.sync().start(0);\n     * // the rate of the LFO will always be an eighth note, even as the tempo changes\n     */\n    sync() {\n        this._oscillator.sync();\n        this._oscillator.syncFrequency();\n        return this;\n    }\n    /**\n     * unsync the LFO from transport control\n     */\n    unsync() {\n        this._oscillator.unsync();\n        this._oscillator.unsyncFrequency();\n        return this;\n    }\n    /**\n     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform\n     */\n    _setStoppedValue() {\n        this._stoppedValue = this._oscillator.getInitialValue();\n        this._stoppedSignal.value = this._stoppedValue;\n    }\n    /**\n     * The minimum output of the LFO.\n     */\n    get min() {\n        return this._toType(this._scaler.min);\n    }\n    set min(min) {\n        min = this._fromType(min);\n        this._scaler.min = min;\n    }\n    /**\n     * The maximum output of the LFO.\n     */\n    get max() {\n        return this._toType(this._scaler.max);\n    }\n    set max(max) {\n        max = this._fromType(max);\n        this._scaler.max = max;\n    }\n    /**\n     * The type of the oscillator: See [[Oscillator.type]]\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n        this._setStoppedValue();\n    }\n    /**\n     * The oscillator's partials array: See [[Oscillator.partials]]\n     */\n    get partials() {\n        return this._oscillator.partials;\n    }\n    set partials(partials) {\n        this._oscillator.partials = partials;\n        this._setStoppedValue();\n    }\n    /**\n     * The phase of the LFO.\n     */\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n        this._setStoppedValue();\n    }\n    /**\n     * The output units of the LFO.\n     */\n    get units() {\n        return this._units;\n    }\n    set units(val) {\n        const currentMin = this.min;\n        const currentMax = this.max;\n        // convert the min and the max\n        this._units = val;\n        this.min = currentMin;\n        this.max = currentMax;\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._oscillator.state;\n    }\n    /**\n     * @param node the destination to connect to\n     * @param outputNum the optional output number\n     * @param inputNum the input number\n     */\n    connect(node, outputNum, inputNum) {\n        if (node instanceof _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param || node instanceof _signal_Signal__WEBPACK_IMPORTED_MODULE_7__.Signal) {\n            this.convert = node.convert;\n            this.units = node.units;\n        }\n        (0,_signal_Signal__WEBPACK_IMPORTED_MODULE_7__.connectSignal)(this, node, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._oscillator.dispose();\n        this._stoppedSignal.dispose();\n        this._zeros.dispose();\n        this._scaler.dispose();\n        this._a2g.dispose();\n        this._amplitudeGain.dispose();\n        this.amplitude.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFO.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/LFO.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OmniOscillator\": () => (/* binding */ OmniOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _AMOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/AMOscillator.js\");\n/* harmony import */ var _FatOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./FatOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FatOscillator.js\");\n/* harmony import */ var _FMOscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n/* harmony import */ var _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./PWMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst OmniOscillatorSourceMap = {\n    am: _AMOscillator__WEBPACK_IMPORTED_MODULE_5__.AMOscillator,\n    fat: _FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator,\n    fm: _FMOscillator__WEBPACK_IMPORTED_MODULE_7__.FMOscillator,\n    oscillator: _Oscillator__WEBPACK_IMPORTED_MODULE_8__.Oscillator,\n    pulse: _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__.PulseOscillator,\n    pwm: _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__.PWMOscillator,\n};\n/**\n * OmniOscillator aggregates all of the oscillator types into one.\n * @example\n * return Tone.Offline(() => {\n * \tconst omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\").toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass OmniOscillator extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OmniOscillator\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"frequency\", \"detune\"]);\n        // set the options\n        this.set(options);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_8__.Oscillator.getDefaults(), _FMOscillator__WEBPACK_IMPORTED_MODULE_7__.FMOscillator.getDefaults(), _AMOscillator__WEBPACK_IMPORTED_MODULE_5__.AMOscillator.getDefaults(), _FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator.getDefaults(), _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__.PulseOscillator.getDefaults(), _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__.PWMOscillator.getDefaults());\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._oscillator.start(time);\n    }\n    /**\n     * start the oscillator\n     */\n    _stop(time) {\n        this._oscillator.stop(time);\n    }\n    _restart(time) {\n        this._oscillator.restart(time);\n        return this;\n    }\n    /**\n     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or\n     * prefix the basic types with \"fm\", \"am\", or \"fat\" to use the FMOscillator, AMOscillator or FatOscillator\n     * types. The oscillator could also be set to \"pwm\" or \"pulse\". All of the parameters of the\n     * oscillator's class are accessible when the oscillator is set to that type, but throws an error\n     * when it's not.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator().toDestination().start();\n     * omniOsc.type = \"pwm\";\n     * // modulationFrequency is parameter which is available\n     * // only when the type is \"pwm\".\n     * omniOsc.modulationFrequency.value = 0.5;\n     */\n    get type() {\n        let prefix = \"\";\n        if ([\"am\", \"fm\", \"fat\"].some(p => this._sourceType === p)) {\n            prefix = this._sourceType;\n        }\n        return prefix + this._oscillator.type;\n    }\n    set type(type) {\n        if (type.substr(0, 2) === \"fm\") {\n            this._createNewOscillator(\"fm\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 2) === \"am\") {\n            this._createNewOscillator(\"am\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 3) === \"fat\") {\n            this._createNewOscillator(\"fat\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(3);\n        }\n        else if (type === \"pwm\") {\n            this._createNewOscillator(\"pwm\");\n            this._oscillator = this._oscillator;\n        }\n        else if (type === \"pulse\") {\n            this._createNewOscillator(\"pulse\");\n        }\n        else {\n            this._createNewOscillator(\"oscillator\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type;\n        }\n    }\n    /**\n     * The value is an empty array when the type is not \"custom\".\n     * This is not available on \"pwm\" and \"pulse\" oscillator types.\n     * See [[Oscillator.partials]]\n     */\n    get partials() {\n        return this._oscillator.partials;\n    }\n    set partials(partials) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partials = partials;\n        }\n    }\n    get partialCount() {\n        return this._oscillator.partialCount;\n    }\n    set partialCount(partialCount) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partialCount = partialCount;\n        }\n    }\n    set(props) {\n        // make sure the type is set first\n        if (Reflect.has(props, \"type\") && props.type) {\n            this.type = props.type;\n        }\n        // then set the rest\n        super.set(props);\n        return this;\n    }\n    /**\n     * connect the oscillator to the frequency and detune signals\n     */\n    _createNewOscillator(oscType) {\n        if (oscType !== this._sourceType) {\n            this._sourceType = oscType;\n            const OscConstructor = OmniOscillatorSourceMap[oscType];\n            // short delay to avoid clicks on the change\n            const now = this.now();\n            if (this._oscillator) {\n                const oldOsc = this._oscillator;\n                oldOsc.stop(now);\n                // dispose the old one\n                this.context.setTimeout(() => oldOsc.dispose(), this.blockTime);\n            }\n            this._oscillator = new OscConstructor({\n                context: this.context,\n            });\n            this.frequency.connect(this._oscillator.frequency);\n            this.detune.connect(this._oscillator.detune);\n            this._oscillator.connect(this.output);\n            this._oscillator.onstop = () => this.onstop(this);\n            if (this.state === \"started\") {\n                this._oscillator.start(now);\n            }\n        }\n    }\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n    }\n    /**\n     * The source type of the oscillator.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare\");\n     * console.log(omniOsc.sourceType); // 'fm'\n     */\n    get sourceType() {\n        return this._sourceType;\n    }\n    set sourceType(sType) {\n        // the basetype defaults to sine\n        let baseType = \"sine\";\n        if (this._oscillator.type !== \"pwm\" && this._oscillator.type !== \"pulse\") {\n            baseType = this._oscillator.type;\n        }\n        // set the type\n        if (sType === \"fm\") {\n            this.type = \"fm\" + baseType;\n        }\n        else if (sType === \"am\") {\n            this.type = \"am\" + baseType;\n        }\n        else if (sType === \"fat\") {\n            this.type = \"fat\" + baseType;\n        }\n        else if (sType === \"oscillator\") {\n            this.type = baseType;\n        }\n        else if (sType === \"pulse\") {\n            this.type = \"pulse\";\n        }\n        else if (sType === \"pwm\") {\n            this.type = \"pwm\";\n        }\n    }\n    _getOscType(osc, sourceType) {\n        return osc instanceof OmniOscillatorSourceMap[sourceType];\n    }\n    /**\n     * The base type of the oscillator. See [[Oscillator.baseType]]\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare4\");\n     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);\n     */\n    get baseType() {\n        return this._oscillator.baseType;\n    }\n    set baseType(baseType) {\n        if (!this._getOscType(this._oscillator, \"pulse\") &&\n            !this._getOscType(this._oscillator, \"pwm\") &&\n            baseType !== \"pulse\" && baseType !== \"pwm\") {\n            this._oscillator.baseType = baseType;\n        }\n    }\n    /**\n     * The width of the oscillator when sourceType === \"pulse\".\n     * See [[PWMOscillator.width]]\n     */\n    get width() {\n        if (this._getOscType(this._oscillator, \"pulse\")) {\n            return this._oscillator.width;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The number of detuned oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get count() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.count;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set count(count) {\n        if (this._getOscType(this._oscillator, \"fat\") && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(count)) {\n            this._oscillator.count = count;\n        }\n    }\n    /**\n     * The detune spread between the oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get spread() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.spread;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set spread(spread) {\n        if (this._getOscType(this._oscillator, \"fat\") && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(spread)) {\n            this._oscillator.spread = spread;\n        }\n    }\n    /**\n     * The type of the modulator oscillator. Only if the oscillator is set to \"am\" or \"fm\" types.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get modulationType() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.modulationType;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set modulationType(mType) {\n        if ((this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(mType)) {\n            this._oscillator.modulationType = mType;\n        }\n    }\n    /**\n     * The modulation index when the sourceType === \"fm\"\n     * See [[FMOscillator]].\n     */\n    get modulationIndex() {\n        if (this._getOscType(this._oscillator, \"fm\")) {\n            return this._oscillator.modulationIndex;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get harmonicity() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.harmonicity;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The modulationFrequency Signal of the oscillator when sourceType === \"pwm\"\n     * see [[PWMOscillator]]\n     * @min 0.1\n     * @max 5\n     */\n    get modulationFrequency() {\n        if (this._getOscType(this._oscillator, \"pwm\")) {\n            return this._oscillator.modulationFrequency;\n        }\n        else {\n            return undefined;\n        }\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_12__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_9__.generateWaveform)(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.detune.dispose();\n        this.frequency.dispose();\n        this._oscillator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=OmniOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/Oscillator.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/Oscillator.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Oscillator\": () => (/* binding */ Oscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Oscillator supports a number of features including\n * phase rotation, multiple oscillator types (see Oscillator.type),\n * and Transport syncing (see Oscillator.syncFrequency).\n *\n * @example\n * // make and start a 440hz sine tone\n * const osc = new Tone.Oscillator(440, \"sine\").toDestination().start();\n * @category Source\n */\nclass Oscillator extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"Oscillator\";\n        /**\n         * the main oscillator\n         */\n        this._oscillator = null;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"frequency\");\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"detune\");\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        this._type = options.type;\n        if (options.partialCount && options.type !== \"custom\") {\n            this._type = this.baseType + options.partialCount.toString();\n        }\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_4__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            partialCount: 0,\n            partials: [],\n            phase: 0,\n            type: \"sine\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        const computedTime = this.toSeconds(time);\n        // new oscillator with previous values\n        const oscillator = new _ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_6__.ToneOscillatorNode({\n            context: this.context,\n            onended: () => this.onstop(this),\n        });\n        this._oscillator = oscillator;\n        if (this._wave) {\n            this._oscillator.setPeriodicWave(this._wave);\n        }\n        else {\n            this._oscillator.type = this._type;\n        }\n        // connect the control signal to the oscillator frequency & detune\n        this._oscillator.connect(this.output);\n        this.frequency.connect(this._oscillator.frequency);\n        this.detune.connect(this._oscillator.detune);\n        // start the oscillator\n        this._oscillator.start(computedTime);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._oscillator) {\n            this._oscillator.stop(computedTime);\n        }\n    }\n    /**\n     * Restart the oscillator. Does not stop the oscillator, but instead\n     * just cancels any scheduled 'stop' from being invoked.\n     */\n    _restart(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"restart\", computedTime);\n        if (this._oscillator) {\n            this._oscillator.cancelStop();\n        }\n        this._state.cancel(computedTime);\n        return this;\n    }\n    /**\n     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,\n     * will also affect the oscillators frequency.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * osc.frequency.value = 440;\n     * // the ratio between the bpm and the frequency will be maintained\n     * osc.syncFrequency();\n     * // double the tempo\n     * Tone.Transport.bpm.value *= 2;\n     * // the frequency of the oscillator is doubled to 880\n     */\n    syncFrequency() {\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the oscillator's frequency from the Transport.\n     * See Oscillator.syncFrequency\n     */\n    unsyncFrequency() {\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Get a cached periodic wave. Avoids having to recompute\n     * the oscillator values when they have already been computed\n     * with the same values.\n     */\n    _getCachedPeriodicWave() {\n        if (this._type === \"custom\") {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.phase === this._phase &&\n                    (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.deepEquals)(description.partials, this._partials);\n            });\n            return oscProps;\n        }\n        else {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.type === this._type &&\n                    description.phase === this._phase;\n            });\n            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;\n            return oscProps;\n        }\n    }\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        const isBasicType = [\"sine\", \"square\", \"sawtooth\", \"triangle\"].indexOf(type) !== -1;\n        if (this._phase === 0 && isBasicType) {\n            this._wave = undefined;\n            this._partialCount = 0;\n            // just go with the basic approach\n            if (this._oscillator !== null) {\n                // already tested that it's a basic type\n                this._oscillator.type = type;\n            }\n        }\n        else {\n            // first check if the value is cached\n            const cache = this._getCachedPeriodicWave();\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isDefined)(cache)) {\n                const { partials, wave } = cache;\n                this._wave = wave;\n                this._partials = partials;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n            }\n            else {\n                const [real, imag] = this._getRealImaginary(type, this._phase);\n                const periodicWave = this.context.createPeriodicWave(real, imag);\n                this._wave = periodicWave;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n                // set the cache\n                Oscillator._periodicWaveCache.push({\n                    imag,\n                    partialCount: this._partialCount,\n                    partials: this._partials,\n                    phase: this._phase,\n                    real,\n                    type: this._type,\n                    wave: this._wave,\n                });\n                if (Oscillator._periodicWaveCache.length > 100) {\n                    Oscillator._periodicWaveCache.shift();\n                }\n            }\n        }\n    }\n    get baseType() {\n        return this._type.replace(this.partialCount.toString(), \"\");\n    }\n    set baseType(baseType) {\n        if (this.partialCount && this._type !== \"custom\" && baseType !== \"custom\") {\n            this.type = baseType + this.partialCount;\n        }\n        else {\n            this.type = baseType;\n        }\n    }\n    get partialCount() {\n        return this._partialCount;\n    }\n    set partialCount(p) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(p, 0);\n        let type = this._type;\n        const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(this._type);\n        if (partial) {\n            type = partial[1];\n        }\n        if (this._type !== \"custom\") {\n            if (p === 0) {\n                this.type = type;\n            }\n            else {\n                this.type = type + p.toString();\n            }\n        }\n        else {\n            // extend or shorten the partials array\n            const fullPartials = new Float32Array(p);\n            // copy over the partials array\n            this._partials.forEach((v, i) => fullPartials[i] = v);\n            this._partials = Array.from(fullPartials);\n            this.type = this._type;\n        }\n    }\n    /**\n     * Returns the real and imaginary components based\n     * on the oscillator type.\n     * @returns [real: Float32Array, imaginary: Float32Array]\n     */\n    _getRealImaginary(type, phase) {\n        const fftSize = 4096;\n        let periodicWaveSize = fftSize / 2;\n        const real = new Float32Array(periodicWaveSize);\n        const imag = new Float32Array(periodicWaveSize);\n        let partialCount = 1;\n        if (type === \"custom\") {\n            partialCount = this._partials.length + 1;\n            this._partialCount = this._partials.length;\n            periodicWaveSize = partialCount;\n            // if the partial count is 0, don't bother doing any computation\n            if (this._partials.length === 0) {\n                return [real, imag];\n            }\n        }\n        else {\n            const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(type);\n            if (partial) {\n                partialCount = parseInt(partial[2], 10) + 1;\n                this._partialCount = parseInt(partial[2], 10);\n                type = partial[1];\n                partialCount = Math.max(partialCount, 2);\n                periodicWaveSize = partialCount;\n            }\n            else {\n                this._partialCount = 0;\n            }\n            this._partials = [];\n        }\n        for (let n = 1; n < periodicWaveSize; ++n) {\n            const piFactor = 2 / (n * Math.PI);\n            let b;\n            switch (type) {\n                case \"sine\":\n                    b = (n <= partialCount) ? 1 : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"square\":\n                    b = (n & 1) ? 2 * piFactor : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"sawtooth\":\n                    b = piFactor * ((n & 1) ? 1 : -1);\n                    this._partials[n - 1] = b;\n                    break;\n                case \"triangle\":\n                    if (n & 1) {\n                        b = 2 * (piFactor * piFactor) * ((((n - 1) >> 1) & 1) ? -1 : 1);\n                    }\n                    else {\n                        b = 0;\n                    }\n                    this._partials[n - 1] = b;\n                    break;\n                case \"custom\":\n                    b = this._partials[n - 1];\n                    break;\n                default:\n                    throw new TypeError(\"Oscillator: invalid type: \" + type);\n            }\n            if (b !== 0) {\n                real[n] = -b * Math.sin(phase * n);\n                imag[n] = b * Math.cos(phase * n);\n            }\n            else {\n                real[n] = 0;\n                imag[n] = 0;\n            }\n        }\n        return [real, imag];\n    }\n    /**\n     * Compute the inverse FFT for a given phase.\n     */\n    _inverseFFT(real, imag, phase) {\n        let sum = 0;\n        const len = real.length;\n        for (let i = 0; i < len; i++) {\n            sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);\n        }\n        return sum;\n    }\n    /**\n     * Returns the initial value of the oscillator when stopped.\n     * E.g. a \"sine\" oscillator with phase = 90 would return an initial value of -1.\n     */\n    getInitialValue() {\n        const [real, imag] = this._getRealImaginary(this._type, 0);\n        let maxValue = 0;\n        const twoPi = Math.PI * 2;\n        const testPositions = 32;\n        // check for peaks in 16 places\n        for (let i = 0; i < testPositions; i++) {\n            maxValue = Math.max(this._inverseFFT(real, imag, (i / testPositions) * twoPi), maxValue);\n        }\n        return (0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.clamp)(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);\n    }\n    get partials() {\n        return this._partials.slice(0, this.partialCount);\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this.type = \"custom\";\n        }\n    }\n    get phase() {\n        return this._phase * (180 / Math.PI);\n    }\n    set phase(phase) {\n        this._phase = phase * Math.PI / 180;\n        // reset the type\n        this.type = this._type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        if (this._oscillator !== null) {\n            this._oscillator.dispose();\n        }\n        this._wave = undefined;\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n/**\n * Cache the periodic waves to avoid having to redo computations\n */\nOscillator._periodicWaveCache = [];\n//# sourceMappingURL=Oscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/Oscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js":
/*!******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"generateWaveform\": () => (/* binding */ generateWaveform)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n\n\n/**\n * Render a segment of the oscillator to an offline context and return the results as an array\n */\nfunction generateWaveform(instance, length) {\n    return (0,tslib__WEBPACK_IMPORTED_MODULE_1__.__awaiter)(this, void 0, void 0, function* () {\n        const duration = length / instance.context.sampleRate;\n        const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_0__.OfflineContext(1, duration, instance.context.sampleRate);\n        const clone = new instance.constructor(Object.assign(instance.get(), {\n            // should do 2 iterations\n            frequency: 2 / duration,\n            // zero out the detune\n            detune: 0,\n            context\n        })).toDestination();\n        clone.start(0);\n        const buffer = yield context.render();\n        return buffer.getChannelData(0);\n    });\n}\n//# sourceMappingURL=OscillatorInterface.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PWMOscillator\": () => (/* binding */ PWMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _PulseOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n\n\n\n\n\n\n\n\n/**\n * PWMOscillator modulates the width of a Tone.PulseOscillator\n * at the modulationFrequency. This has the effect of continuously\n * changing the timbre of the oscillator by altering the harmonics\n * generated.\n * @example\n * return Tone.Offline(() => {\n * \tconst pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass PWMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]));\n        this.name = \"PWMOscillator\";\n        this.sourceType = \"pwm\";\n        /**\n         * Scale the oscillator so it doesn't go silent\n         * at the extreme values.\n         */\n        this._scale = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]);\n        this._pulse = new _PulseOscillator__WEBPACK_IMPORTED_MODULE_6__.PulseOscillator({\n            context: this.context,\n            frequency: options.modulationFrequency,\n        });\n        // change the pulse oscillator type\n        this._pulse.carrierType = \"sine\";\n        this.modulationFrequency = this._pulse.frequency;\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n        });\n        this.frequency = this._modulator.frequency;\n        this.detune = this._modulator.detune;\n        // connections\n        this._modulator.chain(this._scale, this._pulse.width);\n        this._pulse.connect(this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"modulationFrequency\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_3__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            modulationFrequency: 0.4,\n            phase: 0,\n            type: \"pwm\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._modulator.start(time);\n        this._pulse.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._modulator.stop(time);\n        this._pulse.stop(time);\n    }\n    /**\n     * restart the oscillator\n     */\n    _restart(time) {\n        this._modulator.restart(time);\n        this._pulse.restart(time);\n    }\n    /**\n     * The type of the oscillator. Always returns \"pwm\".\n     */\n    get type() {\n        return \"pwm\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pwm\".\n     */\n    get baseType() {\n        return \"pwm\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._modulator.phase;\n    }\n    set phase(phase) {\n        this._modulator.phase = phase;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._pulse.dispose();\n        this._scale.dispose();\n        this._modulator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PWMOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js":
/*!**************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PulseOscillator\": () => (/* binding */ PulseOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * PulseOscillator is an oscillator with control over pulse width,\n * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is\n * a square wave.\n * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).\n * ```\n *    width = -0.25        width = 0.0          width = 0.25\n *\n *   +-----+            +-------+       +    +-------+     +-+\n *   |     |            |       |       |            |     |\n *   |     |            |       |       |            |     |\n * +-+     +-------+    +       +-------+            +-----+\n *\n *\n *    width = -0.5                              width = 0.5\n *\n *     +---+                                 +-------+   +---+\n *     |   |                                         |   |\n *     |   |                                         |   |\n * +---+   +-------+                                 +---+\n *\n *\n *    width = -0.75                             width = 0.75\n *\n *       +-+                                 +-------+ +-----+\n *       | |                                         | |\n *       | |                                         | |\n * +-----+ +-------+                                 +-+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass PulseOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]));\n        this.name = \"PulseOscillator\";\n        /**\n         * gate the width amount\n         */\n        this._widthGate = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * Threshold the signal to turn it into a square\n         */\n        this._thresh = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_4__.WaveShaper({\n            context: this.context,\n            mapping: val => val <= 0 ? -1 : 1,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]);\n        this.width = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: options.width,\n        });\n        this._triangle = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: \"triangle\",\n        });\n        this.frequency = this._triangle.frequency;\n        this.detune = this._triangle.detune;\n        // connections\n        this._triangle.chain(this._thresh, this.output);\n        this.width.chain(this._widthGate, this._thresh);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"width\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_5__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            phase: 0,\n            type: \"pulse\",\n            width: 0.2,\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._triangle.start(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._triangle.stop(time);\n        // the width is still connected to the output.\n        // that needs to be stopped also\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(0, time);\n    }\n    _restart(time) {\n        this._triangle.restart(time);\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._triangle.phase;\n    }\n    set phase(phase) {\n        this._triangle.phase = phase;\n    }\n    /**\n     * The type of the oscillator. Always returns \"pulse\".\n     */\n    get type() {\n        return \"pulse\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pulse\".\n     */\n    get baseType() {\n        return \"pulse\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * *Internal use* The carrier oscillator type is fed through the\n     * waveshaper node to create the pulse. Using different carrier oscillators\n     * changes oscillator's behavior.\n     */\n    set carrierType(type) {\n        this._triangle.type = type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up method.\n     */\n    dispose() {\n        super.dispose();\n        this._triangle.dispose();\n        this.width.dispose();\n        this._widthGate.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PulseOscillator.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneOscillatorNode\": () => (/* binding */ ToneOscillatorNode)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _OneShotSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Wrapper around the native fire-and-forget OscillatorNode.\n * Adds the ability to reschedule the stop method.\n * ***[[Oscillator]] is better for most use-cases***\n * @category Source\n */\nclass ToneOscillatorNode extends _OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"ToneOscillatorNode\";\n        /**\n         * The oscillator\n         */\n        this._oscillator = this.context.createOscillator();\n        this._internalChannels = [this._oscillator];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._oscillator, this._gainNode);\n        this.type = options.type;\n        this.frequency = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._oscillator.frequency,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._oscillator.detune,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            type: \"sine\",\n        });\n    }\n    /**\n     * Start the oscillator node at the given time\n     * @param  time When to start the oscillator\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._oscillator.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._oscillator.stop(time);\n    }\n    /**\n     * Sets an arbitrary custom periodic waveform given a PeriodicWave.\n     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave\n     */\n    setPeriodicWave(periodicWave) {\n        this._oscillator.setPeriodicWave(periodicWave);\n        return this;\n    }\n    /**\n     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._oscillator.disconnect();\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneOscillatorNode.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/version.js":
/*!************************************************!*\
  !*** ./node_modules/tone/build/esm/version.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"version\": () => (/* binding */ version)\n/* harmony export */ });\nconst version = \"14.7.77\";\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://react-demo/./node_modules/tone/build/esm/version.js?");

/***/ }),

/***/ "./node_modules/tslib/tslib.es6.js":
/*!*****************************************!*\
  !*** ./node_modules/tslib/tslib.es6.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"__assign\": () => (/* binding */ __assign),\n/* harmony export */   \"__asyncDelegator\": () => (/* binding */ __asyncDelegator),\n/* harmony export */   \"__asyncGenerator\": () => (/* binding */ __asyncGenerator),\n/* harmony export */   \"__asyncValues\": () => (/* binding */ __asyncValues),\n/* harmony export */   \"__await\": () => (/* binding */ __await),\n/* harmony export */   \"__awaiter\": () => (/* binding */ __awaiter),\n/* harmony export */   \"__classPrivateFieldGet\": () => (/* binding */ __classPrivateFieldGet),\n/* harmony export */   \"__classPrivateFieldSet\": () => (/* binding */ __classPrivateFieldSet),\n/* harmony export */   \"__createBinding\": () => (/* binding */ __createBinding),\n/* harmony export */   \"__decorate\": () => (/* binding */ __decorate),\n/* harmony export */   \"__exportStar\": () => (/* binding */ __exportStar),\n/* harmony export */   \"__extends\": () => (/* binding */ __extends),\n/* harmony export */   \"__generator\": () => (/* binding */ __generator),\n/* harmony export */   \"__importDefault\": () => (/* binding */ __importDefault),\n/* harmony export */   \"__importStar\": () => (/* binding */ __importStar),\n/* harmony export */   \"__makeTemplateObject\": () => (/* binding */ __makeTemplateObject),\n/* harmony export */   \"__metadata\": () => (/* binding */ __metadata),\n/* harmony export */   \"__param\": () => (/* binding */ __param),\n/* harmony export */   \"__read\": () => (/* binding */ __read),\n/* harmony export */   \"__rest\": () => (/* binding */ __rest),\n/* harmony export */   \"__spread\": () => (/* binding */ __spread),\n/* harmony export */   \"__spreadArray\": () => (/* binding */ __spreadArray),\n/* harmony export */   \"__spreadArrays\": () => (/* binding */ __spreadArrays),\n/* harmony export */   \"__values\": () => (/* binding */ __values)\n/* harmony export */ });\n/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nfunction __extends(d, b) {\r\n    if (typeof b !== \"function\" && b !== null)\r\n        throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nvar __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nfunction __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                t[p[i]] = s[p[i]];\r\n        }\r\n    return t;\r\n}\r\n\r\nfunction __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nfunction __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nfunction __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nfunction __awaiter(thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nfunction __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nvar __createBinding = Object.create ? (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\r\n}) : (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    o[k2] = m[k];\r\n});\r\n\r\nfunction __exportStar(m, o) {\r\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\r\n}\r\n\r\nfunction __values(o) {\r\n    var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\r\n    if (m) return m.call(o);\r\n    if (o && typeof o.length === \"number\") return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n    throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\r\n}\r\n\r\nfunction __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nfunction __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nfunction __spreadArrays() {\r\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n            r[k] = a[j];\r\n    return r;\r\n}\r\n\r\nfunction __spreadArray(to, from, pack) {\r\n    if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\r\n        if (ar || !(i in from)) {\r\n            if (!ar) ar = Array.prototype.slice.call(from, 0, i);\r\n            ar[i] = from[i];\r\n        }\r\n    }\r\n    return to.concat(ar || Array.prototype.slice.call(from));\r\n}\r\n\r\nfunction __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nfunction __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nfunction __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nfunction __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nfunction __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nvar __setModuleDefault = Object.create ? (function(o, v) {\r\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\r\n}) : function(o, v) {\r\n    o[\"default\"] = v;\r\n};\r\n\r\nfunction __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\r\n    __setModuleDefault(result, mod);\r\n    return result;\r\n}\r\n\r\nfunction __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n\r\nfunction __classPrivateFieldGet(receiver, state, kind, f) {\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\r\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\r\n}\r\n\r\nfunction __classPrivateFieldSet(receiver, state, value, kind, f) {\r\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\r\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\r\n}\r\n\n\n//# sourceURL=webpack://react-demo/./node_modules/tslib/tslib.es6.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/publicPath */
/******/ 	(() => {
/******/ 		var scriptUrl;
/******/ 		if (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + "";
/******/ 		var document = __webpack_require__.g.document;
/******/ 		if (!scriptUrl && document) {
/******/ 			if (document.currentScript)
/******/ 				scriptUrl = document.currentScript.src
/******/ 			if (!scriptUrl) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				if(scripts.length) scriptUrl = scripts[scripts.length - 1].src
/******/ 			}
/******/ 		}
/******/ 		// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 		// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 		if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 		scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 		__webpack_require__.p = scriptUrl;
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;